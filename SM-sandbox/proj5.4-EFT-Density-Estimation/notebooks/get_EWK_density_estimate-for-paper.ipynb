{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing standard library\n",
      "Importing python data libraries\n",
      "Importing third party libraries\n",
      "Importing custom backends\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#  Required imports\n",
    "\n",
    "print(\"Importing standard library\")\n",
    "import os, sys, time\n",
    "\n",
    "print(\"Importing python data libraries\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Importing third party libraries\")\n",
    "import dill as pickle\n",
    "\n",
    "print(\"Importing custom backends\")\n",
    "sys.path.append(\"/Users/Ste/PostDoc/git-with-DP/SM-sandbox/proj5.4-EFT-Density-Estimation\")\n",
    "from backends.data_preparation import DataTable\n",
    "from backends.density_model    import DensityModel, get_sum_gauss_density\n",
    "from backends.plot             import plot_data, plot_ratio, plot_pull, get_ratio_1D\n",
    "from backends.stats            import whiten_axes, unwhiten_axes\n",
    "from backends.utils            import make_sure_dir_exists_for_filename\n",
    "\n",
    "import backends.plot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Inputs config\n",
    "\n",
    "cWtil_vals      = [0, -0.4, -0.2, 0.2, 0.4]\n",
    "cWtil_eval_vals = [0, -0.4, -0.3, -0.2, -0.1, 0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "input_fnames = {}\n",
    "input_fnames [0   ] = \"../Data/SM_EWK_1M_rivet_output.pickle\"\n",
    "\n",
    "#  \"../Data/SM_EWK_rivet_output.pickle\"\n",
    "#  \"../Data/SM_EWK_500k_rivet_output.pickle\"\n",
    "#  \"../Data/SM_EWK_1M_rivet_output.pickle\"\n",
    "\n",
    "input_fnames [-0.4] = \"../Data/cWtil_m0p4_full_200k_rivet_output.pickle\"\n",
    "input_fnames [-0.3] = \"../Data/cWtil_m0p3_full_200k_rivet_output.pickle\"\n",
    "input_fnames [-0.2] = \"../Data/cWtil_m0p2_full_200k_rivet_output.pickle\"\n",
    "input_fnames [-0.1] = \"../Data/cWtil_m0p1_full_200k_rivet_output.pickle\"\n",
    "input_fnames [ 0.1] = \"../Data/cWtil_0p1_full_200k_rivet_output.pickle\"\n",
    "input_fnames [ 0.2] = \"../Data/cWtil_0p2_full_200k_rivet_output.pickle\"\n",
    "input_fnames [ 0.3] = \"../Data/cWtil_0p3_full_200k_rivet_output.pickle\"\n",
    "input_fnames [ 0.4] = \"../Data/cWtil_0p4_full_200k_rivet_output.pickle\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Model config\n",
    "\n",
    "output_size_per_stage     = 10\n",
    "max_epochs                = 1000\n",
    "batch_size                = 200\n",
    "epoch_increase_per_level  = 20\n",
    "early_stopping_patience   = 10\n",
    "early_stopping_min_delta  = 0\n",
    "validation_split          = 0.5\n",
    "\n",
    "white_linear_fraction_data  = 0.\n",
    "white_linear_fraction_gauss = 0.\n",
    "whitening_num_points        = 200\n",
    "whitening_func_form         = \"step\"\n",
    "whitening_alpha, whitening_beta, whitening_gamma = 3, 2, 2\n",
    "\n",
    "load_whitening_funcs = None                          #  None  or  \".whitening_func_paper_step.pickle\"\n",
    "save_whitening_funcs = \".whitening_funcs.pickle\"     #  None  or  \".whitening_func_paper_step.pickle\"\n",
    "\n",
    "load_model_dir = \".EWK_density_model_paper_step\"     #  None  or  \".EWK_density_model_paper_step\"\n",
    "save_model_dir = \".EWK_density_model_paper_step\"     #  None  or  \".EWK_density_model_paper_step\"\n",
    "\n",
    "learning_rate = 0.001     # 0.01 for SGD or 0.001 otherwise\n",
    "optimiser     = \"adam\"     # SGD, Adam or AdaDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Data config\n",
    "\n",
    "observable_limits = {}\n",
    "observable_limits [\"m_ll\"      ] = [75    , 105  ]\n",
    "observable_limits [\"pT_ll\"     ] = [0     , 900  ]\n",
    "observable_limits [\"theta_ll\"  ] = [0     , np.pi]\n",
    "observable_limits [\"rap_ll\"    ] = [0     , 2.2  ]\n",
    "observable_limits [\"m_jj\"      ] = [150   , 5000 ]\n",
    "observable_limits [\"pT_jj\"     ] = [0     , 900  ]\n",
    "observable_limits [\"theta_jj\"  ] = [0     , np.pi]\n",
    "observable_limits [\"rap_jj\"    ] = [0     , 4.4  ]\n",
    "observable_limits [\"pT_j1\"     ] = [40    , 1200 ]\n",
    "observable_limits [\"pT_j2\"     ] = [35    , 1200 ]\n",
    "observable_limits [\"Dy_j_j\"    ] = [0     , 8.8  ]\n",
    "observable_limits [\"Dphi_j_j\"  ] = [-np.pi, np.pi]\n",
    "observable_limits [\"N_jets\"    ] = [2     , 5    ]\n",
    "observable_limits [\"N_gap_jets\"] = [0     , 2    ]\n",
    "\n",
    "remove_observables = []   # [\"N_jets\", \"pT_ll\", \"rap_ll\", \"theta_ll\", \"pT_jj\", \"theta_jj\", \"rap_jj\", \"pT_j1\", \"pT_j2\", \"N_gap_jets\"]\n",
    "\n",
    "int_observables = [\"N_jets\", \"N_gap_jets\"]\n",
    "\n",
    "observables_order = [\"Dphi_j_j\", \"Dy_j_j\", \"m_jj\", \"m_ll\", \"N_gap_jets\", \"N_jets\", \"pT_j1\", \"pT_j2\", \"pT_jj\", \"pT_ll\", \"rap_jj\", \"rap_ll\", \"theta_jj\", \"theta_ll\"]\n",
    "\n",
    "plot.observable_limits = observable_limits\n",
    "plot.int_observables   = int_observables\n",
    "\n",
    "num_observables = len(observables_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data table for cWtil=0\n",
      " -- events from file ../Data/SM_EWK_1M_rivet_output.pickle\n",
      " -- Table created with 1000000 events\n",
      " -- filtering observable m_ll between 75 and 105\n",
      " -- 660799 events survived\n",
      " -- filtering observable pT_ll between 0 and 900\n",
      " -- 660766 events survived\n",
      " -- filtering observable theta_ll between 0 and 3.141592653589793\n",
      " -- 660766 events survived\n",
      " -- filtering observable rap_ll between 0 and 2.2\n",
      " -- 652255 events survived\n",
      " -- filtering observable m_jj between 150 and 5000\n",
      " -- 643177 events survived\n",
      " -- filtering observable pT_jj between 0 and 900\n",
      " -- 643177 events survived\n",
      " -- filtering observable theta_jj between 0 and 3.141592653589793\n",
      " -- 643177 events survived\n",
      " -- filtering observable rap_jj between 0 and 4.4\n",
      " -- 643177 events survived\n",
      " -- filtering observable pT_j1 between 40 and 1200\n",
      " -- 643054 events survived\n",
      " -- filtering observable pT_j2 between 35 and 1200\n",
      " -- 642591 events survived\n",
      " -- filtering observable Dy_j_j between 0 and 8.8\n",
      " -- 642591 events survived\n",
      " -- filtering observable Dphi_j_j between -3.141592653589793 and 3.141592653589793\n",
      " -- 642591 events survived\n",
      " -- filtering observable N_jets between 2 and 5\n",
      " -- 642591 events survived\n",
      " -- filtering observable N_gap_jets between 0 and 2\n",
      " -- 642591 events survived\n",
      " -- ordering observables\n",
      "* Registered the following keys:\n",
      "    +---------------------------------------+\n",
      "    | Column | Name       | Type            |\n",
      "    +---------------------------------------+\n",
      "    | 0      | Dphi_j_j   | <class 'float'> |\n",
      "    | 1      | Dy_j_j     | <class 'float'> |\n",
      "    | 2      | m_jj       | <class 'float'> |\n",
      "    | 3      | m_ll       | <class 'float'> |\n",
      "    | 4      | N_gap_jets | <class 'int'>   |\n",
      "    | 5      | N_jets     | <class 'int'>   |\n",
      "    | 6      | pT_j1      | <class 'float'> |\n",
      "    | 7      | pT_j2      | <class 'float'> |\n",
      "    | 8      | pT_jj      | <class 'float'> |\n",
      "    | 9      | pT_ll      | <class 'float'> |\n",
      "    | 10     | rap_jj     | <class 'float'> |\n",
      "    | 11     | rap_ll     | <class 'float'> |\n",
      "    | 12     | theta_jj   | <class 'float'> |\n",
      "    | 13     | theta_ll   | <class 'float'> |\n",
      "    +---------------------------------------+\n",
      "\n",
      "* Registered the following weights:\n",
      "    +-------------------------+\n",
      "    | Name   | Sum of weights |\n",
      "    +-------------------------+\n",
      "    | weight | 5.7223         |\n",
      "    +-------------------------+\n",
      "\n",
      "* Number of events       : 642591\n",
      "* Cross section per event: 0.0506539\n",
      "* Total cross section    : 0.28985799682702523 +/- 0.00036199675556542664 pb\n",
      "Creating data table for cWtil=-0.4\n",
      " -- events from file ../Data/cWtil_m0p4_full_200k_rivet_output.pickle\n",
      " -- Table created with 200000 events\n",
      " -- filtering observable m_ll between 75 and 105\n",
      " -- 132558 events survived\n",
      " -- filtering observable pT_ll between 0 and 900\n",
      " -- 132504 events survived\n",
      " -- filtering observable theta_ll between 0 and 3.141592653589793\n",
      " -- 132504 events survived\n",
      " -- filtering observable rap_ll between 0 and 2.2\n",
      " -- 130801 events survived\n",
      " -- filtering observable m_jj between 150 and 5000\n",
      " -- 129045 events survived\n",
      " -- filtering observable pT_jj between 0 and 900\n",
      " -- 129045 events survived\n",
      " -- filtering observable theta_jj between 0 and 3.141592653589793\n",
      " -- 129045 events survived\n",
      " -- filtering observable rap_jj between 0 and 4.4\n",
      " -- 129045 events survived\n",
      " -- filtering observable pT_j1 between 40 and 1200\n",
      " -- 129020 events survived\n",
      " -- filtering observable pT_j2 between 35 and 1200\n",
      " -- 128931 events survived\n",
      " -- filtering observable Dy_j_j between 0 and 8.8\n",
      " -- 128931 events survived\n",
      " -- filtering observable Dphi_j_j between -3.141592653589793 and 3.141592653589793\n",
      " -- 128931 events survived\n",
      " -- filtering observable N_jets between 2 and 5\n",
      " -- 128931 events survived\n",
      " -- filtering observable N_gap_jets between 0 and 2\n",
      " -- 128931 events survived\n",
      " -- ordering observables\n",
      "* Registered the following keys:\n",
      "    +---------------------------------------+\n",
      "    | Column | Name       | Type            |\n",
      "    +---------------------------------------+\n",
      "    | 0      | Dphi_j_j   | <class 'float'> |\n",
      "    | 1      | Dy_j_j     | <class 'float'> |\n",
      "    | 2      | m_jj       | <class 'float'> |\n",
      "    | 3      | m_ll       | <class 'float'> |\n",
      "    | 4      | N_gap_jets | <class 'int'>   |\n",
      "    | 5      | N_jets     | <class 'int'>   |\n",
      "    | 6      | pT_j1      | <class 'float'> |\n",
      "    | 7      | pT_j2      | <class 'float'> |\n",
      "    | 8      | pT_jj      | <class 'float'> |\n",
      "    | 9      | pT_ll      | <class 'float'> |\n",
      "    | 10     | rap_jj     | <class 'float'> |\n",
      "    | 11     | rap_ll     | <class 'float'> |\n",
      "    | 12     | theta_jj   | <class 'float'> |\n",
      "    | 13     | theta_ll   | <class 'float'> |\n",
      "    +---------------------------------------+\n",
      "\n",
      "* Registered the following weights:\n",
      "    +-------------------------+\n",
      "    | Name   | Sum of weights |\n",
      "    +-------------------------+\n",
      "    | weight | 1.1596         |\n",
      "    +-------------------------+\n",
      "\n",
      "* Number of events       : 128931\n",
      "* Cross section per event: 0.253858\n",
      "* Total cross section    : 0.29436735760231797 +/- 0.0008207435991470465 pb\n",
      "Creating data table for cWtil=-0.3\n",
      " -- events from file ../Data/cWtil_m0p3_full_200k_rivet_output.pickle\n",
      " -- Table created with 200000 events\n",
      " -- filtering observable m_ll between 75 and 105\n",
      " -- 132119 events survived\n",
      " -- filtering observable pT_ll between 0 and 900\n",
      " -- 132092 events survived\n",
      " -- filtering observable theta_ll between 0 and 3.141592653589793\n",
      " -- 132092 events survived\n",
      " -- filtering observable rap_ll between 0 and 2.2\n",
      " -- 130364 events survived\n",
      " -- filtering observable m_jj between 150 and 5000\n",
      " -- 128505 events survived\n",
      " -- filtering observable pT_jj between 0 and 900\n",
      " -- 128505 events survived\n",
      " -- filtering observable theta_jj between 0 and 3.141592653589793\n",
      " -- 128505 events survived\n",
      " -- filtering observable rap_jj between 0 and 4.4\n",
      " -- 128505 events survived\n",
      " -- filtering observable pT_j1 between 40 and 1200\n",
      " -- 128479 events survived\n",
      " -- filtering observable pT_j2 between 35 and 1200\n",
      " -- 128388 events survived\n",
      " -- filtering observable Dy_j_j between 0 and 8.8\n",
      " -- 128388 events survived\n",
      " -- filtering observable Dphi_j_j between -3.141592653589793 and 3.141592653589793\n",
      " -- 128388 events survived\n",
      " -- filtering observable N_jets between 2 and 5\n",
      " -- 128388 events survived\n",
      " -- filtering observable N_gap_jets between 0 and 2\n",
      " -- 128388 events survived\n",
      " -- ordering observables\n",
      "* Registered the following keys:\n",
      "    +---------------------------------------+\n",
      "    | Column | Name       | Type            |\n",
      "    +---------------------------------------+\n",
      "    | 0      | Dphi_j_j   | <class 'float'> |\n",
      "    | 1      | Dy_j_j     | <class 'float'> |\n",
      "    | 2      | m_jj       | <class 'float'> |\n",
      "    | 3      | m_ll       | <class 'float'> |\n",
      "    | 4      | N_gap_jets | <class 'int'>   |\n",
      "    | 5      | N_jets     | <class 'int'>   |\n",
      "    | 6      | pT_j1      | <class 'float'> |\n",
      "    | 7      | pT_j2      | <class 'float'> |\n",
      "    | 8      | pT_jj      | <class 'float'> |\n",
      "    | 9      | pT_ll      | <class 'float'> |\n",
      "    | 10     | rap_jj     | <class 'float'> |\n",
      "    | 11     | rap_ll     | <class 'float'> |\n",
      "    | 12     | theta_jj   | <class 'float'> |\n",
      "    | 13     | theta_ll   | <class 'float'> |\n",
      "    +---------------------------------------+\n",
      "\n",
      "* Registered the following weights:\n",
      "    +-------------------------+\n",
      "    | Name   | Sum of weights |\n",
      "    +-------------------------+\n",
      "    | weight | 1.1485         |\n",
      "    +-------------------------+\n",
      "\n",
      "* Number of events       : 128388\n",
      "* Cross section per event: 0.253388\n",
      "* Total cross section    : 0.2910035786539249 +/- 0.0008130792268672345 pb\n",
      "Creating data table for cWtil=-0.2\n",
      " -- events from file ../Data/cWtil_m0p2_full_200k_rivet_output.pickle\n",
      " -- Table created with 200000 events\n",
      " -- filtering observable m_ll between 75 and 105\n",
      " -- 132228 events survived\n",
      " -- filtering observable pT_ll between 0 and 900\n",
      " -- 132213 events survived\n",
      " -- filtering observable theta_ll between 0 and 3.141592653589793\n",
      " -- 132213 events survived\n",
      " -- filtering observable rap_ll between 0 and 2.2\n",
      " -- 130485 events survived\n",
      " -- filtering observable m_jj between 150 and 5000\n",
      " -- 128644 events survived\n",
      " -- filtering observable pT_jj between 0 and 900\n",
      " -- 128644 events survived\n",
      " -- filtering observable theta_jj between 0 and 3.141592653589793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- 128644 events survived\n",
      " -- filtering observable rap_jj between 0 and 4.4\n",
      " -- 128644 events survived\n",
      " -- filtering observable pT_j1 between 40 and 1200\n",
      " -- 128618 events survived\n",
      " -- filtering observable pT_j2 between 35 and 1200\n",
      " -- 128530 events survived\n",
      " -- filtering observable Dy_j_j between 0 and 8.8\n",
      " -- 128530 events survived\n",
      " -- filtering observable Dphi_j_j between -3.141592653589793 and 3.141592653589793\n",
      " -- 128530 events survived\n",
      " -- filtering observable N_jets between 2 and 5\n",
      " -- 128530 events survived\n",
      " -- filtering observable N_gap_jets between 0 and 2\n",
      " -- 128530 events survived\n",
      " -- ordering observables\n",
      "* Registered the following keys:\n",
      "    +---------------------------------------+\n",
      "    | Column | Name       | Type            |\n",
      "    +---------------------------------------+\n",
      "    | 0      | Dphi_j_j   | <class 'float'> |\n",
      "    | 1      | Dy_j_j     | <class 'float'> |\n",
      "    | 2      | m_jj       | <class 'float'> |\n",
      "    | 3      | m_ll       | <class 'float'> |\n",
      "    | 4      | N_gap_jets | <class 'int'>   |\n",
      "    | 5      | N_jets     | <class 'int'>   |\n",
      "    | 6      | pT_j1      | <class 'float'> |\n",
      "    | 7      | pT_j2      | <class 'float'> |\n",
      "    | 8      | pT_jj      | <class 'float'> |\n",
      "    | 9      | pT_ll      | <class 'float'> |\n",
      "    | 10     | rap_jj     | <class 'float'> |\n",
      "    | 11     | rap_ll     | <class 'float'> |\n",
      "    | 12     | theta_jj   | <class 'float'> |\n",
      "    | 13     | theta_ll   | <class 'float'> |\n",
      "    +---------------------------------------+\n",
      "\n",
      "* Registered the following weights:\n",
      "    +-------------------------+\n",
      "    | Name   | Sum of weights |\n",
      "    +-------------------------+\n",
      "    | weight | 1.1468         |\n",
      "    +-------------------------+\n",
      "\n",
      "* Number of events       : 128530\n",
      "* Cross section per event: 0.253394\n",
      "* Total cross section    : 0.2906024945442304 +/- 0.0008115021658446098 pb\n",
      "Creating data table for cWtil=-0.1\n",
      " -- events from file ../Data/cWtil_m0p1_full_200k_rivet_output.pickle\n",
      " -- Table created with 200000 events\n",
      " -- filtering observable m_ll between 75 and 105\n",
      " -- 132144 events survived\n",
      " -- filtering observable pT_ll between 0 and 900\n",
      " -- 132134 events survived\n",
      " -- filtering observable theta_ll between 0 and 3.141592653589793\n",
      " -- 132134 events survived\n",
      " -- filtering observable rap_ll between 0 and 2.2\n",
      " -- 130432 events survived\n",
      " -- filtering observable m_jj between 150 and 5000\n",
      " -- 128636 events survived\n",
      " -- filtering observable pT_jj between 0 and 900\n",
      " -- 128636 events survived\n",
      " -- filtering observable theta_jj between 0 and 3.141592653589793\n",
      " -- 128636 events survived\n",
      " -- filtering observable rap_jj between 0 and 4.4\n",
      " -- 128636 events survived\n",
      " -- filtering observable pT_j1 between 40 and 1200\n",
      " -- 128620 events survived\n",
      " -- filtering observable pT_j2 between 35 and 1200\n",
      " -- 128519 events survived\n",
      " -- filtering observable Dy_j_j between 0 and 8.8\n",
      " -- 128519 events survived\n",
      " -- filtering observable Dphi_j_j between -3.141592653589793 and 3.141592653589793\n",
      " -- 128519 events survived\n",
      " -- filtering observable N_jets between 2 and 5\n",
      " -- 128519 events survived\n",
      " -- filtering observable N_gap_jets between 0 and 2\n",
      " -- 128519 events survived\n",
      " -- ordering observables\n",
      "* Registered the following keys:\n",
      "    +---------------------------------------+\n",
      "    | Column | Name       | Type            |\n",
      "    +---------------------------------------+\n",
      "    | 0      | Dphi_j_j   | <class 'float'> |\n",
      "    | 1      | Dy_j_j     | <class 'float'> |\n",
      "    | 2      | m_jj       | <class 'float'> |\n",
      "    | 3      | m_ll       | <class 'float'> |\n",
      "    | 4      | N_gap_jets | <class 'int'>   |\n",
      "    | 5      | N_jets     | <class 'int'>   |\n",
      "    | 6      | pT_j1      | <class 'float'> |\n",
      "    | 7      | pT_j2      | <class 'float'> |\n",
      "    | 8      | pT_jj      | <class 'float'> |\n",
      "    | 9      | pT_ll      | <class 'float'> |\n",
      "    | 10     | rap_jj     | <class 'float'> |\n",
      "    | 11     | rap_ll     | <class 'float'> |\n",
      "    | 12     | theta_jj   | <class 'float'> |\n",
      "    | 13     | theta_ll   | <class 'float'> |\n",
      "    +---------------------------------------+\n",
      "\n",
      "* Registered the following weights:\n",
      "    +-------------------------+\n",
      "    | Name   | Sum of weights |\n",
      "    +-------------------------+\n",
      "    | weight | 1.1447         |\n",
      "    +-------------------------+\n",
      "\n",
      "* Number of events       : 128519\n",
      "* Cross section per event: 0.25306\n",
      "* Total cross section    : 0.28969011911026327 +/- 0.0008089814289552211 pb\n",
      "Creating data table for cWtil=0.1\n",
      " -- events from file ../Data/cWtil_0p1_full_200k_rivet_output.pickle\n",
      " -- Table created with 200000 events\n",
      " -- filtering observable m_ll between 75 and 105\n",
      " -- 131985 events survived\n",
      " -- filtering observable pT_ll between 0 and 900\n",
      " -- 131974 events survived\n",
      " -- filtering observable theta_ll between 0 and 3.141592653589793\n",
      " -- 131974 events survived\n",
      " -- filtering observable rap_ll between 0 and 2.2\n",
      " -- 130351 events survived\n",
      " -- filtering observable m_jj between 150 and 5000\n",
      " -- 128565 events survived\n",
      " -- filtering observable pT_jj between 0 and 900\n",
      " -- 128565 events survived\n",
      " -- filtering observable theta_jj between 0 and 3.141592653589793\n",
      " -- 128565 events survived\n",
      " -- filtering observable rap_jj between 0 and 4.4\n",
      " -- 128565 events survived\n",
      " -- filtering observable pT_j1 between 40 and 1200\n",
      " -- 128548 events survived\n",
      " -- filtering observable pT_j2 between 35 and 1200\n",
      " -- 128455 events survived\n",
      " -- filtering observable Dy_j_j between 0 and 8.8\n",
      " -- 128455 events survived\n",
      " -- filtering observable Dphi_j_j between -3.141592653589793 and 3.141592653589793\n",
      " -- 128455 events survived\n",
      " -- filtering observable N_jets between 2 and 5\n",
      " -- 128455 events survived\n",
      " -- filtering observable N_gap_jets between 0 and 2\n",
      " -- 128455 events survived\n",
      " -- ordering observables\n",
      "* Registered the following keys:\n",
      "    +---------------------------------------+\n",
      "    | Column | Name       | Type            |\n",
      "    +---------------------------------------+\n",
      "    | 0      | Dphi_j_j   | <class 'float'> |\n",
      "    | 1      | Dy_j_j     | <class 'float'> |\n",
      "    | 2      | m_jj       | <class 'float'> |\n",
      "    | 3      | m_ll       | <class 'float'> |\n",
      "    | 4      | N_gap_jets | <class 'int'>   |\n",
      "    | 5      | N_jets     | <class 'int'>   |\n",
      "    | 6      | pT_j1      | <class 'float'> |\n",
      "    | 7      | pT_j2      | <class 'float'> |\n",
      "    | 8      | pT_jj      | <class 'float'> |\n",
      "    | 9      | pT_ll      | <class 'float'> |\n",
      "    | 10     | rap_jj     | <class 'float'> |\n",
      "    | 11     | rap_ll     | <class 'float'> |\n",
      "    | 12     | theta_jj   | <class 'float'> |\n",
      "    | 13     | theta_ll   | <class 'float'> |\n",
      "    +---------------------------------------+\n",
      "\n",
      "* Registered the following weights:\n",
      "    +-------------------------+\n",
      "    | Name   | Sum of weights |\n",
      "    +-------------------------+\n",
      "    | weight | 1.1446         |\n",
      "    +-------------------------+\n",
      "\n",
      "* Number of events       : 128455\n",
      "* Cross section per event: 0.253617\n",
      "* Total cross section    : 0.2902942495257387 +/- 0.0008108709395510602 pb\n",
      "Creating data table for cWtil=0.2\n",
      " -- events from file ../Data/cWtil_0p2_full_200k_rivet_output.pickle\n",
      " -- Table created with 200000 events\n",
      " -- filtering observable m_ll between 75 and 105\n",
      " -- 132282 events survived\n",
      " -- filtering observable pT_ll between 0 and 900\n",
      " -- 132264 events survived\n",
      " -- filtering observable theta_ll between 0 and 3.141592653589793\n",
      " -- 132264 events survived\n",
      " -- filtering observable rap_ll between 0 and 2.2\n",
      " -- 130568 events survived\n",
      " -- filtering observable m_jj between 150 and 5000\n",
      " -- 128743 events survived\n",
      " -- filtering observable pT_jj between 0 and 900\n",
      " -- 128743 events survived\n",
      " -- filtering observable theta_jj between 0 and 3.141592653589793\n",
      " -- 128743 events survived\n",
      " -- filtering observable rap_jj between 0 and 4.4\n",
      " -- 128743 events survived\n",
      " -- filtering observable pT_j1 between 40 and 1200\n",
      " -- 128724 events survived\n",
      " -- filtering observable pT_j2 between 35 and 1200\n",
      " -- 128639 events survived\n",
      " -- filtering observable Dy_j_j between 0 and 8.8\n",
      " -- 128639 events survived\n",
      " -- filtering observable Dphi_j_j between -3.141592653589793 and 3.141592653589793\n",
      " -- 128639 events survived\n",
      " -- filtering observable N_jets between 2 and 5\n",
      " -- 128639 events survived\n",
      " -- filtering observable N_gap_jets between 0 and 2\n",
      " -- 128639 events survived\n",
      " -- ordering observables\n",
      "* Registered the following keys:\n",
      "    +---------------------------------------+\n",
      "    | Column | Name       | Type            |\n",
      "    +---------------------------------------+\n",
      "    | 0      | Dphi_j_j   | <class 'float'> |\n",
      "    | 1      | Dy_j_j     | <class 'float'> |\n",
      "    | 2      | m_jj       | <class 'float'> |\n",
      "    | 3      | m_ll       | <class 'float'> |\n",
      "    | 4      | N_gap_jets | <class 'int'>   |\n",
      "    | 5      | N_jets     | <class 'int'>   |\n",
      "    | 6      | pT_j1      | <class 'float'> |\n",
      "    | 7      | pT_j2      | <class 'float'> |\n",
      "    | 8      | pT_jj      | <class 'float'> |\n",
      "    | 9      | pT_ll      | <class 'float'> |\n",
      "    | 10     | rap_jj     | <class 'float'> |\n",
      "    | 11     | rap_ll     | <class 'float'> |\n",
      "    | 12     | theta_jj   | <class 'float'> |\n",
      "    | 13     | theta_ll   | <class 'float'> |\n",
      "    +---------------------------------------+\n",
      "\n",
      "* Registered the following weights:\n",
      "    +-------------------------+\n",
      "    | Name   | Sum of weights |\n",
      "    +-------------------------+\n",
      "    | weight | 1.1480         |\n",
      "    +-------------------------+\n",
      "\n",
      "* Number of events       : 128639\n",
      "* Cross section per event: 0.253345\n",
      "* Total cross section    : 0.2908465083472163 +/- 0.0008118427314740658 pb\n",
      "Creating data table for cWtil=0.3\n",
      " -- events from file ../Data/cWtil_0p3_full_200k_rivet_output.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Table created with 200000 events\n",
      " -- filtering observable m_ll between 75 and 105\n",
      " -- 132342 events survived\n",
      " -- filtering observable pT_ll between 0 and 900\n",
      " -- 132326 events survived\n",
      " -- filtering observable theta_ll between 0 and 3.141592653589793\n",
      " -- 132326 events survived\n",
      " -- filtering observable rap_ll between 0 and 2.2\n",
      " -- 130576 events survived\n",
      " -- filtering observable m_jj between 150 and 5000\n",
      " -- 128713 events survived\n",
      " -- filtering observable pT_jj between 0 and 900\n",
      " -- 128713 events survived\n",
      " -- filtering observable theta_jj between 0 and 3.141592653589793\n",
      " -- 128713 events survived\n",
      " -- filtering observable rap_jj between 0 and 4.4\n",
      " -- 128713 events survived\n",
      " -- filtering observable pT_j1 between 40 and 1200\n",
      " -- 128683 events survived\n",
      " -- filtering observable pT_j2 between 35 and 1200\n",
      " -- 128598 events survived\n",
      " -- filtering observable Dy_j_j between 0 and 8.8\n",
      " -- 128598 events survived\n",
      " -- filtering observable Dphi_j_j between -3.141592653589793 and 3.141592653589793\n",
      " -- 128598 events survived\n",
      " -- filtering observable N_jets between 2 and 5\n",
      " -- 128598 events survived\n",
      " -- filtering observable N_gap_jets between 0 and 2\n",
      " -- 128598 events survived\n",
      " -- ordering observables\n",
      "* Registered the following keys:\n",
      "    +---------------------------------------+\n",
      "    | Column | Name       | Type            |\n",
      "    +---------------------------------------+\n",
      "    | 0      | Dphi_j_j   | <class 'float'> |\n",
      "    | 1      | Dy_j_j     | <class 'float'> |\n",
      "    | 2      | m_jj       | <class 'float'> |\n",
      "    | 3      | m_ll       | <class 'float'> |\n",
      "    | 4      | N_gap_jets | <class 'int'>   |\n",
      "    | 5      | N_jets     | <class 'int'>   |\n",
      "    | 6      | pT_j1      | <class 'float'> |\n",
      "    | 7      | pT_j2      | <class 'float'> |\n",
      "    | 8      | pT_jj      | <class 'float'> |\n",
      "    | 9      | pT_ll      | <class 'float'> |\n",
      "    | 10     | rap_jj     | <class 'float'> |\n",
      "    | 11     | rap_ll     | <class 'float'> |\n",
      "    | 12     | theta_jj   | <class 'float'> |\n",
      "    | 13     | theta_ll   | <class 'float'> |\n",
      "    +---------------------------------------+\n",
      "\n",
      "* Registered the following weights:\n",
      "    +-------------------------+\n",
      "    | Name   | Sum of weights |\n",
      "    +-------------------------+\n",
      "    | weight | 1.1508         |\n",
      "    +-------------------------+\n",
      "\n",
      "* Number of events       : 128598\n",
      "* Cross section per event: 0.253896\n",
      "* Total cross section    : 0.2921898682826477 +/- 0.0008157149907009277 pb\n",
      "Creating data table for cWtil=0.4\n",
      " -- events from file ../Data/cWtil_0p4_full_200k_rivet_output.pickle\n",
      " -- Table created with 200000 events\n",
      " -- filtering observable m_ll between 75 and 105\n",
      " -- 132565 events survived\n",
      " -- filtering observable pT_ll between 0 and 900\n",
      " -- 132512 events survived\n",
      " -- filtering observable theta_ll between 0 and 3.141592653589793\n",
      " -- 132512 events survived\n",
      " -- filtering observable rap_ll between 0 and 2.2\n",
      " -- 130829 events survived\n",
      " -- filtering observable m_jj between 150 and 5000\n",
      " -- 128987 events survived\n",
      " -- filtering observable pT_jj between 0 and 900\n",
      " -- 128987 events survived\n",
      " -- filtering observable theta_jj between 0 and 3.141592653589793\n",
      " -- 128987 events survived\n",
      " -- filtering observable rap_jj between 0 and 4.4\n",
      " -- 128987 events survived\n",
      " -- filtering observable pT_j1 between 40 and 1200\n",
      " -- 128952 events survived\n",
      " -- filtering observable pT_j2 between 35 and 1200\n",
      " -- 128856 events survived\n",
      " -- filtering observable Dy_j_j between 0 and 8.8\n",
      " -- 128856 events survived\n",
      " -- filtering observable Dphi_j_j between -3.141592653589793 and 3.141592653589793\n",
      " -- 128856 events survived\n",
      " -- filtering observable N_jets between 2 and 5\n",
      " -- 128856 events survived\n",
      " -- filtering observable N_gap_jets between 0 and 2\n",
      " -- 128856 events survived\n",
      " -- ordering observables\n",
      "* Registered the following keys:\n",
      "    +---------------------------------------+\n",
      "    | Column | Name       | Type            |\n",
      "    +---------------------------------------+\n",
      "    | 0      | Dphi_j_j   | <class 'float'> |\n",
      "    | 1      | Dy_j_j     | <class 'float'> |\n",
      "    | 2      | m_jj       | <class 'float'> |\n",
      "    | 3      | m_ll       | <class 'float'> |\n",
      "    | 4      | N_gap_jets | <class 'int'>   |\n",
      "    | 5      | N_jets     | <class 'int'>   |\n",
      "    | 6      | pT_j1      | <class 'float'> |\n",
      "    | 7      | pT_j2      | <class 'float'> |\n",
      "    | 8      | pT_jj      | <class 'float'> |\n",
      "    | 9      | pT_ll      | <class 'float'> |\n",
      "    | 10     | rap_jj     | <class 'float'> |\n",
      "    | 11     | rap_ll     | <class 'float'> |\n",
      "    | 12     | theta_jj   | <class 'float'> |\n",
      "    | 13     | theta_ll   | <class 'float'> |\n",
      "    +---------------------------------------+\n",
      "\n",
      "* Registered the following weights:\n",
      "    +-------------------------+\n",
      "    | Name   | Sum of weights |\n",
      "    +-------------------------+\n",
      "    | weight | 1.1613         |\n",
      "    +-------------------------+\n",
      "\n",
      "* Number of events       : 128856\n",
      "* Cross section per event: 0.253525\n",
      "* Total cross section    : 0.294414018624078 +/- 0.0008211161349799041 pb\n"
     ]
    }
   ],
   "source": [
    "#  Load and format the data\n",
    "#\n",
    "\n",
    "data_tables = {}\n",
    "for cWtil in cWtil_eval_vals :\n",
    "    input_fname = input_fnames [cWtil]\n",
    "    print(f\"Creating data table for cWtil={cWtil}\")\n",
    "    print(f\" -- events from file {input_fname}\")\n",
    "    data = DataTable(input_fname)\n",
    "    print(f\" -- Table created with {data.get_num_events()} events\")\n",
    "    for observable, limits in observable_limits.items() :\n",
    "        print(f\" -- filtering observable {observable} between {limits[0]} and {limits[1]}\")\n",
    "        data.filter(observable, limits[0], limits[1])\n",
    "        print(f\" -- {data.get_num_events()} events survived\")\n",
    "    for observable in remove_observables :\n",
    "        print(f\" -- removing observable {observable}\")\n",
    "        data.remove_column(observable)\n",
    "    print(\" -- ordering observables\")\n",
    "    data.reorder(*observables_order)\n",
    "    data.print_summary()\n",
    "    data_tables [cWtil] = data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitening dataset for cWtil=0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-995a5e3059af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Whitening dataset for cWtil={cWtil}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     white_data_to_fit[cWtil], whitening_funcs = whiten_axes (observable_data[cWtil], data.types, axis_configs=axis_configs, whitening_funcs=whitening_funcs, weights=data.get_weights(), \n\u001b[0;32m---> 17\u001b[0;31m                                                              func_form=whitening_func_form, alpha=whitening_alpha, beta=whitening_beta, gamma=whitening_gamma)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_whitening_funcs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PostDoc/git-with-DP/SM-sandbox/proj5.4-EFT-Density-Estimation/backends/stats.py\u001b[0m in \u001b[0;36mwhiten_axes\u001b[0;34m(data, types, axis_configs, whitening_funcs, weights, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhitening_funcs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                 \u001b[0mwhite_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_whitening_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecial_whiten_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobs_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_configs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mwhite_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_whitening_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecial_whiten_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobs_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_configs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhitening_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhitening_funcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PostDoc/git-with-DP/SM-sandbox/proj5.4-EFT-Density-Estimation/backends/stats.py\u001b[0m in \u001b[0;36mspecial_whiten_axis\u001b[0;34m(dataset, axis_config, whitening_func, weights, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mwhitening_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_special_encoding_constants_for_axis\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mwhitening_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_special_encoding_constants_for_axis\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0mwhite_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhitening_func\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwhite_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhitening_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PostDoc/git-with-DP/SM-sandbox/proj5.4-EFT-Density-Estimation/backends/stats.py\u001b[0m in \u001b[0;36mget_special_encoding_constants_for_axis\u001b[0;34m(dataset, axis, axmin, axmax, ax_npoints, data_frac_constant, gauss_frac_constant, weights, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mdata_cdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mA\u001b[0m \u001b[0;32min\u001b[0m \u001b[0max_scan_points\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mdata_cdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mdata_cdf\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mconstant_cdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max_scan_points\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maxmin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxmax\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maxmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PostDoc/git-with-DP/SM-sandbox/proj5.4-EFT-Density-Estimation/backends/stats.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mdata_cdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mA\u001b[0m \u001b[0;32min\u001b[0m \u001b[0max_scan_points\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mdata_cdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mdata_cdf\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mconstant_cdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max_scan_points\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maxmin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxmax\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maxmin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "whitening_funcs = None\n",
    "if (type(load_whitening_funcs) != type(None)) :\n",
    "    print(f\"Loading whitening functions from file {load_whitening_funcs}\")\n",
    "    whitening_funcs = pickle.load(open(load_whitening_funcs, \"rb\"))\n",
    "\n",
    "axis_configs = [[observable_limits[key][0], observable_limits[key][1], whitening_num_points,  white_linear_fraction_data, white_linear_fraction_gauss] for key in data.keys]\n",
    "\n",
    "observable_data, weight_data, white_data_to_fit = {}, {}, {}\n",
    "for cWtil in cWtil_vals :\n",
    "    data = data_tables [cWtil]\n",
    "    #  Seperate data from weights\n",
    "    observable_data [cWtil], weight_data [cWtil] = data.get_observables_and_weights()\n",
    "    #  Whiten data\n",
    "    print(f\"Whitening dataset for cWtil={cWtil}\")\n",
    "    white_data_to_fit[cWtil], whitening_funcs = whiten_axes (observable_data[cWtil], data.types, axis_configs=axis_configs, whitening_funcs=whitening_funcs, weights=data.get_weights(), \n",
    "                                                             func_form=whitening_func_form, alpha=whitening_alpha, beta=whitening_beta, gamma=whitening_gamma)\n",
    "\n",
    "if type(save_whitening_funcs) != type(None) :\n",
    "    print(f\"Saving whitening functions to file {save_whitening_funcs}\")\n",
    "    pickle.dump(whitening_funcs, open(save_whitening_funcs, \"wb\"))\n",
    "\n",
    "weights_to_fit = {k:i/np.sum(i) for k,i in weight_data.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Weight edges more highly to reduce interpolation bias\n",
    "\n",
    "weights_to_fit = {k:(1+np.fabs(k)/np.max(np.fabs(cWtil_vals)))*i/np.sum(i) for k,i in weight_data.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data(observable_data  [0], weight_data   [0], keys=data.keys, bins=20, lims=True)\n",
    "plot_data(white_data_to_fit[0], weights_to_fit[0], keys=data.keys, bins=20, lims=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Load model if requested, otherwise build and fit\n",
    "#\n",
    "\n",
    "if type(load_model_dir) != type(None) :\n",
    "    density_model = DensityModel.from_dir(load_model_dir)\n",
    "else :\n",
    "    #  Create density model\n",
    "    density_model = DensityModel(name            = \"EWK_density_model\", \n",
    "                                 num_gaussians   = output_size_per_stage, \n",
    "                                 num_conditions  = 1, \n",
    "                                 num_observables = data.get_num_observables(), \n",
    "                                 types           = data.types,\n",
    "                                 int_limits      = {idx:observable_limits[obs] for idx,(obs,t) in enumerate(zip(data.keys, data.types)) if t == int},\n",
    "                                 verbose         = True,\n",
    "                                 learning_rate   = learning_rate,\n",
    "                                 optimiser       = optimiser)\n",
    "    fit_times = {}\n",
    "    for obs_idx in range(white_data_to_fit[0].shape[1]) :\n",
    "        fit_start_time = time.time()\n",
    "        num_epochs = max_epochs + obs_idx*epoch_increase_per_level\n",
    "        density_model.fit(white_data_to_fit, \n",
    "                          weights_to_fit,\n",
    "                          observable                = obs_idx,\n",
    "                          max_epochs_per_observable = num_epochs,\n",
    "                          early_stopping_patience   = early_stopping_patience,\n",
    "                          early_stopping_min_delta  = early_stopping_min_delta,\n",
    "                          validation_split          = validation_split,\n",
    "                          batch_size_per_observable = batch_size)\n",
    "        fit_times [obs_idx] = [num_epochs, time.time() - fit_start_time]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Use this cell to add training epochs to whichever indices appear undertrained\n",
    "\n",
    "'''improve_indices   = [i for i in range(num_observables)]\n",
    "impove_batch_size = 5000\n",
    "impove_num_epochs = 200\n",
    "improve_patience  = 10\n",
    "improve_validation_split = 0.5\n",
    "\n",
    "added_fit_times = {}\n",
    "for obs_idx in improve_indices :\n",
    "    fit_start_time = time.time()\n",
    "    density_model.fit(white_data_to_fit, \n",
    "                      weights_to_fit,\n",
    "                      observable                = obs_idx,\n",
    "                      max_epochs_per_observable = impove_num_epochs,\n",
    "                      early_stopping_patience   = improve_patience,\n",
    "                      validation_split          = improve_validation_split,\n",
    "                      batch_size_per_observable = impove_batch_size)\n",
    "    added_fit_times [obs_idx] = [impove_num_epochs, time.time() - fit_start_time]\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Save model if requested\n",
    "\n",
    "if type(save_model_dir) != type(None) :\n",
    "    density_model.save_to_dir(save_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  Generate a large number of datapoints\n",
    "#\n",
    "\n",
    "'''n_gen = 100000\n",
    "\n",
    "fake_white_datapoints = {}\n",
    "for cWtil in cWtil_eval_vals :\n",
    "    n_gen = n_gen # len(observable_data[cWtil])\n",
    "    print(f\"Generating {n_gen} fake datapoints for cWtil={cWtil}\")\n",
    "    start = time.time()\n",
    "    fake_white_datapoints[cWtil] = density_model.sample(n_gen, [cWtil])\n",
    "    end = time.time()\n",
    "    print(f\"{n_gen} datapoints generated in {int(end-start):.0f}s\")\n",
    "\n",
    "#  Unwhiten generated data\n",
    "#\n",
    "print(\"Unwhitening the generated datapoints\")\n",
    "fake_datapoints = {}\n",
    "for cWtil in cWtil_eval_vals :\n",
    "    print(f\"Unwhitening generated datapoints for cWtil={cWtil}\")\n",
    "    fake_datapoints [cWtil] = unwhiten_axes(fake_white_datapoints[cWtil], whitening_funcs)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generate a large number of datapoints at 0.\n",
    "#\n",
    "\n",
    "n_gen = 5000\n",
    "\n",
    "print(f\"Generating {n_gen} fake datapoints for cWtil=[0]\")\n",
    "start = time.time()\n",
    "\n",
    "fake_white_datapoints_SM = density_model.sample(n_gen, [0])\n",
    "end = time.time()\n",
    "print(f\"{n_gen} datapoints generated at cWtil=0 in {int(end-start):.0f}s\")\n",
    "\n",
    "#  Unwhiten generated data\n",
    "#\n",
    "\n",
    "print(\"Unwhitening fake datapoints for cWtil=0\")\n",
    "start = time.time()\n",
    "fake_datapoints_SM = unwhiten_axes(fake_white_datapoints_SM, whitening_funcs)\n",
    "end = time.time()\n",
    "print(f\"{n_gen} datapoints unwhitened at cWtil=0 in {int(end-start):.0f}s\")\n",
    "\n",
    "\n",
    "n_gen = 500000\n",
    "\n",
    "print(f\"Generating {n_gen} fake datapoints for cWtil=[0]\")\n",
    "start = time.time()\n",
    "\n",
    "fake_white_datapoints_SM_big = density_model.sample(n_gen, [0])\n",
    "end = time.time()\n",
    "print(f\"{n_gen} datapoints generated at cWtil=0 in {int(end-start):.0f}s\")\n",
    "\n",
    "#  Unwhiten generated data\n",
    "#\n",
    "\n",
    "print(\"Unwhitening fake datapoints for cWtil=0\")\n",
    "start = time.time()\n",
    "fake_datapoints_SM_big = unwhiten_axes(fake_white_datapoints_SM_big, whitening_funcs)\n",
    "end = time.time()\n",
    "print(f\"{n_gen} datapoints unwhitened at cWtil=0 in {int(end-start):.0f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Get datapoint likelihoods at 0 hypothesis\n",
    "#\n",
    "\n",
    "fake_datapoint_SM_likelihood = density_model.evaluate(0, fake_white_datapoints_SM)\n",
    "\n",
    "fake_datapoint_weights = {}\n",
    "for cWtil in cWtil_eval_vals :\n",
    "    start = time.time()\n",
    "    fake_datapoint_weights [cWtil] = density_model.evaluate(cWtil, fake_white_datapoints_SM) / fake_datapoint_SM_likelihood\n",
    "    end = time.time()\n",
    "    print(f\"{len(fake_white_datapoints_SM)} datapoints evaluated at cWtil = {cWtil} in {(end-start):.2f}s\")\n",
    "    start = time.time()\n",
    "    dataset_NLL = density_model.get_NLL(cWtil, fake_white_datapoints_SM)\n",
    "    end = time.time()\n",
    "    print(f\"-- NLL = {dataset_NLL}, eval time is {(end-start):.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  Plotting mixture of Gaussians, since it was observed that -ve deviations around SM are hard to model\n",
    "#       if the distribution is dominated by a single Gaussian mode\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "params = density_model.likelihood_models[0].get_gauss_params([0])[0]\n",
    "fracs  = params[:output_size_per_stage]\n",
    "means  = params[output_size_per_stage:2*output_size_per_stage]\n",
    "sigmas = params[2*output_size_per_stage:3*output_size_per_stage]\n",
    "\n",
    "x = np.linspace(-5, 5, 201)\n",
    "y1 = 0.\n",
    "plt.hist(white_data_to_fit[0][:,0], weights=weights_to_fit[0], density=True, color=\"blue\", alpha=0.3, bins=np.linspace(-5, 5, 81))\n",
    "for i in range(output_size_per_stage) :\n",
    "    yp = fracs[i]*stats.norm.pdf(x, means[i], sigmas[i])\n",
    "    plt.plot(x, yp, c=\"r\", linewidth=1, linestyle=\"--\")\n",
    "    y1 = y1 + yp\n",
    "plt.plot(x, y1, c=\"k\", linewidth=3, linestyle=\"--\")\n",
    "plt.show()\n",
    "\n",
    "params = density_model.likelihood_models[0].get_gauss_params([0.4])[0]\n",
    "fracs  = params[:output_size_per_stage]\n",
    "means  = params[output_size_per_stage:2*output_size_per_stage]\n",
    "sigmas = params[2*output_size_per_stage:3*output_size_per_stage]\n",
    "\n",
    "y2 = 0.\n",
    "plt.hist(white_data_to_fit[0.4][:,0], weights=weights_to_fit[0.4], density=True, color=\"blue\", alpha=0.3, bins=np.linspace(-5, 5, 81))\n",
    "for i in range(output_size_per_stage) :\n",
    "    yp = fracs[i]*stats.norm.pdf(x, means[i], sigmas[i])\n",
    "    plt.plot(x, yp, c=\"r\", linewidth=1, linestyle=\"--\")\n",
    "    y2 = y2 + yp\n",
    "plt.plot(x, y1, c=\"k\", linewidth=1, linestyle=\"--\")\n",
    "plt.plot(x, y2, c=\"grey\", linewidth=3, linestyle=\"--\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, (y2-y1)/y1, \"--\")\n",
    "plt.axhline(0, linewidth=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  Plot original and generate data (total phase space)\n",
    "\n",
    "plot_data(white_data_to_fit[0]        , weights_to_fit[0], keys=data.keys, bins=20, lims=False)\n",
    "plot_data(fake_white_datapoints_SM_big, None             , keys=data.keys, bins=20, lims=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  Plot ratio and pull between original and generated data (total phase space)\n",
    "\n",
    "plot_ratio(observable_data[0]  , fake_datapoints_SM_big, weights_to_fit[0], None, keys=data.keys, bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Remove events for which key lies outside the interval [minimum, maximum]\n",
    "#\n",
    "def filter_data (events, weights, keys, key, minimum, maximum) :\n",
    "    col_idx = keys.index(key)\n",
    "    new_events, new_weights = [], []\n",
    "    for row, weight in zip(events, weights) :\n",
    "        val = row[col_idx]\n",
    "        if val < minimum : continue\n",
    "        if val > maximum : continue\n",
    "        new_events.append(row)\n",
    "        new_weights.append(weight)\n",
    "    return np.array(new_events), np.array(new_weights)\n",
    "\n",
    "\n",
    "#  Plot the datapoints provided\n",
    "#\n",
    "def plot_observable (observable, data_num, data_den, weights_num=None, weights_den=None, keys=None, cuts=[], save=\"\", lims=True, bins=20, label=None) :\n",
    "    if type(weights_num) == type(None) :\n",
    "        weights_num = np.ones(shape=(data_num.shape[0],))\n",
    "    if type(keys) == type(None) :\n",
    "        keys = [f\"obs{i}\" for i in range(len(data_num))]\n",
    "    filtered_data_num, filtered_weights_num = data_num, weights_num\n",
    "    for cut in cuts :\n",
    "        print(f\"Filtering {cut[0]} between {cut[1]} and {cut[2]} for numerator\")\n",
    "        filtered_data_num, filtered_weights_num = filter_data (filtered_data_num, filtered_weights_num, keys, cut[0], cut[1], cut[2])\n",
    "    print(f\"Numerator filter efficiency is {100.*np.sum(filtered_weights_num)/np.sum(weights_num):.3f}%\")\n",
    "    \n",
    "    if type(weights_den) == type(None) :\n",
    "        weights_den = np.ones(shape=(data_den.shape[0],))\n",
    "    filtered_data_den, filtered_weights_den = data_den, weights_den\n",
    "    for cut in cuts :\n",
    "        print(f\"Filtering {cut[0]} between {cut[1]} and {cut[2]} for denominator\")\n",
    "        filtered_data_den, filtered_weights_den = filter_data (filtered_data_den, filtered_weights_den, keys, cut[0], cut[1], cut[2])\n",
    "    print(f\"Denominator filter efficiency is {100.*np.sum(filtered_weights_den)/np.sum(weights_den):.3f}%\")\n",
    "    \n",
    "    obs_idx = keys.index(observable)\n",
    "    \n",
    "    if lims : \n",
    "        obs_lims = observable_limits[observable]\n",
    "    else :\n",
    "        obs_lims = [-5., 5.]\n",
    "    if observable in int_observables : bins = np.linspace(obs_lims[0]-0.5, obs_lims[1]+0.5, 1+(obs_lims[1]-obs_lims[0]))\n",
    "    else                             : bins = np.linspace(obs_lims[0], obs_lims[1], bins+1)\n",
    "        \n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.set_xlabel(observable, weight=\"bold\", fontsize=12)\n",
    "    data_x, data_z, data_ez = get_ratio_1D(filtered_data_den[:,obs_idx], filtered_data_num[:,obs_idx], bins, filtered_weights_den, filtered_weights_num, as_lines=True)\n",
    "    data_z = np.nan_to_num(data_z)\n",
    "    ax.plot(data_x, data_z-1., color=\"k\", label=label)\n",
    "    \n",
    "    #ax.fill_between(data_x, data_z+data_ez-1, data_z-data_ez-1, alpha=0.2, color=\"grey\")\n",
    "    \n",
    "    ax.axhline(0 , linestyle=\"-\", c=\"grey\", linewidth=2)\n",
    "    ax.axhline(0.1 , linestyle=\"--\", c=\"grey\", linewidth=0.5)\n",
    "    ax.axhline(0.2 , linestyle=\"--\", c=\"grey\", linewidth=0.5)\n",
    "    ax.axhline(0.3 , linestyle=\"--\", c=\"grey\", linewidth=0.5)\n",
    "    ax.axhline(0.4 , linestyle=\"--\", c=\"grey\", linewidth=0.5)\n",
    "    ax.axhline(-0.1 , linestyle=\"--\", c=\"grey\", linewidth=0.5)\n",
    "    ax.axhline(-0.2 , linestyle=\"--\", c=\"grey\", linewidth=0.5)\n",
    "    ax.axhline(-0.3 , linestyle=\"--\", c=\"grey\", linewidth=0.5)\n",
    "    ax.axhline(-0.4 , linestyle=\"--\", c=\"grey\", linewidth=0.5)\n",
    "    ax.set_ylim([-0.9, 0.9])\n",
    "    \n",
    "    if type(label) != type(None) :\n",
    "        ax.legend(loc=\"upper right\", frameon=False, fontsize=16)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot the datapoints provided\n",
    "#\n",
    "def get_eff (data, weights=None, keys=[], cuts=[]) :\n",
    "    if type(weights) == type(None) :\n",
    "        weights = np.ones(shape=(data.shape[0],))\n",
    "    filtered_data, filtered_weights = data, weights\n",
    "    for cut in cuts :\n",
    "        filtered_data, filtered_weights = filter_data (filtered_data, filtered_weights, keys, cut[0], cut[1], cut[2])\n",
    "    return 100.*np.sum(filtered_weights)/np.sum(weights), 100.*np.sqrt(np.sum(filtered_weights*filtered_weights))/np.sum(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot data (VBF fiducial)\n",
    "\n",
    "cuts = []\n",
    "cuts.append([\"m_jj\"    , 1000, 5000])\n",
    "cuts.append([\"Dy_j_j\"  , 2   , 8.8 ])\n",
    "cuts.append([\"Dphi_j_j\", 0   , 1.5 ])\n",
    "\n",
    "x1, x2, y1, y2, ey2 = [], [], [], [], []\n",
    "\n",
    "for cWtil in sorted(cWtil_eval_vals) :\n",
    "    e1 = get_eff(fake_datapoints_SM, weights=fake_datapoint_weights[cWtil], keys=data.keys, cuts=[[\"Dphi_j_j\", -1.5, 0]])\n",
    "    x1.append(cWtil)\n",
    "    y1.append(e1[0])\n",
    "    \n",
    "for cWtil in sorted(cWtil_vals) :\n",
    "    e2 = get_eff(observable_data[cWtil], weights_to_fit[cWtil], keys=data.keys, cuts=[[\"Dphi_j_j\", -1.5, 0]])\n",
    "    x2.append(cWtil)\n",
    "    y2.append(e2[0])\n",
    "    ey2.append(e2[1])\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(x1, y1, \"x--\")\n",
    "ax.errorbar(x2, y2, yerr=ey2, fmt=\"o--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Plot the datapoints provided\n",
    "#\n",
    "def plot_observable_on_axis (ax, observable, data_num, data_den, weights_num=None, weights_den=None, keys=None, cuts=[], save=\"\", lims=True, bins=20, label=None, normed=True, ebar=False) :\n",
    "    if type(weights_num) == type(None) :\n",
    "        weights_num = np.ones(shape=(data_num.shape[0],))\n",
    "    if type(keys) == type(None) :\n",
    "        keys = [f\"obs{i}\" for i in range(len(data_num))]\n",
    "    filtered_data_num, filtered_weights_num = data_num, weights_num\n",
    "    for cut in cuts :\n",
    "        print(f\"Filtering {cut[0]} between {cut[1]} and {cut[2]} for numerator\")\n",
    "        filtered_data_num, filtered_weights_num = filter_data (filtered_data_num, filtered_weights_num, keys, cut[0], cut[1], cut[2])\n",
    "    \n",
    "    if type(weights_den) == type(None) :\n",
    "        weights_den = np.ones(shape=(data_den.shape[0],))\n",
    "    filtered_data_den, filtered_weights_den = data_den, weights_den\n",
    "    for cut in cuts :\n",
    "        print(f\"Filtering {cut[0]} between {cut[1]} and {cut[2]} for denominator\")\n",
    "        filtered_data_den, filtered_weights_den = filter_data (filtered_data_den, filtered_weights_den, keys, cut[0], cut[1], cut[2])\n",
    "    \n",
    "    obs_idx = keys.index(observable)\n",
    "    if lims : obs_lims = observable_limits[observable]\n",
    "    else    : obs_lims = [-5., 5.]\n",
    "    if observable in int_observables : bins = np.linspace(obs_lims[0]-0.5, obs_lims[1]+0.5, 1+(obs_lims[1]-obs_lims[0]))\n",
    "    else                             : bins = np.linspace(obs_lims[0], obs_lims[1], bins+1)\n",
    "        \n",
    "    data_x, data_z, data_ez = get_ratio_1D(filtered_data_den[:,obs_idx], filtered_data_num[:,obs_idx], bins, filtered_weights_den, filtered_weights_num, as_lines=True, normed=normed)\n",
    "    data_z = np.nan_to_num(data_z)\n",
    "    ax.plot(data_x, data_z-1., color=\"k\", label=label)\n",
    "    if ebar :ax.fill_between(data_x, data_z+data_ez-1, data_z-data_ez-1, alpha=0.3, color=\"grey\")\n",
    "    ax.set_xlim([bins[0], bins[-1]])\n",
    "    \n",
    "    ax.axhline(0    , linestyle=\"-\" , c=\"grey\", linewidth=2  )\n",
    "    for h in [-0.4, -0.3, -0.2, -0.1, 0.1, 0.2, 0.3, 0.4] :\n",
    "        ax.axhline(h, linestyle=\"--\", c=\"grey\", linewidth=0.5)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for fig_idx, cWtil in enumerate(sorted(cWtil_eval_vals)) :\n",
    "    fig = plt.figure(figsize=(2*num_observables, 7))\n",
    "    for idx, obs in enumerate(observables_order) :\n",
    "        ax1 = fig.add_subplot(2, num_observables, 1+idx)\n",
    "        data = data_tables [cWtil]\n",
    "        observables, weights = data.get_observables_and_weights()\n",
    "        plot_observable_on_axis (ax1, obs, observables, observable_data[0], weights, weights_to_fit[0], keys=data.keys, bins=20, normed=True, ebar=True)\n",
    "        ax2 = fig.add_subplot(2, num_observables, num_observables+1+idx)\n",
    "        plot_observable_on_axis (ax2, obs, fake_datapoints_SM, fake_datapoints_SM, fake_datapoint_weights[cWtil], fake_datapoint_weights[0], keys=data.keys, bins=20, normed=True)\n",
    "        ax2.set_xlabel(obs, weight=\"bold\", fontsize=19, labelpad=20)\n",
    "        if idx == 0 :\n",
    "            ax1.set_ylabel(\"MG5 events\"   , fontsize=19, labelpad=20, weight=\"bold\")\n",
    "            ax2.set_ylabel(\"Density model\", fontsize=19, labelpad=20, weight=\"bold\")\n",
    "        else :\n",
    "            ax1.set_yticks([])\n",
    "            ax2.set_yticks([])\n",
    "        if idx == num_observables-1 :\n",
    "            ax1.text(0.86, 0.92, r\"$\\frac{\\sigma({\\tilde c}_W=\"+f\"{cWtil:.1f})~~[N={observables.shape[0]}]\"+r\"}{\\sigma_{SM}\"+f\"~~~~~~~~~~~~~~~~[N={observable_data[0].shape[0]}]\"+\"}$\"       , fontsize=19, transform=ax1.transAxes, ha=\"right\", va=\"top\", bbox=dict(facecolor='white', edgecolor='grey', pad=4.0))\n",
    "            ax2.text(0.86, 0.92, r\"$\\frac{\\sigma({\\tilde c}_W=\"+f\"{cWtil:.1f})~~[N={fake_datapoints_SM.shape[0]}]\"+r\"}{\\sigma_{SM}\"+f\"~~~~~~~~~~~~~~~~[N={fake_datapoints_SM.shape[0]}]\"+\"}$\", fontsize=19, transform=ax2.transAxes, ha=\"right\", va=\"top\", bbox=dict(facecolor='white', edgecolor='grey', pad=4.0))\n",
    "        ax1.set_ylim([-0.7, 1.])\n",
    "        ax2.set_ylim([-0.7, 1.])\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    plt.savefig(f\"figures/EWK_cWtil_dependence_{fig_idx}.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(2*num_observables, 5))\n",
    "for idx, obs in enumerate(observables_order) :\n",
    "    ax = fig.add_subplot(1, num_observables, 1+idx)\n",
    "    datapoints_true, weights_true = data_tables [0].get_observables_and_weights()\n",
    "    plot_observable_on_axis (ax, obs, fake_datapoints_SM_big, datapoints_true, None, weights_true, keys=data.keys, bins=20, normed=True, ebar=True)\n",
    "    ax.set_xlabel(obs, weight=\"bold\", fontsize=19, labelpad=20)\n",
    "    if idx == 0 :\n",
    "        ax.set_ylabel(f\"Ratio to MG5 [N={datapoints_true.shape[0]}]\", fontsize=19, labelpad=20, weight=\"bold\")\n",
    "    else :\n",
    "        ax.set_yticks([])\n",
    "    if idx == num_observables-1 :\n",
    "        ax.text(0.5, 0.92, r\"${\\rm Density~model}~({\\tilde c}_{\\rm W}=\"+f\"0)$ [N={fake_datapoints_SM_big.shape[0]}]\", fontsize=16, transform=ax.transAxes, ha=\"right\", va=\"top\", bbox=dict(facecolor='white', edgecolor='grey', pad=10.0))\n",
    "    ax.set_ylim([-0.7, 1.])\n",
    "plt.subplots_adjust(wspace=0)\n",
    "plt.savefig(f\"figures/EWK_ratio_at_SM.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
