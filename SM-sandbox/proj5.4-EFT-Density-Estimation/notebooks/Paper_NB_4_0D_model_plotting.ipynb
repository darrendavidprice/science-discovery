{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Plot a model with many observables (no external parameter dependence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will generate a large number of datapoints using our trained model, and compare them with our trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing standard library\n",
      "Importing python data libraries\n",
      "Importing third party libraries\n",
      "Importing custom backends\n"
     ]
    }
   ],
   "source": [
    "#  Required imports\n",
    "\n",
    "print(\"Importing standard library\")\n",
    "import os, sys, time\n",
    "\n",
    "print(\"Importing python data libraries\")\n",
    "import numpy as np\n",
    "from   matplotlib import pyplot as plt, colors\n",
    "\n",
    "print(\"Importing third party libraries\")\n",
    "import dill as pickle\n",
    "\n",
    "print(\"Importing custom backends\")\n",
    "sys.path.append(\"/Users/Ste/PostDoc/git-with-DP/SM-sandbox/proj5.4-EFT-Density-Estimation\")\n",
    "from backends.density_model    import DensityModel\n",
    "from backends.plot             import histo_to_line, plot_data, plot_ratio, plot_pull, get_ratio_1D\n",
    "from backends.stats            import whiten_axes, unwhiten_axes\n",
    "\n",
    "from backends import plot as plot, density_model as density_model, VBFZ_analysis as VBFZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Inputs config\n",
    "\n",
    "input_fname = \"../Data/SM_EWK_1M_rivet_output.pickle\"\n",
    "\n",
    "#    v4\n",
    "###  IF REGENERATING DATA MAKE SURE THAT TRANSFORMATIONS ARE OFF (AS MISSING OBSERVABLES)\n",
    "###    AND OBSERVABLE ORDER IS REVERSED\n",
    "#load_whitening_funcs = \".whitening_funcs_paper_0D_v4.pickle\"\n",
    "#load_model_dir       = \".EWK_density_model_paper_0D_v4\"\n",
    "#remove_observables   = [\"rap_jj\", \"pT_jj\", \"m_ll\", \"m_jj\", \"N_jets\", \"N_gap_jets\", \"Dy_j_j\", \"Dphi_j_j\"]\n",
    "\n",
    "#    v5\n",
    "###  IF REGENERATING DATA MAKE SURE THAT TRANSFORMATIONS ARE OFF (AS NO pT_jj)\n",
    "###    AND OBSERVABLE ORDER IS REVERSED\n",
    "#load_whitening_funcs = \".whitening_funcs_paper_0D_v5.pickle\"\n",
    "#load_model_dir       = \".EWK_density_model_paper_0D_v5\"\n",
    "#remove_observables   = [\"pT_jj\", \"m_ll\", \"Dy_j_j\", \"Dphi_j_j\"]\n",
    "\n",
    "#    v7\n",
    "###  IF REGENERATING DATA MAKE SURE THAT TRANSFORMATIONS ARE OFF (AS NO pT_jj)\n",
    "###    AND OBSERVABLE ORDER IS REVERSED\n",
    "#load_whitening_funcs = \".whitening_funcs_paper_0D_v7.pickle\"\n",
    "#load_model_dir       = \".EWK_density_model_paper_0D_v7\"\n",
    "#remove_observables   = [\"pT_jj\"]\n",
    "\n",
    "#    v8\n",
    "#   relatively wide, 30 gauss\n",
    "###  IF REGENERATING DATA MAKE SURE THAT TRANSFORMATIONS ARE OFF (AS NO pT_jj)\n",
    "###    AND OBSERVABLE ORDER IS REVERSED\n",
    "#load_whitening_funcs = \".whitening_funcs_paper_0D_v8.pickle\"\n",
    "#load_model_dir       = \".EWK_density_model_paper_0D_v8\"\n",
    "#remove_observables = [\"pT_jj\", \"N_jets\", \"N_gap_jets\", \"m_ll\", \"Dy_j_j\"]\n",
    "\n",
    "#    v9\n",
    "#   relatively wide, 50 gauss, first 4 obs trained\n",
    "###  IF REGENERATING DATA MAKE SURE THAT TRANSFORMATIONS ARE OFF (AS NO pT_jj)\n",
    "###    AND OBSERVABLE ORDER IS REVERSED\n",
    "#load_whitening_funcs = \".whitening_funcs_paper_0D_v10.pickle\"\n",
    "#load_model_dir       = \".EWK_density_model_paper_0D_v10\"\n",
    "#remove_observables = [\"pT_jj\", \"N_jets\", \"N_gap_jets\", \"m_ll\", \"Dy_j_j\"]\n",
    "\n",
    "tag = \"GQR1p0\"\n",
    "\n",
    "load_whitening_funcs = \".whitening_funcs_paper_0D_nominal.pickle\"\n",
    "remove_observables = [\"pT_jj\", \"N_jets\", \"N_gap_jets\", \"m_ll\", \"Dy_j_j\"]\n",
    "load_model_dir       = f\".EWK_density_model_paper_0D_{tag}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured with 7 observables: rap_ll, rap_jj, pT_ll, pT_j2, pT_j1, m_jj, Dphi_j_j\n"
     ]
    }
   ],
   "source": [
    "#  Configure VBFZ observables\n",
    "#\n",
    "VBFZ.configure(remove_observables)\n",
    "print(f\"Configured with {VBFZ.num_observables} observables: \" + \", \".join(VBFZ.observables))\n",
    "\n",
    "#  Configure plot functions with observable information\n",
    "#\n",
    "plot.int_observables   = VBFZ.int_observables\n",
    "plot.observable_limits = VBFZ.transformed_observable_limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading events from file ../Data/SM_EWK_1M_rivet_output.pickle\n",
      " -- Table created with 1000000 events\n",
      " -- filtering observable m_ll between 75 and 105\n",
      " -- 660799 events survived\n",
      " -- filtering observable pT_ll between 0 and 900\n",
      " -- 660766 events survived\n",
      " -- filtering observable theta_ll between 0 and 3.141592653589793\n",
      " -- 660766 events survived\n",
      " -- filtering observable rap_ll between 0 and 2.2\n",
      " -- 652255 events survived\n",
      " -- filtering observable m_jj between 150 and 5000\n",
      " -- 643177 events survived\n",
      " -- filtering observable pT_jj between 0 and 900\n",
      " -- 643177 events survived\n",
      " -- filtering observable theta_jj between 0 and 3.141592653589793\n",
      " -- 643177 events survived\n",
      " -- filtering observable rap_jj between 0 and 4.4\n",
      " -- 643177 events survived\n",
      " -- filtering observable pT_j1 between 40 and 1200\n",
      " -- 643054 events survived\n",
      " -- filtering observable pT_j2 between 40 and 1200\n",
      " -- 641867 events survived\n",
      " -- filtering observable Dy_j_j between 0 and 8.8\n",
      " -- 641867 events survived\n",
      " -- filtering observable Dphi_j_j between -3.141592653589793 and 3.141592653589793\n",
      " -- 641867 events survived\n",
      " -- filtering observable N_jets between 2 and 5\n",
      " -- 641867 events survived\n",
      " -- filtering observable N_gap_jets between 0 and 2\n",
      " -- 641867 events survived\n",
      " -- removing observable pT_jj\n",
      " -- removing observable N_jets\n",
      " -- removing observable N_gap_jets\n",
      " -- removing observable m_ll\n",
      " -- removing observable Dy_j_j\n",
      " -- removing observable theta_ll\n",
      " -- removing observable theta_jj\n",
      " -- ordering observables\n",
      "* Registered the following keys:\n",
      "    +-------------------------------------+\n",
      "    | Column | Name     | Type            |\n",
      "    +-------------------------------------+\n",
      "    | 0      | rap_ll   | <class 'float'> |\n",
      "    | 1      | rap_jj   | <class 'float'> |\n",
      "    | 2      | pT_ll    | <class 'float'> |\n",
      "    | 3      | pT_j2    | <class 'float'> |\n",
      "    | 4      | pT_j1    | <class 'float'> |\n",
      "    | 5      | m_jj     | <class 'float'> |\n",
      "    | 6      | Dphi_j_j | <class 'float'> |\n",
      "    +-------------------------------------+\n",
      "\n",
      "* Registered the following weights:\n",
      "    +-------------------------+\n",
      "    | Name   | Sum of weights |\n",
      "    +-------------------------+\n",
      "    | weight | 5.7155         |\n",
      "    +-------------------------+\n",
      "\n",
      "* Number of events       : 641867\n",
      "* Cross section per event: 0.0506539\n",
      "* Total cross section    : 0.2895143852053732 +/- 0.00036177091762935984 pb\n"
     ]
    }
   ],
   "source": [
    "#  Load and format the data\n",
    "#\n",
    "data_table = VBFZ.load_table(input_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading whitening functions from file .whitening_funcs_paper_0D_nominal.pickle\n",
      "Transforming data\n",
      "Projecting data onto latent space\n"
     ]
    }
   ],
   "source": [
    "#  Load whitening funcs if a file was provided\n",
    "#  -  this is faster when re-running with the same data and whitening settings later on\n",
    "\n",
    "print(f\"Loading whitening functions from file {load_whitening_funcs}\")\n",
    "whitening_funcs = pickle.load(open(load_whitening_funcs, \"rb\"))\n",
    "\n",
    "\n",
    "#  Separate data from weights\n",
    "true_data, true_data_weights = data_table.get_observables_and_weights()\n",
    "\n",
    "\n",
    "#  Transform data\n",
    "print(\"Transforming data\")\n",
    "transformed_data = VBFZ.transform_observables_fwd(true_data, data_table.keys)\n",
    "\n",
    "\n",
    "#  Whiten data\n",
    "print(\"Projecting data onto latent space\")\n",
    "white_data, _ = whiten_axes(transformed_data, data_table.types, whitening_funcs=whitening_funcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading density model from file .EWK_density_model_paper_0D_GQR0p1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Required entry 'learning_rate_evo_factor' not found in file '.EWK_density_model_paper_0D_GQR0p1/density_model.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-27d2752aacaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading density model from file {load_model_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdensity_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDensityModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_model_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/PostDoc/git-with-DP/SM-sandbox/proj5.4-EFT-Density-Estimation/backends/density_model.py\u001b[0m in \u001b[0;36mfrom_dir\u001b[0;34m(cls, dirname, verbose)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;34m\"\"\"Create a new instance from the data saved in the directory provided\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dflt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gaussians\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_observables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_conditions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_build\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PostDoc/git-with-DP/SM-sandbox/proj5.4-EFT-Density-Estimation/backends/density_model.py\u001b[0m in \u001b[0;36mload_from_dir\u001b[0;34m(self, dirname)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_initializer\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mget_from_dictionary\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bias_initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mget_from_dictionary\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"learning_rate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate_evo_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_from_dictionary\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"learning_rate_evo_factor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimiser\u001b[0m                \u001b[0;34m=\u001b[0m \u001b[0mget_from_dictionary\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"optimiser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m               \u001b[0;34m=\u001b[0m \u001b[0mget_from_dictionary\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"activation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PostDoc/git-with-DP/SM-sandbox/proj5.4-EFT-Density-Estimation/backends/density_model.py\u001b[0m in \u001b[0;36mget_from_dictionary\u001b[0;34m(dictionary, label)\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_from_dictionary\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Required entry '{label}' not found in file '{pfile_name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m         \u001b[0mmodel_files\u001b[0m                   \u001b[0;34m=\u001b[0m \u001b[0mget_from_dictionary\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto_load\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_files\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Required entry 'learning_rate_evo_factor' not found in file '.EWK_density_model_paper_0D_GQR0p1/density_model.pickle'"
     ]
    }
   ],
   "source": [
    "#  Load model\n",
    "#\n",
    "\n",
    "print(f\"Loading density model from file {load_model_dir}\")\n",
    "density_model = DensityModel.from_dir(load_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Generate a large number of datapoints at 0.\n",
    "#\n",
    "\n",
    "n_gen = 1000000\n",
    "\n",
    "print(f\"Generating {n_gen} fake datapoints\")\n",
    "start = time.time()\n",
    "fake_white_datapoints = density_model.sample(n_gen, [1.], n_processes=8)\n",
    "end = time.time()\n",
    "print(f\"{n_gen} datapoints generated in {int(end-start):.0f}s\")\n",
    "\n",
    "#  Unwhiten generated data\n",
    "#\n",
    "\n",
    "print(\"Unwhitening fake datapoints\")\n",
    "start = time.time()\n",
    "fake_transformed_datapoints = unwhiten_axes(fake_white_datapoints, whitening_funcs)\n",
    "fake_datapoints = VBFZ.transform_observables_back(fake_transformed_datapoints, data_table.keys)\n",
    "end = time.time()\n",
    "print(f\"{n_gen} datapoints unwhitened in {int(end-start):.0f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_observables = \"pT_j1\", \"pT_j2\", \"pT_jj\", \"pT_ll\", \"m_jj\", \"rap_jj\"\n",
    "\n",
    "VBFZ.obs_ticks [\"rap_jj\"] = [1, 2.5, 4]\n",
    "VBFZ.obs_ticklabels [\"rap_jj\"] = [\"1\", \"2.5\", \"4\"]\n",
    "\n",
    "log_axis_functions = (lambda x : x**(1./3.), lambda x : x*x*x)\n",
    "        \n",
    "        \n",
    "def get_bins_latent (obs, num_bins=20) :\n",
    "    #global int_observables, transformed_observable_limits  #  VBFZ-tag\n",
    "    transformed_observable_limits = VBFZ.transformed_observable_limits  #  NB-tag\n",
    "    observable_limits             = VBFZ.observable_limits  #  NB-tag\n",
    "    int_observables               = VBFZ.int_observables   #  NB-tag\n",
    "    if obs in int_observables :\n",
    "        obs_lims = observable_limits[obs]\n",
    "        #obs_lims = transformed_observable_limits[obs]\n",
    "        return np.linspace(obs_lims[0]-0.5, obs_lims[1]+0.5, 2+(obs_lims[1]-obs_lims[0]))\n",
    "    return np.linspace(-5, 5, num_bins+1)\n",
    "\n",
    "def get_bins_physical (obs, num_bins=20, base=np.e) :\n",
    "    #global int_observables, observable_limits  #  VBFZ-tag\n",
    "    observable_limits = VBFZ.observable_limits  #  NB-tag\n",
    "    int_observables   = VBFZ.int_observables   #  NB-tag\n",
    "    obs_lims = observable_limits[obs] \n",
    "    if obs in int_observables : \n",
    "        return np.linspace(obs_lims[0]-0.5, obs_lims[1]+0.5, 2+(obs_lims[1]-obs_lims[0]))\n",
    "    if obs in log_observables :\n",
    "        log_physical_limits = np.log(np.array(obs_lims) + 10) / np.log(base)\n",
    "        bins = np.exp(np.linspace(log_physical_limits[0], log_physical_limits[1], num_bins+1)*np.log(base)) - 10\n",
    "        if np.fabs(bins[0]) < 1e-15 : bins[0] = 0\n",
    "        return bins\n",
    "    return np.linspace(obs_lims[0], obs_lims[1], num_bins+1)\n",
    "            \n",
    "            \n",
    "def get_bins (obs, is_latent=False, num_bins=20) :\n",
    "    if is_latent :\n",
    "        return get_bins_latent (obs, num_bins=num_bins)\n",
    "    return get_bins_physical (obs, num_bins=num_bins)\n",
    "\n",
    "\n",
    "\n",
    "def get_obs_label (obs) :\n",
    "    return VBFZ.get_obs_label(obs)\n",
    "    \n",
    "def get_obs_ticks (obs, is_latent=False) :\n",
    "    #global int_observables  #  VBFZ-tag\n",
    "    int_observables = VBFZ.int_observables   #  NB-tag\n",
    "    if is_latent :\n",
    "        if obs not in int_observables : return np.array([-3, 0, 3])\n",
    "        return VBFZ.get_obs_ticks(obs)\n",
    "    return VBFZ.get_obs_ticks(obs)\n",
    "\n",
    "def get_obs_ticklabels (obs, is_latent=False) :\n",
    "    #global int_observables  #  VBFZ-tag\n",
    "    int_observables = VBFZ.int_observables   #  NB-tag\n",
    "    if is_latent :\n",
    "        if obs not in int_observables : return np.array([\"-3\", \"0\", \"3\"])\n",
    "        return VBFZ.get_obs_ticklabels(obs)\n",
    "    return VBFZ.get_obs_ticklabels(obs)\n",
    "\n",
    "\n",
    "def get_obs_for_2D_plot (observables) :\n",
    "    num_observables = len(observables)\n",
    "    obs_to_plot = []\n",
    "    for obs_idx_x, obs_x in enumerate(observables) :\n",
    "        if obs_idx_x == num_observables-1 : continue  #  Don't plot observable -1 on x axis\n",
    "        for obs_idx_y, obs_y in enumerate(observables) :\n",
    "            if obs_idx_y == 0         : continue   #  Don't plot observable 0 on y axis\n",
    "            if obs_idx_y <= obs_idx_x : continue   #  Don't plot above diagonal on y axis\n",
    "            obs_to_plot.append((obs_idx_x, obs_x, obs_idx_y, obs_y))\n",
    "    return obs_to_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_projections (datapoints, weights=None, label=\"\", savefig=\"\", is_latent=False, num_bins=20, vmin=1e-5) :\n",
    "    \"\"\"plot the 2D projections of the datapoints provided\"\"\"\n",
    "    \n",
    "    #global observables, num_observables, observable_limits, transformed_observable_limits, int_observables, log_observables   # VBFZ-tag\n",
    "    observables      , num_observables = VBFZ.observables      , VBFZ.num_observables    # NB-tag\n",
    "    observable_limits, int_observables = VBFZ.observable_limits, VBFZ.int_observables    # NB-tag\n",
    "    transformed_observable_limits = VBFZ.transformed_observable_limits    # NB-tag\n",
    "    #\n",
    "    #  If no weights provided then assume uniform\n",
    "    #\n",
    "    if type(weights) == type(None) :\n",
    "        weights = np.ones(shape=(datapoints.shape[0],))\n",
    "    #\n",
    "    #  Save the list of indices to plot (to make sure all loops are over consistent sets)\n",
    "    #\n",
    "    norm_const = {}\n",
    "    obs_to_plot = get_obs_for_2D_plot (observables)\n",
    "    for obs_idx_x, obs_x, obs_idx_y, obs_y in obs_to_plot :\n",
    "        bins_x, bins_y = get_bins(obs_x, is_latent=is_latent, num_bins=num_bins), get_bins(obs_y, is_latent=is_latent, num_bins=num_bins)\n",
    "        vals, _, _     = np.histogram2d(datapoints[:,obs_idx_x], datapoints[:,obs_idx_y], weights=weights, bins=(bins_x, bins_y))\n",
    "        norm_const[(obs_idx_x, obs_idx_y)] = np.nanmax(vals.flatten())\n",
    "    #\n",
    "    #  Make plot\n",
    "    #\n",
    "    fig = plt.figure(figsize=(20, 14))\n",
    "    for obs_idx_x, obs_x, obs_idx_y, obs_y in obs_to_plot :\n",
    "        xlo    = obs_idx_x / (num_observables-1)    #  Get axis x coordinates\n",
    "        xwidth = 1.        / (num_observables-1)\n",
    "        ylo     = (num_observables-obs_idx_y-1) / (num_observables-1)   #  Get axis y coordinates\n",
    "        yheight = 1.                            / (num_observables-1)\n",
    "        #\n",
    "        #  Create axis\n",
    "        #\n",
    "        ax = fig.add_axes([xlo, ylo, 0.95*xwidth, 0.95*yheight])\n",
    "        #\n",
    "        #  Format log axes\n",
    "        #\n",
    "        if not is_latent :\n",
    "            if obs_x in log_observables : ax.set_xscale(\"function\", functions=log_axis_functions )\n",
    "            if obs_y in log_observables : ax.set_yscale(\"function\", functions=log_axis_functions )\n",
    "        #\n",
    "        #  Draw axis ticks and labels\n",
    "        #\n",
    "        ax.set_xticks(get_obs_ticks(obs_x, is_latent=is_latent))\n",
    "        ax.set_yticks(get_obs_ticks(obs_y, is_latent=is_latent))\n",
    "        if obs_idx_y == num_observables-1 : \n",
    "            ax.get_xaxis().set_ticklabels(get_obs_ticklabels(obs_x, is_latent=is_latent))\n",
    "            ax.set_xlabel(get_obs_label(obs_x).replace(\"  [\",\"\\n[\"), fontsize=19, labelpad=20, va=\"top\", ha=\"center\")\n",
    "        else :\n",
    "            ax.get_xaxis().set_ticklabels([])\n",
    "        if obs_idx_x == 0 : \n",
    "            ax.get_yaxis().set_ticklabels(get_obs_ticklabels(obs_y, is_latent=is_latent))\n",
    "            ax.set_ylabel(get_obs_label(obs_y).replace(\"  [\",\"\\n[\"), fontsize=19, labelpad=20, rotation=0, va=\"center\", ha=\"right\")\n",
    "        else :\n",
    "            ax.get_yaxis().set_ticklabels([])\n",
    "        #\n",
    "        #  Format tick params\n",
    "        #\n",
    "        ax.tick_params(which=\"both\", right=True, top=True, direction=\"in\", labelsize=15)\n",
    "        #\n",
    "        #  Draw histogram\n",
    "        #\n",
    "        bins_x, bins_y = get_bins(obs_x, is_latent=is_latent, num_bins=num_bins), get_bins(obs_y, is_latent=is_latent, num_bins=num_bins)\n",
    "        _, _, _, patches = ax.hist2d(datapoints[:,obs_idx_x], datapoints[:,obs_idx_y], weights=weights/norm_const[(obs_idx_x, obs_idx_y)], bins=(bins_x, bins_y),\n",
    "                                  vmin=vmin, vmax=1, norm=colors.LogNorm(), cmap=\"inferno\")\n",
    "        #\n",
    "        #  Draw label\n",
    "        #\n",
    "        if (obs_idx_x==0) and (obs_idx_y==1) and len(label) > 0 :\n",
    "            ax.text(0, 1.2, label, weight=\"bold\", ha=\"left\", va=\"bottom\", transform=ax.transAxes, fontsize=21)\n",
    "    #\n",
    "    #  Draw colour bar\n",
    "    #\n",
    "    cbar_ax = fig.add_axes([0.76, 0.5, 0.03, 0.45])\n",
    "    cbar    = fig.colorbar(patches, cax=cbar_ax)\n",
    "    cbar_ax.tick_params(labelsize=14)\n",
    "    cbar   .set_ticks([1, 0.1, 0.01, 0.001, 0.0001, 1e-5])\n",
    "    cbar   .set_label(r\"$\\frac{p(x)}{{\\rm max}~p(x)}$\", fontsize=25, labelpad=50, rotation=0, va=\"center\")\n",
    "    #\n",
    "    #  Save and show plot\n",
    "    #\n",
    "    if len(savefig) > 0 :\n",
    "        plt.savefig(savefig, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "cmap_bwr  = cm.get_cmap('bwr', 256)\n",
    "newcolors = cmap_bwr(np.linspace(0, 1, 256))\n",
    "newcolors [math.ceil(256*2/6)-1:math.floor(256*4/6)-1] = np.array([68/256, 223/256, 68/256, 1])\n",
    "custom_colormap = ListedColormap(newcolors, name='BlueToRed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_2D_ratios (datapoints_num, datapoints_den, weights_num=None, weights_den=None, label=\"\", savefig=\"\", is_latent=False, num_bins=20) :\n",
    "    \n",
    "    #global observables, num_observables, observable_limits, transformed_observable_limits, int_observables, log_observables   # VBFZ-tag\n",
    "    observables      , num_observables = VBFZ.observables      , VBFZ.num_observables    # NB-tag\n",
    "    observable_limits, int_observables = VBFZ.observable_limits, VBFZ.int_observables    # NB-tag\n",
    "    transformed_observable_limits = VBFZ.transformed_observable_limits    # NB-tag\n",
    "    #\n",
    "    #  If no weights provided then assume uniform\n",
    "    #\n",
    "    if type(weights_num) == type(None) : weights_num = np.ones(shape=(datapoints_num.shape[0],))\n",
    "    if type(weights_den) == type(None) : weights_den = np.ones(shape=(datapoints_den.shape[0],))\n",
    "    #\n",
    "    #  Save the list of indices to plot (to make sure all loops are over consistent sets)\n",
    "    #\n",
    "    obs_to_plot = get_obs_for_2D_plot (observables)\n",
    "    #\n",
    "    #  Make plot\n",
    "    #\n",
    "    fig = plt.figure(figsize=(20, 14))\n",
    "    vmin = 1e-5\n",
    "    for obs_idx_x, obs_x, obs_idx_y, obs_y in obs_to_plot :\n",
    "        xlo    = obs_idx_x / (num_observables-1)    #  Get axis x coordinates\n",
    "        xwidth = 1.        / (num_observables-1)\n",
    "        ylo     = (num_observables-obs_idx_y-1) / (num_observables-1)   #  Get axis y coordinates\n",
    "        yheight = 1.                            / (num_observables-1)\n",
    "        #\n",
    "        #  Create axis\n",
    "        #\n",
    "        ax = fig.add_axes([xlo, ylo, 0.95*xwidth, 0.95*yheight])\n",
    "        #\n",
    "        #  Format log axes\n",
    "        #\n",
    "        if not is_latent :\n",
    "            if obs_x in log_observables : ax.set_xscale(\"function\", functions=log_axis_functions )\n",
    "            if obs_y in log_observables : ax.set_yscale(\"function\", functions=log_axis_functions )\n",
    "        #\n",
    "        #  Draw axis ticks and labels\n",
    "        #\n",
    "        ax.set_xticks(get_obs_ticks(obs_x, is_latent=is_latent))\n",
    "        ax.set_yticks(get_obs_ticks(obs_y, is_latent=is_latent))\n",
    "        if obs_idx_y == num_observables-1 : \n",
    "            ax.get_xaxis().set_ticklabels(get_obs_ticklabels(obs_x, is_latent=is_latent))\n",
    "            ax.set_xlabel(get_obs_label(obs_x).replace(\"  [\",\"\\n[\"), fontsize=19, labelpad=20, va=\"top\", ha=\"center\")\n",
    "        else :\n",
    "            ax.get_xaxis().set_ticklabels([])\n",
    "        if obs_idx_x == 0 : \n",
    "            ax.get_yaxis().set_ticklabels(get_obs_ticklabels(obs_y, is_latent=is_latent))\n",
    "            ax.set_ylabel(get_obs_label(obs_y).replace(\"  [\",\"\\n[\"), fontsize=19, labelpad=20, rotation=0, va=\"center\", ha=\"right\")\n",
    "        else :\n",
    "            ax.get_yaxis().set_ticklabels([])\n",
    "        #\n",
    "        #  Format tick params\n",
    "        #\n",
    "        ax.tick_params(which=\"both\", right=True, top=True, direction=\"in\", labelsize=15)\n",
    "        #\n",
    "        #  Draw histogram\n",
    "        #\n",
    "        bins_x, bins_y = get_bins(obs_x, is_latent=is_latent, num_bins=num_bins), get_bins(obs_y, is_latent=is_latent, num_bins=num_bins)\n",
    "        X, Y, ratio, ratio_err = plot.get_ratio_2D (datapoints_num[:,obs_idx_x], datapoints_num[:,obs_idx_y],\n",
    "                                                    datapoints_den[:,obs_idx_x], datapoints_den[:,obs_idx_y],\n",
    "                                                    bins_x, bins_y, weights1=weights_num, weights2=weights_den)            \n",
    "        im = ax.pcolormesh(X, Y, ratio.transpose()-1, cmap=custom_colormap, vmin=-0.3, vmax=0.3)\n",
    "        #\n",
    "        #  Draw label\n",
    "        #\n",
    "        if (obs_idx_x==0) and (obs_idx_y==1) and len(label) > 0 :\n",
    "            ax.text(0, 1.2, label, weight=\"bold\", ha=\"left\", va=\"bottom\", transform=ax.transAxes, fontsize=21)\n",
    "    #\n",
    "    #  Draw colour bar\n",
    "    #\n",
    "    cbar_ax = fig.add_axes([0.76, 0.5, 0.03, 0.45])\n",
    "    cbar    = fig.colorbar(im, cax=cbar_ax)\n",
    "    cbar_ax.tick_params(labelsize=14)\n",
    "    cbar   .set_ticks([-0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3])\n",
    "    cbar   .set_label(r\"$\\frac{p(x)}{{\\rm max}~p(x)}$\", fontsize=25, labelpad=50, rotation=0, va=\"center\")\n",
    "    #\n",
    "    #  Save and show plot\n",
    "    #\n",
    "    if len(savefig) > 0 :\n",
    "        plt.savefig(savefig, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_2D_ratios(fake_white_datapoints, white_data, weights_den=true_data_weights, is_latent=True, \n",
    "               label=\"Samples from density model / MG5 events (latent space)\",\n",
    "               savefig=f\"figures/paper0D_model/2D_ratios_latent_{tag}.pdf\")\n",
    "\n",
    "plot_2D_projections(white_data, weights=true_data_weights, is_latent=True, \n",
    "                    label=\"MG5 events (latent space)\",\n",
    "                    savefig=f\"figures/paper0D_model/2D_dist_MG5_latent_{tag}.pdf\")\n",
    "\n",
    "plot_2D_projections(fake_white_datapoints, is_latent=True, \n",
    "                    label=\"Samples from density model (latent space)\",\n",
    "                    savefig=f\"figures/paper0D_model/2D_dist_model_latent_{tag}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  black below cbar threshold\n",
    "\n",
    "\n",
    "plot_2D_ratios(fake_datapoints, true_data, weights_den=true_data_weights, is_latent=False, \n",
    "               label=\"Samples from density model / MG5 events (physical space)\",\n",
    "               savefig=f\"figures/paper0D_model/2D_ratios_physical_{tag}.pdf\")\n",
    "\n",
    "plot_2D_projections(true_data, weights=true_data_weights, is_latent=False, \n",
    "                    label=\"MG5 events (physical space)\",\n",
    "                    savefig=f\"figures/paper0D_model/2D_dist_MG5_physical_{tag}.pdf\",\n",
    "                    vmin=1e-4)\n",
    "\n",
    "plot_2D_projections(fake_datapoints, is_latent=False, \n",
    "                    label=\"Samples from density model (physical space)\",\n",
    "                    savefig=f\"figures/paper0D_model/2D_dist_model_physical_{tag}.pdf\",\n",
    "                    vmin=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_1D_projections (datapoints_num, datapoints_den, weights_num=None, weights_den=None, savefig=\"\", is_latent=False, num_bins=20, max_cols=7) :\n",
    "    \"\"\"plot the 1D projections of the datapoints provided\"\"\"\n",
    "    \n",
    "    #global observables, num_observables, observable_limits, transformed_observable_limits, int_observables, log_observables   # VBFZ-tag\n",
    "    observables      , num_observables = VBFZ.observables      , VBFZ.num_observables    # NB-tag\n",
    "    observable_limits, int_observables = VBFZ.observable_limits, VBFZ.int_observables    # NB-tag\n",
    "    transformed_observable_limits = VBFZ.transformed_observable_limits    # NB-tag\n",
    "    #\n",
    "    #  If no weights provided then assume uniform\n",
    "    #\n",
    "    if type(weights_num) == type(None) : weights_num = np.ones(shape=(datapoints_num.shape[0],))\n",
    "    if type(weights_den) == type(None) : weights_den = np.ones(shape=(datapoints_den.shape[0],))\n",
    "    #\n",
    "    #  Calculate out plot dimensions and create figure\n",
    "    #\n",
    "    num_cols = np.min([max_cols, num_observables])\n",
    "    num_rows = math.ceil(num_observables/num_cols)\n",
    "    fig = plt.figure(figsize=(2*num_cols, 6*num_rows))\n",
    "    #\n",
    "    #  Loop over subplots\n",
    "    #\n",
    "    axes1, axes2 = [], []\n",
    "    ymins, ymaxs = [], []\n",
    "    for row_idx in range(num_rows) :\n",
    "        for col_idx in range(num_cols) :\n",
    "            obs_idx = num_cols*row_idx + col_idx\n",
    "            if obs_idx >= num_observables : continue\n",
    "            observable = observables[obs_idx]\n",
    "            #\n",
    "            #  Get axis co-ordinates\n",
    "            #\n",
    "            xlo, xwidth  = col_idx/num_cols, 1./num_cols\n",
    "            ylo, yheight = 1. - (1+row_idx)/num_rows, 1./num_rows\n",
    "            #\n",
    "            #\n",
    "            #  Get values of distributions\n",
    "            #\n",
    "            #  get binning\n",
    "            bins = get_bins(observable, is_latent=is_latent, num_bins=num_bins)\n",
    "            #  numerator histo values\n",
    "            hvals_num, _ = np.histogram(datapoints_num[:,obs_idx], bins=bins, weights=weights_num            )\n",
    "            herrs_num, _ = np.histogram(datapoints_num[:,obs_idx], bins=bins, weights=weights_num*weights_num)\n",
    "            herrs_num    = np.sqrt(herrs_num)\n",
    "            hvals_num, herrs_num = hvals_num/np.sum(weights_num), herrs_num/np.sum(weights_num)\n",
    "            #  denominator histo values\n",
    "            hvals_den, _ = np.histogram(datapoints_den[:,obs_idx], bins=bins, weights=weights_den            )\n",
    "            herrs_den, _ = np.histogram(datapoints_den[:,obs_idx], bins=bins, weights=weights_den*weights_den)\n",
    "            herrs_den    = np.sqrt(herrs_den)\n",
    "            hvals_den, herrs_den = hvals_den/np.sum(weights_den), herrs_den/np.sum(weights_den)\n",
    "            #  histograms expressed as lines\n",
    "            plot_x, plot_y_num, plot_ey_num = plot.histo_to_line(bins, hvals_num, herrs_num)\n",
    "            _     , plot_y_den, plot_ey_den = plot.histo_to_line(bins, hvals_den, herrs_den)\n",
    "            #\n",
    "            #  Create absolute distribution plot (top panel of each observable)\n",
    "            #\n",
    "            ax1 = fig.add_axes([xlo, ylo+0.6*yheight, 0.95*xwidth, 0.38*yheight])\n",
    "            ax1.plot(plot_x, plot_y_num, \"-\", color=\"k\"      , linewidth=2, label=\"MG5 events\")\n",
    "            ax1.fill_between(plot_x, plot_y_num-plot_ey_num, plot_y_num+plot_ey_num, color=\"lightgrey\", alpha=1)\n",
    "            ax1.plot(plot_x, plot_y_den, \"-\", color=\"darkred\", linewidth=2, label=\"Samples from density model\")\n",
    "            ax1.fill_between(plot_x, plot_y_den-plot_ey_den, plot_y_den+plot_ey_den, color=\"red\", alpha=0.2)\n",
    "            ax1.set_yscale(\"log\")\n",
    "            #\n",
    "            # Save ymin, ymax and top axis for this observable\n",
    "            #\n",
    "            ymin, ymax = np.min([plot_y_num-plot_ey_num, plot_y_den-plot_ey_den]), np.max([plot_y_num+plot_ey_num, plot_y_den+plot_ey_den])\n",
    "            ymins.append(ymin)\n",
    "            ymaxs.append(ymax)\n",
    "            axes1.append(ax1)\n",
    "            #\n",
    "            #  Create ratio plot (bottom panel of each observable) and save it\n",
    "            #\n",
    "            ax2 = fig.add_axes([xlo, ylo+0.2*yheight, 0.95*xwidth, 0.38*yheight])\n",
    "            ax2.axhline(0, c=\"darkred\", linewidth=2)\n",
    "            ax2.fill_between(plot_x, -plot_ey_den/plot_y_den, plot_ey_den/plot_y_den, color=\"red\", alpha=0.2)\n",
    "            ax2.plot(plot_x, (plot_y_num-plot_y_den)/plot_y_den, c=\"k\", linewidth=2)\n",
    "            ax2.fill_between(plot_x, (plot_y_num-plot_ey_num-plot_y_den)/plot_y_num, (plot_y_num+plot_ey_num-plot_y_den)/plot_y_num, color=\"lightgrey\", alpha=0.5)\n",
    "            axes2.append(ax2)\n",
    "            #\n",
    "            #  Set ylim and draw horizontal reference lines\n",
    "            #\n",
    "            ax2.set_ylim([-0.12, 0.12])\n",
    "            for h in [-0.1, -0.05, 0.05, 0.1] :\n",
    "                ax2.axhline(h, linestyle=\"--\", c=\"grey\", linewidth=0.5)\n",
    "            #  \n",
    "            #  Set x limits and scale\n",
    "            #  \n",
    "            ax1.set_xlim([bins[0], bins[-1]])\n",
    "            ax2.set_xlim([bins[0], bins[-1]])\n",
    "            if not is_latent :\n",
    "                if observable in log_observables :\n",
    "                    ax1.set_xscale(\"function\", functions=log_axis_functions )\n",
    "                    ax2.set_xscale(\"function\", functions=log_axis_functions )\n",
    "            #\n",
    "            #  Set axis ticks\n",
    "            #   \n",
    "            if col_idx > 0 :\n",
    "                ax1.get_yaxis().set_ticklabels([])\n",
    "                ax2.get_yaxis().set_ticklabels([])\n",
    "            ax1.set_xticks(get_obs_ticks(observable, is_latent=is_latent))\n",
    "            ax2.set_xticks(get_obs_ticks(observable, is_latent=is_latent))\n",
    "            ax1.get_xaxis().set_ticklabels([])\n",
    "            ax2.get_xaxis().set_ticklabels(get_obs_ticklabels(observable, is_latent=is_latent))\n",
    "            #   \n",
    "            #  Set axis labels\n",
    "            #   \n",
    "            ax2.set_xlabel(get_obs_label(observable), fontsize=19, labelpad=20)\n",
    "            if col_idx == 0 : \n",
    "                ax1.set_ylabel(\"Normalised\\nentries\", fontsize=19, labelpad=75, rotation=0, va=\"center\")\n",
    "                ax2.set_ylabel(\"Ratio to\\ndensity\\nmodel\", fontsize=19, labelpad=65, rotation=0, va=\"center\")\n",
    "                ax2.set_yticks     ([-0.1, -0.05, 0, 0.05, 0.1])\n",
    "                ax2.set_yticklabels([r\"$-10\\%$\", r\"$-5\\%$\", r\"$0$\", r\"$+5\\%$\", r\"$+10\\%$\"])\n",
    "            #  \n",
    "            #  Set tick params\n",
    "            #  \n",
    "            ax1.tick_params(which=\"both\", right=True, top=True, direction=\"in\", labelsize=15)\n",
    "            ax2.tick_params(which=\"both\", right=True, top=True, direction=\"in\", labelsize=15)\n",
    "    #\n",
    "    #  Set consistent axis y lims\n",
    "    #\n",
    "    ymin, ymax = np.min([y for y in ymins if y > 0])/2., 2.*np.max(ymaxs)\n",
    "    for ax in axes1 :\n",
    "        ax.set_ylim([ymin, ymax])\n",
    "    #\n",
    "    #  Set y-axis ticks and legend\n",
    "    #\n",
    "    axes1[0].legend(loc=(0, 1.05), frameon=True, edgecolor=\"white\", facecolor=\"white\", ncol=2, fontsize=17)\n",
    "    #\n",
    "    #  Save and show figure\n",
    "    #\n",
    "    if len(savefig) > 0 :\n",
    "        plt.savefig(savefig, bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_1D_projections(true_data, fake_datapoints, weights_num=true_data_weights, is_latent=False,\n",
    "                    savefig=f\"figures/paper0D_model/1D_dist_physical_{tag}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_1D_projections(white_data, fake_white_datapoints, weights_num=true_data_weights, is_latent=True,\n",
    "                    savefig=f\"figures/paper0D_model/1D_dist_latent_{tag}.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
