{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input  = 1\n",
    "n_output = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"My Discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 8)                 16        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 169\n",
      "Trainable params: 169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"My Discriminator\")\n",
    "\n",
    "model.add(Dense(8, activation=\"sigmoid\", input_shape=(n_input,)))\n",
    "model.add(Dense(8, activation=\"sigmoid\"))\n",
    "model.add(Dense(8, activation=\"sigmoid\"))\n",
    "\n",
    "model.add(Dense(n_output, activation=\"linear\"))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 10, 11)\n",
    "\n",
    "y = 20 + np.multiply(x, x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VFX+x/H3yaQnkE4gBRIgEAihhmYAaSo2ioKKSokoirrq/mzYFncXLCuiqMhKEXFF6YoiYqVKr6H3IAnpISE9mcz5/TFDiJhQ0iYZvq/nyZPJvefO/R7BDydn7j1Xaa0RQghhu+ysXYAQQoiaJUEvhBA2ToJeCCFsnAS9EELYOAl6IYSwcRL0Qghh464Y9EqpT5VSKUqp/eXse1YppZVSvpaflVLqA6XUcaVUrFKqc00ULYQQ4updzYj+M2DQpRuVUsHAzcAfZTbfCoRZvsYDM6teohBCiKq4YtBrrdcDGeXseg94ASh7x9UQ4HNttgXwVEo1qZZKhRBCVIp9ZQ5SSg0BErTWe5VSZXcFAmfK/Bxv2ZZ4uffz9fXVISEhlSlFCCGuWzt37kzTWvtdqd01B71SyhV4GfO0TaUppcZjnt6hadOm7NixoypvJ4QQ1x2l1OmraVeZq25aAKHAXqVUHBAE7FJKNQYSgOAybYMs2/5Caz1Lax2ltY7y87viP0hCCCEq6ZqDXmu9T2vdSGsdorUOwTw901lrnQR8C4y2XH3TA8jSWl922kYIIUTNuprLK78CNgOtlVLxSqlxl2m+CjgJHAdmA49XS5VCCCEq7Ypz9FrrkVfYH1LmtQaeqHpZUFxcTHx8PAUFBdXxdqKWODs7ExQUhIODg7VLEUJYVOqqm9oQHx9PgwYNCAkJ4ZIre0QdpbUmPT2d+Ph4QkNDrV2OEMKizi6BUFBQgI+Pj4R8PaKUwsfHR34LE6KOqbNBD0jI10PyZyZE3VOng14IIUTVSdBXIDMzk48//tjaZTB27FiWLl0KwIYNG4iIiKBjx47k5+dbuTIhRJXNu938VcMk6CtwuaA3Go21XI3ZggULeOmll9izZw8uLi5WqUEIUf9I0Fdg4sSJnDhxgo4dO/L888+zdu1aevfuzeDBg2nbti1xcXG0a9eutP3UqVN5/fXXAThx4gSDBg2iS5cu9O7dm8OHD//l/V9//XVGjRpFz549CQsLY/bs2YD5ypUnn3yS1q1bM3DgQFJSUgCYM2cOixcv5rXXXuOBBx6o+f8AQgibUWcvryzrn98d4ODZ89X6nm0DGjLpzogK97/11lvs37+fPXv2ALB27Vp27drF/v37CQ0NJS4ursJjx48fz3//+1/CwsLYunUrjz/+OL/99ttf2sXGxrJlyxZyc3Pp1KkTt99+O1u2bOHIkSMcPHiQ5ORk2rZty0MPPcTDDz/Mxo0bueOOOxg+fHiV+y+EuH7Ui6CvK7p163bF68NzcnLYtGkTI0aMKN1WWFhYbtshQ4bg4uKCi4sL/fr1Y9u2baxfv56RI0diMBgICAigf//+1doHIUTdEaOSAZhXw+epF0F/uZF3bXJzcyt9bW9vj8lkKv35wrXjJpMJT0/P0t8ELufSSxHl0kQhRE2QOfoKNGjQgOzs7Ar3+/v7k5KSQnp6OoWFhaxcuRKAhg0bEhoaypIlSwDznPvevXvLfY8VK1ZQUFBAeno6a9eupWvXrvTp04dFixZRUlJCYmIia9asqf7OCSGuKxL0FfDx8SE6Opp27drx/PPP/2W/g4MD//jHP+jWrRs33XQT4eHhpfsWLFjA3Llz6dChAxEREaxYsaLcc7Rv355+/frRo0cPXnvtNQICAhg2bBhhYWG0bduW0aNH07NnzxrroxDi+qDM65BZV1RUlL70wSOHDh2iTZs2Vqqo5r3++uu4u7vz3HPPWbuUamfrf3ZCVJeYz6IAmDe2cg9eUkrt1FpHXamdjOiFEMLG1YsPY23RhWvuhRCipsmIXgghbJwEvRBC2DgJeiGEsHG2FfS1tBKcEELUJ7YV9NWoKssU33bbbWRmZlb63O7u7pfdX1eWUBZC1A8S9BWoyjLFq1atwtPTsybKAiTohbAVrQvycCyzlEpNkaCvwJWWKQYYOnQoXbp0ISIiglmzZpUeGxISQlpaGnFxcbRp04ZHHnmEiIgIbr755nIfGHLq1Cl69uxJZGQkr776aun2nJwcBgwYQOfOnYmMjCy9w/bS2ipqJ4Sow1KP8Pfks9yXkVrjp7ridfRKqU+BO4AUrXU7y7Z3gDuBIuAEEKO1zrTsewkYB5QAT2mtf6xylT9MhKR9V26XFGv+fjXz9I0j4da3Ktx9pWWKAT799FO8vb3Jz8+na9eu3H333fj4+PzpfY4dO8ZXX33F7Nmzueeee1i2bBkPPvjgn9o8/fTTTJgwgdGjRzNjxozS7c7Oznz99dc0bNiQtLQ0evToweDBg/9Sm9FoLLedLJImRB1lLIRl4yhSdqzw9KFfDZ/uakb0nwGDLtn2M9BOa90eOAq8BKCUagvcB0RYjvlYKWWotmqt7NJlij/44AM6dOhAjx49OHPmDMeOHfvLMaGhoXTs2BGALl26lLuO/e+//87IkSMBGDVqVOl2rTUvv/wy7du3Z+DAgSQkJJCcnPyX46+2nRCijvhtMiTt41PfRmTZ1/x9q1c8g9Z6vVIq5JJtP5X5cQtw4UkYQ4CFWutC4JRS6jjQDdhcpSovM/L+kwsj+Zjvq3S6ipRdpnjt2rX88ssvbN68GVdXV/r27Vu6VHFZTk5Opa8NBkOFz3otb/S9YMECUlNT2blzJw4ODoSEhJR7jqttJ4SoA06ug00fojuPZXnGWrwoqfFTVscc/UPAD5bXgcCZMvviLdvqnSstU5yVlYWXlxeurq4cPnyYLVu2VPpc0dHRLFy4EDCHdtlzNGrUCAcHB9asWcPp06fLra2idkKIOiYvA75+DHxasrh5FBnKxPkirxo/bZWCXin1CmAEFlypbTnHjldK7VBK7UhNrfkPI67VlZYpHjRoEEajkTZt2jBx4kR69OhR6XNNnz6dGTNmEBkZSUJCQun2Bx54gB07dhAZGcnnn39euhTypbVV1E4IUYdoDSufgdxUTg96gzd3TseY2xLT+fY1fuqrWqbYMnWz8sKHsZZtY4FHgQFa6zzLtpcAtNZvWn7+EXhda33ZqZtqW6a4hqduxNWRZYqFKMfuBbDicYr7/YN+p7eSaTyJd2YULbx31PgyxZX6FEApNQh4AbjxQshbfAt8qZSaBgQAYcC2ypyjUiTghRB1UfoJ+OEFTM16cXdcEVkcYoD/E5y3m1Mrp7/i1I1S6ivMH6a2VkrFK6XGAR8BDYCflVJ7lFL/BdBaHwAWAweB1cATWuua/6RBCCHqqpJiWD4ebWfgCeMITpqWEOLamfdve7TWSriaq25GlrN57mXaTwGmVKUoIYSwGevfgYQdfODzEuuMy3B1dmT2bW/X6n0ucmesEELUlD+2oNe/wzqXgczIz8TgGsdrPV+isVvjWi1Dgl4IIWpCQRamZY+QbNeIv+XdhFvjn7kx6EYGtxhc66XYVNDHrI4hZnWMtcsQQgiKvnsOnRXPkwWPEhz5G64OzkzqOckqS5PYVNBb24Xlhc+ePcvw4cPLbdO3b18uvZT0Uu+//z55eRcvZqrqsscVkeWQhagZOTsW4nhgMR+VDKNlPwN/5B7i5e4v4+fqZ5V6JOhrQEBAAEuXLq308ZcGfU0ve1wRCXohrl1GwnFY+X/s0mE0GvowPyXOZ2DTgdwWepvVapKgr8DEiRP/tJLk66+/ztSpU69qSeC4uDjatTPfW5afn899991HmzZtGDZs2J/WupkwYQJRUVFEREQwadIkwLxQ2tmzZ+nXrx/9+pnXtLuw7DHAtGnTaNeuHe3ateP9998vPZ8shyyE9aVk5nLm09GgTRQO/phvEqfj7uDOqz1etepqsjW/bFo1eHvb2xzOOHzFdhfaXM08fbh3OC92e7HC/ffeey/PPPMMTzzxBACLFy/mxx9/rHDp4Ir+EGfOnImrqyuHDh0iNjaWzp07l+6bMmUK3t7elJSUMGDAAGJjY3nqqaeYNm0aa9aswdfX90/vtXPnTubNm8fWrVvRWtO9e3duvPFGvLy8ZDlkIawsMSuflR+/yCMlBzjeayr7HPZwMP0gU2+cio+Lz5XfoAbJiL4CnTp1IiUlhbNnz7J37168vLwIDg6+5iWB169fXxq47du3p337i+taLF68mM6dO9OpUycOHDjAwYMHL1vTxo0bGTZsGG5ubri7u3PXXXexYcMGQJZDFsKa4s/l8Y+Pv2Bs4ZdkhNxBSefezNw7k0Ehg7gl5BZrl1c/RvSXG3mXdWEkP2/QvGo574gRI1i6dClJSUnce++9QPUtCXzq1CmmTp3K9u3b8fLyYuzYsVVaWliWQxbCOk6n5/LQrHXMLXwX7e5Pg+Hv8eiaJ2jo2JCXu798+YMbR9ZKjTKiv4x7772XhQsXsnTpUkaMGAFc+5LAffr04csvvwRg//79xMaan4J1/vx53Nzc8PDwIDk5mR9++KH0mIqWSO7duzfffPMNeXl55Obm8vXXX9O7d++r7o8shyxE9TqRmsO9n2zh8cI5NCMJx+GzmHV8CYczDjOp5yS8nGt+CeKrUS9G9NYSERFBdnY2gYGBNGnSBDAvHXznnXcSGRlJVFTUFZcEnjBhAjExMbRp04Y2bdrQpUsXADp06ECnTp0IDw8nODiY6Ojo0mPGjx/PoEGDCAgIYM2aNaXbO3fuzNixY+nWrRsADz/8MJ06dSp3mqY806dP5/777+ftt99myJAhpdsr6lPZ5ZBvvfVWXnzxxWvquxC27GhyNvfP3kpf0xbu5lfo9XcONvRh9obZ3NH8Dvo37W/tEktd1TLFNa26limu7qkbUTmyTLGwdQfPnufBuVvxV+dYaf8CBq+mFI1dxb2rR5FVmMXXQ77Gw8mjxuuo0WWK6yoJeCFETdsXn8WDc7fiaq9Y1vh/GBIL4O65zDwwl+OZx5kxYEathPy1kDl6IYS4Srv+OMf9c7bg7mTPqu77cT2zHga9yT5dwKf7P2Voy6H0Cepj7TL/ok4HfV2YVhLXRv7MhK3aHpfBqDlb8XZzZPndHnhtfgNa305Bh/t45fdX8HPx44WuL1i7zHLV2aB3dnYmPT1dgqMe0VqTnp6Os7OztUsRolptOpHG6Lnb8PdwZtFDHfH/6Qlw8YLBHzBj78ecyjrFv274Fw0cG1i71HLV2Tn6oKAg4uPjqYsPDhcVc3Z2JigoyNplCFFt1h9N5ZHPd9DU25UFj3Sn0YZ/QOoheHAZu3PPMP/AfEa0GsENgTdYu9QK1dmgd3BwIDQ01NplCCGuY78dTuax/+2iRSN3vhjXDZ/E9bDtE+g+gfyQaF79djhN3JrwbNSz1i71sups0AshRK2Yd7v5e8z3f9q8en8Sf/tqF+GNG/K/cd3wNGXBN49Do7Yw8HU+2DWdP7L/YO7Nc3FzcKv9uq9BnZ2jF0IIa/lu71me+HIX7QI9+OLh7ni6OMC3T0JBFtw9h+3p+/ji0BeMDB9JtybdrF3uFcmIXgghyli+K57nluylSzMv5sV0w93JHrbPhaOrYdBb5HmH8tq3dxHcIJhnOj9j7XKvigS9EEJYLN5+hheXx9Ij1Ie5Y6NwdbSH1CPw4yvQYgB0e5Rp297gbM5Z5g2ah6uDq7VLvioydSOEEMD/tpzmhWWx9Grpy6dju5pD3lgEyx4GR1cY+jGbk7ay6MgiHmz7IF38u1i75Kt2xaBXSn2qlEpRSu0vs81bKfWzUuqY5buXZbtSSn2glDqulIpVSnWu+J2FEKKMebdf/GC0ln16rj2vfbOf/uGNmD06ChdHg3nHmsmQFAuDPyTHyZ1JmyYR0jCEpzo9ZZU6K+tqRvSfAYMu2TYR+FVrHQb8avkZ4FYgzPI1HphZPWUKIUT101rTNz2cf6X04pYIf/77YBecHSwhf3Id/P4BdImB8NuZumMqyXnJTO41GWf7+nVT4BWDXmu9Hsi4ZPMQYL7l9XxgaJntn2uzLYCnUqpJdRUrhBDVpcho4vmlscSl9ce/4R4+ur8zjvaWSMzLgK8fA58WcMsUNiZsZNmxZYyJGEMHvw7WLbwSKjtH76+1TrS8TgL8La8DgTNl2sVbtv2FUmq8UmqHUmqH3P0qhKhN5wuKeeiz7SzdGU+Iz1raNPkaB4MlDrWGlc9AbgrcPYfzlDBp0yRaeLTgiY5PWLfwSqryh7HavBjNNS9Io7WepbWO0lpH+fn5VbUMIYS4Kmcz8xkxczNbTqbzn+HtCfVbw5+esLnnSzi4Avq/CgGdeHvb26TnpzOl1xScDE4Vvm9dVtmgT74wJWP5nmLZngAEl2kXZNkmhBBWtz8hi6EzfudsZj6fxXTjnqjgPzfIOAk/vADNesENT7H2zFq+PfEt4yLHEeEbYZ2iq0Flg/5bYIzl9RhgRZntoy1X3/QAsspM8QghhNWsOZLCvZ9sxt5OsWRCT3qF+f65QUkxLHsE7Axw1ydkFmXzz83/pJVXKx5r/5h1iq4mV7xhSin1FdAX8FVKxQOTgLeAxUqpccBp4B5L81XAbcBxIA+IqYGahRDimny59Q9eW7Gf1v4NmBfTFf+G5Vw1s/4dSNgBw+eBRxBvrn+RzIJMZg6ciYPBofaLrkZXDHqt9cgKdg0op60G6uenFUIIm2Myad756Qgz156gb2s/Prq/s3lJg0u0LMg3B32HkdDuLn45/QurTq3i8Y6PE+4dboXKq5csgSCEqBNiVDIA1fXk50JjCc8tieW7vWe5v3tT/jU4AnvDJbPVBVk0LyxgfFoSeATDrf8hoyCDf2/5N2282/Bw5MPVVI11SdALIWxOZl4R4z/fyba4DF68pRWPdXREnfoN0o5B2lHL92OQk8RrgBHgrtng3JApa5/lfNF55tw8Bwe7+j1lc4EEvRDCNhTlQvpx0uIO8P2adYwpOM1s/3N4/H4a1uVfbOfsAb6toeVA8G3JB7GfcNrRiXebdmf1qdX8dPonnu78NGFeYdbrSzWToBdC1B9aQ3aSZVR+FNKPXxyhZ5nv1fQFRqEoahiMc6Nw8B0IvmHgEwa+rcDNl7IXzu8+vgCAtPw0Jm+dTKRvJGMjxlqhczVHgl4IUfcYC83XtF8I9AtTLWnHoCj7YjsHN3OIN+3JMdNdfBSryHQLYdKYO2nexLfi97+ERvOvzf8ivzifydGTsbezrWi0rd4IIeqtXtlZdMnLgekdIfM0aNPFnQ0DzYHecaR5VO5rGZ03aAJK8enGU/z7+4O0D/Jk7pgofN2v7Q7WDEzsPLOGZ7s8S3PP5tXcM+uToBdCWN/BbxmXnkKSvQOEdoDIERcD3aclOLmXe1iJSTN55QHm/R7HzW39mX5fp4tLDF+FvOI8sijhD4x09OvIqLajqqtHdYoEvRDCutKOwzePc9LRiTebBDH7nvlXPgbILyrhmUW7+fFAMjHRIbx6e1sMduqyx+QV57EndQ/bk7azPWk7B9IOYFRGDBr+Hf1vDHZX/49EfSJBL4SwnqJcWDwKDA7M8PHBqK5uVZa0nEIenr+DvfGZ/OOOtjzUK7TcdvnGfPakXAz2/Wn7MWoj9sqeCN8IYtrFsDb2M9xRhHiEVGPH6hYJeiGEdWgN3z0DKYfgwWVkbHzxqg47kZpDzLztpGQX8N8Hu3BLROPSfQXGAvam7i0N9ti0WIwmIwZlIMIngjERY+jauCudGnUqfd7r7tjPa6R7dYkEvRDCOrbPgX2Lod8r0HIAbLzyIdtOZTD+fzswKMVXj/SgbaAr25O2sy1pmznYU2MpNhVjp+yI8IlgVNtRdGvcjU6NOuHm4FbzfaqjJOiFELXvzHZY/RKE3Qy9n7uqQ77be5Znl+ykkV8Sd3TL54ODXxK7LpYiUxF2yo423m14oM0DdG3clc6NOuPuWP4HuNcjCXohRO3KTYMlY6BhExj2CdhVPC9fVFJEbGosM7f8xKazW3FueYYsVcyXRxXh3uGMDB9pnorx70RDx4a12In6RYJeCFF7TCWw9CFz2I/7CVy9/7wbze6U3WxL3Mb25O3sTdlLQUkBWis83YMZ3PpeejTpRpfGXSTYr4EEvRCi9qyZAqfWweAPIaBj6WajyUgcxWRgYvQPowEI82xFQ2MvzsU3YUznfrwyKAq7K1w+KconQS+EqB1HfoAN70KnUdB5dOlmrTVvbH2DNGXCV9vxat9pBLtG8PevjhGXlM2/h7Tj/u5NrVh4/SdBL4SoeRknYfmj0KQD3Db1T7s+if2EJUeX0FgbCMKeIKdujJ2zjaz8YuaMiaJf60ZWKtp2VPaZsUIIcXWK82HRaPOKkfd8Dg4XH+O3/NhyZuyZweAWgwnEQEZuKMNnbqJEaxY/1rN2Qr5xpPnLhknQCyFqjtbw/bOQvM/8YA+vkNJd6+PX86/N/yI6IJrXb3idpMxOxJ4ZRYCnC18/Hk1EgIf16rYxEvRCiJqzaz7sWQB9XoBWN5dujk2N5dm1zxLuHc4b0e8wacVhDicNw9M1jiUTehLg6WLFom2PzNELIWpGwi5Y9Ty06A99J5ZujsuK44lfn8DP1Y9Xukxl9Nw97E84T1PvDYT6/UZD56esWLRtkhG9EKL65WXA4jHg7g93zQHLqpBp+Wk89stj2Ck7xoRO4YFPDnA6PY/Zo6No0T4ZuyYRVi7cNlUp6JVSf1dKHVBK7VdKfaWUclZKhSqltiqljiulFimlHKurWCFEPWAqgeWPQE4S3DMf3HwAyCnKYcIvE8goyKCH6wu8uOgswd6ufP+33tzU1t/KRdu2Sk/dKKUCgaeAtlrrfKXUYuA+4DbgPa31QqXUf4FxwMxqqVYIUfetfweO/wK3T4PALgAUlxTzzNpnOHbuGEGFT7JoH4zsFsykOyNwdrDuGvDzBs2z6vlrQ1WnbuwBF6WUPeAKJAL9gaWW/fOBoVU8hxCivjj2C6x9CzqMhKiHADBpE6/+/ipbE7dil34Px/8IZOqIDrx5V3urh/z1otIjeq11glJqKvAHkA/8BOwEMrXWRkuzeCCwylUKIeq+c6dh+cPgH2EezSvzcgXTdkxj1alVFKUOwpcbWPB4Z9o0kXVqalOlR/RKKS9gCBAKBABuwKBrOH68UmqHUmpHampqZcsQQtQFxQWweLR5fv6ez8HR/FCP2Xs/Y/7B+RRl9KRvo3tZ8WS0hLwVVGXqZiBwSmudqrUuBpYD0YCnZSoHIAhIKO9grfUsrXWU1jrKz8+vCmUIIazuhxcgcQ8M+y/4tABgzq7lfLDnXYzZ7Xi2y/P8d1QXGjo7WLnQ61NVrqP/A+ihlHLFPHUzANgBrAGGAwuBMcCKqhYphKjDdn9hvjGq198h/HYA/rNuJZ+f/BeG4ubMvW0aNzRvYuUir29VmaPfqpRaCuwCjMBuYBbwPbBQKTXZsm1udRQqhKiDEmPNSxyE9IZ+r1JQXMLfl69iQ+4/cVb+LBk+h1Bv+Y3d2pTW2to1EBUVpXfs2GHtMoQQ1yL/HMzqC8ZCeHQDpwtdeeTLn0lw+Q/uTg4sH7qQwAYykq9JSqmdWuuoK7WTJRCEENfOZIKvH4OseBi7ip9Ol/Dssh8h4CPcnDULbp8rIV+HSNALIa7dxmlwdDUlt7zNf/Y35JMNm/FtOR+TYxYzb5pFS6+W1q5QlCFBL4S4aJ75w1Rivq+4zYk1sGYKBa2HMXpve7bFHSMscgXJxlNM6zONLv5daqdWcdUk6IUQVy8rHpaNI69hC245fjdpRVn0jd7IzoydvNz9ZQY2G2jtCkU5ZPVKIcTVMRaiF4+hqDCfO1MfxcG1AQ/ccpSdGT/wcOTDjAwfae0KRQVkRC+EKBWjkgEob5mvwu9fwilhB08XPU14RBeiOx3nze1zGNxiME91kjXk6zIJeiHEFZ1Z9xnBu+cyp+R2ut4WQ2jTOJ5ZO4XoQPNjAJVlXRtRN0nQCyEqpLVm9a+/0nfD8+y2a0unh97H3j2Rh398gTbebZh24zQc7GRZg7pO5uiFEOXKLyrhtUWbaL3+CQoN7jR7dBHe3rk8+euT+Ln6MWPADFwdXK1dprgKEvRCiL84lZbLsBkb6XVgEiF2qTQY9QUlDV147GfzYwA/GfgJPi4+1i5TXCWZuhFC/Elqdhvu/HAj4+y+ZZBhO9w8hZzADkxYPZZzheeYd8s8ghsGW7tMcQ0k6IUQAGQXFHM4cTCJWV14oNEJnsn+EtoOobjbeJ757XFOZJ7gwwEfEuErD/CubyTohaiDYlbHALX3PNN1R1N5aVksiVmd6Oj5I5NLVqG8W2C68wNe2WR+DODk6Mn0CuxVK/WI6iVBL8R17HxBMW98f4iF28/Qws+Nbk1nMzlrK6rIDsZ8x7T9c/jh1A883flphrQcYu1yRSVJ0AtxnVp3NJWJy2JJPl/Aozc25+/dXEn4ZCstigrg7rl8nrqd+QfnMzJ8JOPajbN2uaIKJOiFuM6cLyhmyspDLNphHsUvm3ADnYp2wZyHCSguYoZfY5q7u/HO+n9yU7ObeLHri3JDVD0nQS/EdWTtkRReWr6P5PMFPHZjC54Z0ALnTdNg7ZvQqA3/9G7AMQd75mx8mS7+XXiz95sY7AzWLltUkQS9ENeB8wXFTF55kMU74mnZyN08ivfVsPg+zp/8lSNtB3Gkzc1s2TmdcxTTvGFLpvebjpPBydqli2ogQS+EjVtzJIWXl+8j+Xw+o3t7EN22iC2np/HZj19zxK6EhGbBkH8Adh3AAWiIHTMHzsTDycPapYtqIkEvhA0qNhWzL/kY7679jR2JB3D3S6FR00S+Tsvm6/WgtKaZQREZEM3wwB6Ee4cT7h3O84sGAdDYrbGVeyCqkwS9EPVcTlEOR84d4XDGYY5kmL8fPXecEl0MgIuPA2E+rWnjOYDw+L2En9pMWFBvXO+ZA67eVq5e1AYJeiHqCa01yXnJpWF+IdzPZJ8pbePp5ImhOIj8tJ74OTbn5YEDuLlVO+wzTsGiUZB6GPq9Ar2fBTtZ6up6UaWgV0p5AnOAdoAGHgKOAIuAECAOuEdrfa5KVQpxndFaU1BSwMqTKy/G3eJWAAAcNElEQVQGe8YRzhVe/F+paYOmhHuHM7TlUMK9w8nI8OXNlWdJzS7ksRtb8PTAMJzsDXDgG1jxJNg7wqjl0KK/FXsmrKGqI/rpwGqt9XCllCPgCrwM/Kq1fkspNRGYCLxYxfMIcd04mH6QA+kHKCgp4KUNL+Fo50hLr5b0a9qvdC69lVcr3BzcAMjKL+bfKw+ydOcpWvm7M2tUFB2CPaGkGFa/Cls+hqCuMOIz8AiybueEVVQ66JVSHkAfYCyA1roIKFJKDQH6WprNB9YiQS/EFRWbipmzbw6z9s5CKUWzBs14r997hHiEVPhwjzWHU5i4PJa0nCKe6NeCpwZYRvHnz8KSGDizBbo9CjdPNo/oxXWpKiP6UCAVmKeU6gDsBJ4G/LXWiZY2SYB/1UoUwvadyDzBKxtf4UD6AW5vfjsJ2QnY29kT5hVWbvuLo/h4Wvm7M3t0FO2DPM07T66DZeOgKA/unguRw2uxJ6IuqkrQ2wOdgb9prbcqpaZjnqYppbXWSild3sFKqfHAeICmTZtWoQwh6i+TNvG/g//jg10f4Orgyrs3vsvNITeXrl5Znt8OJ/PS8n1/HcWbTPD7e/DbZPAJg7Hfg1/rWuyNqKuqEvTxQLzWeqvl56WYgz5ZKdVEa52olGoCpJR3sNZ6FjALICoqqtx/DISwZWeyz/Da76+xM3knfYP7MqnnJHxdfM07k/b9pX1WXjH/WnmQZbviae3f4M+j+Pxz8PVjcHQ1tBsOd04HJ/drL6pxZBV6JOqqSge91jpJKXVGKdVaa30EGAActHyNAd6yfF9RLZUKYSO01iw9tpR3tr+DQRmYHD2ZwS0GX3bhsLKj+Cf7teRvA1qaR/EAZ/fA4tHmeflb34Fuj4AsQibKqOpVN38DFliuuDkJxGB+Du1ipdQ44DRwTxXPIYTNSMlLYdKmSWxM2Ej3Jt359w3/pol7kwrbZ+UV88+VB1i+K4HW/g2YM7orkUGWpQm0hl2fw6rnwc0PYn6A4K611BNRn1Qp6LXWe4CocnYNqMr7CmFrtNasOrWKN7a+QVFJES91e4n7wu/DTlV801JaTituem8d6blF/K1/S57sX2YUX5QHq56DPQvM18XfNQfc5GHdonxyZ6wQNexcwTn+veXf/Hz6Z9r7tWdK9BRCPEIqbJ+Qmc+BhOGkZEcS3tiRuWPKjOIB0k/A4jGQvB9ufNH8VU1LCdfWowtF7ZKgF6IGrT2zltc3vU5WURZPd36amIiYCtd3zyk0MnPtceZsOEVxSTghPmv59sm3cbQvM+o/tBK+mWAO9geWQtjAWuqJqM8k6IW4nHm3m7/HfH9Nh+UU5fD29rf55vg3tPJqxSc3fUJr7/IvdSwxaZbsOMPUn46SllPI0I4BJGc/h7ND1sWQLzHCr/+ETR9AQGe4Zz54ymXJ4upI0AtxGTEqGYBrmdDYmriV135/jeS8ZB6JfIQJHSbgYCj/ztaNx9KY/P1BDidl06WZF7NHd6FTUy9iPsu62Cg7CZY+BKd/h64Pwy1vgL08EERcPQl6IapJvjGf93e+z5eHvySkYQif3/o5Hfw6lNv2eEoOb646xK+HUwjycmHG/Z25LbJx6SWW87TlhvK432FpDBRmw12zob1cxCaunQS9ENVgb+peXt34KnHn43igzQM83flpXOxd/tIuI7eI6b8c5Yutf+DqYGDireGMvSEEZ4dL5u21hvMJMP9O8A6FUd+Af9ta6o2wNRL0QlRBcUkxM/fOZO7+ufi7+jPn5jl0b9L9L+0KjSV8vuk0H/x2jNxCI/d3b8ozA1vh626Zgsk/B0n7zXfEJu2DxN1QnAdth8Dgj8C5YS33TNgSCXohKulIxhFe2fgKR84dYWjLobzQ9QUaODb4UxutNT8eSOLNHw5zOj2Pvq18+Udvd5obT8L27y4Ge9bFh4fg7g8GJ2gQACPmy12uosok6IW4RkaTkc8OfMaMPTPwcPTgw/4f0je471/a7T+dwv++W40pcR/PuCXSr2kSnslHYMF5cwNlZ158LLi7+UPWxu3APxIa+F+82kdCXlQDCXohrsHp86d5eePLxKbGclOzm3itx2t4OXtBXkbp6DzvzG4yT+6idcFp3lYl4ABau6Ic20HkCPPCYY3bQ6M24Ohq7S6J64AEvRBXwaRNLDy8kPd2voejnT1vNx/BrUUKtfwx89z6+fjSttnai6M6hLigB+nYtTeuwZ1Q3qHVdveqENdKgl6IywgsKsS3qIDxX/Vna3E60QXF/CslhUZHD5qnXnxboZv2JLYkmNlH3dmc24Se7cN5cVA4wd4yWhd1gwS9EOUxFmL88WW6nE/nPz5elBSm8Q/tyfDAbqio9ubpl0Zt2fxHHpO/P8iBs+fpGOzJrNFt6NLM29rVC/EnEvRCXCIpfgvLf/wby8kh2c8HbxN8cdf3BHtcXHLgVFoub351gJ8OJhPo6cL0+zoyuEPAZdeUF8JaJOiFwHwlzYb4DSzd9SEbM4+iDRDtGYF75gk8lV1pyGfmFfHBr8f5fHMcTvZ2PH9La8b1Cv3rDU9C1CES9OK6djbnLMuPLefrY8tJyU/Fz2jkYeXB3YM+IiAgipjPzI9bKC4x8b/Np5n+6zGyC4q5t2sw/3dTa/wayJozou6ToBfXHaPJyPr49Sw5uoTfE34HoFeJgVfSUunT8WHsB0wCyyJkWkN6TmtueW89J9Ny6dXSl1dub0ObJnKnqqg/JOhFnRezOgao+kMxEnISWH5sOd8c+4aU/BQauTRivH80d+35jgDlAMM+h1Y3A+Y7WjefTGfPmTFk5jWnhR/MG9uVvq39ZB5e1DsS9MKmFZuKS0fvmxI2AdA7qDevhj5H773fYb9lATS9Ae6eAx6BlJg0q/cn8cn6E8TGZ+FgaESY//eseuojHAwVP/av2l3j+vdCXI4EvbBJCTkJLDu6jG+Of0NqfiqNXBvxWIfHGNZyGE3yMmHJWEg9An2ehxsnUmBSLNlymtnrT/JHRh6hvm68eVckP+y/B4OdsXZDXohqJkEvbEaxqZh1Z9ax9OhSNp3dhFKK3oG9Gd5qOL0Ce2GvDLD7C1j1PDi5w6jlnGvci/+tPcX8TXGk5xbRMdiTl28L56a2jTHYKX46aLR2t4SoMgl6Ue/FZ8ez7Ngyvj72NekF6fi7+jOhwwSGhQ2jsVtjc6PCHFj5d9i3GEJ6kzDgQ2bvzmPRZ7+RX1zCgPBGPHpjC7qGeMkcvLA5VQ56pZQB2AEkaK3vUEqFAgsBH2AnMEprXVTV8whRVrGpmLVn1paO3u2UHX0C+zC81XCiA6OxtyvzVztpn3mqJuMkKV3+jzdybue7mYewUzCkYyDj+zSnlX+DCs8lRH1XHSP6p4FDwIXrzd4G3tNaL1RK/RcYB8yshvMIwZnzZ1h2zDz3nl6QTmO3xjze8XGGtSwzer9Aa9g5D/3DRIodPXjH921m/x6Iu1M643qFEhMdQhOPvz4F6k8aR9ZcZ4SoJVUKeqVUEHA7MAX4P2X+nbc/cL+lyXzgdSToRRWYtInMwkwe+ekRtiRuMY/eg/owotUIogOiMZS3KmTBeUzfPoXdwa/Z7dCJR86Nx87YiBcHhXJ/96Z4uJT/sO5LVfWSTiHqgqqO6N8HXgAu/N7rA2RqrS98ghUPBFbxHOI6tvnsZg6mH6SgpIB8Yz5PdHyCYS2H4e/mX+ExBad3UrRwDK75CUwtvpcf3e/jhZtbMrRTIE72slSBuP5UOuiVUncAKVrrnUqpvpU4fjwwHqBp06ZXaC3qhAtPPaqFa7yTcpOYumMqP8b9iJOGFtiz7K4fyh+9W2TkFLJ3+X+IPvk+ubohb3m9Td+bBvNcG3/s7OQDVnH9qsqIPhoYrJS6DXDGPEc/HfBUStlbRvVBQEJ5B2utZwGzAKKionQV6hA2pLikmC8OfcHMvTMxaRNPdHyCzbtnY4eqMOTPZOTxxZo9dIn9Bzer7ex16Y4e8jFvhLes5eqFqJsqHfRa65eAlwAsI/rntNYPKKWWAMMxX3kzBlhRDXWK68DWxK28sfUNTmadpG9wX17s+iJBDYLYuntOue33J2TxyfqTxO9bzwcOHxKgMkjr+SodbnoW7OQGJyEuqInr6F8EFiqlJgO7gbk1cA5hQ5Jzk3l3x7v8EPcDge6BfNT/I24MvrHctlprNh5P45N1J9l4PJUnnFbzvtOX0CAAw4gf8Q3uWsvVC1H3VUvQa63XAmstr08C3arjfYVtKzYV8+WhL/l4z8cYTUYe7/A4Me1icLZ3/ktbk7ZjxZ4EPll3koOJ5wlzL2Jd4FyapW+A1nfAkI/AxcsKvRCi7pM7Y4VVbE/azpQtUziRdYI+QX2Y2HUiwQ2D/9LubGY+p9N7cTYzinVH9tDCz425/Y303/cy6lwqDHobuj8KcjerEBWSoBe1KjUvlak7prLq1CoC3QP5sP+H9A3u+6c2WfnF/LAvka93J7AtLgOtb8LDJY6P7htA//SvsFszGTyDYdxPENjZOh0Roh6RoBe1othUzFeHvuLjvR9TXFLMYx0eY1y7caXTNIXGEtYcTmXFngR+PZRCUYmJ5r5u/N/AVvx+4nEaGVIZuOtXOPErtB0Cgz8EZw8r90qI+kGCXlyZ1pAUC+fiwGSElf9n3l46XVJm2qScbTuKzzElez/HS3Lo5ejHS54RNE2KRye+TlJ2EcdTcjiZlkOhURPtYGBUkDthjdzxdXdClSjCco7SPTcbOAu3vwtR42SqRohrIEEvKpaVAPuWQOwiSDmIEcizM9Dw4ArAcuuDvnALRJlbISzb0uzg3QbOrHR1JMBo4v3z+fQvyMSkj1JYUoKxROOuNZ2AKIPCwVlhpxQqQ0PGxfcZVFII9s7w0I/QpH0tdV4I2yFBL/6sMBsOfQd7F8Kp9YCG4O5w+zSeif2IXIOBeWN3XPYtjCYjCw8vZMaeGRSWFPJIxFiGhIzm5wMZ3LE7gQNnz2OwU/QO82Vox0BuauuPs9Nl/ipeuCNXQl6ISpGgF1BihFNrzeF++HsozgOvELjxRWh/D/i0ACD3wJXXptuVvIspW6dw9NxRuje+ga4NHmLDLnh/ye+YNHQI8mDSnW25o30Afg2carZfQghAgr7+qa71ZrQ2r9Meu8g8PZOTDM6e0OE+aH8fBHe7pnnwtPw03tv5Ht+e+BZPRz/aGv7Gxo1B/FKcRlNvV57sH8bQjgE093OvWt1CiGsmQX+9OX8WYheXzrtj5wCtbjEHfNjNYH9to2yjyciiw4uYvusjCkryscsawJnEG8lxcWNElwCGdgqkc1NPeWqTEFYkQV/PxKhkAK5plfTCHPO8e+xCOLkO0BDUzXwFS8Rd4OpdqVq+P7qJ/2x/kwxjHMacMExpQ7gpLJKhAwPp08oPR3tZb0aIukCC3laVzrsvgsMrK5x3v1ZFRjdmrNvNF8dmkuOwGVOxByHqMcZ0u5NbI5vQwPnqHughhKg9EvS2Jmmf+UPVsvPu7e81T80Ed7/m689LTJqDZ8+z6UQau888QJ5jKnvtxqPsi+jicReTej9NqE/lfiMQQtQOCXpbcP6sOdj3LoKUAxfn3dvfa/5+DfPuJpPmQFI6Px0+zJYzxzicFkeRSkM5ZGDfOB4nx0wivaOY3Ps1mns2r8FOCSGqiwR9fVWFeXeTNpGWn0Z8djzx2fHsSznF/uRT/HH+DOeNKWhDFkpZboDyBRflQIBbAFlFJnxdmrPgjk9r98PVWniilRC2TIK+PjmfSLecbDrm58LUsDLz7i+YR+9l5t2zi7JJyEkgITuB+BxzoMfnxJOQk0B8dgLFpqI/vbWpuCH2Jl+auLSjlU8zooJa0t6/OYHugfi5+mGn7IhZHQMgV9AIUc9I0FdWbTw/NfMPiPsdTlu+Mk4yAcixs6O44ygSWw0kvoGvOcDjviV+nyXIc+LJKsz601s527nhiC95eR7k5fbAVOxFA0MjOjZpQd/mrekd1oQQH1cJcSFskAR9XaE1ZJyEuI1wepM52LPOmPc5e5LRtDu/t+rNzLO/kWynMGauw7R1Tenh9nb2BLoHEugeSIuG4RQXepF6zo3jZx05k+JCtskVDxcHejT35oZIX3q28CGskbsEuxDXAQl6azGZIO1ImWDfBDlJ5n1ufpia3sDBTveywcHExswj7Evbj04+hL2doiF23NN+PIHugQS5B9HQ3p+TSXZsOZnJlgPp/JiUDYC7kz3dQr0Z3dmHni18aNukIXZ2EuxCXG8k6Cvpmm9cMpVA8v4yUzGbID/DvK9hIIT2ISuwE5tcXdiYdYyNZ38n4/RuFIpIv0gmdJxAn8A+vLNyNCUlTrR1GcHmo+nMPZHO/rOxaA3ODnZ0DfHmzg4B3NDCh8hAD+wNctOSENc7CfqaUlIMiXsvjtj/2AIX5s29QqD1beimPTniHcCG88fZkLCRvUc/waRNeDh5EB0QTRe/njSy70BKlj0nz+YyfW8O207+jfwibzYc246jwY6OTT15ekAYN7TwpUOwB072Bqt2WwhR90jQV5fiAji76+KI/cw2KM417/NtBe3ugmbRZAd0YEvuaTbEb2Dj8U9JzU8FIMi1FV0aDse+sC0Z5/z5+Vg+i3KLgIMAOBgUzXzccHVMxa/BQaYMfYEuzbxwcZRgF0JcXr0O+guX+80bdE0rv1QLR5OJFoUF8NsU84g9fjuUFJp3+reDTg9As2h0054cN57np1NrWXPyW47tnoKJEgy4YF8YTlFGP4qywzhU0oBDgK+7I819DdwS4U9zX3ea+7nRws+dIC8X7A12xHz2LAC9wv5T630WQtRPlQ56pVQw8Dngj/nxQrO01tOVUt7AIiAEiAPu0Vqfq3qpdYSpBHbN5934U7ibTJAyFZp0gG6PYAzuyZkGHTiQWcL6+E3s3/MbidumYbQzd7+koAnGnN6o/DYEu4bTwq8hLTq609zPEui+7ni41t21YqzxD6oQouqqMqI3As9qrXcppRoAO5VSPwNjgV+11m8ppSYCE4EXq16q9ZhMmtwiI0Vx23D7dSLOqbHEOXixyKUdnuGvczBDc+zQCVJiN6Jc52JwPYWyKwGTEw10W0Kd7qar/w20b9KU5r4XR+eV0jiyejsnhLB5lQ56rXUikGh5na2UOgQEAkOAvpZm84G1WCHoC40l5BaWkFtoJLvASG6RkZxCI7mWrxzLvpzCS7cbLx5XWExuYTFORRk867CIu+w3kKg9+I9xPKuLu2BnSsDp5GwcGxyhxCsdB8DPqRlRjUZwa4t+9ArqioOh7o7QhRDXB6W1vnKrK72JUiHAeqAd8IfW2tOyXQHnLvxckaioKL1jx+WfQ1qem798iKTcMzganDBpEyXahMnypTGh0KA0oEGZzN8xlW67sF9Z9inLdl2mzZU4G5zp0aQHvYN60yuwFwHuAdfcDyGEqAyl1E6tddSV2lX5w1illDuwDHhGa32+7J2WWmutSlfH+stx44HxAE2bNq3cybUBbXLG0d4de4MBezsD9gY7HOwM2BsMONgZcDAYcDTY42gwv3ayN+BgsMfJ3h4ngx32BnsUCoMyYKfsLn5lJ2F3/Gfzd88Q7Frfhl0Df+ww71+4fRrO2PHVyI04GeTZp0KIuqtKQa+UcsAc8gu01sstm5OVUk201olKqSZASnnHaq1nAbPAPKKvzPkDfYwE+vhW74eEOanwy+uw5wto0ARued+8GuQlSwWs2f4BgIS8EKLOq8pVNwqYCxzSWk8rs+tbYAzwluX7iipVWFtKjLDjU1gzGYpy4YanzKtCOjWwdmVCCFElVRnRRwOjgH1KqT2WbS9jDvjFSqlxwGngnqqVWAv+2ALfPwfJ+yD0RrjtHfBrbe2qhBCiWlTlqpuNQEUrZA2o7PvWqpwU+PkfsPcr83ozIz6DtkOv7nF7cpmjEKKeqNd3xlZ6br7ECNvnwJopUJwPvf4OvZ8DJ/fqLVAIIeqAeh30lXJ6E6x63rySZIv+cOt/wDfM2lUJIUSNuX6CPjvJPE0TuwgaBsE9/4M2d17dNE05ZDkAIUR9YftBX1IM22bBmjfNi471ftb85ehm7cqEEKJW2HbQx200T9OkHISWA83TNGUeoC2EENeD+h30FT2g+3wi/Pwa7FsCHk3hvi+h9W2VnqYRQoj6rH4H/aVKimHrf2HtW+bXfV4wX1Hj6GrtyoQQwmpsJ+hPrjNP06QdgbBb4Na3wLu5tasSQgirq/9BbyyEJTFwYDl4NoORC6H1rdauSggh6oz6HfR56eYRfPI+6PsSRD8NDi7WrkoIIeqU+h30jm7g4gUP/wreodauRggh6qRKPs+ujrB3Br82EvJCCHEZ9TvohRBCXJEEvRBC2DgJeiGEsHH1+8PYS++IFUII8RcyohdCCBsnQS+EEDZOgl4IIWycBL0QQtg4CXohhLBxEvRCCGHjJOiFEMLGSdALIYSNk6AXQggbp7TW1q4BpVQqcLqSh/sCadVYTn0gfb4+SJ+vD1XpczOttd+VGtWJoK8KpdQOrXWUteuoTdLn64P0+fpQG32WqRshhLBxEvRCCGHjbCHoZ1m7ACuQPl8fpM/Xhxrvc72foxdCCHF5tjCiF0IIcRn1OuiVUoOUUkeUUseVUhOtXU9NU0oFK6XWKKUOKqUOKKWetnZNtUEpZVBK7VZKrbR2LbVFKeWplFqqlDqslDqklOpp7ZpqklLq75a/0/uVUl8ppZytXVNNUEp9qpRKUUrtL7PNWyn1s1LqmOW7V3Wft94GvVLKAMwAbgXaAiOVUm2tW1WNMwLPaq3bAj2AJ66DPgM8DRyydhG1bDqwWmsdDnTAhvuvlAoEngKitNbtAANwn3WrqjGfAYMu2TYR+FVrHQb8avm5WtXboAe6Ace11ie11kXAQmCIlWuqUVrrRK31LsvrbMz/8wdat6qapZQKAm4H5li7ltqilPIA+gBzAbTWRVrrTOtWVePsARellD3gCpy1cj01Qmu9Hsi4ZPMQYL7l9XxgaHWftz4HfSBwpszP8dh46JWllAoBOgFbrVtJjXsfeAEwWbuQWhQKpALzLFNWc5RSbtYuqqZorROAqcAfQCKQpbX+ybpV1Sp/rXWi5XUS4F/dJ6jPQX/dUkq5A8uAZ7TW561dT01RSt0BpGitd1q7llpmD3QGZmqtOwG51MCv83WFZU56COZ/4AIAN6XUg9atyjq0+TLIar8Usj4HfQIQXObnIMs2m6aUcsAc8gu01sutXU8NiwYGK6XiME/N9VdKfWHdkmpFPBCvtb7w29pSzMFvqwYCp7TWqVrrYmA5cIOVa6pNyUqpJgCW7ynVfYL6HPTbgTClVKhSyhHzhzffWrmmGqWUUpjnbQ9pradZu56aprV+SWsdpLUOwfzn+5vW2uZHelrrJOCMUqq1ZdMA4KAVS6ppfwA9lFKulr/jA7DhD5/L8S0wxvJ6DLCiuk9gX91vWFu01kal1JPAj5g/pf9Ua33AymXVtGhgFLBPKbXHsu1lrfUqK9YkasbfgAWWQcxJIMbK9dQYrfVWpdRSYBfmK8t2Y6N3yCqlvgL6Ar5KqXhgEvAWsFgpNQ7zKr73VPt55c5YIYSwbfV56kYIIcRVkKAXQggbJ0EvhBA2ToJeCCFsnAS9EELYOAl6IYSwcRL0Qghh4yTohRDCxv0/94UVVe8faH4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_smeared     = y + np.random.normal(0, np.sqrt(y), len(y))\n",
    "y_smeared_val = y + np.random.normal(0, np.sqrt(y), len(y))\n",
    "\n",
    "plt.plot(x, y, label = \"true pdf\")\n",
    "plt.errorbar(x, y_smeared, yerr=np.sqrt(y_smeared), label = \"train data\")\n",
    "plt.errorbar(x, y_smeared_val, yerr=np.sqrt(y_smeared), label = \"validation data\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11 samples, validate on 11 samples\n",
      "Epoch 1/100000\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 4020.4048 - val_loss: 3897.0186\n",
      "Epoch 2/100000\n",
      "11/11 [==============================] - 0s 204us/step - loss: 4019.3669 - val_loss: 3895.9768\n",
      "Epoch 3/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 4018.3279 - val_loss: 3894.9338\n",
      "Epoch 4/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 4017.2876 - val_loss: 3893.9546\n",
      "Epoch 5/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 4016.3108 - val_loss: 3892.9541\n",
      "Epoch 6/100000\n",
      "11/11 [==============================] - 0s 201us/step - loss: 4015.3127 - val_loss: 3891.9399\n",
      "Epoch 7/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 4014.3018 - val_loss: 3890.8931\n",
      "Epoch 8/100000\n",
      "11/11 [==============================] - 0s 989us/step - loss: 4013.2576 - val_loss: 3889.8452\n",
      "Epoch 9/100000\n",
      "11/11 [==============================] - 0s 714us/step - loss: 4012.2117 - val_loss: 3888.7954\n",
      "Epoch 10/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 4011.1648 - val_loss: 3887.7451\n",
      "Epoch 11/100000\n",
      "11/11 [==============================] - 0s 830us/step - loss: 4010.1172 - val_loss: 3886.6929\n",
      "Epoch 12/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 4009.0674 - val_loss: 3885.6382\n",
      "Epoch 13/100000\n",
      "11/11 [==============================] - 0s 953us/step - loss: 4008.0164 - val_loss: 3884.5796\n",
      "Epoch 14/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 4006.9602 - val_loss: 3883.5234\n",
      "Epoch 15/100000\n",
      "11/11 [==============================] - 0s 754us/step - loss: 4005.9062 - val_loss: 3882.4587\n",
      "Epoch 16/100000\n",
      "11/11 [==============================] - 0s 204us/step - loss: 4004.8445 - val_loss: 3881.3994\n",
      "Epoch 17/100000\n",
      "11/11 [==============================] - 0s 790us/step - loss: 4003.7876 - val_loss: 3880.3389\n",
      "Epoch 18/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4002.7295 - val_loss: 3879.2764\n",
      "Epoch 19/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 4001.6697 - val_loss: 3878.2119\n",
      "Epoch 20/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 4000.6079 - val_loss: 3877.1462\n",
      "Epoch 21/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3999.5452 - val_loss: 3876.0674\n",
      "Epoch 22/100000\n",
      "11/11 [==============================] - 0s 740us/step - loss: 3998.4695 - val_loss: 3874.9866\n",
      "Epoch 23/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 3997.3914 - val_loss: 3873.9158\n",
      "Epoch 24/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 3996.3232 - val_loss: 3872.8438\n",
      "Epoch 25/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3995.2537 - val_loss: 3871.7698\n",
      "Epoch 26/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 3994.1826 - val_loss: 3870.6814\n",
      "Epoch 27/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3993.0967 - val_loss: 3869.5908\n",
      "Epoch 28/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3992.0093 - val_loss: 3868.4990\n",
      "Epoch 29/100000\n",
      "11/11 [==============================] - 0s 786us/step - loss: 3990.9202 - val_loss: 3867.4055\n",
      "Epoch 30/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3989.8291 - val_loss: 3866.3228\n",
      "Epoch 31/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3988.7493 - val_loss: 3865.2256\n",
      "Epoch 32/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 3987.6548 - val_loss: 3864.1265\n",
      "Epoch 33/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3986.5588 - val_loss: 3863.0388\n",
      "Epoch 34/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3985.4736 - val_loss: 3861.9365\n",
      "Epoch 35/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3984.3740 - val_loss: 3860.8447\n",
      "Epoch 36/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3983.2852 - val_loss: 3859.7510\n",
      "Epoch 37/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 3982.1946 - val_loss: 3858.6555\n",
      "Epoch 38/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3981.1016 - val_loss: 3857.5469\n",
      "Epoch 39/100000\n",
      "11/11 [==============================] - 0s 746us/step - loss: 3979.9954 - val_loss: 3856.4360\n",
      "Epoch 40/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3978.8875 - val_loss: 3855.3350\n",
      "Epoch 41/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3977.7891 - val_loss: 3854.2205\n",
      "Epoch 42/100000\n",
      "11/11 [==============================] - 0s 804us/step - loss: 3976.6780 - val_loss: 3853.1157\n",
      "Epoch 43/100000\n",
      "11/11 [==============================] - 0s 591us/step - loss: 3975.5764 - val_loss: 3851.9983\n",
      "Epoch 44/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3974.4609 - val_loss: 3850.8899\n",
      "Epoch 45/100000\n",
      "11/11 [==============================] - 0s 770us/step - loss: 3973.3555 - val_loss: 3849.7791\n",
      "Epoch 46/100000\n",
      "11/11 [==============================] - 0s 898us/step - loss: 3972.2478 - val_loss: 3848.6670\n",
      "Epoch 47/100000\n",
      "11/11 [==============================] - 0s 824us/step - loss: 3971.1384 - val_loss: 3847.5532\n",
      "Epoch 48/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3970.0273 - val_loss: 3846.4260\n",
      "Epoch 49/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3968.9033 - val_loss: 3845.2983\n",
      "Epoch 50/100000\n",
      "11/11 [==============================] - 0s 922us/step - loss: 3967.7781 - val_loss: 3844.1680\n",
      "Epoch 51/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 3966.6514 - val_loss: 3843.0461\n",
      "Epoch 52/100000\n",
      "11/11 [==============================] - 0s 730us/step - loss: 3965.5320 - val_loss: 3841.9226\n",
      "Epoch 53/100000\n",
      "11/11 [==============================] - 0s 712us/step - loss: 3964.4111 - val_loss: 3840.7969\n",
      "Epoch 54/100000\n",
      "11/11 [==============================] - 0s 989us/step - loss: 3963.2883 - val_loss: 3839.6689\n",
      "Epoch 55/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 3962.1641 - val_loss: 3838.5393\n",
      "Epoch 56/100000\n",
      "11/11 [==============================] - 0s 749us/step - loss: 3961.0374 - val_loss: 3837.3992\n",
      "Epoch 57/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 3959.8994 - val_loss: 3836.2654\n",
      "Epoch 58/100000\n",
      "11/11 [==============================] - 0s 689us/step - loss: 3958.7688 - val_loss: 3835.1299\n",
      "Epoch 59/100000\n",
      "11/11 [==============================] - 0s 728us/step - loss: 3957.6365 - val_loss: 3833.9929\n",
      "Epoch 60/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3956.5022 - val_loss: 3832.8538\n",
      "Epoch 61/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3955.3662 - val_loss: 3831.7124\n",
      "Epoch 62/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3954.2280 - val_loss: 3830.5603\n",
      "Epoch 63/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3953.0789 - val_loss: 3829.4150\n",
      "Epoch 64/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3951.9368 - val_loss: 3828.2686\n",
      "Epoch 65/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3950.7927 - val_loss: 3827.1194\n",
      "Epoch 66/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3949.6462 - val_loss: 3825.9680\n",
      "Epoch 67/100000\n",
      "11/11 [==============================] - 0s 729us/step - loss: 3948.4985 - val_loss: 3824.8154\n",
      "Epoch 68/100000\n",
      "11/11 [==============================] - 0s 749us/step - loss: 3947.3486 - val_loss: 3823.6604\n",
      "Epoch 69/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 3946.1968 - val_loss: 3822.5029\n",
      "Epoch 70/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 3945.0427 - val_loss: 3821.3367\n",
      "Epoch 71/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 3943.8792 - val_loss: 3820.1755\n",
      "Epoch 72/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3942.7212 - val_loss: 3819.0125\n",
      "Epoch 73/100000\n",
      "11/11 [==============================] - 0s 803us/step - loss: 3941.5610 - val_loss: 3817.8401\n",
      "Epoch 74/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 3940.3921 - val_loss: 3816.6733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100000\n",
      "11/11 [==============================] - 0s 719us/step - loss: 3939.2280 - val_loss: 3815.4971\n",
      "Epoch 76/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 3938.0549 - val_loss: 3814.3264\n",
      "Epoch 77/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 3936.8870 - val_loss: 3813.1460\n",
      "Epoch 78/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 3935.7107 - val_loss: 3811.9712\n",
      "Epoch 79/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 3934.5383 - val_loss: 3810.7944\n",
      "Epoch 80/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 3933.3647 - val_loss: 3809.6086\n",
      "Epoch 81/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 3932.1821 - val_loss: 3808.4275\n",
      "Epoch 82/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 3931.0042 - val_loss: 3807.2380\n",
      "Epoch 83/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 3929.8174 - val_loss: 3806.0525\n",
      "Epoch 84/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 3928.6357 - val_loss: 3804.8657\n",
      "Epoch 85/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 3927.4524 - val_loss: 3803.6768\n",
      "Epoch 86/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 3926.2664 - val_loss: 3802.4866\n",
      "Epoch 87/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 3925.0789 - val_loss: 3801.2930\n",
      "Epoch 88/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 3923.8889 - val_loss: 3800.0916\n",
      "Epoch 89/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 3922.6907 - val_loss: 3798.8945\n",
      "Epoch 90/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 3921.4968 - val_loss: 3797.6892\n",
      "Epoch 91/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 3920.2947 - val_loss: 3796.4880\n",
      "Epoch 92/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 3919.0969 - val_loss: 3795.2788\n",
      "Epoch 93/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 3917.8906 - val_loss: 3794.0674\n",
      "Epoch 94/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 3916.6829 - val_loss: 3792.8601\n",
      "Epoch 95/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 3915.4788 - val_loss: 3791.6448\n",
      "Epoch 96/100000\n",
      "11/11 [==============================] - 0s 580us/step - loss: 3914.2666 - val_loss: 3790.4333\n",
      "Epoch 97/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 3913.0586 - val_loss: 3789.2202\n",
      "Epoch 98/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 3911.8486 - val_loss: 3788.0049\n",
      "Epoch 99/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 3910.6367 - val_loss: 3786.7874\n",
      "Epoch 100/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 3909.4221 - val_loss: 3785.5674\n",
      "Epoch 101/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 3908.2061 - val_loss: 3784.3401\n",
      "Epoch 102/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 3906.9822 - val_loss: 3783.1169\n",
      "Epoch 103/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 3905.7620 - val_loss: 3781.8857\n",
      "Epoch 104/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 3904.5342 - val_loss: 3780.6577\n",
      "Epoch 105/100000\n",
      "11/11 [==============================] - 0s 837us/step - loss: 3903.3101 - val_loss: 3779.4226\n",
      "Epoch 106/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 3902.0779 - val_loss: 3778.1904\n",
      "Epoch 107/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 3900.8491 - val_loss: 3776.9568\n",
      "Epoch 108/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 3899.6187 - val_loss: 3775.7151\n",
      "Epoch 109/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 3898.3806 - val_loss: 3774.4773\n",
      "Epoch 110/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 3897.1460 - val_loss: 3773.2314\n",
      "Epoch 111/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 3895.9038 - val_loss: 3771.9897\n",
      "Epoch 112/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 3894.6655 - val_loss: 3770.7458\n",
      "Epoch 113/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 3893.4243 - val_loss: 3769.4939\n",
      "Epoch 114/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 3892.1760 - val_loss: 3768.2458\n",
      "Epoch 115/100000\n",
      "11/11 [==============================] - 0s 677us/step - loss: 3890.9314 - val_loss: 3766.9900\n",
      "Epoch 116/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 3889.6794 - val_loss: 3765.7327\n",
      "Epoch 117/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 3888.4255 - val_loss: 3764.4780\n",
      "Epoch 118/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 3887.1748 - val_loss: 3763.2217\n",
      "Epoch 119/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 3885.9216 - val_loss: 3761.9631\n",
      "Epoch 120/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 3884.6663 - val_loss: 3760.6975\n",
      "Epoch 121/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 3883.4041 - val_loss: 3759.4346\n",
      "Epoch 122/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 3882.1445 - val_loss: 3758.1655\n",
      "Epoch 123/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 3880.8789 - val_loss: 3756.8984\n",
      "Epoch 124/100000\n",
      "11/11 [==============================] - 0s 594us/step - loss: 3879.6157 - val_loss: 3755.6250\n",
      "Epoch 125/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 3878.3455 - val_loss: 3754.3540\n",
      "Epoch 126/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 3877.0781 - val_loss: 3753.0813\n",
      "Epoch 127/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 3875.8088 - val_loss: 3751.8069\n",
      "Epoch 128/100000\n",
      "11/11 [==============================] - 0s 586us/step - loss: 3874.5374 - val_loss: 3750.5298\n",
      "Epoch 129/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 3873.2642 - val_loss: 3749.2507\n",
      "Epoch 130/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 3871.9890 - val_loss: 3747.9697\n",
      "Epoch 131/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 3870.7117 - val_loss: 3746.6868\n",
      "Epoch 132/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 3869.4319 - val_loss: 3745.4021\n",
      "Epoch 133/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 3868.1509 - val_loss: 3744.1108\n",
      "Epoch 134/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 3866.8630 - val_loss: 3742.8174\n",
      "Epoch 135/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 3865.5732 - val_loss: 3741.5266\n",
      "Epoch 136/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 3864.2861 - val_loss: 3740.2295\n",
      "Epoch 137/100000\n",
      "11/11 [==============================] - 0s 842us/step - loss: 3862.9924 - val_loss: 3738.9304\n",
      "Epoch 138/100000\n",
      "11/11 [==============================] - 0s 867us/step - loss: 3861.6968 - val_loss: 3737.6292\n",
      "Epoch 139/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 3860.3992 - val_loss: 3736.3267\n",
      "Epoch 140/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 3859.1001 - val_loss: 3735.0217\n",
      "Epoch 141/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 3857.7991 - val_loss: 3733.7148\n",
      "Epoch 142/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 3856.4954 - val_loss: 3732.4062\n",
      "Epoch 143/100000\n",
      "11/11 [==============================] - 0s 700us/step - loss: 3855.1907 - val_loss: 3731.0959\n",
      "Epoch 144/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 3853.8835 - val_loss: 3729.7834\n",
      "Epoch 145/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 3852.5750 - val_loss: 3728.4695\n",
      "Epoch 146/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 3851.2642 - val_loss: 3727.1533\n",
      "Epoch 147/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 3849.9517 - val_loss: 3725.8352\n",
      "Epoch 148/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 3848.6377 - val_loss: 3724.5156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 3847.3218 - val_loss: 3723.1938\n",
      "Epoch 150/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 3846.0037 - val_loss: 3721.8708\n",
      "Epoch 151/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 3844.6838 - val_loss: 3720.5459\n",
      "Epoch 152/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 3843.3623 - val_loss: 3719.2195\n",
      "Epoch 153/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 3842.0393 - val_loss: 3717.8948\n",
      "Epoch 154/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 3840.7185 - val_loss: 3716.5647\n",
      "Epoch 155/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 3839.3916 - val_loss: 3715.2327\n",
      "Epoch 156/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 3838.0640 - val_loss: 3713.8992\n",
      "Epoch 157/100000\n",
      "11/11 [==============================] - 0s 181us/step - loss: 3836.7336 - val_loss: 3712.5640\n",
      "Epoch 158/100000\n",
      "11/11 [==============================] - 0s 663us/step - loss: 3835.4021 - val_loss: 3711.2268\n",
      "Epoch 159/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 3834.0688 - val_loss: 3709.8928\n",
      "Epoch 160/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 3832.7380 - val_loss: 3708.5525\n",
      "Epoch 161/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 3831.4021 - val_loss: 3707.2109\n",
      "Epoch 162/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 3830.0635 - val_loss: 3705.8679\n",
      "Epoch 163/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 3828.7244 - val_loss: 3704.5234\n",
      "Epoch 164/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 3827.3828 - val_loss: 3703.1775\n",
      "Epoch 165/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 3826.0405 - val_loss: 3701.8335\n",
      "Epoch 166/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 3824.7007 - val_loss: 3700.4885\n",
      "Epoch 167/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 3823.3586 - val_loss: 3699.1421\n",
      "Epoch 168/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 3822.0156 - val_loss: 3697.7932\n",
      "Epoch 169/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 3820.6716 - val_loss: 3696.4443\n",
      "Epoch 170/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 3819.3259 - val_loss: 3695.0938\n",
      "Epoch 171/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 3817.9788 - val_loss: 3693.7419\n",
      "Epoch 172/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 3816.6299 - val_loss: 3692.3884\n",
      "Epoch 173/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 3815.2805 - val_loss: 3691.0342\n",
      "Epoch 174/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 3813.9299 - val_loss: 3689.6782\n",
      "Epoch 175/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 3812.5781 - val_loss: 3688.3218\n",
      "Epoch 176/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 3811.2244 - val_loss: 3686.9602\n",
      "Epoch 177/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 3809.8669 - val_loss: 3685.6016\n",
      "Epoch 178/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 3808.5115 - val_loss: 3684.2415\n",
      "Epoch 179/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 3807.1548 - val_loss: 3682.8804\n",
      "Epoch 180/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 3805.7971 - val_loss: 3681.5186\n",
      "Epoch 181/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 3804.4392 - val_loss: 3680.1555\n",
      "Epoch 182/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 3803.0796 - val_loss: 3678.7920\n",
      "Epoch 183/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 3801.7197 - val_loss: 3677.4272\n",
      "Epoch 184/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 3800.3586 - val_loss: 3676.0618\n",
      "Epoch 185/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 3798.9963 - val_loss: 3674.6953\n",
      "Epoch 186/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 3797.6338 - val_loss: 3673.3289\n",
      "Epoch 187/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 3796.2710 - val_loss: 3671.9609\n",
      "Epoch 188/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 3794.9062 - val_loss: 3670.5923\n",
      "Epoch 189/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 3793.5420 - val_loss: 3669.2236\n",
      "Epoch 190/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 3792.1765 - val_loss: 3667.8540\n",
      "Epoch 191/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 3790.8103 - val_loss: 3666.4841\n",
      "Epoch 192/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 3789.4443 - val_loss: 3665.1135\n",
      "Epoch 193/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 3788.0771 - val_loss: 3663.7429\n",
      "Epoch 194/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 3786.7095 - val_loss: 3662.3711\n",
      "Epoch 195/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 3785.3416 - val_loss: 3660.9993\n",
      "Epoch 196/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 3783.9736 - val_loss: 3659.6240\n",
      "Epoch 197/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 3782.6016 - val_loss: 3658.2517\n",
      "Epoch 198/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 3781.2334 - val_loss: 3656.8789\n",
      "Epoch 199/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 3779.8640 - val_loss: 3655.5029\n",
      "Epoch 200/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 3778.4915 - val_loss: 3654.1299\n",
      "Epoch 201/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3777.1221 - val_loss: 3652.7563\n",
      "Epoch 202/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3775.7522 - val_loss: 3651.3835\n",
      "Epoch 203/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3774.3826 - val_loss: 3650.0100\n",
      "Epoch 204/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3773.0127 - val_loss: 3648.6335\n",
      "Epoch 205/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3771.6399 - val_loss: 3647.2571\n",
      "Epoch 206/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3770.2671 - val_loss: 3645.8835\n",
      "Epoch 207/100000\n",
      "11/11 [==============================] - 0s 827us/step - loss: 3768.8970 - val_loss: 3644.5103\n",
      "Epoch 208/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3767.5276 - val_loss: 3643.1343\n",
      "Epoch 209/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 3766.1548 - val_loss: 3641.7607\n",
      "Epoch 210/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 3764.7854 - val_loss: 3640.3850\n",
      "Epoch 211/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 3763.4133 - val_loss: 3639.0093\n",
      "Epoch 212/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 3762.0413 - val_loss: 3637.6370\n",
      "Epoch 213/100000\n",
      "11/11 [==============================] - 0s 599us/step - loss: 3760.6721 - val_loss: 3636.2649\n",
      "Epoch 214/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3759.3040 - val_loss: 3634.8899\n",
      "Epoch 215/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3757.9326 - val_loss: 3633.5156\n",
      "Epoch 216/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 3756.5623 - val_loss: 3632.1416\n",
      "Epoch 217/100000\n",
      "11/11 [==============================] - 0s 693us/step - loss: 3755.1914 - val_loss: 3630.7705\n",
      "Epoch 218/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 3753.8245 - val_loss: 3629.3977\n",
      "Epoch 219/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 3752.4546 - val_loss: 3628.0249\n",
      "Epoch 220/100000\n",
      "11/11 [==============================] - 0s 756us/step - loss: 3751.0857 - val_loss: 3626.6526\n",
      "Epoch 221/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 3749.7166 - val_loss: 3625.2837\n",
      "Epoch 222/100000\n",
      "11/11 [==============================] - 0s 874us/step - loss: 3748.3518 - val_loss: 3623.9126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 3746.9844 - val_loss: 3622.5447\n",
      "Epoch 224/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3745.6201 - val_loss: 3621.1743\n",
      "Epoch 225/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3744.2532 - val_loss: 3619.8047\n",
      "Epoch 226/100000\n",
      "11/11 [==============================] - 0s 740us/step - loss: 3742.8877 - val_loss: 3618.4360\n",
      "Epoch 227/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 3741.5227 - val_loss: 3617.0703\n",
      "Epoch 228/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 3740.1604 - val_loss: 3615.7056\n",
      "Epoch 229/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 3738.7993 - val_loss: 3614.3389\n",
      "Epoch 230/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 3737.4360 - val_loss: 3612.9727\n",
      "Epoch 231/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 3736.0735 - val_loss: 3611.6096\n",
      "Epoch 232/100000\n",
      "11/11 [==============================] - 0s 644us/step - loss: 3734.7146 - val_loss: 3610.2476\n",
      "Epoch 233/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3733.3557 - val_loss: 3608.8865\n",
      "Epoch 234/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 3731.9978 - val_loss: 3607.5251\n",
      "Epoch 235/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 3730.6414 - val_loss: 3606.1655\n",
      "Epoch 236/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 3729.2849 - val_loss: 3604.8062\n",
      "Epoch 237/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 3727.9294 - val_loss: 3603.4482\n",
      "Epoch 238/100000\n",
      "11/11 [==============================] - 0s 871us/step - loss: 3726.5745 - val_loss: 3602.0901\n",
      "Epoch 239/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 3725.2209 - val_loss: 3600.7336\n",
      "Epoch 240/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 3723.8674 - val_loss: 3599.3774\n",
      "Epoch 241/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 3722.5156 - val_loss: 3598.0225\n",
      "Epoch 242/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 3721.1641 - val_loss: 3596.6655\n",
      "Epoch 243/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 3719.8110 - val_loss: 3595.3125\n",
      "Epoch 244/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 3718.4612 - val_loss: 3593.9595\n",
      "Epoch 245/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 3717.1123 - val_loss: 3592.6079\n",
      "Epoch 246/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 3715.7642 - val_loss: 3591.2571\n",
      "Epoch 247/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 3714.4170 - val_loss: 3589.9072\n",
      "Epoch 248/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 3713.0710 - val_loss: 3588.5579\n",
      "Epoch 249/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 3711.7258 - val_loss: 3587.2095\n",
      "Epoch 250/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 3710.3806 - val_loss: 3585.8625\n",
      "Epoch 251/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 3709.0374 - val_loss: 3584.5164\n",
      "Epoch 252/100000\n",
      "11/11 [==============================] - 0s 903us/step - loss: 3707.6946 - val_loss: 3583.1709\n",
      "Epoch 253/100000\n",
      "11/11 [==============================] - 0s 667us/step - loss: 3706.3530 - val_loss: 3581.8240\n",
      "Epoch 254/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 3705.0100 - val_loss: 3580.4805\n",
      "Epoch 255/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 3703.6702 - val_loss: 3579.1377\n",
      "Epoch 256/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 3702.3311 - val_loss: 3577.7961\n",
      "Epoch 257/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 3700.9929 - val_loss: 3576.4548\n",
      "Epoch 258/100000\n",
      "11/11 [==============================] - 0s 688us/step - loss: 3699.6560 - val_loss: 3575.1150\n",
      "Epoch 259/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 3698.3201 - val_loss: 3573.7764\n",
      "Epoch 260/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 3696.9844 - val_loss: 3572.4385\n",
      "Epoch 261/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 3695.6501 - val_loss: 3571.0994\n",
      "Epoch 262/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 3694.3147 - val_loss: 3569.7634\n",
      "Epoch 263/100000\n",
      "11/11 [==============================] - 0s 724us/step - loss: 3692.9827 - val_loss: 3568.4260\n",
      "Epoch 264/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 3691.6492 - val_loss: 3567.0898\n",
      "Epoch 265/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 3690.3167 - val_loss: 3565.7571\n",
      "Epoch 266/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 3688.9875 - val_loss: 3564.4250\n",
      "Epoch 267/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 3687.6592 - val_loss: 3563.0940\n",
      "Epoch 268/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 3686.3318 - val_loss: 3561.7620\n",
      "Epoch 269/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 3685.0037 - val_loss: 3560.4333\n",
      "Epoch 270/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 3683.6782 - val_loss: 3559.1055\n",
      "Epoch 271/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 3682.3540 - val_loss: 3557.7783\n",
      "Epoch 272/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 3681.0310 - val_loss: 3556.4524\n",
      "Epoch 273/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 3679.7087 - val_loss: 3555.1279\n",
      "Epoch 274/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 3678.3877 - val_loss: 3553.8044\n",
      "Epoch 275/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 3677.0681 - val_loss: 3552.4822\n",
      "Epoch 276/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 3675.7493 - val_loss: 3551.1604\n",
      "Epoch 277/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 3674.4319 - val_loss: 3549.8381\n",
      "Epoch 278/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 3673.1130 - val_loss: 3548.5193\n",
      "Epoch 279/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 3671.7971 - val_loss: 3547.1992\n",
      "Epoch 280/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 3670.4807 - val_loss: 3545.8821\n",
      "Epoch 281/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 3669.1677 - val_loss: 3544.5667\n",
      "Epoch 282/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 3667.8557 - val_loss: 3543.2522\n",
      "Epoch 283/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 3666.5452 - val_loss: 3541.9368\n",
      "Epoch 284/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 3665.2334 - val_loss: 3540.6250\n",
      "Epoch 285/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 3663.9248 - val_loss: 3539.3142\n",
      "Epoch 286/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 3662.6179 - val_loss: 3538.0022\n",
      "Epoch 287/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 3661.3096 - val_loss: 3536.6943\n",
      "Epoch 288/100000\n",
      "11/11 [==============================] - 0s 654us/step - loss: 3660.0049 - val_loss: 3535.3875\n",
      "Epoch 289/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 3658.7021 - val_loss: 3534.0818\n",
      "Epoch 290/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 3657.3999 - val_loss: 3532.7773\n",
      "Epoch 291/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 3656.0991 - val_loss: 3531.4724\n",
      "Epoch 292/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 3654.7976 - val_loss: 3530.1709\n",
      "Epoch 293/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 3653.4998 - val_loss: 3528.8708\n",
      "Epoch 294/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 3652.2031 - val_loss: 3527.5718\n",
      "Epoch 295/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 3650.9080 - val_loss: 3526.2742\n",
      "Epoch 296/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 3649.6143 - val_loss: 3524.9766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 3648.3203 - val_loss: 3523.6821\n",
      "Epoch 298/100000\n",
      "11/11 [==============================] - 0s 795us/step - loss: 3647.0291 - val_loss: 3522.3892\n",
      "Epoch 299/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 3645.7400 - val_loss: 3521.0977\n",
      "Epoch 300/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 3644.4517 - val_loss: 3519.8083\n",
      "Epoch 301/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 3643.1663 - val_loss: 3518.5198\n",
      "Epoch 302/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 3641.8813 - val_loss: 3517.2334\n",
      "Epoch 303/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 3640.5984 - val_loss: 3515.9482\n",
      "Epoch 304/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 3639.3167 - val_loss: 3514.6650\n",
      "Epoch 305/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 3638.0374 - val_loss: 3513.3831\n",
      "Epoch 306/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 3636.7593 - val_loss: 3512.1016\n",
      "Epoch 307/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 3635.4807 - val_loss: 3510.8235\n",
      "Epoch 308/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 3634.2063 - val_loss: 3509.5469\n",
      "Epoch 309/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 3632.9333 - val_loss: 3508.2725\n",
      "Epoch 310/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 3631.6624 - val_loss: 3506.9993\n",
      "Epoch 311/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 3630.3931 - val_loss: 3505.7288\n",
      "Epoch 312/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 3629.1257 - val_loss: 3504.4592\n",
      "Epoch 313/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 3627.8601 - val_loss: 3503.1917\n",
      "Epoch 314/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 3626.5962 - val_loss: 3501.9268\n",
      "Epoch 315/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 3625.3345 - val_loss: 3500.6633\n",
      "Epoch 316/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 3624.0750 - val_loss: 3499.4021\n",
      "Epoch 317/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 3622.8167 - val_loss: 3498.1409\n",
      "Epoch 318/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 3621.5593 - val_loss: 3496.8835\n",
      "Epoch 319/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 3620.3054 - val_loss: 3495.6279\n",
      "Epoch 320/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 3619.0532 - val_loss: 3494.3748\n",
      "Epoch 321/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 3617.8037 - val_loss: 3493.1233\n",
      "Epoch 322/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 3616.5557 - val_loss: 3491.8743\n",
      "Epoch 323/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 3615.3103 - val_loss: 3490.6272\n",
      "Epoch 324/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 3614.0664 - val_loss: 3489.3821\n",
      "Epoch 325/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 3612.8252 - val_loss: 3488.1396\n",
      "Epoch 326/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 3611.5859 - val_loss: 3486.8992\n",
      "Epoch 327/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 3610.3494 - val_loss: 3485.6604\n",
      "Epoch 328/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 3609.1140 - val_loss: 3484.4243\n",
      "Epoch 329/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 3607.8813 - val_loss: 3483.1907\n",
      "Epoch 330/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 3606.6514 - val_loss: 3481.9587\n",
      "Epoch 331/100000\n",
      "11/11 [==============================] - 0s 968us/step - loss: 3605.4229 - val_loss: 3480.7295\n",
      "Epoch 332/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 3604.1970 - val_loss: 3479.5022\n",
      "Epoch 333/100000\n",
      "11/11 [==============================] - 0s 724us/step - loss: 3602.9729 - val_loss: 3478.2759\n",
      "Epoch 334/100000\n",
      "11/11 [==============================] - 0s 648us/step - loss: 3601.7502 - val_loss: 3477.0515\n",
      "Epoch 335/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 3600.5298 - val_loss: 3475.8313\n",
      "Epoch 336/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 3599.3127 - val_loss: 3474.6118\n",
      "Epoch 337/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 3598.0967 - val_loss: 3473.3948\n",
      "Epoch 338/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3596.8835 - val_loss: 3472.1814\n",
      "Epoch 339/100000\n",
      "11/11 [==============================] - 0s 610us/step - loss: 3595.6736 - val_loss: 3470.9709\n",
      "Epoch 340/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 3594.4666 - val_loss: 3469.7625\n",
      "Epoch 341/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 3593.2615 - val_loss: 3468.5547\n",
      "Epoch 342/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 3592.0576 - val_loss: 3467.3508\n",
      "Epoch 343/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 3590.8569 - val_loss: 3466.1494\n",
      "Epoch 344/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 3589.6592 - val_loss: 3464.9509\n",
      "Epoch 345/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 3588.4641 - val_loss: 3463.7539\n",
      "Epoch 346/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3587.2703 - val_loss: 3462.5596\n",
      "Epoch 347/100000\n",
      "11/11 [==============================] - 0s 809us/step - loss: 3586.0796 - val_loss: 3461.3682\n",
      "Epoch 348/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 3584.8916 - val_loss: 3460.1787\n",
      "Epoch 349/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 3583.7061 - val_loss: 3458.9915\n",
      "Epoch 350/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 3582.5225 - val_loss: 3457.8076\n",
      "Epoch 351/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 3581.3413 - val_loss: 3456.6250\n",
      "Epoch 352/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 3580.1626 - val_loss: 3455.4453\n",
      "Epoch 353/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 3578.9861 - val_loss: 3454.2681\n",
      "Epoch 354/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 3577.8125 - val_loss: 3453.0930\n",
      "Epoch 355/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 3576.6409 - val_loss: 3451.9204\n",
      "Epoch 356/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 3575.4719 - val_loss: 3450.7500\n",
      "Epoch 357/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 3574.3054 - val_loss: 3449.5823\n",
      "Epoch 358/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 3573.1409 - val_loss: 3448.4170\n",
      "Epoch 359/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 3571.9788 - val_loss: 3447.2539\n",
      "Epoch 360/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 3570.8196 - val_loss: 3446.0938\n",
      "Epoch 361/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 3569.6626 - val_loss: 3444.9351\n",
      "Epoch 362/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 3568.5078 - val_loss: 3443.7795\n",
      "Epoch 363/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 3567.3552 - val_loss: 3442.6257\n",
      "Epoch 364/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 3566.2053 - val_loss: 3441.4749\n",
      "Epoch 365/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 3565.0576 - val_loss: 3440.3259\n",
      "Epoch 366/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 3563.9124 - val_loss: 3439.1797\n",
      "Epoch 367/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 3562.7693 - val_loss: 3438.0342\n",
      "Epoch 368/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 3561.6272 - val_loss: 3436.8923\n",
      "Epoch 369/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 3560.4885 - val_loss: 3435.7515\n",
      "Epoch 370/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 3559.3518 - val_loss: 3434.6143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/100000\n",
      "11/11 [==============================] - 0s 581us/step - loss: 3558.2180 - val_loss: 3433.4783\n",
      "Epoch 372/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 3557.0850 - val_loss: 3432.3452\n",
      "Epoch 373/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 3555.9561 - val_loss: 3431.2151\n",
      "Epoch 374/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 3554.8291 - val_loss: 3430.0859\n",
      "Epoch 375/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 3553.7031 - val_loss: 3428.9602\n",
      "Epoch 376/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 3552.5806 - val_loss: 3427.8367\n",
      "Epoch 377/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 3551.4602 - val_loss: 3426.7151\n",
      "Epoch 378/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 3550.3428 - val_loss: 3425.5945\n",
      "Epoch 379/100000\n",
      "11/11 [==============================] - 0s 623us/step - loss: 3549.2258 - val_loss: 3424.4775\n",
      "Epoch 380/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 3548.1123 - val_loss: 3423.3618\n",
      "Epoch 381/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 3547.0000 - val_loss: 3422.2478\n",
      "Epoch 382/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 3545.8892 - val_loss: 3421.1367\n",
      "Epoch 383/100000\n",
      "11/11 [==============================] - 0s 713us/step - loss: 3544.7812 - val_loss: 3420.0271\n",
      "Epoch 384/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 3543.6755 - val_loss: 3418.9197\n",
      "Epoch 385/100000\n",
      "11/11 [==============================] - 0s 919us/step - loss: 3542.5713 - val_loss: 3417.8147\n",
      "Epoch 386/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 3541.4697 - val_loss: 3416.7131\n",
      "Epoch 387/100000\n",
      "11/11 [==============================] - 0s 604us/step - loss: 3540.3713 - val_loss: 3415.6118\n",
      "Epoch 388/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 3539.2737 - val_loss: 3414.5142\n",
      "Epoch 389/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 3538.1797 - val_loss: 3413.4177\n",
      "Epoch 390/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 3537.0862 - val_loss: 3412.3245\n",
      "Epoch 391/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 3535.9963 - val_loss: 3411.2319\n",
      "Epoch 392/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 3534.9072 - val_loss: 3410.1423\n",
      "Epoch 393/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 3533.8213 - val_loss: 3409.0549\n",
      "Epoch 394/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 3532.7373 - val_loss: 3407.9688\n",
      "Epoch 395/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 3531.6541 - val_loss: 3406.8857\n",
      "Epoch 396/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 3530.5745 - val_loss: 3405.8044\n",
      "Epoch 397/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 3529.4963 - val_loss: 3404.7249\n",
      "Epoch 398/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 3528.4204 - val_loss: 3403.6462\n",
      "Epoch 399/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 3527.3452 - val_loss: 3402.5701\n",
      "Epoch 400/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 3526.2720 - val_loss: 3401.4963\n",
      "Epoch 401/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 3525.2024 - val_loss: 3400.4241\n",
      "Epoch 402/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 3524.1331 - val_loss: 3399.3545\n",
      "Epoch 403/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 3523.0667 - val_loss: 3398.2854\n",
      "Epoch 404/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 3522.0015 - val_loss: 3397.2197\n",
      "Epoch 405/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 3520.9390 - val_loss: 3396.1548\n",
      "Epoch 406/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 3519.8774 - val_loss: 3395.0916\n",
      "Epoch 407/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 3518.8174 - val_loss: 3394.0305\n",
      "Epoch 408/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 3517.7595 - val_loss: 3392.9717\n",
      "Epoch 409/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 3516.7046 - val_loss: 3391.9155\n",
      "Epoch 410/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 3515.6514 - val_loss: 3390.8594\n",
      "Epoch 411/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 3514.5986 - val_loss: 3389.8069\n",
      "Epoch 412/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 3513.5491 - val_loss: 3388.7546\n",
      "Epoch 413/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 3512.5002 - val_loss: 3387.7053\n",
      "Epoch 414/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 3511.4541 - val_loss: 3386.6572\n",
      "Epoch 415/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 3510.4102 - val_loss: 3385.6104\n",
      "Epoch 416/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 3509.3665 - val_loss: 3384.5664\n",
      "Epoch 417/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 3508.3252 - val_loss: 3383.5227\n",
      "Epoch 418/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 3507.2854 - val_loss: 3382.4822\n",
      "Epoch 419/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 3506.2483 - val_loss: 3381.4431\n",
      "Epoch 420/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 3505.2124 - val_loss: 3380.4048\n",
      "Epoch 421/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 3504.1775 - val_loss: 3379.3696\n",
      "Epoch 422/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 3503.1453 - val_loss: 3378.3352\n",
      "Epoch 423/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 3502.1143 - val_loss: 3377.3032\n",
      "Epoch 424/100000\n",
      "11/11 [==============================] - 0s 581us/step - loss: 3501.0850 - val_loss: 3376.2712\n",
      "Epoch 425/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 3500.0569 - val_loss: 3375.2412\n",
      "Epoch 426/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 3499.0298 - val_loss: 3374.2139\n",
      "Epoch 427/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 3498.0061 - val_loss: 3373.1873\n",
      "Epoch 428/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 3496.9827 - val_loss: 3372.1619\n",
      "Epoch 429/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 3495.9602 - val_loss: 3371.1384\n",
      "Epoch 430/100000\n",
      "11/11 [==============================] - 0s 594us/step - loss: 3494.9404 - val_loss: 3370.1172\n",
      "Epoch 431/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3493.9226 - val_loss: 3369.0967\n",
      "Epoch 432/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3492.9053 - val_loss: 3368.0779\n",
      "Epoch 433/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3491.8896 - val_loss: 3367.0603\n",
      "Epoch 434/100000\n",
      "11/11 [==============================] - 0s 590us/step - loss: 3490.8752 - val_loss: 3366.0447\n",
      "Epoch 435/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3489.8625 - val_loss: 3365.0312\n",
      "Epoch 436/100000\n",
      "11/11 [==============================] - 0s 961us/step - loss: 3488.8523 - val_loss: 3364.0186\n",
      "Epoch 437/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 3487.8430 - val_loss: 3363.0085\n",
      "Epoch 438/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 3486.8359 - val_loss: 3361.9983\n",
      "Epoch 439/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 3485.8291 - val_loss: 3360.9907\n",
      "Epoch 440/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 3484.8252 - val_loss: 3359.9851\n",
      "Epoch 441/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 3483.8225 - val_loss: 3358.9805\n",
      "Epoch 442/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 3482.8210 - val_loss: 3357.9773\n",
      "Epoch 443/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 3481.8213 - val_loss: 3356.9758\n",
      "Epoch 444/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 3480.8225 - val_loss: 3355.9756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3479.8257 - val_loss: 3354.9766\n",
      "Epoch 446/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 3478.8303 - val_loss: 3353.9795\n",
      "Epoch 447/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3477.8359 - val_loss: 3352.9827\n",
      "Epoch 448/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3476.8423 - val_loss: 3351.9873\n",
      "Epoch 449/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 3475.8499 - val_loss: 3350.9937\n",
      "Epoch 450/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 3474.8601 - val_loss: 3350.0007\n",
      "Epoch 451/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 3473.8704 - val_loss: 3349.0107\n",
      "Epoch 452/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 3472.8831 - val_loss: 3348.0203\n",
      "Epoch 453/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 3471.8962 - val_loss: 3347.0327\n",
      "Epoch 454/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 3470.9116 - val_loss: 3346.0461\n",
      "Epoch 455/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 3469.9280 - val_loss: 3345.0610\n",
      "Epoch 456/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 3468.9460 - val_loss: 3344.0767\n",
      "Epoch 457/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 3467.9651 - val_loss: 3343.0945\n",
      "Epoch 458/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 3466.9858 - val_loss: 3342.1123\n",
      "Epoch 459/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 3466.0068 - val_loss: 3341.1321\n",
      "Epoch 460/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 3465.0298 - val_loss: 3340.1538\n",
      "Epoch 461/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 3464.0544 - val_loss: 3339.1760\n",
      "Epoch 462/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 3463.0803 - val_loss: 3338.2000\n",
      "Epoch 463/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 3462.1072 - val_loss: 3337.2251\n",
      "Epoch 464/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 3461.1353 - val_loss: 3336.2510\n",
      "Epoch 465/100000\n",
      "11/11 [==============================] - 0s 203us/step - loss: 3460.1643 - val_loss: 3335.2783\n",
      "Epoch 466/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 3459.1953 - val_loss: 3334.3076\n",
      "Epoch 467/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 3458.2268 - val_loss: 3333.3374\n",
      "Epoch 468/100000\n",
      "11/11 [==============================] - 0s 197us/step - loss: 3457.2603 - val_loss: 3332.3687\n",
      "Epoch 469/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 3456.2944 - val_loss: 3331.3999\n",
      "Epoch 470/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 3455.3289 - val_loss: 3330.4336\n",
      "Epoch 471/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 3454.3657 - val_loss: 3329.4685\n",
      "Epoch 472/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 3453.4033 - val_loss: 3328.5042\n",
      "Epoch 473/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 3452.4429 - val_loss: 3327.5405\n",
      "Epoch 474/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 3451.4822 - val_loss: 3326.5784\n",
      "Epoch 475/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 3450.5234 - val_loss: 3325.6179\n",
      "Epoch 476/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 3449.5657 - val_loss: 3324.6584\n",
      "Epoch 477/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 3448.6094 - val_loss: 3323.7002\n",
      "Epoch 478/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 3447.6538 - val_loss: 3322.7429\n",
      "Epoch 479/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 3446.6995 - val_loss: 3321.7859\n",
      "Epoch 480/100000\n",
      "11/11 [==============================] - 0s 200us/step - loss: 3445.7458 - val_loss: 3320.8311\n",
      "Epoch 481/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 3444.7939 - val_loss: 3319.8772\n",
      "Epoch 482/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 3443.8435 - val_loss: 3318.9243\n",
      "Epoch 483/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 3442.8936 - val_loss: 3317.9727\n",
      "Epoch 484/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 3441.9451 - val_loss: 3317.0225\n",
      "Epoch 485/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 3440.9971 - val_loss: 3316.0725\n",
      "Epoch 486/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 3440.0508 - val_loss: 3315.1243\n",
      "Epoch 487/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 3439.1057 - val_loss: 3314.1765\n",
      "Epoch 488/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 3438.1611 - val_loss: 3313.2302\n",
      "Epoch 489/100000\n",
      "11/11 [==============================] - 0s 812us/step - loss: 3437.2178 - val_loss: 3312.2849\n",
      "Epoch 490/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3436.2759 - val_loss: 3311.3401\n",
      "Epoch 491/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 3435.3337 - val_loss: 3310.3960\n",
      "Epoch 492/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3434.3928 - val_loss: 3309.4539\n",
      "Epoch 493/100000\n",
      "11/11 [==============================] - 0s 629us/step - loss: 3433.4534 - val_loss: 3308.5127\n",
      "Epoch 494/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3432.5156 - val_loss: 3307.5718\n",
      "Epoch 495/100000\n",
      "11/11 [==============================] - 0s 644us/step - loss: 3431.5781 - val_loss: 3306.6321\n",
      "Epoch 496/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 3430.6406 - val_loss: 3305.6931\n",
      "Epoch 497/100000\n",
      "11/11 [==============================] - 0s 932us/step - loss: 3429.7053 - val_loss: 3304.7549\n",
      "Epoch 498/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 3428.7703 - val_loss: 3303.8193\n",
      "Epoch 499/100000\n",
      "11/11 [==============================] - 0s 903us/step - loss: 3427.8374 - val_loss: 3302.8843\n",
      "Epoch 500/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3426.9053 - val_loss: 3301.9490\n",
      "Epoch 501/100000\n",
      "11/11 [==============================] - 0s 825us/step - loss: 3425.9729 - val_loss: 3301.0159\n",
      "Epoch 502/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 3425.0432 - val_loss: 3300.0830\n",
      "Epoch 503/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 3424.1130 - val_loss: 3299.1509\n",
      "Epoch 504/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3423.1838 - val_loss: 3298.2197\n",
      "Epoch 505/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3422.2561 - val_loss: 3297.2898\n",
      "Epoch 506/100000\n",
      "11/11 [==============================] - 0s 804us/step - loss: 3421.3289 - val_loss: 3296.3604\n",
      "Epoch 507/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 3420.4026 - val_loss: 3295.4326\n",
      "Epoch 508/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 3419.4773 - val_loss: 3294.5049\n",
      "Epoch 509/100000\n",
      "11/11 [==============================] - 0s 205us/step - loss: 3418.5537 - val_loss: 3293.5796\n",
      "Epoch 510/100000\n",
      "11/11 [==============================] - 0s 591us/step - loss: 3417.6306 - val_loss: 3292.6541\n",
      "Epoch 511/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 3416.7080 - val_loss: 3291.7307\n",
      "Epoch 512/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 3415.7876 - val_loss: 3290.8076\n",
      "Epoch 513/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 3414.8674 - val_loss: 3289.8850\n",
      "Epoch 514/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 3413.9478 - val_loss: 3288.9639\n",
      "Epoch 515/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 3413.0298 - val_loss: 3288.0437\n",
      "Epoch 516/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 3412.1125 - val_loss: 3287.1243\n",
      "Epoch 517/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 3411.1960 - val_loss: 3286.2061\n",
      "Epoch 518/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 3410.2805 - val_loss: 3285.2883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 519/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 3409.3665 - val_loss: 3284.3708\n",
      "Epoch 520/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 3408.4514 - val_loss: 3283.4553\n",
      "Epoch 521/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 3407.5391 - val_loss: 3282.5400\n",
      "Epoch 522/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 3406.6267 - val_loss: 3281.6252\n",
      "Epoch 523/100000\n",
      "11/11 [==============================] - 0s 205us/step - loss: 3405.7146 - val_loss: 3280.7117\n",
      "Epoch 524/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 3404.8044 - val_loss: 3279.7998\n",
      "Epoch 525/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 3403.8948 - val_loss: 3278.8870\n",
      "Epoch 526/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 3402.9858 - val_loss: 3277.9766\n",
      "Epoch 527/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 3402.0779 - val_loss: 3277.0664\n",
      "Epoch 528/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 3401.1709 - val_loss: 3276.1572\n",
      "Epoch 529/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 3400.2646 - val_loss: 3275.2490\n",
      "Epoch 530/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 3399.3591 - val_loss: 3274.3416\n",
      "Epoch 531/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 3398.4546 - val_loss: 3273.4343\n",
      "Epoch 532/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 3397.5500 - val_loss: 3272.5283\n",
      "Epoch 533/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 3396.6470 - val_loss: 3271.6233\n",
      "Epoch 534/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 3395.7451 - val_loss: 3270.7188\n",
      "Epoch 535/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 3394.8438 - val_loss: 3269.8154\n",
      "Epoch 536/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 3393.9429 - val_loss: 3268.9119\n",
      "Epoch 537/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 3393.0427 - val_loss: 3268.0100\n",
      "Epoch 538/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 3392.1436 - val_loss: 3267.1079\n",
      "Epoch 539/100000\n",
      "11/11 [==============================] - 0s 621us/step - loss: 3391.2444 - val_loss: 3266.2070\n",
      "Epoch 540/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 3390.3467 - val_loss: 3265.3076\n",
      "Epoch 541/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 3389.4495 - val_loss: 3264.4084\n",
      "Epoch 542/100000\n",
      "11/11 [==============================] - 0s 888us/step - loss: 3388.5532 - val_loss: 3263.5093\n",
      "Epoch 543/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3387.6577 - val_loss: 3262.6111\n",
      "Epoch 544/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 3386.7620 - val_loss: 3261.7146\n",
      "Epoch 545/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3385.8687 - val_loss: 3260.8181\n",
      "Epoch 546/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3384.9749 - val_loss: 3259.9221\n",
      "Epoch 547/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 3384.0818 - val_loss: 3259.0273\n",
      "Epoch 548/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 3383.1904 - val_loss: 3258.1335\n",
      "Epoch 549/100000\n",
      "11/11 [==============================] - 0s 737us/step - loss: 3382.2993 - val_loss: 3257.2400\n",
      "Epoch 550/100000\n",
      "11/11 [==============================] - 0s 745us/step - loss: 3381.4087 - val_loss: 3256.3477\n",
      "Epoch 551/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 3380.5188 - val_loss: 3255.4561\n",
      "Epoch 552/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 3379.6304 - val_loss: 3254.5647\n",
      "Epoch 553/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 3378.7419 - val_loss: 3253.6748\n",
      "Epoch 554/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 3377.8547 - val_loss: 3252.7844\n",
      "Epoch 555/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 3376.9673 - val_loss: 3251.8953\n",
      "Epoch 556/100000\n",
      "11/11 [==============================] - 0s 994us/step - loss: 3376.0806 - val_loss: 3251.0063\n",
      "Epoch 557/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 3375.1953 - val_loss: 3250.1194\n",
      "Epoch 558/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3374.3103 - val_loss: 3249.2314\n",
      "Epoch 559/100000\n",
      "11/11 [==============================] - 0s 970us/step - loss: 3373.4258 - val_loss: 3248.3447\n",
      "Epoch 560/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3372.5420 - val_loss: 3247.4585\n",
      "Epoch 561/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 3371.6587 - val_loss: 3246.5740\n",
      "Epoch 562/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 3370.7771 - val_loss: 3245.6897\n",
      "Epoch 563/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3369.8953 - val_loss: 3244.8054\n",
      "Epoch 564/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3369.0142 - val_loss: 3243.9219\n",
      "Epoch 565/100000\n",
      "11/11 [==============================] - 0s 745us/step - loss: 3368.1335 - val_loss: 3243.0398\n",
      "Epoch 566/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 3367.2539 - val_loss: 3242.1580\n",
      "Epoch 567/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 3366.3750 - val_loss: 3241.2771\n",
      "Epoch 568/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 3365.4968 - val_loss: 3240.3962\n",
      "Epoch 569/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 3364.6196 - val_loss: 3239.5159\n",
      "Epoch 570/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3363.7419 - val_loss: 3238.6370\n",
      "Epoch 571/100000\n",
      "11/11 [==============================] - 0s 644us/step - loss: 3362.8655 - val_loss: 3237.7581\n",
      "Epoch 572/100000\n",
      "11/11 [==============================] - 0s 827us/step - loss: 3361.9897 - val_loss: 3236.8799\n",
      "Epoch 573/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 3361.1140 - val_loss: 3236.0024\n",
      "Epoch 574/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 3360.2397 - val_loss: 3235.1257\n",
      "Epoch 575/100000\n",
      "11/11 [==============================] - 0s 586us/step - loss: 3359.3657 - val_loss: 3234.2493\n",
      "Epoch 576/100000\n",
      "11/11 [==============================] - 0s 950us/step - loss: 3358.4922 - val_loss: 3233.3740\n",
      "Epoch 577/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 3357.6196 - val_loss: 3232.4993\n",
      "Epoch 578/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 3356.7476 - val_loss: 3231.6248\n",
      "Epoch 579/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 3355.8760 - val_loss: 3230.7507\n",
      "Epoch 580/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 3355.0046 - val_loss: 3229.8774\n",
      "Epoch 581/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 3354.1345 - val_loss: 3229.0049\n",
      "Epoch 582/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 3353.2646 - val_loss: 3228.1328\n",
      "Epoch 583/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 3352.3953 - val_loss: 3227.2615\n",
      "Epoch 584/100000\n",
      "11/11 [==============================] - 0s 878us/step - loss: 3351.5264 - val_loss: 3226.3899\n",
      "Epoch 585/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3350.6584 - val_loss: 3225.5193\n",
      "Epoch 586/100000\n",
      "11/11 [==============================] - 0s 654us/step - loss: 3349.7898 - val_loss: 3224.6492\n",
      "Epoch 587/100000\n",
      "11/11 [==============================] - 0s 927us/step - loss: 3348.9226 - val_loss: 3223.7798\n",
      "Epoch 588/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 3348.0564 - val_loss: 3222.9111\n",
      "Epoch 589/100000\n",
      "11/11 [==============================] - 0s 774us/step - loss: 3347.1904 - val_loss: 3222.0427\n",
      "Epoch 590/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3346.3250 - val_loss: 3221.1748\n",
      "Epoch 591/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3345.4600 - val_loss: 3220.3076\n",
      "Epoch 592/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3344.5955 - val_loss: 3219.4412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 593/100000\n",
      "11/11 [==============================] - 0s 864us/step - loss: 3343.7312 - val_loss: 3218.5742\n",
      "Epoch 594/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 3342.8679 - val_loss: 3217.7080\n",
      "Epoch 595/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 3342.0046 - val_loss: 3216.8430\n",
      "Epoch 596/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 3341.1421 - val_loss: 3215.9783\n",
      "Epoch 597/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 3340.2803 - val_loss: 3215.1140\n",
      "Epoch 598/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 3339.4187 - val_loss: 3214.2500\n",
      "Epoch 599/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 3338.5571 - val_loss: 3213.3867\n",
      "Epoch 600/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 3337.6968 - val_loss: 3212.5237\n",
      "Epoch 601/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 3336.8367 - val_loss: 3211.6616\n",
      "Epoch 602/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 3335.9773 - val_loss: 3210.7998\n",
      "Epoch 603/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 3335.1182 - val_loss: 3209.9377\n",
      "Epoch 604/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 3334.2593 - val_loss: 3209.0771\n",
      "Epoch 605/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 3333.4014 - val_loss: 3208.2166\n",
      "Epoch 606/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 3332.5432 - val_loss: 3207.3564\n",
      "Epoch 607/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 3331.6860 - val_loss: 3206.4968\n",
      "Epoch 608/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 3330.8291 - val_loss: 3205.6382\n",
      "Epoch 609/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 3329.9729 - val_loss: 3204.7791\n",
      "Epoch 610/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 3329.1174 - val_loss: 3203.9209\n",
      "Epoch 611/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 3328.2620 - val_loss: 3203.0632\n",
      "Epoch 612/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 3327.4070 - val_loss: 3202.2061\n",
      "Epoch 613/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 3326.5518 - val_loss: 3201.3486\n",
      "Epoch 614/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 3325.6982 - val_loss: 3200.4924\n",
      "Epoch 615/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 3324.8440 - val_loss: 3199.6360\n",
      "Epoch 616/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 3323.9907 - val_loss: 3198.7798\n",
      "Epoch 617/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 3323.1375 - val_loss: 3197.9243\n",
      "Epoch 618/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 3322.2849 - val_loss: 3197.0693\n",
      "Epoch 619/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 3321.4321 - val_loss: 3196.2148\n",
      "Epoch 620/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 3320.5803 - val_loss: 3195.3601\n",
      "Epoch 621/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 3319.7290 - val_loss: 3194.5068\n",
      "Epoch 622/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 3318.8779 - val_loss: 3193.6533\n",
      "Epoch 623/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 3318.0273 - val_loss: 3192.7998\n",
      "Epoch 624/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 3317.1760 - val_loss: 3191.9470\n",
      "Epoch 625/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 3316.3264 - val_loss: 3191.0945\n",
      "Epoch 626/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 3315.4768 - val_loss: 3190.2424\n",
      "Epoch 627/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 3314.6274 - val_loss: 3189.3906\n",
      "Epoch 628/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 3313.7783 - val_loss: 3188.5393\n",
      "Epoch 629/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 3312.9297 - val_loss: 3187.6882\n",
      "Epoch 630/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 3312.0818 - val_loss: 3186.8374\n",
      "Epoch 631/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 3311.2334 - val_loss: 3185.9868\n",
      "Epoch 632/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 3310.3857 - val_loss: 3185.1370\n",
      "Epoch 633/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 3309.5383 - val_loss: 3184.2866\n",
      "Epoch 634/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 3308.6912 - val_loss: 3183.4373\n",
      "Epoch 635/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 3307.8445 - val_loss: 3182.5874\n",
      "Epoch 636/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 3306.9971 - val_loss: 3181.7380\n",
      "Epoch 637/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 3306.1506 - val_loss: 3180.8892\n",
      "Epoch 638/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 3305.3044 - val_loss: 3180.0405\n",
      "Epoch 639/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 3304.4580 - val_loss: 3179.1917\n",
      "Epoch 640/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 3303.6123 - val_loss: 3178.3435\n",
      "Epoch 641/100000\n",
      "11/11 [==============================] - 0s 719us/step - loss: 3302.7671 - val_loss: 3177.4951\n",
      "Epoch 642/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 3301.9211 - val_loss: 3176.6475\n",
      "Epoch 643/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 3301.0767 - val_loss: 3175.7998\n",
      "Epoch 644/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 3300.2314 - val_loss: 3174.9524\n",
      "Epoch 645/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 3299.3870 - val_loss: 3174.1052\n",
      "Epoch 646/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 3298.5427 - val_loss: 3173.2578\n",
      "Epoch 647/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 3297.6978 - val_loss: 3172.4104\n",
      "Epoch 648/100000\n",
      "11/11 [==============================] - 0s 195us/step - loss: 3296.8533 - val_loss: 3171.5640\n",
      "Epoch 649/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 3296.0095 - val_loss: 3170.7173\n",
      "Epoch 650/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 3295.1655 - val_loss: 3169.8708\n",
      "Epoch 651/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 3294.3218 - val_loss: 3169.0244\n",
      "Epoch 652/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 3293.4783 - val_loss: 3168.1782\n",
      "Epoch 653/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 3292.6345 - val_loss: 3167.3320\n",
      "Epoch 654/100000\n",
      "11/11 [==============================] - 0s 826us/step - loss: 3291.7913 - val_loss: 3166.4861\n",
      "Epoch 655/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 3290.9478 - val_loss: 3165.6399\n",
      "Epoch 656/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 3290.1047 - val_loss: 3164.7932\n",
      "Epoch 657/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 3289.2607 - val_loss: 3163.9470\n",
      "Epoch 658/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 3288.4177 - val_loss: 3163.1016\n",
      "Epoch 659/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 3287.5745 - val_loss: 3162.2556\n",
      "Epoch 660/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 3286.7307 - val_loss: 3161.4092\n",
      "Epoch 661/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 3285.8877 - val_loss: 3160.5632\n",
      "Epoch 662/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 3285.0444 - val_loss: 3159.7173\n",
      "Epoch 663/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 3284.2009 - val_loss: 3158.8708\n",
      "Epoch 664/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 3283.3577 - val_loss: 3158.0249\n",
      "Epoch 665/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 3282.5142 - val_loss: 3157.1782\n",
      "Epoch 666/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 443us/step - loss: 3281.6704 - val_loss: 3156.3318\n",
      "Epoch 667/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 3280.8267 - val_loss: 3155.4844\n",
      "Epoch 668/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 3279.9822 - val_loss: 3154.6375\n",
      "Epoch 669/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 3279.1382 - val_loss: 3153.7905\n",
      "Epoch 670/100000\n",
      "11/11 [==============================] - 0s 205us/step - loss: 3278.2937 - val_loss: 3152.9431\n",
      "Epoch 671/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 3277.4495 - val_loss: 3152.0959\n",
      "Epoch 672/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 3276.6045 - val_loss: 3151.2478\n",
      "Epoch 673/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 3275.7600 - val_loss: 3150.3999\n",
      "Epoch 674/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 3274.9141 - val_loss: 3149.5510\n",
      "Epoch 675/100000\n",
      "11/11 [==============================] - 0s 704us/step - loss: 3274.0681 - val_loss: 3148.7024\n",
      "Epoch 676/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 3273.2224 - val_loss: 3147.8538\n",
      "Epoch 677/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 3272.3760 - val_loss: 3147.0042\n",
      "Epoch 678/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 3271.5298 - val_loss: 3146.1541\n",
      "Epoch 679/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 3270.6821 - val_loss: 3145.3040\n",
      "Epoch 680/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 3269.8350 - val_loss: 3144.4531\n",
      "Epoch 681/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 3268.9873 - val_loss: 3143.6023\n",
      "Epoch 682/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 3268.1384 - val_loss: 3142.7507\n",
      "Epoch 683/100000\n",
      "11/11 [==============================] - 0s 784us/step - loss: 3267.2898 - val_loss: 3141.8982\n",
      "Epoch 684/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3266.4404 - val_loss: 3141.0447\n",
      "Epoch 685/100000\n",
      "11/11 [==============================] - 0s 742us/step - loss: 3265.5898 - val_loss: 3140.1917\n",
      "Epoch 686/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3264.7393 - val_loss: 3139.3376\n",
      "Epoch 687/100000\n",
      "11/11 [==============================] - 0s 856us/step - loss: 3263.8877 - val_loss: 3138.4829\n",
      "Epoch 688/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3263.0361 - val_loss: 3137.6279\n",
      "Epoch 689/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 3262.1833 - val_loss: 3136.7720\n",
      "Epoch 690/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3261.3306 - val_loss: 3135.9150\n",
      "Epoch 691/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3260.4766 - val_loss: 3135.0576\n",
      "Epoch 692/100000\n",
      "11/11 [==============================] - 0s 750us/step - loss: 3259.6221 - val_loss: 3134.1995\n",
      "Epoch 693/100000\n",
      "11/11 [==============================] - 0s 747us/step - loss: 3258.7666 - val_loss: 3133.3401\n",
      "Epoch 694/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 3257.9102 - val_loss: 3132.4802\n",
      "Epoch 695/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3257.0532 - val_loss: 3131.6189\n",
      "Epoch 696/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3256.1946 - val_loss: 3130.7571\n",
      "Epoch 697/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 3255.3357 - val_loss: 3129.8943\n",
      "Epoch 698/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 3254.4751 - val_loss: 3129.0303\n",
      "Epoch 699/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 3253.6143 - val_loss: 3128.1655\n",
      "Epoch 700/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 3252.7522 - val_loss: 3127.2991\n",
      "Epoch 701/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 3251.8884 - val_loss: 3126.4312\n",
      "Epoch 702/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 3251.0237 - val_loss: 3125.5627\n",
      "Epoch 703/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 3250.1580 - val_loss: 3124.6931\n",
      "Epoch 704/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 3249.2913 - val_loss: 3123.8218\n",
      "Epoch 705/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 3248.4226 - val_loss: 3122.9495\n",
      "Epoch 706/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 3247.5532 - val_loss: 3122.0759\n",
      "Epoch 707/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 3246.6821 - val_loss: 3121.2002\n",
      "Epoch 708/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 3245.8096 - val_loss: 3120.3240\n",
      "Epoch 709/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 3244.9360 - val_loss: 3119.4456\n",
      "Epoch 710/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 3244.0608 - val_loss: 3118.5657\n",
      "Epoch 711/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 3243.1836 - val_loss: 3117.6843\n",
      "Epoch 712/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 3242.3049 - val_loss: 3116.8008\n",
      "Epoch 713/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 3241.4243 - val_loss: 3115.9163\n",
      "Epoch 714/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 3240.5427 - val_loss: 3115.0295\n",
      "Epoch 715/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 3239.6584 - val_loss: 3114.1406\n",
      "Epoch 716/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 3238.7732 - val_loss: 3113.2500\n",
      "Epoch 717/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 3237.8853 - val_loss: 3112.3579\n",
      "Epoch 718/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 3236.9961 - val_loss: 3111.4641\n",
      "Epoch 719/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 3236.1047 - val_loss: 3110.5674\n",
      "Epoch 720/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 3235.2112 - val_loss: 3109.6689\n",
      "Epoch 721/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 3234.3162 - val_loss: 3108.7688\n",
      "Epoch 722/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 3233.4187 - val_loss: 3107.8662\n",
      "Epoch 723/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 3232.5188 - val_loss: 3106.9617\n",
      "Epoch 724/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 3231.6172 - val_loss: 3106.0544\n",
      "Epoch 725/100000\n",
      "11/11 [==============================] - 0s 643us/step - loss: 3230.7126 - val_loss: 3105.1448\n",
      "Epoch 726/100000\n",
      "11/11 [==============================] - 0s 731us/step - loss: 3229.8069 - val_loss: 3104.2334\n",
      "Epoch 727/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3228.8975 - val_loss: 3103.3188\n",
      "Epoch 728/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3227.9861 - val_loss: 3102.4026\n",
      "Epoch 729/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3227.0728 - val_loss: 3101.4836\n",
      "Epoch 730/100000\n",
      "11/11 [==============================] - 0s 989us/step - loss: 3226.1570 - val_loss: 3100.5623\n",
      "Epoch 731/100000\n",
      "11/11 [==============================] - 0s 956us/step - loss: 3225.2383 - val_loss: 3099.6382\n",
      "Epoch 732/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 3224.3174 - val_loss: 3098.7117\n",
      "Epoch 733/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 3223.3936 - val_loss: 3097.7827\n",
      "Epoch 734/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 3222.4673 - val_loss: 3096.8508\n",
      "Epoch 735/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 3221.5391 - val_loss: 3095.9163\n",
      "Epoch 736/100000\n",
      "11/11 [==============================] - 0s 771us/step - loss: 3220.6077 - val_loss: 3094.9790\n",
      "Epoch 737/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 3219.6733 - val_loss: 3094.0391\n",
      "Epoch 738/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 3218.7361 - val_loss: 3093.0967\n",
      "Epoch 739/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 3217.7966 - val_loss: 3092.1509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 740/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 3216.8540 - val_loss: 3091.2029\n",
      "Epoch 741/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 3215.9092 - val_loss: 3090.2517\n",
      "Epoch 742/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 3214.9609 - val_loss: 3089.2976\n",
      "Epoch 743/100000\n",
      "11/11 [==============================] - 0s 847us/step - loss: 3214.0100 - val_loss: 3088.3401\n",
      "Epoch 744/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 3213.0557 - val_loss: 3087.3806\n",
      "Epoch 745/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 3212.0994 - val_loss: 3086.4182\n",
      "Epoch 746/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 3211.1396 - val_loss: 3085.4524\n",
      "Epoch 747/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 3210.1775 - val_loss: 3084.4841\n",
      "Epoch 748/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 3209.2119 - val_loss: 3083.5127\n",
      "Epoch 749/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 3208.2439 - val_loss: 3082.5388\n",
      "Epoch 750/100000\n",
      "11/11 [==============================] - 0s 202us/step - loss: 3207.2727 - val_loss: 3081.5618\n",
      "Epoch 751/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 3206.2991 - val_loss: 3080.5823\n",
      "Epoch 752/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 3205.3225 - val_loss: 3079.6001\n",
      "Epoch 753/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 3204.3438 - val_loss: 3078.6150\n",
      "Epoch 754/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 3203.3618 - val_loss: 3077.6272\n",
      "Epoch 755/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 3202.3772 - val_loss: 3076.6360\n",
      "Epoch 756/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 3201.3892 - val_loss: 3075.6428\n",
      "Epoch 757/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 3200.3987 - val_loss: 3074.6470\n",
      "Epoch 758/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 3199.4062 - val_loss: 3073.6482\n",
      "Epoch 759/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 3198.4104 - val_loss: 3072.6470\n",
      "Epoch 760/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 3197.4131 - val_loss: 3071.6436\n",
      "Epoch 761/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 3196.4119 - val_loss: 3070.6367\n",
      "Epoch 762/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 3195.4092 - val_loss: 3069.6287\n",
      "Epoch 763/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 3194.4038 - val_loss: 3068.6179\n",
      "Epoch 764/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 3193.3960 - val_loss: 3067.6045\n",
      "Epoch 765/100000\n",
      "11/11 [==============================] - 0s 193us/step - loss: 3192.3865 - val_loss: 3066.5896\n",
      "Epoch 766/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 3191.3743 - val_loss: 3065.5718\n",
      "Epoch 767/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 3190.3601 - val_loss: 3064.5518\n",
      "Epoch 768/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 3189.3438 - val_loss: 3063.5310\n",
      "Epoch 769/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 3188.3257 - val_loss: 3062.5071\n",
      "Epoch 770/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 3187.3049 - val_loss: 3061.4814\n",
      "Epoch 771/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 3186.2834 - val_loss: 3060.4553\n",
      "Epoch 772/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 3185.2600 - val_loss: 3059.4260\n",
      "Epoch 773/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 3184.2341 - val_loss: 3058.3962\n",
      "Epoch 774/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 3183.2073 - val_loss: 3057.3643\n",
      "Epoch 775/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 3182.1790 - val_loss: 3056.3313\n",
      "Epoch 776/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 3181.1492 - val_loss: 3055.2969\n",
      "Epoch 777/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 3180.1179 - val_loss: 3054.2615\n",
      "Epoch 778/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 3179.0859 - val_loss: 3053.2244\n",
      "Epoch 779/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 3178.0525 - val_loss: 3052.1868\n",
      "Epoch 780/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 3177.0181 - val_loss: 3051.1477\n",
      "Epoch 781/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 3175.9827 - val_loss: 3050.1079\n",
      "Epoch 782/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 3174.9456 - val_loss: 3049.0674\n",
      "Epoch 783/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 3173.9084 - val_loss: 3048.0259\n",
      "Epoch 784/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 3172.8704 - val_loss: 3046.9841\n",
      "Epoch 785/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 3171.8318 - val_loss: 3045.9414\n",
      "Epoch 786/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 3170.7930 - val_loss: 3044.8984\n",
      "Epoch 787/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 3169.7529 - val_loss: 3043.8552\n",
      "Epoch 788/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 3168.7131 - val_loss: 3042.8110\n",
      "Epoch 789/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 3167.6721 - val_loss: 3041.7671\n",
      "Epoch 790/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 3166.6318 - val_loss: 3040.7227\n",
      "Epoch 791/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 3165.5906 - val_loss: 3039.6782\n",
      "Epoch 792/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 3164.5498 - val_loss: 3038.6335\n",
      "Epoch 793/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 3163.5085 - val_loss: 3037.5896\n",
      "Epoch 794/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 3162.4678 - val_loss: 3036.5454\n",
      "Epoch 795/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 3161.4268 - val_loss: 3035.5015\n",
      "Epoch 796/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 3160.3865 - val_loss: 3034.4578\n",
      "Epoch 797/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 3159.3462 - val_loss: 3033.4143\n",
      "Epoch 798/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 3158.3064 - val_loss: 3032.3713\n",
      "Epoch 799/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 3157.2666 - val_loss: 3031.3289\n",
      "Epoch 800/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 3156.2275 - val_loss: 3030.2869\n",
      "Epoch 801/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 3155.1890 - val_loss: 3029.2454\n",
      "Epoch 802/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 3154.1509 - val_loss: 3028.2046\n",
      "Epoch 803/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 3153.1135 - val_loss: 3027.1643\n",
      "Epoch 804/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 3152.0767 - val_loss: 3026.1243\n",
      "Epoch 805/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 3151.0398 - val_loss: 3025.0859\n",
      "Epoch 806/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 3150.0049 - val_loss: 3024.0479\n",
      "Epoch 807/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 3148.9705 - val_loss: 3023.0115\n",
      "Epoch 808/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 3147.9368 - val_loss: 3021.9751\n",
      "Epoch 809/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 3146.9041 - val_loss: 3020.9399\n",
      "Epoch 810/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 3145.8728 - val_loss: 3019.9060\n",
      "Epoch 811/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 3144.8420 - val_loss: 3018.8728\n",
      "Epoch 812/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 3143.8123 - val_loss: 3017.8408\n",
      "Epoch 813/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 369us/step - loss: 3142.7834 - val_loss: 3016.8101\n",
      "Epoch 814/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 3141.7561 - val_loss: 3015.7803\n",
      "Epoch 815/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 3140.7290 - val_loss: 3014.7515\n",
      "Epoch 816/100000\n",
      "11/11 [==============================] - 0s 631us/step - loss: 3139.7041 - val_loss: 3013.7241\n",
      "Epoch 817/100000\n",
      "11/11 [==============================] - 0s 200us/step - loss: 3138.6797 - val_loss: 3012.6978\n",
      "Epoch 818/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 3137.6572 - val_loss: 3011.6726\n",
      "Epoch 819/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 3136.6353 - val_loss: 3010.6492\n",
      "Epoch 820/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 3135.6150 - val_loss: 3009.6265\n",
      "Epoch 821/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 3134.5959 - val_loss: 3008.6052\n",
      "Epoch 822/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 3133.5781 - val_loss: 3007.5852\n",
      "Epoch 823/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 3132.5618 - val_loss: 3006.5667\n",
      "Epoch 824/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 3131.5461 - val_loss: 3005.5498\n",
      "Epoch 825/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 3130.5327 - val_loss: 3004.5337\n",
      "Epoch 826/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 3129.5203 - val_loss: 3003.5193\n",
      "Epoch 827/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 3128.5093 - val_loss: 3002.5063\n",
      "Epoch 828/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 3127.4993 - val_loss: 3001.4944\n",
      "Epoch 829/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 3126.4912 - val_loss: 3000.4844\n",
      "Epoch 830/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 3125.4836 - val_loss: 2999.4749\n",
      "Epoch 831/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 3124.4780 - val_loss: 2998.4673\n",
      "Epoch 832/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 3123.4736 - val_loss: 2997.4617\n",
      "Epoch 833/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 3122.4712 - val_loss: 2996.4563\n",
      "Epoch 834/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 3121.4697 - val_loss: 2995.4534\n",
      "Epoch 835/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 3120.4697 - val_loss: 2994.4517\n",
      "Epoch 836/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 3119.4712 - val_loss: 2993.4517\n",
      "Epoch 837/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 3118.4744 - val_loss: 2992.4529\n",
      "Epoch 838/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 3117.4790 - val_loss: 2991.4556\n",
      "Epoch 839/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 3116.4851 - val_loss: 2990.4595\n",
      "Epoch 840/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 3115.4924 - val_loss: 2989.4646\n",
      "Epoch 841/100000\n",
      "11/11 [==============================] - 0s 204us/step - loss: 3114.5010 - val_loss: 2988.4717\n",
      "Epoch 842/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 3113.5115 - val_loss: 2987.4802\n",
      "Epoch 843/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 3112.5232 - val_loss: 2986.4900\n",
      "Epoch 844/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 3111.5361 - val_loss: 2985.5015\n",
      "Epoch 845/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 3110.5510 - val_loss: 2984.5142\n",
      "Epoch 846/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 3109.5667 - val_loss: 2983.5283\n",
      "Epoch 847/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 3108.5845 - val_loss: 2982.5439\n",
      "Epoch 848/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 3107.6038 - val_loss: 2981.5610\n",
      "Epoch 849/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 3106.6240 - val_loss: 2980.5798\n",
      "Epoch 850/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 3105.6455 - val_loss: 2979.5999\n",
      "Epoch 851/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 3104.6689 - val_loss: 2978.6213\n",
      "Epoch 852/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 3103.6938 - val_loss: 2977.6443\n",
      "Epoch 853/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 3102.7195 - val_loss: 2976.6682\n",
      "Epoch 854/100000\n",
      "11/11 [==============================] - 0s 625us/step - loss: 3101.7471 - val_loss: 2975.6941\n",
      "Epoch 855/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 3100.7764 - val_loss: 2974.7207\n",
      "Epoch 856/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 3099.8062 - val_loss: 2973.7493\n",
      "Epoch 857/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 3098.8381 - val_loss: 2972.7791\n",
      "Epoch 858/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 3097.8711 - val_loss: 2971.8103\n",
      "Epoch 859/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 3096.9055 - val_loss: 2970.8430\n",
      "Epoch 860/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 3095.9414 - val_loss: 2969.8772\n",
      "Epoch 861/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 3094.9788 - val_loss: 2968.9126\n",
      "Epoch 862/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 3094.0173 - val_loss: 2967.9490\n",
      "Epoch 863/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 3093.0571 - val_loss: 2966.9873\n",
      "Epoch 864/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 3092.0986 - val_loss: 2966.0264\n",
      "Epoch 865/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 3091.1406 - val_loss: 2965.0669\n",
      "Epoch 866/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 3090.1846 - val_loss: 2964.1091\n",
      "Epoch 867/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 3089.2302 - val_loss: 2963.1526\n",
      "Epoch 868/100000\n",
      "11/11 [==============================] - 0s 204us/step - loss: 3088.2766 - val_loss: 2962.1970\n",
      "Epoch 869/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 3087.3245 - val_loss: 2961.2432\n",
      "Epoch 870/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 3086.3740 - val_loss: 2960.2905\n",
      "Epoch 871/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 3085.4243 - val_loss: 2959.3391\n",
      "Epoch 872/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 3084.4763 - val_loss: 2958.3894\n",
      "Epoch 873/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 3083.5295 - val_loss: 2957.4399\n",
      "Epoch 874/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 3082.5830 - val_loss: 2956.4924\n",
      "Epoch 875/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 3081.6392 - val_loss: 2955.5461\n",
      "Epoch 876/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 3080.6956 - val_loss: 2954.6008\n",
      "Epoch 877/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 3079.7537 - val_loss: 2953.6570\n",
      "Epoch 878/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 3078.8132 - val_loss: 2952.7141\n",
      "Epoch 879/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 3077.8728 - val_loss: 2951.7727\n",
      "Epoch 880/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 3076.9353 - val_loss: 2950.8328\n",
      "Epoch 881/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 3075.9983 - val_loss: 2949.8938\n",
      "Epoch 882/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 3075.0625 - val_loss: 2948.9561\n",
      "Epoch 883/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 3074.1279 - val_loss: 2948.0195\n",
      "Epoch 884/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 3073.1946 - val_loss: 2947.0842\n",
      "Epoch 885/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 3072.2625 - val_loss: 2946.1499\n",
      "Epoch 886/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 3071.3311 - val_loss: 2945.2170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 887/100000\n",
      "11/11 [==============================] - 0s 829us/step - loss: 3070.4016 - val_loss: 2944.2849\n",
      "Epoch 888/100000\n",
      "11/11 [==============================] - 0s 972us/step - loss: 3069.4727 - val_loss: 2943.3545\n",
      "Epoch 889/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3068.5454 - val_loss: 2942.4248\n",
      "Epoch 890/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3067.6187 - val_loss: 2941.4963\n",
      "Epoch 891/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 3066.6936 - val_loss: 2940.5691\n",
      "Epoch 892/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3065.7693 - val_loss: 2939.6431\n",
      "Epoch 893/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3064.8462 - val_loss: 2938.7180\n",
      "Epoch 894/100000\n",
      "11/11 [==============================] - 0s 997us/step - loss: 3063.9248 - val_loss: 2937.7942\n",
      "Epoch 895/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3063.0037 - val_loss: 2936.8718\n",
      "Epoch 896/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3062.0842 - val_loss: 2935.9500\n",
      "Epoch 897/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3061.1658 - val_loss: 2935.0295\n",
      "Epoch 898/100000\n",
      "11/11 [==============================] - 0s 787us/step - loss: 3060.2485 - val_loss: 2934.1101\n",
      "Epoch 899/100000\n",
      "11/11 [==============================] - 0s 665us/step - loss: 3059.3323 - val_loss: 2933.1919\n",
      "Epoch 900/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 3058.4170 - val_loss: 2932.2744\n",
      "Epoch 901/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 3057.5029 - val_loss: 2931.3579\n",
      "Epoch 902/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 3056.5891 - val_loss: 2930.4431\n",
      "Epoch 903/100000\n",
      "11/11 [==============================] - 0s 629us/step - loss: 3055.6775 - val_loss: 2929.5291\n",
      "Epoch 904/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 3054.7666 - val_loss: 2928.6160\n",
      "Epoch 905/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 3053.8564 - val_loss: 2927.7041\n",
      "Epoch 906/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 3052.9478 - val_loss: 2926.7932\n",
      "Epoch 907/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 3052.0398 - val_loss: 2925.8833\n",
      "Epoch 908/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 3051.1335 - val_loss: 2924.9744\n",
      "Epoch 909/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 3050.2273 - val_loss: 2924.0667\n",
      "Epoch 910/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 3049.3225 - val_loss: 2923.1599\n",
      "Epoch 911/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 3048.4187 - val_loss: 2922.2537\n",
      "Epoch 912/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 3047.5156 - val_loss: 2921.3491\n",
      "Epoch 913/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 3046.6143 - val_loss: 2920.4451\n",
      "Epoch 914/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 3045.7134 - val_loss: 2919.5420\n",
      "Epoch 915/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 3044.8135 - val_loss: 2918.6404\n",
      "Epoch 916/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 3043.9148 - val_loss: 2917.7393\n",
      "Epoch 917/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 3043.0171 - val_loss: 2916.8391\n",
      "Epoch 918/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 3042.1201 - val_loss: 2915.9404\n",
      "Epoch 919/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 3041.2241 - val_loss: 2915.0425\n",
      "Epoch 920/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 3040.3291 - val_loss: 2914.1455\n",
      "Epoch 921/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 3039.4351 - val_loss: 2913.2493\n",
      "Epoch 922/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 3038.5420 - val_loss: 2912.3538\n",
      "Epoch 923/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 3037.6499 - val_loss: 2911.4600\n",
      "Epoch 924/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 3036.7585 - val_loss: 2910.5664\n",
      "Epoch 925/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 3035.8687 - val_loss: 2909.6741\n",
      "Epoch 926/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 3034.9788 - val_loss: 2908.7827\n",
      "Epoch 927/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 3034.0908 - val_loss: 2907.8916\n",
      "Epoch 928/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 3033.2029 - val_loss: 2907.0020\n",
      "Epoch 929/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 3032.3162 - val_loss: 2906.1133\n",
      "Epoch 930/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 3031.4304 - val_loss: 2905.2253\n",
      "Epoch 931/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 3030.5454 - val_loss: 2904.3381\n",
      "Epoch 932/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 3029.6611 - val_loss: 2903.4521\n",
      "Epoch 933/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 3028.7783 - val_loss: 2902.5667\n",
      "Epoch 934/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 3027.8960 - val_loss: 2901.6826\n",
      "Epoch 935/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 3027.0149 - val_loss: 2900.7991\n",
      "Epoch 936/100000\n",
      "11/11 [==============================] - 0s 838us/step - loss: 3026.1343 - val_loss: 2899.9163\n",
      "Epoch 937/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3025.2542 - val_loss: 2899.0339\n",
      "Epoch 938/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3024.3750 - val_loss: 2898.1526\n",
      "Epoch 939/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3023.4971 - val_loss: 2897.2725\n",
      "Epoch 940/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3022.6201 - val_loss: 2896.3931\n",
      "Epoch 941/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3021.7432 - val_loss: 2895.5146\n",
      "Epoch 942/100000\n",
      "11/11 [==============================] - 0s 834us/step - loss: 3020.8679 - val_loss: 2894.6370\n",
      "Epoch 943/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3019.9932 - val_loss: 2893.7603\n",
      "Epoch 944/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 3019.1194 - val_loss: 2892.8843\n",
      "Epoch 945/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 3018.2463 - val_loss: 2892.0095\n",
      "Epoch 946/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 3017.3748 - val_loss: 2891.1350\n",
      "Epoch 947/100000\n",
      "11/11 [==============================] - 0s 687us/step - loss: 3016.5032 - val_loss: 2890.2617\n",
      "Epoch 948/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 3015.6328 - val_loss: 2889.3889\n",
      "Epoch 949/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 3014.7632 - val_loss: 2888.5173\n",
      "Epoch 950/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 3013.8945 - val_loss: 2887.6462\n",
      "Epoch 951/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 3013.0264 - val_loss: 2886.7764\n",
      "Epoch 952/100000\n",
      "11/11 [==============================] - 0s 716us/step - loss: 3012.1592 - val_loss: 2885.9065\n",
      "Epoch 953/100000\n",
      "11/11 [==============================] - 0s 764us/step - loss: 3011.2927 - val_loss: 2885.0376\n",
      "Epoch 954/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 3010.4272 - val_loss: 2884.1704\n",
      "Epoch 955/100000\n",
      "11/11 [==============================] - 0s 727us/step - loss: 3009.5623 - val_loss: 2883.3030\n",
      "Epoch 956/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 3008.6978 - val_loss: 2882.4368\n",
      "Epoch 957/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 3007.8345 - val_loss: 2881.5710\n",
      "Epoch 958/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 3006.9724 - val_loss: 2880.7065\n",
      "Epoch 959/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 3006.1104 - val_loss: 2879.8425\n",
      "Epoch 960/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 3005.2493 - val_loss: 2878.9795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 3004.3892 - val_loss: 2878.1165\n",
      "Epoch 962/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 3003.5295 - val_loss: 2877.2549\n",
      "Epoch 963/100000\n",
      "11/11 [==============================] - 0s 656us/step - loss: 3002.6709 - val_loss: 2876.3940\n",
      "Epoch 964/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 3001.8125 - val_loss: 2875.5337\n",
      "Epoch 965/100000\n",
      "11/11 [==============================] - 0s 721us/step - loss: 3000.9556 - val_loss: 2874.6743\n",
      "Epoch 966/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 3000.0991 - val_loss: 2873.8154\n",
      "Epoch 967/100000\n",
      "11/11 [==============================] - 0s 607us/step - loss: 2999.2429 - val_loss: 2872.9573\n",
      "Epoch 968/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 2998.3877 - val_loss: 2872.1001\n",
      "Epoch 969/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 2997.5337 - val_loss: 2871.2437\n",
      "Epoch 970/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 2996.6799 - val_loss: 2870.3879\n",
      "Epoch 971/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 2995.8274 - val_loss: 2869.5327\n",
      "Epoch 972/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 2994.9751 - val_loss: 2868.6782\n",
      "Epoch 973/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 2994.1235 - val_loss: 2867.8245\n",
      "Epoch 974/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 2993.2727 - val_loss: 2866.9717\n",
      "Epoch 975/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 2992.4226 - val_loss: 2866.1194\n",
      "Epoch 976/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 2991.5735 - val_loss: 2865.2678\n",
      "Epoch 977/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 2990.7244 - val_loss: 2864.4170\n",
      "Epoch 978/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 2989.8767 - val_loss: 2863.5667\n",
      "Epoch 979/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 2989.0291 - val_loss: 2862.7170\n",
      "Epoch 980/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 2988.1829 - val_loss: 2861.8682\n",
      "Epoch 981/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 2987.3369 - val_loss: 2861.0203\n",
      "Epoch 982/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 2986.4915 - val_loss: 2860.1726\n",
      "Epoch 983/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 2985.6470 - val_loss: 2859.3264\n",
      "Epoch 984/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 2984.8032 - val_loss: 2858.4800\n",
      "Epoch 985/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 2983.9602 - val_loss: 2857.6343\n",
      "Epoch 986/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 2983.1174 - val_loss: 2856.7896\n",
      "Epoch 987/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 2982.2756 - val_loss: 2855.9456\n",
      "Epoch 988/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 2981.4346 - val_loss: 2855.1023\n",
      "Epoch 989/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 2980.5940 - val_loss: 2854.2595\n",
      "Epoch 990/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 2979.7546 - val_loss: 2853.4177\n",
      "Epoch 991/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 2978.9155 - val_loss: 2852.5764\n",
      "Epoch 992/100000\n",
      "11/11 [==============================] - 0s 701us/step - loss: 2978.0764 - val_loss: 2851.7351\n",
      "Epoch 993/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 2977.2385 - val_loss: 2850.8950\n",
      "Epoch 994/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 2976.4016 - val_loss: 2850.0554\n",
      "Epoch 995/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 2975.5647 - val_loss: 2849.2166\n",
      "Epoch 996/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 2974.7288 - val_loss: 2848.3784\n",
      "Epoch 997/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 2973.8936 - val_loss: 2847.5408\n",
      "Epoch 998/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 2973.0588 - val_loss: 2846.7041\n",
      "Epoch 999/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 2972.2249 - val_loss: 2845.8674\n",
      "Epoch 1000/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 2971.3916 - val_loss: 2845.0320\n",
      "Epoch 1001/100000\n",
      "11/11 [==============================] - 0s 625us/step - loss: 2970.5588 - val_loss: 2844.1970\n",
      "Epoch 1002/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 2969.7263 - val_loss: 2843.3625\n",
      "Epoch 1003/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 2968.8950 - val_loss: 2842.5291\n",
      "Epoch 1004/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 2968.0645 - val_loss: 2841.6960\n",
      "Epoch 1005/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 2967.2341 - val_loss: 2840.8633\n",
      "Epoch 1006/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 2966.4045 - val_loss: 2840.0315\n",
      "Epoch 1007/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 2965.5754 - val_loss: 2839.2002\n",
      "Epoch 1008/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 2964.7471 - val_loss: 2838.3696\n",
      "Epoch 1009/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 2963.9194 - val_loss: 2837.5393\n",
      "Epoch 1010/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 2963.0920 - val_loss: 2836.7100\n",
      "Epoch 1011/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 2962.2656 - val_loss: 2835.8811\n",
      "Epoch 1012/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 2961.4395 - val_loss: 2835.0530\n",
      "Epoch 1013/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 2960.6143 - val_loss: 2834.2253\n",
      "Epoch 1014/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 2959.7896 - val_loss: 2833.3984\n",
      "Epoch 1015/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 2958.9653 - val_loss: 2832.5720\n",
      "Epoch 1016/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 2958.1416 - val_loss: 2831.7458\n",
      "Epoch 1017/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 2957.3186 - val_loss: 2830.9209\n",
      "Epoch 1018/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 2956.4961 - val_loss: 2830.0959\n",
      "Epoch 1019/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 2955.6746 - val_loss: 2829.2717\n",
      "Epoch 1020/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 2954.8530 - val_loss: 2828.4487\n",
      "Epoch 1021/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 2954.0327 - val_loss: 2827.6257\n",
      "Epoch 1022/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 2953.2126 - val_loss: 2826.8032\n",
      "Epoch 1023/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 2952.3928 - val_loss: 2825.9814\n",
      "Epoch 1024/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 2951.5742 - val_loss: 2825.1604\n",
      "Epoch 1025/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 2950.7556 - val_loss: 2824.3396\n",
      "Epoch 1026/100000\n",
      "11/11 [==============================] - 0s 776us/step - loss: 2949.9377 - val_loss: 2823.5195\n",
      "Epoch 1027/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 2949.1208 - val_loss: 2822.7002\n",
      "Epoch 1028/100000\n",
      "11/11 [==============================] - 0s 694us/step - loss: 2948.3040 - val_loss: 2821.8813\n",
      "Epoch 1029/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 2947.4880 - val_loss: 2821.0627\n",
      "Epoch 1030/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 2946.6721 - val_loss: 2820.2446\n",
      "Epoch 1031/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 2945.8572 - val_loss: 2819.4275\n",
      "Epoch 1032/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 2945.0430 - val_loss: 2818.6108\n",
      "Epoch 1033/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 2944.2290 - val_loss: 2817.7947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1034/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 2943.4160 - val_loss: 2816.9790\n",
      "Epoch 1035/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 2942.6033 - val_loss: 2816.1641\n",
      "Epoch 1036/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 2941.7908 - val_loss: 2815.3494\n",
      "Epoch 1037/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 2940.9790 - val_loss: 2814.5354\n",
      "Epoch 1038/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 2940.1677 - val_loss: 2813.7224\n",
      "Epoch 1039/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 2939.3572 - val_loss: 2812.9092\n",
      "Epoch 1040/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 2938.5474 - val_loss: 2812.0972\n",
      "Epoch 1041/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 2937.7380 - val_loss: 2811.2854\n",
      "Epoch 1042/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 2936.9290 - val_loss: 2810.4741\n",
      "Epoch 1043/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 2936.1206 - val_loss: 2809.6633\n",
      "Epoch 1044/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 2935.3127 - val_loss: 2808.8530\n",
      "Epoch 1045/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 2934.5056 - val_loss: 2808.0437\n",
      "Epoch 1046/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 2933.6985 - val_loss: 2807.2346\n",
      "Epoch 1047/100000\n",
      "11/11 [==============================] - 0s 695us/step - loss: 2932.8921 - val_loss: 2806.4260\n",
      "Epoch 1048/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 2932.0864 - val_loss: 2805.6179\n",
      "Epoch 1049/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 2931.2810 - val_loss: 2804.8108\n",
      "Epoch 1050/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 2930.4768 - val_loss: 2804.0039\n",
      "Epoch 1051/100000\n",
      "11/11 [==============================] - 0s 586us/step - loss: 2929.6726 - val_loss: 2803.1975\n",
      "Epoch 1052/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 2928.8694 - val_loss: 2802.3916\n",
      "Epoch 1053/100000\n",
      "11/11 [==============================] - 0s 652us/step - loss: 2928.0662 - val_loss: 2801.5862\n",
      "Epoch 1054/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 2927.2639 - val_loss: 2800.7810\n",
      "Epoch 1055/100000\n",
      "11/11 [==============================] - 0s 673us/step - loss: 2926.4612 - val_loss: 2799.9768\n",
      "Epoch 1056/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 2925.6599 - val_loss: 2799.1731\n",
      "Epoch 1057/100000\n",
      "11/11 [==============================] - 0s 636us/step - loss: 2924.8591 - val_loss: 2798.3696\n",
      "Epoch 1058/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 2924.0583 - val_loss: 2797.5671\n",
      "Epoch 1059/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 2923.2583 - val_loss: 2796.7649\n",
      "Epoch 1060/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 2922.4592 - val_loss: 2795.9634\n",
      "Epoch 1061/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 2921.6604 - val_loss: 2795.1621\n",
      "Epoch 1062/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 2920.8621 - val_loss: 2794.3613\n",
      "Epoch 1063/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 2920.0642 - val_loss: 2793.5608\n",
      "Epoch 1064/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 2919.2666 - val_loss: 2792.7615\n",
      "Epoch 1065/100000\n",
      "11/11 [==============================] - 0s 888us/step - loss: 2918.4697 - val_loss: 2791.9619\n",
      "Epoch 1066/100000\n",
      "11/11 [==============================] - 0s 869us/step - loss: 2917.6733 - val_loss: 2791.1633\n",
      "Epoch 1067/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 2916.8772 - val_loss: 2790.3655\n",
      "Epoch 1068/100000\n",
      "11/11 [==============================] - 0s 703us/step - loss: 2916.0818 - val_loss: 2789.5676\n",
      "Epoch 1069/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 2915.2874 - val_loss: 2788.7700\n",
      "Epoch 1070/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 2914.4924 - val_loss: 2787.9736\n",
      "Epoch 1071/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 2913.6987 - val_loss: 2787.1775\n",
      "Epoch 1072/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 2912.9053 - val_loss: 2786.3818\n",
      "Epoch 1073/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 2912.1123 - val_loss: 2785.5864\n",
      "Epoch 1074/100000\n",
      "11/11 [==============================] - 0s 758us/step - loss: 2911.3196 - val_loss: 2784.7917\n",
      "Epoch 1075/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 2910.5276 - val_loss: 2783.9976\n",
      "Epoch 1076/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 2909.7363 - val_loss: 2783.2041\n",
      "Epoch 1077/100000\n",
      "11/11 [==============================] - 0s 667us/step - loss: 2908.9456 - val_loss: 2782.4109\n",
      "Epoch 1078/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 2908.1553 - val_loss: 2781.6177\n",
      "Epoch 1079/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 2907.3650 - val_loss: 2780.8257\n",
      "Epoch 1080/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 2906.5757 - val_loss: 2780.0342\n",
      "Epoch 1081/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 2905.7869 - val_loss: 2779.2424\n",
      "Epoch 1082/100000\n",
      "11/11 [==============================] - 0s 712us/step - loss: 2904.9980 - val_loss: 2778.4514\n",
      "Epoch 1083/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 2904.2100 - val_loss: 2777.6611\n",
      "Epoch 1084/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 2903.4221 - val_loss: 2776.8713\n",
      "Epoch 1085/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 2902.6353 - val_loss: 2776.0820\n",
      "Epoch 1086/100000\n",
      "11/11 [==============================] - 0s 905us/step - loss: 2901.8486 - val_loss: 2775.2927\n",
      "Epoch 1087/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 2901.0623 - val_loss: 2774.5039\n",
      "Epoch 1088/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 2900.2764 - val_loss: 2773.7161\n",
      "Epoch 1089/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 2899.4912 - val_loss: 2772.9285\n",
      "Epoch 1090/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 2898.7061 - val_loss: 2772.1416\n",
      "Epoch 1091/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 2897.9221 - val_loss: 2771.3547\n",
      "Epoch 1092/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 2897.1384 - val_loss: 2770.5686\n",
      "Epoch 1093/100000\n",
      "11/11 [==============================] - 0s 619us/step - loss: 2896.3545 - val_loss: 2769.7830\n",
      "Epoch 1094/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 2895.5715 - val_loss: 2768.9976\n",
      "Epoch 1095/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 2894.7891 - val_loss: 2768.2126\n",
      "Epoch 1096/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 2894.0068 - val_loss: 2767.4280\n",
      "Epoch 1097/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 2893.2251 - val_loss: 2766.6443\n",
      "Epoch 1098/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 2892.4438 - val_loss: 2765.8606\n",
      "Epoch 1099/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 2891.6631 - val_loss: 2765.0774\n",
      "Epoch 1100/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 2890.8828 - val_loss: 2764.2947\n",
      "Epoch 1101/100000\n",
      "11/11 [==============================] - 0s 631us/step - loss: 2890.1028 - val_loss: 2763.5125\n",
      "Epoch 1102/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 2889.3232 - val_loss: 2762.7307\n",
      "Epoch 1103/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 2888.5444 - val_loss: 2761.9495\n",
      "Epoch 1104/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 2887.7659 - val_loss: 2761.1687\n",
      "Epoch 1105/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 2886.9880 - val_loss: 2760.3884\n",
      "Epoch 1106/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 2886.2107 - val_loss: 2759.6084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1107/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 2885.4333 - val_loss: 2758.8291\n",
      "Epoch 1108/100000\n",
      "11/11 [==============================] - 0s 784us/step - loss: 2884.6565 - val_loss: 2758.0498\n",
      "Epoch 1109/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 2883.8804 - val_loss: 2757.2717\n",
      "Epoch 1110/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 2883.1045 - val_loss: 2756.4934\n",
      "Epoch 1111/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 2882.3291 - val_loss: 2755.7158\n",
      "Epoch 1112/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 2881.5542 - val_loss: 2754.9385\n",
      "Epoch 1113/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 2880.7798 - val_loss: 2754.1616\n",
      "Epoch 1114/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 2880.0056 - val_loss: 2753.3855\n",
      "Epoch 1115/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 2879.2322 - val_loss: 2752.6094\n",
      "Epoch 1116/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 2878.4585 - val_loss: 2751.8337\n",
      "Epoch 1117/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 2877.6858 - val_loss: 2751.0588\n",
      "Epoch 1118/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 2876.9138 - val_loss: 2750.2842\n",
      "Epoch 1119/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 2876.1416 - val_loss: 2749.5100\n",
      "Epoch 1120/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 2875.3701 - val_loss: 2748.7361\n",
      "Epoch 1121/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 2874.5991 - val_loss: 2747.9626\n",
      "Epoch 1122/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 2873.8286 - val_loss: 2747.1899\n",
      "Epoch 1123/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 2873.0586 - val_loss: 2746.4177\n",
      "Epoch 1124/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 2872.2888 - val_loss: 2745.6458\n",
      "Epoch 1125/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 2871.5195 - val_loss: 2744.8743\n",
      "Epoch 1126/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 2870.7510 - val_loss: 2744.1033\n",
      "Epoch 1127/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 2869.9829 - val_loss: 2743.3328\n",
      "Epoch 1128/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 2869.2148 - val_loss: 2742.5625\n",
      "Epoch 1129/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 2868.4475 - val_loss: 2741.7930\n",
      "Epoch 1130/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 2867.6804 - val_loss: 2741.0234\n",
      "Epoch 1131/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 2866.9138 - val_loss: 2740.2544\n",
      "Epoch 1132/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 2866.1475 - val_loss: 2739.4861\n",
      "Epoch 1133/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 2865.3818 - val_loss: 2738.7180\n",
      "Epoch 1134/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 2864.6165 - val_loss: 2737.9502\n",
      "Epoch 1135/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 2863.8513 - val_loss: 2737.1831\n",
      "Epoch 1136/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 2863.0869 - val_loss: 2736.4163\n",
      "Epoch 1137/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 2862.3230 - val_loss: 2735.6499\n",
      "Epoch 1138/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 2861.5591 - val_loss: 2734.8843\n",
      "Epoch 1139/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 2860.7961 - val_loss: 2734.1182\n",
      "Epoch 1140/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 2860.0330 - val_loss: 2733.3530\n",
      "Epoch 1141/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 2859.2705 - val_loss: 2732.5884\n",
      "Epoch 1142/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 2858.5085 - val_loss: 2731.8242\n",
      "Epoch 1143/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 2857.7471 - val_loss: 2731.0601\n",
      "Epoch 1144/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 2856.9858 - val_loss: 2730.2966\n",
      "Epoch 1145/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 2856.2249 - val_loss: 2729.5334\n",
      "Epoch 1146/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 2855.4646 - val_loss: 2728.7708\n",
      "Epoch 1147/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 2854.7043 - val_loss: 2728.0081\n",
      "Epoch 1148/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 2853.9446 - val_loss: 2727.2463\n",
      "Epoch 1149/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 2853.1855 - val_loss: 2726.4846\n",
      "Epoch 1150/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 2852.4268 - val_loss: 2725.7236\n",
      "Epoch 1151/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 2851.6687 - val_loss: 2724.9631\n",
      "Epoch 1152/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 2850.9104 - val_loss: 2724.2029\n",
      "Epoch 1153/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 2850.1528 - val_loss: 2723.4431\n",
      "Epoch 1154/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 2849.3955 - val_loss: 2722.6833\n",
      "Epoch 1155/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 2848.6389 - val_loss: 2721.9241\n",
      "Epoch 1156/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 2847.8823 - val_loss: 2721.1655\n",
      "Epoch 1157/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 2847.1262 - val_loss: 2720.4072\n",
      "Epoch 1158/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 2846.3708 - val_loss: 2719.6492\n",
      "Epoch 1159/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 2845.6155 - val_loss: 2718.8916\n",
      "Epoch 1160/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 2844.8606 - val_loss: 2718.1345\n",
      "Epoch 1161/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 2844.1064 - val_loss: 2717.3779\n",
      "Epoch 1162/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 2843.3523 - val_loss: 2716.6218\n",
      "Epoch 1163/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 2842.5986 - val_loss: 2715.8657\n",
      "Epoch 1164/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 2841.8455 - val_loss: 2715.1101\n",
      "Epoch 1165/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 2841.0928 - val_loss: 2714.3552\n",
      "Epoch 1166/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 2840.3401 - val_loss: 2713.6003\n",
      "Epoch 1167/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 2839.5881 - val_loss: 2712.8459\n",
      "Epoch 1168/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 2838.8364 - val_loss: 2712.0920\n",
      "Epoch 1169/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 2838.0852 - val_loss: 2711.3384\n",
      "Epoch 1170/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 2837.3342 - val_loss: 2710.5852\n",
      "Epoch 1171/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 2836.5837 - val_loss: 2709.8323\n",
      "Epoch 1172/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 2835.8337 - val_loss: 2709.0796\n",
      "Epoch 1173/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 2835.0837 - val_loss: 2708.3279\n",
      "Epoch 1174/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 2834.3342 - val_loss: 2707.5759\n",
      "Epoch 1175/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 2833.5852 - val_loss: 2706.8247\n",
      "Epoch 1176/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 2832.8367 - val_loss: 2706.0740\n",
      "Epoch 1177/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 2832.0884 - val_loss: 2705.3232\n",
      "Epoch 1178/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 2831.3408 - val_loss: 2704.5730\n",
      "Epoch 1179/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 2830.5935 - val_loss: 2703.8232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1180/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 2829.8459 - val_loss: 2703.0735\n",
      "Epoch 1181/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 2829.0991 - val_loss: 2702.3245\n",
      "Epoch 1182/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 2828.3525 - val_loss: 2701.5759\n",
      "Epoch 1183/100000\n",
      "11/11 [==============================] - 0s 702us/step - loss: 2827.6064 - val_loss: 2700.8274\n",
      "Epoch 1184/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 2826.8611 - val_loss: 2700.0798\n",
      "Epoch 1185/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 2826.1160 - val_loss: 2699.3323\n",
      "Epoch 1186/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 2825.3708 - val_loss: 2698.5850\n",
      "Epoch 1187/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 2824.6262 - val_loss: 2697.8379\n",
      "Epoch 1188/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 2823.8823 - val_loss: 2697.0916\n",
      "Epoch 1189/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 2823.1384 - val_loss: 2696.3457\n",
      "Epoch 1190/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 2822.3953 - val_loss: 2695.5999\n",
      "Epoch 1191/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 2821.6521 - val_loss: 2694.8545\n",
      "Epoch 1192/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 2820.9094 - val_loss: 2694.1099\n",
      "Epoch 1193/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 2820.1672 - val_loss: 2693.3652\n",
      "Epoch 1194/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 2819.4255 - val_loss: 2692.6211\n",
      "Epoch 1195/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 2818.6838 - val_loss: 2691.8772\n",
      "Epoch 1196/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 2817.9429 - val_loss: 2691.1338\n",
      "Epoch 1197/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 2817.2019 - val_loss: 2690.3909\n",
      "Epoch 1198/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 2816.4619 - val_loss: 2689.6482\n",
      "Epoch 1199/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 2815.7217 - val_loss: 2688.9058\n",
      "Epoch 1200/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 2814.9822 - val_loss: 2688.1638\n",
      "Epoch 1201/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 2814.2427 - val_loss: 2687.4221\n",
      "Epoch 1202/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 2813.5037 - val_loss: 2686.6807\n",
      "Epoch 1203/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 2812.7649 - val_loss: 2685.9399\n",
      "Epoch 1204/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 2812.0269 - val_loss: 2685.1995\n",
      "Epoch 1205/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 2811.2888 - val_loss: 2684.4592\n",
      "Epoch 1206/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 2810.5513 - val_loss: 2683.7195\n",
      "Epoch 1207/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 2809.8142 - val_loss: 2682.9802\n",
      "Epoch 1208/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 2809.0779 - val_loss: 2682.2407\n",
      "Epoch 1209/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 2808.3411 - val_loss: 2681.5020\n",
      "Epoch 1210/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 2807.6047 - val_loss: 2680.7637\n",
      "Epoch 1211/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 2806.8691 - val_loss: 2680.0259\n",
      "Epoch 1212/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 2806.1338 - val_loss: 2679.2883\n",
      "Epoch 1213/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 2805.3992 - val_loss: 2678.5508\n",
      "Epoch 1214/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 2804.6643 - val_loss: 2677.8137\n",
      "Epoch 1215/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 2803.9299 - val_loss: 2677.0771\n",
      "Epoch 1216/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 2803.1960 - val_loss: 2676.3411\n",
      "Epoch 1217/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 2802.4624 - val_loss: 2675.6052\n",
      "Epoch 1218/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 2801.7290 - val_loss: 2674.8699\n",
      "Epoch 1219/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 2800.9963 - val_loss: 2674.1345\n",
      "Epoch 1220/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 2800.2639 - val_loss: 2673.3994\n",
      "Epoch 1221/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 2799.5315 - val_loss: 2672.6650\n",
      "Epoch 1222/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 2798.7998 - val_loss: 2671.9312\n",
      "Epoch 1223/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 2798.0686 - val_loss: 2671.1973\n",
      "Epoch 1224/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 2797.3372 - val_loss: 2670.4636\n",
      "Epoch 1225/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 2796.6064 - val_loss: 2669.7305\n",
      "Epoch 1226/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 2795.8757 - val_loss: 2668.9978\n",
      "Epoch 1227/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 2795.1455 - val_loss: 2668.2654\n",
      "Epoch 1228/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 2794.4158 - val_loss: 2667.5330\n",
      "Epoch 1229/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 2793.6865 - val_loss: 2666.8015\n",
      "Epoch 1230/100000\n",
      "11/11 [==============================] - 0s 604us/step - loss: 2792.9573 - val_loss: 2666.0698\n",
      "Epoch 1231/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 2792.2285 - val_loss: 2665.3389\n",
      "Epoch 1232/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 2791.5000 - val_loss: 2664.6084\n",
      "Epoch 1233/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 2790.7720 - val_loss: 2663.8779\n",
      "Epoch 1234/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 2790.0439 - val_loss: 2663.1479\n",
      "Epoch 1235/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 2789.3171 - val_loss: 2662.4180\n",
      "Epoch 1236/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 2788.5898 - val_loss: 2661.6890\n",
      "Epoch 1237/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 2787.8633 - val_loss: 2660.9600\n",
      "Epoch 1238/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 2787.1367 - val_loss: 2660.2312\n",
      "Epoch 1239/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 2786.4109 - val_loss: 2659.5029\n",
      "Epoch 1240/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 2785.6853 - val_loss: 2658.7751\n",
      "Epoch 1241/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 2784.9600 - val_loss: 2658.0474\n",
      "Epoch 1242/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 2784.2349 - val_loss: 2657.3201\n",
      "Epoch 1243/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 2783.5100 - val_loss: 2656.5933\n",
      "Epoch 1244/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 2782.7859 - val_loss: 2655.8665\n",
      "Epoch 1245/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 2782.0620 - val_loss: 2655.1406\n",
      "Epoch 1246/100000\n",
      "11/11 [==============================] - 0s 754us/step - loss: 2781.3384 - val_loss: 2654.4146\n",
      "Epoch 1247/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 2780.6150 - val_loss: 2653.6890\n",
      "Epoch 1248/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 2779.8921 - val_loss: 2652.9636\n",
      "Epoch 1249/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2779.1697 - val_loss: 2652.2383\n",
      "Epoch 1250/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 2778.4470 - val_loss: 2651.5142\n",
      "Epoch 1251/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 2777.7251 - val_loss: 2650.7900\n",
      "Epoch 1252/100000\n",
      "11/11 [==============================] - 0s 724us/step - loss: 2777.0034 - val_loss: 2650.0659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1253/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 2776.2822 - val_loss: 2649.3420\n",
      "Epoch 1254/100000\n",
      "11/11 [==============================] - 0s 668us/step - loss: 2775.5613 - val_loss: 2648.6189\n",
      "Epoch 1255/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 2774.8406 - val_loss: 2647.8960\n",
      "Epoch 1256/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 2774.1204 - val_loss: 2647.1736\n",
      "Epoch 1257/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 2773.4006 - val_loss: 2646.4514\n",
      "Epoch 1258/100000\n",
      "11/11 [==============================] - 0s 610us/step - loss: 2772.6809 - val_loss: 2645.7295\n",
      "Epoch 1259/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 2771.9617 - val_loss: 2645.0078\n",
      "Epoch 1260/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 2771.2427 - val_loss: 2644.2866\n",
      "Epoch 1261/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 2770.5242 - val_loss: 2643.5659\n",
      "Epoch 1262/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 2769.8062 - val_loss: 2642.8452\n",
      "Epoch 1263/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 2769.0879 - val_loss: 2642.1250\n",
      "Epoch 1264/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 2768.3701 - val_loss: 2641.4053\n",
      "Epoch 1265/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 2767.6531 - val_loss: 2640.6855\n",
      "Epoch 1266/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 2766.9360 - val_loss: 2639.9666\n",
      "Epoch 1267/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 2766.2195 - val_loss: 2639.2473\n",
      "Epoch 1268/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 2765.5032 - val_loss: 2638.5288\n",
      "Epoch 1269/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 2764.7869 - val_loss: 2637.8105\n",
      "Epoch 1270/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 2764.0713 - val_loss: 2637.0923\n",
      "Epoch 1271/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 2763.3562 - val_loss: 2636.3748\n",
      "Epoch 1272/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 2762.6409 - val_loss: 2635.6577\n",
      "Epoch 1273/100000\n",
      "11/11 [==============================] - 0s 198us/step - loss: 2761.9265 - val_loss: 2634.9404\n",
      "Epoch 1274/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 2761.2119 - val_loss: 2634.2236\n",
      "Epoch 1275/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 2760.4978 - val_loss: 2633.5071\n",
      "Epoch 1276/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 2759.7842 - val_loss: 2632.7913\n",
      "Epoch 1277/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 2759.0706 - val_loss: 2632.0752\n",
      "Epoch 1278/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 2758.3572 - val_loss: 2631.3601\n",
      "Epoch 1279/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 2757.6448 - val_loss: 2630.6448\n",
      "Epoch 1280/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 2756.9319 - val_loss: 2629.9299\n",
      "Epoch 1281/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 2756.2197 - val_loss: 2629.2153\n",
      "Epoch 1282/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 2755.5078 - val_loss: 2628.5015\n",
      "Epoch 1283/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 2754.7966 - val_loss: 2627.7876\n",
      "Epoch 1284/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 2754.0850 - val_loss: 2627.0740\n",
      "Epoch 1285/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 2753.3740 - val_loss: 2626.3608\n",
      "Epoch 1286/100000\n",
      "11/11 [==============================] - 0s 782us/step - loss: 2752.6636 - val_loss: 2625.6479\n",
      "Epoch 1287/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 2751.9531 - val_loss: 2624.9353\n",
      "Epoch 1288/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 2751.2434 - val_loss: 2624.2236\n",
      "Epoch 1289/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 2750.5339 - val_loss: 2623.5115\n",
      "Epoch 1290/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 2749.8245 - val_loss: 2622.7998\n",
      "Epoch 1291/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 2749.1155 - val_loss: 2622.0884\n",
      "Epoch 1292/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 2748.4070 - val_loss: 2621.3777\n",
      "Epoch 1293/100000\n",
      "11/11 [==============================] - 0s 614us/step - loss: 2747.6985 - val_loss: 2620.6670\n",
      "Epoch 1294/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 2746.9905 - val_loss: 2619.9568\n",
      "Epoch 1295/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 2746.2830 - val_loss: 2619.2468\n",
      "Epoch 1296/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 2745.5757 - val_loss: 2618.5374\n",
      "Epoch 1297/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 2744.8687 - val_loss: 2617.8279\n",
      "Epoch 1298/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 2744.1616 - val_loss: 2617.1187\n",
      "Epoch 1299/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 2743.4553 - val_loss: 2616.4099\n",
      "Epoch 1300/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 2742.7493 - val_loss: 2615.7014\n",
      "Epoch 1301/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 2742.0432 - val_loss: 2614.9937\n",
      "Epoch 1302/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 2741.3381 - val_loss: 2614.2856\n",
      "Epoch 1303/100000\n",
      "11/11 [==============================] - 0s 859us/step - loss: 2740.6326 - val_loss: 2613.5784\n",
      "Epoch 1304/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 2739.9277 - val_loss: 2612.8711\n",
      "Epoch 1305/100000\n",
      "11/11 [==============================] - 0s 781us/step - loss: 2739.2231 - val_loss: 2612.1643\n",
      "Epoch 1306/100000\n",
      "11/11 [==============================] - 0s 719us/step - loss: 2738.5193 - val_loss: 2611.4573\n",
      "Epoch 1307/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 2737.8152 - val_loss: 2610.7515\n",
      "Epoch 1308/100000\n",
      "11/11 [==============================] - 0s 909us/step - loss: 2737.1113 - val_loss: 2610.0452\n",
      "Epoch 1309/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 2736.4080 - val_loss: 2609.3396\n",
      "Epoch 1310/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 2735.7048 - val_loss: 2608.6343\n",
      "Epoch 1311/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 2735.0022 - val_loss: 2607.9292\n",
      "Epoch 1312/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 2734.2998 - val_loss: 2607.2249\n",
      "Epoch 1313/100000\n",
      "11/11 [==============================] - 0s 678us/step - loss: 2733.5974 - val_loss: 2606.5203\n",
      "Epoch 1314/100000\n",
      "11/11 [==============================] - 0s 694us/step - loss: 2732.8958 - val_loss: 2605.8162\n",
      "Epoch 1315/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 2732.1941 - val_loss: 2605.1125\n",
      "Epoch 1316/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 2731.4932 - val_loss: 2604.4092\n",
      "Epoch 1317/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 2730.7922 - val_loss: 2603.7058\n",
      "Epoch 1318/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 2730.0918 - val_loss: 2603.0029\n",
      "Epoch 1319/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 2729.3916 - val_loss: 2602.3005\n",
      "Epoch 1320/100000\n",
      "11/11 [==============================] - 0s 840us/step - loss: 2728.6917 - val_loss: 2601.5979\n",
      "Epoch 1321/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 2727.9915 - val_loss: 2600.8962\n",
      "Epoch 1322/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 2727.2922 - val_loss: 2600.1946\n",
      "Epoch 1323/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 2726.5933 - val_loss: 2599.4932\n",
      "Epoch 1324/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 2725.8945 - val_loss: 2598.7920\n",
      "Epoch 1325/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 2725.1960 - val_loss: 2598.0913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1326/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 2724.4978 - val_loss: 2597.3909\n",
      "Epoch 1327/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 2723.8000 - val_loss: 2596.6907\n",
      "Epoch 1328/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 2723.1025 - val_loss: 2595.9912\n",
      "Epoch 1329/100000\n",
      "11/11 [==============================] - 0s 671us/step - loss: 2722.4053 - val_loss: 2595.2915\n",
      "Epoch 1330/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 2721.7085 - val_loss: 2594.5923\n",
      "Epoch 1331/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 2721.0117 - val_loss: 2593.8936\n",
      "Epoch 1332/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 2720.3154 - val_loss: 2593.1948\n",
      "Epoch 1333/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 2719.6191 - val_loss: 2592.4963\n",
      "Epoch 1334/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 2718.9233 - val_loss: 2591.7983\n",
      "Epoch 1335/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 2718.2283 - val_loss: 2591.1003\n",
      "Epoch 1336/100000\n",
      "11/11 [==============================] - 0s 609us/step - loss: 2717.5327 - val_loss: 2590.4031\n",
      "Epoch 1337/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 2716.8381 - val_loss: 2589.7061\n",
      "Epoch 1338/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 2716.1438 - val_loss: 2589.0093\n",
      "Epoch 1339/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 2715.4490 - val_loss: 2588.3125\n",
      "Epoch 1340/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 2714.7551 - val_loss: 2587.6162\n",
      "Epoch 1341/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 2714.0615 - val_loss: 2586.9202\n",
      "Epoch 1342/100000\n",
      "11/11 [==============================] - 0s 619us/step - loss: 2713.3682 - val_loss: 2586.2249\n",
      "Epoch 1343/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 2712.6748 - val_loss: 2585.5291\n",
      "Epoch 1344/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 2711.9822 - val_loss: 2584.8337\n",
      "Epoch 1345/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 2711.2893 - val_loss: 2584.1389\n",
      "Epoch 1346/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 2710.5974 - val_loss: 2583.4446\n",
      "Epoch 1347/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 2709.9053 - val_loss: 2582.7505\n",
      "Epoch 1348/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 2709.2136 - val_loss: 2582.0564\n",
      "Epoch 1349/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 2708.5225 - val_loss: 2581.3630\n",
      "Epoch 1350/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 2707.8311 - val_loss: 2580.6697\n",
      "Epoch 1351/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 2707.1406 - val_loss: 2579.9768\n",
      "Epoch 1352/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 2706.4502 - val_loss: 2579.2839\n",
      "Epoch 1353/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 2705.7600 - val_loss: 2578.5913\n",
      "Epoch 1354/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 2705.0701 - val_loss: 2577.8992\n",
      "Epoch 1355/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 2704.3801 - val_loss: 2577.2073\n",
      "Epoch 1356/100000\n",
      "11/11 [==============================] - 0s 750us/step - loss: 2703.6912 - val_loss: 2576.5156\n",
      "Epoch 1357/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 2703.0017 - val_loss: 2575.8245\n",
      "Epoch 1358/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 2702.3132 - val_loss: 2575.1333\n",
      "Epoch 1359/100000\n",
      "11/11 [==============================] - 0s 632us/step - loss: 2701.6248 - val_loss: 2574.4426\n",
      "Epoch 1360/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 2700.9365 - val_loss: 2573.7522\n",
      "Epoch 1361/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 2700.2490 - val_loss: 2573.0620\n",
      "Epoch 1362/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 2699.5610 - val_loss: 2572.3721\n",
      "Epoch 1363/100000\n",
      "11/11 [==============================] - 0s 611us/step - loss: 2698.8735 - val_loss: 2571.6826\n",
      "Epoch 1364/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 2698.1865 - val_loss: 2570.9934\n",
      "Epoch 1365/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 2697.5002 - val_loss: 2570.3040\n",
      "Epoch 1366/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 2696.8135 - val_loss: 2569.6155\n",
      "Epoch 1367/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 2696.1274 - val_loss: 2568.9272\n",
      "Epoch 1368/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 2695.4417 - val_loss: 2568.2390\n",
      "Epoch 1369/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 2694.7561 - val_loss: 2567.5510\n",
      "Epoch 1370/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 2694.0706 - val_loss: 2566.8635\n",
      "Epoch 1371/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 2693.3857 - val_loss: 2566.1760\n",
      "Epoch 1372/100000\n",
      "11/11 [==============================] - 0s 586us/step - loss: 2692.7009 - val_loss: 2565.4893\n",
      "Epoch 1373/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 2692.0166 - val_loss: 2564.8027\n",
      "Epoch 1374/100000\n",
      "11/11 [==============================] - 0s 760us/step - loss: 2691.3323 - val_loss: 2564.1162\n",
      "Epoch 1375/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 2690.6487 - val_loss: 2563.4297\n",
      "Epoch 1376/100000\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2689.9646 - val_loss: 2562.7437\n",
      "Epoch 1377/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 2689.2812 - val_loss: 2562.0583\n",
      "Epoch 1378/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 2688.5984 - val_loss: 2561.3728\n",
      "Epoch 1379/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 2687.9153 - val_loss: 2560.6875\n",
      "Epoch 1380/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 2687.2329 - val_loss: 2560.0029\n",
      "Epoch 1381/100000\n",
      "11/11 [==============================] - 0s 716us/step - loss: 2686.5505 - val_loss: 2559.3181\n",
      "Epoch 1382/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 2685.8684 - val_loss: 2558.6343\n",
      "Epoch 1383/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 2685.1873 - val_loss: 2557.9502\n",
      "Epoch 1384/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 2684.5056 - val_loss: 2557.2666\n",
      "Epoch 1385/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 2683.8245 - val_loss: 2556.5835\n",
      "Epoch 1386/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 2683.1438 - val_loss: 2555.9004\n",
      "Epoch 1387/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 2682.4634 - val_loss: 2555.2178\n",
      "Epoch 1388/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 2681.7832 - val_loss: 2554.5349\n",
      "Epoch 1389/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 2681.1033 - val_loss: 2553.8528\n",
      "Epoch 1390/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 2680.4236 - val_loss: 2553.1709\n",
      "Epoch 1391/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 2679.7439 - val_loss: 2552.4893\n",
      "Epoch 1392/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 2679.0652 - val_loss: 2551.8079\n",
      "Epoch 1393/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 2678.3860 - val_loss: 2551.1270\n",
      "Epoch 1394/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 2677.7078 - val_loss: 2550.4463\n",
      "Epoch 1395/100000\n",
      "11/11 [==============================] - 0s 644us/step - loss: 2677.0295 - val_loss: 2549.7656\n",
      "Epoch 1396/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 2676.3513 - val_loss: 2549.0857\n",
      "Epoch 1397/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 2675.6738 - val_loss: 2548.4055\n",
      "Epoch 1398/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2674.9963 - val_loss: 2547.7256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1399/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 2674.3193 - val_loss: 2547.0459\n",
      "Epoch 1400/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 2673.6421 - val_loss: 2546.3667\n",
      "Epoch 1401/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 2672.9656 - val_loss: 2545.6880\n",
      "Epoch 1402/100000\n",
      "11/11 [==============================] - 0s 664us/step - loss: 2672.2891 - val_loss: 2545.0093\n",
      "Epoch 1403/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2671.6128 - val_loss: 2544.3306\n",
      "Epoch 1404/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 2670.9370 - val_loss: 2543.6526\n",
      "Epoch 1405/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 2670.2615 - val_loss: 2542.9746\n",
      "Epoch 1406/100000\n",
      "11/11 [==============================] - 0s 759us/step - loss: 2669.5862 - val_loss: 2542.2971\n",
      "Epoch 1407/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 2668.9109 - val_loss: 2541.6201\n",
      "Epoch 1408/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 2668.2361 - val_loss: 2540.9431\n",
      "Epoch 1409/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 2667.5620 - val_loss: 2540.2664\n",
      "Epoch 1410/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 2666.8877 - val_loss: 2539.5898\n",
      "Epoch 1411/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 2666.2139 - val_loss: 2538.9136\n",
      "Epoch 1412/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 2665.5403 - val_loss: 2538.2378\n",
      "Epoch 1413/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 2664.8672 - val_loss: 2537.5625\n",
      "Epoch 1414/100000\n",
      "11/11 [==============================] - 0s 636us/step - loss: 2664.1938 - val_loss: 2536.8870\n",
      "Epoch 1415/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 2663.5212 - val_loss: 2536.2117\n",
      "Epoch 1416/100000\n",
      "11/11 [==============================] - 0s 709us/step - loss: 2662.8486 - val_loss: 2535.5374\n",
      "Epoch 1417/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 2662.1763 - val_loss: 2534.8630\n",
      "Epoch 1418/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 2661.5044 - val_loss: 2534.1885\n",
      "Epoch 1419/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 2660.8328 - val_loss: 2533.5146\n",
      "Epoch 1420/100000\n",
      "11/11 [==============================] - 0s 723us/step - loss: 2660.1614 - val_loss: 2532.8408\n",
      "Epoch 1421/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 2659.4902 - val_loss: 2532.1670\n",
      "Epoch 1422/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 2658.8193 - val_loss: 2531.4944\n",
      "Epoch 1423/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 2658.1484 - val_loss: 2530.8210\n",
      "Epoch 1424/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 2657.4783 - val_loss: 2530.1487\n",
      "Epoch 1425/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 2656.8083 - val_loss: 2529.4763\n",
      "Epoch 1426/100000\n",
      "11/11 [==============================] - 0s 852us/step - loss: 2656.1384 - val_loss: 2528.8044\n",
      "Epoch 1427/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 2655.4688 - val_loss: 2528.1326\n",
      "Epoch 1428/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 2654.7993 - val_loss: 2527.4609\n",
      "Epoch 1429/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 2654.1306 - val_loss: 2526.7898\n",
      "Epoch 1430/100000\n",
      "11/11 [==============================] - 0s 689us/step - loss: 2653.4619 - val_loss: 2526.1187\n",
      "Epoch 1431/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 2652.7932 - val_loss: 2525.4478\n",
      "Epoch 1432/100000\n",
      "11/11 [==============================] - 0s 615us/step - loss: 2652.1250 - val_loss: 2524.7773\n",
      "Epoch 1433/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 2651.4570 - val_loss: 2524.1072\n",
      "Epoch 1434/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 2650.7896 - val_loss: 2523.4373\n",
      "Epoch 1435/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 2650.1218 - val_loss: 2522.7676\n",
      "Epoch 1436/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 2649.4548 - val_loss: 2522.0979\n",
      "Epoch 1437/100000\n",
      "11/11 [==============================] - 0s 691us/step - loss: 2648.7881 - val_loss: 2521.4290\n",
      "Epoch 1438/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 2648.1216 - val_loss: 2520.7600\n",
      "Epoch 1439/100000\n",
      "11/11 [==============================] - 0s 905us/step - loss: 2647.4553 - val_loss: 2520.0916\n",
      "Epoch 1440/100000\n",
      "11/11 [==============================] - 0s 733us/step - loss: 2646.7891 - val_loss: 2519.4233\n",
      "Epoch 1441/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 2646.1233 - val_loss: 2518.7551\n",
      "Epoch 1442/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 2645.4575 - val_loss: 2518.0869\n",
      "Epoch 1443/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 2644.7922 - val_loss: 2517.4197\n",
      "Epoch 1444/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 2644.1272 - val_loss: 2516.7522\n",
      "Epoch 1445/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 2643.4624 - val_loss: 2516.0854\n",
      "Epoch 1446/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 2642.7976 - val_loss: 2515.4185\n",
      "Epoch 1447/100000\n",
      "11/11 [==============================] - 0s 651us/step - loss: 2642.1338 - val_loss: 2514.7520\n",
      "Epoch 1448/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2641.4697 - val_loss: 2514.0859\n",
      "Epoch 1449/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 2640.8059 - val_loss: 2513.4197\n",
      "Epoch 1450/100000\n",
      "11/11 [==============================] - 0s 621us/step - loss: 2640.1423 - val_loss: 2512.7539\n",
      "Epoch 1451/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 2639.4792 - val_loss: 2512.0889\n",
      "Epoch 1452/100000\n",
      "11/11 [==============================] - 0s 593us/step - loss: 2638.8164 - val_loss: 2511.4233\n",
      "Epoch 1453/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 2638.1541 - val_loss: 2510.7585\n",
      "Epoch 1454/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 2637.4915 - val_loss: 2510.0940\n",
      "Epoch 1455/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2636.8293 - val_loss: 2509.4294\n",
      "Epoch 1456/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 2636.1670 - val_loss: 2508.7654\n",
      "Epoch 1457/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 2635.5056 - val_loss: 2508.1013\n",
      "Epoch 1458/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 2634.8442 - val_loss: 2507.4377\n",
      "Epoch 1459/100000\n",
      "11/11 [==============================] - 0s 691us/step - loss: 2634.1833 - val_loss: 2506.7744\n",
      "Epoch 1460/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 2633.5225 - val_loss: 2506.1113\n",
      "Epoch 1461/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 2632.8618 - val_loss: 2505.4482\n",
      "Epoch 1462/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 2632.2014 - val_loss: 2504.7859\n",
      "Epoch 1463/100000\n",
      "11/11 [==============================] - 0s 777us/step - loss: 2631.5413 - val_loss: 2504.1235\n",
      "Epoch 1464/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 2630.8818 - val_loss: 2503.4614\n",
      "Epoch 1465/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 2630.2222 - val_loss: 2502.7998\n",
      "Epoch 1466/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 2629.5627 - val_loss: 2502.1382\n",
      "Epoch 1467/100000\n",
      "11/11 [==============================] - 0s 642us/step - loss: 2628.9038 - val_loss: 2501.4768\n",
      "Epoch 1468/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 2628.2451 - val_loss: 2500.8159\n",
      "Epoch 1469/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 2627.5862 - val_loss: 2500.1553\n",
      "Epoch 1470/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 2626.9280 - val_loss: 2499.4946\n",
      "Epoch 1471/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 2626.2703 - val_loss: 2498.8342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1472/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 2625.6123 - val_loss: 2498.1743\n",
      "Epoch 1473/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 2624.9551 - val_loss: 2497.5146\n",
      "Epoch 1474/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2624.2976 - val_loss: 2496.8550\n",
      "Epoch 1475/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 2623.6404 - val_loss: 2496.1956\n",
      "Epoch 1476/100000\n",
      "11/11 [==============================] - 0s 593us/step - loss: 2622.9836 - val_loss: 2495.5366\n",
      "Epoch 1477/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 2622.3271 - val_loss: 2494.8779\n",
      "Epoch 1478/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 2621.6709 - val_loss: 2494.2192\n",
      "Epoch 1479/100000\n",
      "11/11 [==============================] - 0s 750us/step - loss: 2621.0149 - val_loss: 2493.5610\n",
      "Epoch 1480/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 2620.3591 - val_loss: 2492.9033\n",
      "Epoch 1481/100000\n",
      "11/11 [==============================] - 0s 911us/step - loss: 2619.7036 - val_loss: 2492.2454\n",
      "Epoch 1482/100000\n",
      "11/11 [==============================] - 0s 806us/step - loss: 2619.0486 - val_loss: 2491.5879\n",
      "Epoch 1483/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 2618.3936 - val_loss: 2490.9307\n",
      "Epoch 1484/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 2617.7385 - val_loss: 2490.2734\n",
      "Epoch 1485/100000\n",
      "11/11 [==============================] - 0s 204us/step - loss: 2617.0842 - val_loss: 2489.6169\n",
      "Epoch 1486/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 2616.4299 - val_loss: 2488.9607\n",
      "Epoch 1487/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 2615.7764 - val_loss: 2488.3044\n",
      "Epoch 1488/100000\n",
      "11/11 [==============================] - 0s 739us/step - loss: 2615.1223 - val_loss: 2487.6487\n",
      "Epoch 1489/100000\n",
      "11/11 [==============================] - 0s 688us/step - loss: 2614.4690 - val_loss: 2486.9927\n",
      "Epoch 1490/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 2613.8159 - val_loss: 2486.3374\n",
      "Epoch 1491/100000\n",
      "11/11 [==============================] - 0s 628us/step - loss: 2613.1628 - val_loss: 2485.6824\n",
      "Epoch 1492/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 2612.5103 - val_loss: 2485.0273\n",
      "Epoch 1493/100000\n",
      "11/11 [==============================] - 0s 615us/step - loss: 2611.8579 - val_loss: 2484.3726\n",
      "Epoch 1494/100000\n",
      "11/11 [==============================] - 0s 625us/step - loss: 2611.2056 - val_loss: 2483.7185\n",
      "Epoch 1495/100000\n",
      "11/11 [==============================] - 0s 581us/step - loss: 2610.5540 - val_loss: 2483.0642\n",
      "Epoch 1496/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 2609.9021 - val_loss: 2482.4104\n",
      "Epoch 1497/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 2609.2507 - val_loss: 2481.7568\n",
      "Epoch 1498/100000\n",
      "11/11 [==============================] - 0s 722us/step - loss: 2608.5994 - val_loss: 2481.1033\n",
      "Epoch 1499/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 2607.9487 - val_loss: 2480.4502\n",
      "Epoch 1500/100000\n",
      "11/11 [==============================] - 0s 705us/step - loss: 2607.2983 - val_loss: 2479.7971\n",
      "Epoch 1501/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 2606.6477 - val_loss: 2479.1445\n",
      "Epoch 1502/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 2605.9976 - val_loss: 2478.4922\n",
      "Epoch 1503/100000\n",
      "11/11 [==============================] - 0s 630us/step - loss: 2605.3474 - val_loss: 2477.8401\n",
      "Epoch 1504/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 2604.6980 - val_loss: 2477.1877\n",
      "Epoch 1505/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 2604.0483 - val_loss: 2476.5364\n",
      "Epoch 1506/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 2603.3994 - val_loss: 2475.8850\n",
      "Epoch 1507/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 2602.7502 - val_loss: 2475.2336\n",
      "Epoch 1508/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 2602.1018 - val_loss: 2474.5825\n",
      "Epoch 1509/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 2601.4531 - val_loss: 2473.9319\n",
      "Epoch 1510/100000\n",
      "11/11 [==============================] - 0s 694us/step - loss: 2600.8049 - val_loss: 2473.2820\n",
      "Epoch 1511/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 2600.1572 - val_loss: 2472.6316\n",
      "Epoch 1512/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 2599.5095 - val_loss: 2471.9817\n",
      "Epoch 1513/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 2598.8623 - val_loss: 2471.3320\n",
      "Epoch 1514/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 2598.2151 - val_loss: 2470.6826\n",
      "Epoch 1515/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 2597.5681 - val_loss: 2470.0337\n",
      "Epoch 1516/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 2596.9211 - val_loss: 2469.3848\n",
      "Epoch 1517/100000\n",
      "11/11 [==============================] - 0s 636us/step - loss: 2596.2751 - val_loss: 2468.7361\n",
      "Epoch 1518/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 2595.6287 - val_loss: 2468.0874\n",
      "Epoch 1519/100000\n",
      "11/11 [==============================] - 0s 697us/step - loss: 2594.9827 - val_loss: 2467.4395\n",
      "Epoch 1520/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 2594.3369 - val_loss: 2466.7913\n",
      "Epoch 1521/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 2593.6917 - val_loss: 2466.1436\n",
      "Epoch 1522/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 2593.0466 - val_loss: 2465.4963\n",
      "Epoch 1523/100000\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2592.4016 - val_loss: 2464.8489\n",
      "Epoch 1524/100000\n",
      "11/11 [==============================] - 0s 975us/step - loss: 2591.7568 - val_loss: 2464.2024\n",
      "Epoch 1525/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 2591.1123 - val_loss: 2463.5557\n",
      "Epoch 1526/100000\n",
      "11/11 [==============================] - 0s 670us/step - loss: 2590.4680 - val_loss: 2462.9092\n",
      "Epoch 1527/100000\n",
      "11/11 [==============================] - 0s 706us/step - loss: 2589.8242 - val_loss: 2462.2627\n",
      "Epoch 1528/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 2589.1804 - val_loss: 2461.6169\n",
      "Epoch 1529/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 2588.5371 - val_loss: 2460.9709\n",
      "Epoch 1530/100000\n",
      "11/11 [==============================] - 0s 809us/step - loss: 2587.8936 - val_loss: 2460.3257\n",
      "Epoch 1531/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 2587.2510 - val_loss: 2459.6804\n",
      "Epoch 1532/100000\n",
      "11/11 [==============================] - 0s 803us/step - loss: 2586.6077 - val_loss: 2459.0354\n",
      "Epoch 1533/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 2585.9656 - val_loss: 2458.3904\n",
      "Epoch 1534/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 2585.3232 - val_loss: 2457.7458\n",
      "Epoch 1535/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 2584.6812 - val_loss: 2457.1018\n",
      "Epoch 1536/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 2584.0393 - val_loss: 2456.4578\n",
      "Epoch 1537/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2583.3975 - val_loss: 2455.8142\n",
      "Epoch 1538/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 2582.7561 - val_loss: 2455.1702\n",
      "Epoch 1539/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 2582.1155 - val_loss: 2454.5271\n",
      "Epoch 1540/100000\n",
      "11/11 [==============================] - 0s 811us/step - loss: 2581.4744 - val_loss: 2453.8843\n",
      "Epoch 1541/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 2580.8340 - val_loss: 2453.2412\n",
      "Epoch 1542/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 2580.1936 - val_loss: 2452.5986\n",
      "Epoch 1543/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 2579.5537 - val_loss: 2451.9561\n",
      "Epoch 1544/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 2578.9141 - val_loss: 2451.3142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1545/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 2578.2742 - val_loss: 2450.6724\n",
      "Epoch 1546/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 2577.6348 - val_loss: 2450.0310\n",
      "Epoch 1547/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 2576.9958 - val_loss: 2449.3896\n",
      "Epoch 1548/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2576.3569 - val_loss: 2448.7485\n",
      "Epoch 1549/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 2575.7185 - val_loss: 2448.1077\n",
      "Epoch 1550/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 2575.0798 - val_loss: 2447.4670\n",
      "Epoch 1551/100000\n",
      "11/11 [==============================] - 0s 639us/step - loss: 2574.4414 - val_loss: 2446.8264\n",
      "Epoch 1552/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 2573.8040 - val_loss: 2446.1865\n",
      "Epoch 1553/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 2573.1660 - val_loss: 2445.5466\n",
      "Epoch 1554/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 2572.5288 - val_loss: 2444.9070\n",
      "Epoch 1555/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 2571.8914 - val_loss: 2444.2673\n",
      "Epoch 1556/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 2571.2544 - val_loss: 2443.6282\n",
      "Epoch 1557/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 2570.6179 - val_loss: 2442.9893\n",
      "Epoch 1558/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 2569.9812 - val_loss: 2442.3506\n",
      "Epoch 1559/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 2569.3452 - val_loss: 2441.7122\n",
      "Epoch 1560/100000\n",
      "11/11 [==============================] - 0s 787us/step - loss: 2568.7092 - val_loss: 2441.0737\n",
      "Epoch 1561/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 2568.0735 - val_loss: 2440.4355\n",
      "Epoch 1562/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 2567.4377 - val_loss: 2439.7981\n",
      "Epoch 1563/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 2566.8025 - val_loss: 2439.1604\n",
      "Epoch 1564/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 2566.1672 - val_loss: 2438.5232\n",
      "Epoch 1565/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 2565.5327 - val_loss: 2437.8862\n",
      "Epoch 1566/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 2564.8982 - val_loss: 2437.2493\n",
      "Epoch 1567/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 2564.2634 - val_loss: 2436.6128\n",
      "Epoch 1568/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 2563.6296 - val_loss: 2435.9766\n",
      "Epoch 1569/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 2562.9958 - val_loss: 2435.3401\n",
      "Epoch 1570/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 2562.3618 - val_loss: 2434.7041\n",
      "Epoch 1571/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 2561.7288 - val_loss: 2434.0686\n",
      "Epoch 1572/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 2561.0955 - val_loss: 2433.4333\n",
      "Epoch 1573/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 2560.4626 - val_loss: 2432.7981\n",
      "Epoch 1574/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 2559.8298 - val_loss: 2432.1631\n",
      "Epoch 1575/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 2559.1975 - val_loss: 2431.5283\n",
      "Epoch 1576/100000\n",
      "11/11 [==============================] - 0s 643us/step - loss: 2558.5649 - val_loss: 2430.8938\n",
      "Epoch 1577/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 2557.9326 - val_loss: 2430.2595\n",
      "Epoch 1578/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 2557.3010 - val_loss: 2429.6257\n",
      "Epoch 1579/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 2556.6697 - val_loss: 2428.9919\n",
      "Epoch 1580/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 2556.0381 - val_loss: 2428.3584\n",
      "Epoch 1581/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 2555.4072 - val_loss: 2427.7251\n",
      "Epoch 1582/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 2554.7766 - val_loss: 2427.0920\n",
      "Epoch 1583/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 2554.1455 - val_loss: 2426.4587\n",
      "Epoch 1584/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 2553.5154 - val_loss: 2425.8262\n",
      "Epoch 1585/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 2552.8850 - val_loss: 2425.1938\n",
      "Epoch 1586/100000\n",
      "11/11 [==============================] - 0s 711us/step - loss: 2552.2551 - val_loss: 2424.5623\n",
      "Epoch 1587/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 2551.6255 - val_loss: 2423.9299\n",
      "Epoch 1588/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 2550.9961 - val_loss: 2423.2986\n",
      "Epoch 1589/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 2550.3669 - val_loss: 2422.6672\n",
      "Epoch 1590/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 2549.7380 - val_loss: 2422.0354\n",
      "Epoch 1591/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 2549.1094 - val_loss: 2421.4048\n",
      "Epoch 1592/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 2548.4807 - val_loss: 2420.7742\n",
      "Epoch 1593/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 2547.8525 - val_loss: 2420.1436\n",
      "Epoch 1594/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 2547.2244 - val_loss: 2419.5134\n",
      "Epoch 1595/100000\n",
      "11/11 [==============================] - 0s 760us/step - loss: 2546.5967 - val_loss: 2418.8833\n",
      "Epoch 1596/100000\n",
      "11/11 [==============================] - 0s 950us/step - loss: 2545.9690 - val_loss: 2418.2534\n",
      "Epoch 1597/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 2545.3418 - val_loss: 2417.6235\n",
      "Epoch 1598/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 2544.7146 - val_loss: 2416.9944\n",
      "Epoch 1599/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 2544.0876 - val_loss: 2416.3655\n",
      "Epoch 1600/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 2543.4609 - val_loss: 2415.7366\n",
      "Epoch 1601/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 2542.8345 - val_loss: 2415.1079\n",
      "Epoch 1602/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 2542.2085 - val_loss: 2414.4795\n",
      "Epoch 1603/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 2541.5823 - val_loss: 2413.8513\n",
      "Epoch 1604/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 2540.9570 - val_loss: 2413.2236\n",
      "Epoch 1605/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 2540.3315 - val_loss: 2412.5955\n",
      "Epoch 1606/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 2539.7061 - val_loss: 2411.9680\n",
      "Epoch 1607/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 2539.0811 - val_loss: 2411.3408\n",
      "Epoch 1608/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 2538.4561 - val_loss: 2410.7139\n",
      "Epoch 1609/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 2537.8315 - val_loss: 2410.0869\n",
      "Epoch 1610/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 2537.2073 - val_loss: 2409.4604\n",
      "Epoch 1611/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 2536.5830 - val_loss: 2408.8342\n",
      "Epoch 1612/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 2535.9592 - val_loss: 2408.2080\n",
      "Epoch 1613/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 2535.3359 - val_loss: 2407.5823\n",
      "Epoch 1614/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 2534.7124 - val_loss: 2406.9568\n",
      "Epoch 1615/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 2534.0891 - val_loss: 2406.3313\n",
      "Epoch 1616/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 2533.4666 - val_loss: 2405.7061\n",
      "Epoch 1617/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 2532.8435 - val_loss: 2405.0813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1618/100000\n",
      "11/11 [==============================] - 0s 768us/step - loss: 2532.2212 - val_loss: 2404.4568\n",
      "Epoch 1619/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 2531.5989 - val_loss: 2403.8320\n",
      "Epoch 1620/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 2530.9768 - val_loss: 2403.2080\n",
      "Epoch 1621/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 2530.3552 - val_loss: 2402.5837\n",
      "Epoch 1622/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 2529.7336 - val_loss: 2401.9602\n",
      "Epoch 1623/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 2529.1121 - val_loss: 2401.3369\n",
      "Epoch 1624/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 2528.4912 - val_loss: 2400.7131\n",
      "Epoch 1625/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 2527.8701 - val_loss: 2400.0901\n",
      "Epoch 1626/100000\n",
      "11/11 [==============================] - 0s 779us/step - loss: 2527.2493 - val_loss: 2399.4670\n",
      "Epoch 1627/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2526.6289 - val_loss: 2398.8447\n",
      "Epoch 1628/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2526.0090 - val_loss: 2398.2219\n",
      "Epoch 1629/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2525.3889 - val_loss: 2397.5999\n",
      "Epoch 1630/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2524.7690 - val_loss: 2396.9780\n",
      "Epoch 1631/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2524.1497 - val_loss: 2396.3557\n",
      "Epoch 1632/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2523.5303 - val_loss: 2395.7344\n",
      "Epoch 1633/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2522.9111 - val_loss: 2395.1133\n",
      "Epoch 1634/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 2522.2920 - val_loss: 2394.4919\n",
      "Epoch 1635/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 2521.6733 - val_loss: 2393.8713\n",
      "Epoch 1636/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2521.0549 - val_loss: 2393.2507\n",
      "Epoch 1637/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2520.4370 - val_loss: 2392.6301\n",
      "Epoch 1638/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2519.8188 - val_loss: 2392.0100\n",
      "Epoch 1639/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2519.2012 - val_loss: 2391.3901\n",
      "Epoch 1640/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2518.5837 - val_loss: 2390.7703\n",
      "Epoch 1641/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2517.9663 - val_loss: 2390.1506\n",
      "Epoch 1642/100000\n",
      "11/11 [==============================] - 0s 877us/step - loss: 2517.3494 - val_loss: 2389.5315\n",
      "Epoch 1643/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2516.7324 - val_loss: 2388.9124\n",
      "Epoch 1644/100000\n",
      "11/11 [==============================] - 0s 741us/step - loss: 2516.1157 - val_loss: 2388.2935\n",
      "Epoch 1645/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 2515.4998 - val_loss: 2387.6750\n",
      "Epoch 1646/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 2514.8831 - val_loss: 2387.0564\n",
      "Epoch 1647/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 2514.2673 - val_loss: 2386.4385\n",
      "Epoch 1648/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 2513.6519 - val_loss: 2385.8206\n",
      "Epoch 1649/100000\n",
      "11/11 [==============================] - 0s 886us/step - loss: 2513.0364 - val_loss: 2385.2029\n",
      "Epoch 1650/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 2512.4209 - val_loss: 2384.5854\n",
      "Epoch 1651/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 2511.8062 - val_loss: 2383.9685\n",
      "Epoch 1652/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 2511.1912 - val_loss: 2383.3513\n",
      "Epoch 1653/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 2510.5767 - val_loss: 2382.7346\n",
      "Epoch 1654/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 2509.9624 - val_loss: 2382.1179\n",
      "Epoch 1655/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 2509.3479 - val_loss: 2381.5017\n",
      "Epoch 1656/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 2508.7344 - val_loss: 2380.8857\n",
      "Epoch 1657/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 2508.1208 - val_loss: 2380.2695\n",
      "Epoch 1658/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 2507.5076 - val_loss: 2379.6538\n",
      "Epoch 1659/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 2506.8940 - val_loss: 2379.0383\n",
      "Epoch 1660/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 2506.2810 - val_loss: 2378.4231\n",
      "Epoch 1661/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 2505.6680 - val_loss: 2377.8079\n",
      "Epoch 1662/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 2505.0554 - val_loss: 2377.1934\n",
      "Epoch 1663/100000\n",
      "11/11 [==============================] - 0s 633us/step - loss: 2504.4431 - val_loss: 2376.5789\n",
      "Epoch 1664/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 2503.8311 - val_loss: 2375.9646\n",
      "Epoch 1665/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 2503.2190 - val_loss: 2375.3501\n",
      "Epoch 1666/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 2502.6074 - val_loss: 2374.7361\n",
      "Epoch 1667/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 2501.9961 - val_loss: 2374.1228\n",
      "Epoch 1668/100000\n",
      "11/11 [==============================] - 0s 736us/step - loss: 2501.3848 - val_loss: 2373.5093\n",
      "Epoch 1669/100000\n",
      "11/11 [==============================] - 0s 705us/step - loss: 2500.7737 - val_loss: 2372.8960\n",
      "Epoch 1670/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 2500.1628 - val_loss: 2372.2830\n",
      "Epoch 1671/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 2499.5525 - val_loss: 2371.6702\n",
      "Epoch 1672/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 2498.9419 - val_loss: 2371.0576\n",
      "Epoch 1673/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 2498.3318 - val_loss: 2370.4453\n",
      "Epoch 1674/100000\n",
      "11/11 [==============================] - 0s 202us/step - loss: 2497.7222 - val_loss: 2369.8333\n",
      "Epoch 1675/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 2497.1123 - val_loss: 2369.2212\n",
      "Epoch 1676/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 2496.5024 - val_loss: 2368.6096\n",
      "Epoch 1677/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 2495.8936 - val_loss: 2367.9983\n",
      "Epoch 1678/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 2495.2844 - val_loss: 2367.3870\n",
      "Epoch 1679/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 2494.6755 - val_loss: 2366.7759\n",
      "Epoch 1680/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 2494.0669 - val_loss: 2366.1650\n",
      "Epoch 1681/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 2493.4585 - val_loss: 2365.5544\n",
      "Epoch 1682/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 2492.8503 - val_loss: 2364.9443\n",
      "Epoch 1683/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 2492.2424 - val_loss: 2364.3337\n",
      "Epoch 1684/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 2491.6348 - val_loss: 2363.7239\n",
      "Epoch 1685/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 2491.0271 - val_loss: 2363.1143\n",
      "Epoch 1686/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 2490.4199 - val_loss: 2362.5049\n",
      "Epoch 1687/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 2489.8130 - val_loss: 2361.8955\n",
      "Epoch 1688/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 2489.2061 - val_loss: 2361.2861\n",
      "Epoch 1689/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 2488.5994 - val_loss: 2360.6775\n",
      "Epoch 1690/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 2487.9932 - val_loss: 2360.0688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1691/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 2487.3870 - val_loss: 2359.4607\n",
      "Epoch 1692/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 2486.7808 - val_loss: 2358.8525\n",
      "Epoch 1693/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 2486.1750 - val_loss: 2358.2444\n",
      "Epoch 1694/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 2485.5693 - val_loss: 2357.6367\n",
      "Epoch 1695/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 2484.9644 - val_loss: 2357.0295\n",
      "Epoch 1696/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 2484.3591 - val_loss: 2356.4216\n",
      "Epoch 1697/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 2483.7542 - val_loss: 2355.8147\n",
      "Epoch 1698/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 2483.1494 - val_loss: 2355.2078\n",
      "Epoch 1699/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 2482.5452 - val_loss: 2354.6013\n",
      "Epoch 1700/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 2481.9409 - val_loss: 2353.9946\n",
      "Epoch 1701/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 2481.3367 - val_loss: 2353.3884\n",
      "Epoch 1702/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 2480.7329 - val_loss: 2352.7827\n",
      "Epoch 1703/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 2480.1294 - val_loss: 2352.1768\n",
      "Epoch 1704/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 2479.5261 - val_loss: 2351.5710\n",
      "Epoch 1705/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 2478.9229 - val_loss: 2350.9658\n",
      "Epoch 1706/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 2478.3201 - val_loss: 2350.3606\n",
      "Epoch 1707/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 2477.7173 - val_loss: 2349.7559\n",
      "Epoch 1708/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 2477.1147 - val_loss: 2349.1509\n",
      "Epoch 1709/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 2476.5125 - val_loss: 2348.5466\n",
      "Epoch 1710/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 2475.9104 - val_loss: 2347.9421\n",
      "Epoch 1711/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 2475.3086 - val_loss: 2347.3381\n",
      "Epoch 1712/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 2474.7068 - val_loss: 2346.7341\n",
      "Epoch 1713/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 2474.1052 - val_loss: 2346.1306\n",
      "Epoch 1714/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 2473.5042 - val_loss: 2345.5271\n",
      "Epoch 1715/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 2472.9026 - val_loss: 2344.9236\n",
      "Epoch 1716/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 2472.3022 - val_loss: 2344.3206\n",
      "Epoch 1717/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 2471.7017 - val_loss: 2343.7178\n",
      "Epoch 1718/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 2471.1013 - val_loss: 2343.1150\n",
      "Epoch 1719/100000\n",
      "11/11 [==============================] - 0s 205us/step - loss: 2470.5010 - val_loss: 2342.5132\n",
      "Epoch 1720/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2469.9009 - val_loss: 2341.9109\n",
      "Epoch 1721/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2469.3010 - val_loss: 2341.3088\n",
      "Epoch 1722/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2468.7017 - val_loss: 2340.7073\n",
      "Epoch 1723/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2468.1023 - val_loss: 2340.1055\n",
      "Epoch 1724/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2467.5029 - val_loss: 2339.5042\n",
      "Epoch 1725/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2466.9043 - val_loss: 2338.9031\n",
      "Epoch 1726/100000\n",
      "11/11 [==============================] - 0s 970us/step - loss: 2466.3054 - val_loss: 2338.3022\n",
      "Epoch 1727/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 2465.7073 - val_loss: 2337.7014\n",
      "Epoch 1728/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 2465.1089 - val_loss: 2337.1008\n",
      "Epoch 1729/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 2464.5107 - val_loss: 2336.5010\n",
      "Epoch 1730/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 2463.9131 - val_loss: 2335.9009\n",
      "Epoch 1731/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 2463.3154 - val_loss: 2335.3010\n",
      "Epoch 1732/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 2462.7180 - val_loss: 2334.7014\n",
      "Epoch 1733/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 2462.1208 - val_loss: 2334.1018\n",
      "Epoch 1734/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 2461.5239 - val_loss: 2333.5034\n",
      "Epoch 1735/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 2460.9272 - val_loss: 2332.9041\n",
      "Epoch 1736/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 2460.3306 - val_loss: 2332.3049\n",
      "Epoch 1737/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 2459.7344 - val_loss: 2331.7068\n",
      "Epoch 1738/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 2459.1382 - val_loss: 2331.1084\n",
      "Epoch 1739/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 2458.5422 - val_loss: 2330.5103\n",
      "Epoch 1740/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 2457.9465 - val_loss: 2329.9124\n",
      "Epoch 1741/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 2457.3511 - val_loss: 2329.3147\n",
      "Epoch 1742/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 2456.7559 - val_loss: 2328.7170\n",
      "Epoch 1743/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 2456.1604 - val_loss: 2328.1199\n",
      "Epoch 1744/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 2455.5659 - val_loss: 2327.5227\n",
      "Epoch 1745/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 2454.9709 - val_loss: 2326.9260\n",
      "Epoch 1746/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 2454.3765 - val_loss: 2326.3293\n",
      "Epoch 1747/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 2453.7822 - val_loss: 2325.7332\n",
      "Epoch 1748/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 2453.1885 - val_loss: 2325.1365\n",
      "Epoch 1749/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 2452.5947 - val_loss: 2324.5408\n",
      "Epoch 1750/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 2452.0010 - val_loss: 2323.9451\n",
      "Epoch 1751/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 2451.4077 - val_loss: 2323.3494\n",
      "Epoch 1752/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 2450.8147 - val_loss: 2322.7542\n",
      "Epoch 1753/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 2450.2217 - val_loss: 2322.1589\n",
      "Epoch 1754/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 2449.6289 - val_loss: 2321.5642\n",
      "Epoch 1755/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 2449.0364 - val_loss: 2320.9690\n",
      "Epoch 1756/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 2448.4438 - val_loss: 2320.3750\n",
      "Epoch 1757/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 2447.8518 - val_loss: 2319.7803\n",
      "Epoch 1758/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 2447.2600 - val_loss: 2319.1863\n",
      "Epoch 1759/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 2446.6682 - val_loss: 2318.5925\n",
      "Epoch 1760/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 2446.0771 - val_loss: 2317.9990\n",
      "Epoch 1761/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 2445.4856 - val_loss: 2317.4053\n",
      "Epoch 1762/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 2444.8948 - val_loss: 2316.8120\n",
      "Epoch 1763/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 2444.3037 - val_loss: 2316.2190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1764/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 2443.7131 - val_loss: 2315.6262\n",
      "Epoch 1765/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 2443.1226 - val_loss: 2315.0334\n",
      "Epoch 1766/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 2442.5322 - val_loss: 2314.4409\n",
      "Epoch 1767/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 2441.9424 - val_loss: 2313.8489\n",
      "Epoch 1768/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 2441.3523 - val_loss: 2313.2571\n",
      "Epoch 1769/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 2440.7627 - val_loss: 2312.6650\n",
      "Epoch 1770/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 2440.1736 - val_loss: 2312.0732\n",
      "Epoch 1771/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 2439.5842 - val_loss: 2311.4822\n",
      "Epoch 1772/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 2438.9951 - val_loss: 2310.8911\n",
      "Epoch 1773/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 2438.4062 - val_loss: 2310.2998\n",
      "Epoch 1774/100000\n",
      "11/11 [==============================] - 0s 618us/step - loss: 2437.8179 - val_loss: 2309.7092\n",
      "Epoch 1775/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 2437.2295 - val_loss: 2309.1187\n",
      "Epoch 1776/100000\n",
      "11/11 [==============================] - 0s 670us/step - loss: 2436.6411 - val_loss: 2308.5281\n",
      "Epoch 1777/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 2436.0530 - val_loss: 2307.9382\n",
      "Epoch 1778/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 2435.4658 - val_loss: 2307.3481\n",
      "Epoch 1779/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 2434.8782 - val_loss: 2306.7585\n",
      "Epoch 1780/100000\n",
      "11/11 [==============================] - 0s 205us/step - loss: 2434.2908 - val_loss: 2306.1689\n",
      "Epoch 1781/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 2433.7034 - val_loss: 2305.5796\n",
      "Epoch 1782/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 2433.1167 - val_loss: 2304.9907\n",
      "Epoch 1783/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 2432.5300 - val_loss: 2304.4016\n",
      "Epoch 1784/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 2431.9436 - val_loss: 2303.8127\n",
      "Epoch 1785/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 2431.3572 - val_loss: 2303.2244\n",
      "Epoch 1786/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 2430.7710 - val_loss: 2302.6360\n",
      "Epoch 1787/100000\n",
      "11/11 [==============================] - 0s 202us/step - loss: 2430.1853 - val_loss: 2302.0479\n",
      "Epoch 1788/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 2429.5994 - val_loss: 2301.4600\n",
      "Epoch 1789/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 2429.0142 - val_loss: 2300.8726\n",
      "Epoch 1790/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 2428.4287 - val_loss: 2300.2849\n",
      "Epoch 1791/100000\n",
      "11/11 [==============================] - 0s 608us/step - loss: 2427.8438 - val_loss: 2299.6978\n",
      "Epoch 1792/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 2427.2588 - val_loss: 2299.1104\n",
      "Epoch 1793/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 2426.6741 - val_loss: 2298.5237\n",
      "Epoch 1794/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 2426.0896 - val_loss: 2297.9373\n",
      "Epoch 1795/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 2425.5054 - val_loss: 2297.3506\n",
      "Epoch 1796/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 2424.9211 - val_loss: 2296.7642\n",
      "Epoch 1797/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 2424.3376 - val_loss: 2296.1785\n",
      "Epoch 1798/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 2423.7537 - val_loss: 2295.5923\n",
      "Epoch 1799/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 2423.1702 - val_loss: 2295.0068\n",
      "Epoch 1800/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 2422.5872 - val_loss: 2294.4216\n",
      "Epoch 1801/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 2422.0042 - val_loss: 2293.8362\n",
      "Epoch 1802/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 2421.4214 - val_loss: 2293.2510\n",
      "Epoch 1803/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 2420.8389 - val_loss: 2292.6663\n",
      "Epoch 1804/100000\n",
      "11/11 [==============================] - 0s 745us/step - loss: 2420.2561 - val_loss: 2292.0818\n",
      "Epoch 1805/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 2419.6738 - val_loss: 2291.4971\n",
      "Epoch 1806/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2419.0920 - val_loss: 2290.9131\n",
      "Epoch 1807/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2418.5103 - val_loss: 2290.3291\n",
      "Epoch 1808/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 2417.9285 - val_loss: 2289.7454\n",
      "Epoch 1809/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 2417.3469 - val_loss: 2289.1619\n",
      "Epoch 1810/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 2416.7659 - val_loss: 2288.5784\n",
      "Epoch 1811/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 2416.1848 - val_loss: 2287.9951\n",
      "Epoch 1812/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 2415.6040 - val_loss: 2287.4124\n",
      "Epoch 1813/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 2415.0232 - val_loss: 2286.8296\n",
      "Epoch 1814/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2414.4431 - val_loss: 2286.2468\n",
      "Epoch 1815/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 2413.8630 - val_loss: 2285.6646\n",
      "Epoch 1816/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2413.2827 - val_loss: 2285.0823\n",
      "Epoch 1817/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 2412.7031 - val_loss: 2284.5002\n",
      "Epoch 1818/100000\n",
      "11/11 [==============================] - 0s 675us/step - loss: 2412.1238 - val_loss: 2283.9187\n",
      "Epoch 1819/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 2411.5444 - val_loss: 2283.3369\n",
      "Epoch 1820/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 2410.9651 - val_loss: 2282.7561\n",
      "Epoch 1821/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 2410.3862 - val_loss: 2282.1748\n",
      "Epoch 1822/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 2409.8076 - val_loss: 2281.5938\n",
      "Epoch 1823/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 2409.2290 - val_loss: 2281.0132\n",
      "Epoch 1824/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 2408.6506 - val_loss: 2280.4326\n",
      "Epoch 1825/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 2408.0723 - val_loss: 2279.8523\n",
      "Epoch 1826/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 2407.4944 - val_loss: 2279.2720\n",
      "Epoch 1827/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 2406.9170 - val_loss: 2278.6921\n",
      "Epoch 1828/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 2406.3391 - val_loss: 2278.1123\n",
      "Epoch 1829/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 2405.7620 - val_loss: 2277.5330\n",
      "Epoch 1830/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 2405.1848 - val_loss: 2276.9534\n",
      "Epoch 1831/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 2404.6079 - val_loss: 2276.3743\n",
      "Epoch 1832/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 2404.0310 - val_loss: 2275.7959\n",
      "Epoch 1833/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 2403.4546 - val_loss: 2275.2170\n",
      "Epoch 1834/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 2402.8782 - val_loss: 2274.6384\n",
      "Epoch 1835/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 2402.3020 - val_loss: 2274.0601\n",
      "Epoch 1836/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 2401.7263 - val_loss: 2273.4819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1837/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 2401.1504 - val_loss: 2272.9041\n",
      "Epoch 1838/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 2400.5750 - val_loss: 2272.3264\n",
      "Epoch 1839/100000\n",
      "11/11 [==============================] - 0s 604us/step - loss: 2399.9998 - val_loss: 2271.7490\n",
      "Epoch 1840/100000\n",
      "11/11 [==============================] - 0s 662us/step - loss: 2399.4243 - val_loss: 2271.1716\n",
      "Epoch 1841/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 2398.8494 - val_loss: 2270.5945\n",
      "Epoch 1842/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 2398.2749 - val_loss: 2270.0178\n",
      "Epoch 1843/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 2397.7002 - val_loss: 2269.4407\n",
      "Epoch 1844/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 2397.1260 - val_loss: 2268.8643\n",
      "Epoch 1845/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 2396.5518 - val_loss: 2268.2881\n",
      "Epoch 1846/100000\n",
      "11/11 [==============================] - 0s 604us/step - loss: 2395.9780 - val_loss: 2267.7117\n",
      "Epoch 1847/100000\n",
      "11/11 [==============================] - 0s 642us/step - loss: 2395.4043 - val_loss: 2267.1360\n",
      "Epoch 1848/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 2394.8306 - val_loss: 2266.5605\n",
      "Epoch 1849/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 2394.2573 - val_loss: 2265.9846\n",
      "Epoch 1850/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 2393.6843 - val_loss: 2265.4094\n",
      "Epoch 1851/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 2393.1111 - val_loss: 2264.8342\n",
      "Epoch 1852/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 2392.5386 - val_loss: 2264.2595\n",
      "Epoch 1853/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 2391.9658 - val_loss: 2263.6846\n",
      "Epoch 1854/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 2391.3936 - val_loss: 2263.1104\n",
      "Epoch 1855/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 2390.8213 - val_loss: 2262.5359\n",
      "Epoch 1856/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 2390.2495 - val_loss: 2261.9619\n",
      "Epoch 1857/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 2389.6780 - val_loss: 2261.3877\n",
      "Epoch 1858/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 2389.1062 - val_loss: 2260.8142\n",
      "Epoch 1859/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 2388.5349 - val_loss: 2260.2407\n",
      "Epoch 1860/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 2387.9639 - val_loss: 2259.6672\n",
      "Epoch 1861/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 2387.3928 - val_loss: 2259.0940\n",
      "Epoch 1862/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 2386.8220 - val_loss: 2258.5212\n",
      "Epoch 1863/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 2386.2515 - val_loss: 2257.9482\n",
      "Epoch 1864/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 2385.6814 - val_loss: 2257.3760\n",
      "Epoch 1865/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 2385.1111 - val_loss: 2256.8037\n",
      "Epoch 1866/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 2384.5413 - val_loss: 2256.2314\n",
      "Epoch 1867/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 2383.9709 - val_loss: 2255.6594\n",
      "Epoch 1868/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 2383.4014 - val_loss: 2255.0876\n",
      "Epoch 1869/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 2382.8323 - val_loss: 2254.5161\n",
      "Epoch 1870/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 2382.2629 - val_loss: 2253.9451\n",
      "Epoch 1871/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 2381.6943 - val_loss: 2253.3738\n",
      "Epoch 1872/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 2381.1252 - val_loss: 2252.8030\n",
      "Epoch 1873/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 2380.5569 - val_loss: 2252.2322\n",
      "Epoch 1874/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 2379.9883 - val_loss: 2251.6614\n",
      "Epoch 1875/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 2379.4202 - val_loss: 2251.0911\n",
      "Epoch 1876/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 2378.8518 - val_loss: 2250.5210\n",
      "Epoch 1877/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 2378.2844 - val_loss: 2249.9509\n",
      "Epoch 1878/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 2377.7166 - val_loss: 2249.3811\n",
      "Epoch 1879/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 2377.1494 - val_loss: 2248.8115\n",
      "Epoch 1880/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 2376.5820 - val_loss: 2248.2424\n",
      "Epoch 1881/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 2376.0149 - val_loss: 2247.6731\n",
      "Epoch 1882/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 2375.4482 - val_loss: 2247.1040\n",
      "Epoch 1883/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 2374.8816 - val_loss: 2246.5352\n",
      "Epoch 1884/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 2374.3154 - val_loss: 2245.9666\n",
      "Epoch 1885/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 2373.7490 - val_loss: 2245.3982\n",
      "Epoch 1886/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 2373.1831 - val_loss: 2244.8298\n",
      "Epoch 1887/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 2372.6172 - val_loss: 2244.2620\n",
      "Epoch 1888/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 2372.0510 - val_loss: 2243.6943\n",
      "Epoch 1889/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 2371.4858 - val_loss: 2243.1265\n",
      "Epoch 1890/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 2370.9209 - val_loss: 2242.5588\n",
      "Epoch 1891/100000\n",
      "11/11 [==============================] - 0s 737us/step - loss: 2370.3557 - val_loss: 2241.9919\n",
      "Epoch 1892/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 2369.7908 - val_loss: 2241.4248\n",
      "Epoch 1893/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 2369.2261 - val_loss: 2240.8579\n",
      "Epoch 1894/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 2368.6614 - val_loss: 2240.2913\n",
      "Epoch 1895/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 2368.0974 - val_loss: 2239.7249\n",
      "Epoch 1896/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 2367.5330 - val_loss: 2239.1584\n",
      "Epoch 1897/100000\n",
      "11/11 [==============================] - 0s 660us/step - loss: 2366.9692 - val_loss: 2238.5923\n",
      "Epoch 1898/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 2366.4055 - val_loss: 2238.0264\n",
      "Epoch 1899/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 2365.8420 - val_loss: 2237.4609\n",
      "Epoch 1900/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 2365.2791 - val_loss: 2236.8955\n",
      "Epoch 1901/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 2364.7156 - val_loss: 2236.3301\n",
      "Epoch 1902/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2364.1526 - val_loss: 2235.7651\n",
      "Epoch 1903/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2363.5901 - val_loss: 2235.2002\n",
      "Epoch 1904/100000\n",
      "11/11 [==============================] - 0s 755us/step - loss: 2363.0273 - val_loss: 2234.6353\n",
      "Epoch 1905/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 2362.4651 - val_loss: 2234.0710\n",
      "Epoch 1906/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 2361.9028 - val_loss: 2233.5066\n",
      "Epoch 1907/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 2361.3408 - val_loss: 2232.9424\n",
      "Epoch 1908/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 2360.7791 - val_loss: 2232.3787\n",
      "Epoch 1909/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 2360.2173 - val_loss: 2231.8147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1910/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 2359.6565 - val_loss: 2231.2512\n",
      "Epoch 1911/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 2359.0952 - val_loss: 2230.6880\n",
      "Epoch 1912/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 2358.5342 - val_loss: 2230.1248\n",
      "Epoch 1913/100000\n",
      "11/11 [==============================] - 0s 727us/step - loss: 2357.9731 - val_loss: 2229.5618\n",
      "Epoch 1914/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2357.4126 - val_loss: 2228.9993\n",
      "Epoch 1915/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2356.8523 - val_loss: 2228.4365\n",
      "Epoch 1916/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 2356.2922 - val_loss: 2227.8743\n",
      "Epoch 1917/100000\n",
      "11/11 [==============================] - 0s 750us/step - loss: 2355.7322 - val_loss: 2227.3123\n",
      "Epoch 1918/100000\n",
      "11/11 [==============================] - 0s 594us/step - loss: 2355.1724 - val_loss: 2226.7500\n",
      "Epoch 1919/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 2354.6125 - val_loss: 2226.1882\n",
      "Epoch 1920/100000\n",
      "11/11 [==============================] - 0s 740us/step - loss: 2354.0532 - val_loss: 2225.6267\n",
      "Epoch 1921/100000\n",
      "11/11 [==============================] - 0s 873us/step - loss: 2353.4939 - val_loss: 2225.0652\n",
      "Epoch 1922/100000\n",
      "11/11 [==============================] - 0s 665us/step - loss: 2352.9353 - val_loss: 2224.5039\n",
      "Epoch 1923/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2352.3760 - val_loss: 2223.9429\n",
      "Epoch 1924/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2351.8171 - val_loss: 2223.3821\n",
      "Epoch 1925/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 2351.2588 - val_loss: 2222.8215\n",
      "Epoch 1926/100000\n",
      "11/11 [==============================] - 0s 723us/step - loss: 2350.7004 - val_loss: 2222.2610\n",
      "Epoch 1927/100000\n",
      "11/11 [==============================] - 0s 732us/step - loss: 2350.1426 - val_loss: 2221.7007\n",
      "Epoch 1928/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 2349.5845 - val_loss: 2221.1406\n",
      "Epoch 1929/100000\n",
      "11/11 [==============================] - 0s 780us/step - loss: 2349.0266 - val_loss: 2220.5808\n",
      "Epoch 1930/100000\n",
      "11/11 [==============================] - 0s 749us/step - loss: 2348.4695 - val_loss: 2220.0212\n",
      "Epoch 1931/100000\n",
      "11/11 [==============================] - 0s 822us/step - loss: 2347.9121 - val_loss: 2219.4619\n",
      "Epoch 1932/100000\n",
      "11/11 [==============================] - 0s 976us/step - loss: 2347.3550 - val_loss: 2218.9023\n",
      "Epoch 1933/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 2346.7981 - val_loss: 2218.3433\n",
      "Epoch 1934/100000\n",
      "11/11 [==============================] - 0s 777us/step - loss: 2346.2412 - val_loss: 2217.7844\n",
      "Epoch 1935/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 2345.6846 - val_loss: 2217.2258\n",
      "Epoch 1936/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 2345.1284 - val_loss: 2216.6672\n",
      "Epoch 1937/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 2344.5720 - val_loss: 2216.1091\n",
      "Epoch 1938/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 2344.0164 - val_loss: 2215.5508\n",
      "Epoch 1939/100000\n",
      "11/11 [==============================] - 0s 620us/step - loss: 2343.4607 - val_loss: 2214.9929\n",
      "Epoch 1940/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 2342.9048 - val_loss: 2214.4351\n",
      "Epoch 1941/100000\n",
      "11/11 [==============================] - 0s 800us/step - loss: 2342.3496 - val_loss: 2213.8777\n",
      "Epoch 1942/100000\n",
      "11/11 [==============================] - 0s 825us/step - loss: 2341.7944 - val_loss: 2213.3203\n",
      "Epoch 1943/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 2341.2393 - val_loss: 2212.7634\n",
      "Epoch 1944/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 2340.6846 - val_loss: 2212.2061\n",
      "Epoch 1945/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 2340.1299 - val_loss: 2211.6494\n",
      "Epoch 1946/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2339.5757 - val_loss: 2211.0928\n",
      "Epoch 1947/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2339.0212 - val_loss: 2210.5364\n",
      "Epoch 1948/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 2338.4673 - val_loss: 2209.9802\n",
      "Epoch 1949/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2337.9133 - val_loss: 2209.4241\n",
      "Epoch 1950/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 2337.3596 - val_loss: 2208.8682\n",
      "Epoch 1951/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 2336.8062 - val_loss: 2208.3125\n",
      "Epoch 1952/100000\n",
      "11/11 [==============================] - 0s 847us/step - loss: 2336.2529 - val_loss: 2207.7571\n",
      "Epoch 1953/100000\n",
      "11/11 [==============================] - 0s 624us/step - loss: 2335.6997 - val_loss: 2207.2019\n",
      "Epoch 1954/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2335.1467 - val_loss: 2206.6467\n",
      "Epoch 1955/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 2334.5940 - val_loss: 2206.0916\n",
      "Epoch 1956/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 2334.0415 - val_loss: 2205.5374\n",
      "Epoch 1957/100000\n",
      "11/11 [==============================] - 0s 607us/step - loss: 2333.4890 - val_loss: 2204.9827\n",
      "Epoch 1958/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2332.9373 - val_loss: 2204.4282\n",
      "Epoch 1959/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2332.3848 - val_loss: 2203.8740\n",
      "Epoch 1960/100000\n",
      "11/11 [==============================] - 0s 854us/step - loss: 2331.8330 - val_loss: 2203.3201\n",
      "Epoch 1961/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 2331.2812 - val_loss: 2202.7666\n",
      "Epoch 1962/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 2330.7300 - val_loss: 2202.2124\n",
      "Epoch 1963/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 2330.1790 - val_loss: 2201.6592\n",
      "Epoch 1964/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 2329.6277 - val_loss: 2201.1062\n",
      "Epoch 1965/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 2329.0769 - val_loss: 2200.5532\n",
      "Epoch 1966/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 2328.5261 - val_loss: 2200.0002\n",
      "Epoch 1967/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 2327.9756 - val_loss: 2199.4478\n",
      "Epoch 1968/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 2327.4255 - val_loss: 2198.8953\n",
      "Epoch 1969/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 2326.8752 - val_loss: 2198.3430\n",
      "Epoch 1970/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 2326.3254 - val_loss: 2197.7908\n",
      "Epoch 1971/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 2325.7756 - val_loss: 2197.2393\n",
      "Epoch 1972/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 2325.2263 - val_loss: 2196.6875\n",
      "Epoch 1973/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 2324.6768 - val_loss: 2196.1357\n",
      "Epoch 1974/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 2324.1279 - val_loss: 2195.5845\n",
      "Epoch 1975/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 2323.5784 - val_loss: 2195.0332\n",
      "Epoch 1976/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 2323.0298 - val_loss: 2194.4822\n",
      "Epoch 1977/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 2322.4812 - val_loss: 2193.9314\n",
      "Epoch 1978/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 2321.9326 - val_loss: 2193.3811\n",
      "Epoch 1979/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 2321.3850 - val_loss: 2192.8308\n",
      "Epoch 1980/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 2320.8369 - val_loss: 2192.2805\n",
      "Epoch 1981/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 2320.2888 - val_loss: 2191.7307\n",
      "Epoch 1982/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 2319.7412 - val_loss: 2191.1807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1983/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 2319.1936 - val_loss: 2190.6311\n",
      "Epoch 1984/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 2318.6462 - val_loss: 2190.0815\n",
      "Epoch 1985/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 2318.0989 - val_loss: 2189.5322\n",
      "Epoch 1986/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 2317.5522 - val_loss: 2188.9832\n",
      "Epoch 1987/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 2317.0054 - val_loss: 2188.4346\n",
      "Epoch 1988/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 2316.4590 - val_loss: 2187.8860\n",
      "Epoch 1989/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 2315.9126 - val_loss: 2187.3374\n",
      "Epoch 1990/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 2315.3665 - val_loss: 2186.7888\n",
      "Epoch 1991/100000\n",
      "11/11 [==============================] - 0s 607us/step - loss: 2314.8206 - val_loss: 2186.2410\n",
      "Epoch 1992/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 2314.2749 - val_loss: 2185.6931\n",
      "Epoch 1993/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 2313.7295 - val_loss: 2185.1453\n",
      "Epoch 1994/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 2313.1841 - val_loss: 2184.5977\n",
      "Epoch 1995/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 2312.6384 - val_loss: 2184.0505\n",
      "Epoch 1996/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 2312.0938 - val_loss: 2183.5032\n",
      "Epoch 1997/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 2311.5488 - val_loss: 2182.9561\n",
      "Epoch 1998/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 2311.0039 - val_loss: 2182.4092\n",
      "Epoch 1999/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 2310.4600 - val_loss: 2181.8625\n",
      "Epoch 2000/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 2309.9155 - val_loss: 2181.3164\n",
      "Epoch 2001/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 2309.3711 - val_loss: 2180.7698\n",
      "Epoch 2002/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 2308.8271 - val_loss: 2180.2241\n",
      "Epoch 2003/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 2308.2834 - val_loss: 2179.6782\n",
      "Epoch 2004/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 2307.7400 - val_loss: 2179.1323\n",
      "Epoch 2005/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 2307.1965 - val_loss: 2178.5869\n",
      "Epoch 2006/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 2306.6533 - val_loss: 2178.0415\n",
      "Epoch 2007/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 2306.1106 - val_loss: 2177.4963\n",
      "Epoch 2008/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 2305.5679 - val_loss: 2176.9514\n",
      "Epoch 2009/100000\n",
      "11/11 [==============================] - 0s 716us/step - loss: 2305.0251 - val_loss: 2176.4065\n",
      "Epoch 2010/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 2304.4827 - val_loss: 2175.8623\n",
      "Epoch 2011/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 2303.9404 - val_loss: 2175.3176\n",
      "Epoch 2012/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 2303.3984 - val_loss: 2174.7734\n",
      "Epoch 2013/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 2302.8564 - val_loss: 2174.2295\n",
      "Epoch 2014/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 2302.3147 - val_loss: 2173.6853\n",
      "Epoch 2015/100000\n",
      "11/11 [==============================] - 0s 599us/step - loss: 2301.7732 - val_loss: 2173.1416\n",
      "Epoch 2016/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 2301.2317 - val_loss: 2172.5981\n",
      "Epoch 2017/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 2300.6907 - val_loss: 2172.0549\n",
      "Epoch 2018/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 2300.1497 - val_loss: 2171.5120\n",
      "Epoch 2019/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 2299.6089 - val_loss: 2170.9688\n",
      "Epoch 2020/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 2299.0681 - val_loss: 2170.4263\n",
      "Epoch 2021/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 2298.5276 - val_loss: 2169.8838\n",
      "Epoch 2022/100000\n",
      "11/11 [==============================] - 0s 679us/step - loss: 2297.9875 - val_loss: 2169.3413\n",
      "Epoch 2023/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 2297.4475 - val_loss: 2168.7991\n",
      "Epoch 2024/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 2296.9077 - val_loss: 2168.2573\n",
      "Epoch 2025/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 2296.3679 - val_loss: 2167.7151\n",
      "Epoch 2026/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 2295.8286 - val_loss: 2167.1738\n",
      "Epoch 2027/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 2295.2891 - val_loss: 2166.6321\n",
      "Epoch 2028/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 2294.7502 - val_loss: 2166.0911\n",
      "Epoch 2029/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 2294.2112 - val_loss: 2165.5498\n",
      "Epoch 2030/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 2293.6724 - val_loss: 2165.0093\n",
      "Epoch 2031/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 2293.1340 - val_loss: 2164.4685\n",
      "Epoch 2032/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 2292.5955 - val_loss: 2163.9280\n",
      "Epoch 2033/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 2292.0574 - val_loss: 2163.3875\n",
      "Epoch 2034/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 2291.5193 - val_loss: 2162.8474\n",
      "Epoch 2035/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 2290.9817 - val_loss: 2162.3076\n",
      "Epoch 2036/100000\n",
      "11/11 [==============================] - 0s 692us/step - loss: 2290.4438 - val_loss: 2161.7678\n",
      "Epoch 2037/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 2289.9065 - val_loss: 2161.2283\n",
      "Epoch 2038/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 2289.3694 - val_loss: 2160.6890\n",
      "Epoch 2039/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 2288.8323 - val_loss: 2160.1494\n",
      "Epoch 2040/100000\n",
      "11/11 [==============================] - 0s 752us/step - loss: 2288.2952 - val_loss: 2159.6104\n",
      "Epoch 2041/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 2287.7585 - val_loss: 2159.0715\n",
      "Epoch 2042/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 2287.2222 - val_loss: 2158.5327\n",
      "Epoch 2043/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 2286.6855 - val_loss: 2157.9944\n",
      "Epoch 2044/100000\n",
      "11/11 [==============================] - 0s 673us/step - loss: 2286.1497 - val_loss: 2157.4561\n",
      "Epoch 2045/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 2285.6133 - val_loss: 2156.9180\n",
      "Epoch 2046/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 2285.0779 - val_loss: 2156.3799\n",
      "Epoch 2047/100000\n",
      "11/11 [==============================] - 0s 784us/step - loss: 2284.5420 - val_loss: 2155.8420\n",
      "Epoch 2048/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 2284.0066 - val_loss: 2155.3049\n",
      "Epoch 2049/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 2283.4717 - val_loss: 2154.7673\n",
      "Epoch 2050/100000\n",
      "11/11 [==============================] - 0s 865us/step - loss: 2282.9363 - val_loss: 2154.2302\n",
      "Epoch 2051/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 2282.4014 - val_loss: 2153.6929\n",
      "Epoch 2052/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 2281.8667 - val_loss: 2153.1560\n",
      "Epoch 2053/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 2281.3320 - val_loss: 2152.6196\n",
      "Epoch 2054/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 2280.7979 - val_loss: 2152.0830\n",
      "Epoch 2055/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 2280.2637 - val_loss: 2151.5466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2056/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 2279.7297 - val_loss: 2151.0105\n",
      "Epoch 2057/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 2279.1960 - val_loss: 2150.4744\n",
      "Epoch 2058/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 2278.6624 - val_loss: 2149.9385\n",
      "Epoch 2059/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 2278.1289 - val_loss: 2149.4033\n",
      "Epoch 2060/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 2277.5955 - val_loss: 2148.8679\n",
      "Epoch 2061/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 2277.0625 - val_loss: 2148.3328\n",
      "Epoch 2062/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 2276.5295 - val_loss: 2147.7976\n",
      "Epoch 2063/100000\n",
      "11/11 [==============================] - 0s 695us/step - loss: 2275.9971 - val_loss: 2147.2629\n",
      "Epoch 2064/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 2275.4641 - val_loss: 2146.7283\n",
      "Epoch 2065/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 2274.9319 - val_loss: 2146.1936\n",
      "Epoch 2066/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 2274.3997 - val_loss: 2145.6592\n",
      "Epoch 2067/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 2273.8679 - val_loss: 2145.1252\n",
      "Epoch 2068/100000\n",
      "11/11 [==============================] - 0s 201us/step - loss: 2273.3359 - val_loss: 2144.5913\n",
      "Epoch 2069/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 2272.8042 - val_loss: 2144.0576\n",
      "Epoch 2070/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 2272.2729 - val_loss: 2143.5237\n",
      "Epoch 2071/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 2271.7417 - val_loss: 2142.9907\n",
      "Epoch 2072/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 2271.2107 - val_loss: 2142.4570\n",
      "Epoch 2073/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 2270.6797 - val_loss: 2141.9241\n",
      "Epoch 2074/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 2270.1489 - val_loss: 2141.3911\n",
      "Epoch 2075/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 2269.6184 - val_loss: 2140.8584\n",
      "Epoch 2076/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 2269.0881 - val_loss: 2140.3259\n",
      "Epoch 2077/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 2268.5579 - val_loss: 2139.7939\n",
      "Epoch 2078/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 2268.0276 - val_loss: 2139.2617\n",
      "Epoch 2079/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 2267.4983 - val_loss: 2138.7297\n",
      "Epoch 2080/100000\n",
      "11/11 [==============================] - 0s 674us/step - loss: 2266.9685 - val_loss: 2138.1980\n",
      "Epoch 2081/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 2266.4387 - val_loss: 2137.6663\n",
      "Epoch 2082/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 2265.9097 - val_loss: 2137.1350\n",
      "Epoch 2083/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 2265.3804 - val_loss: 2136.6038\n",
      "Epoch 2084/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 2264.8513 - val_loss: 2136.0725\n",
      "Epoch 2085/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 2264.3228 - val_loss: 2135.5417\n",
      "Epoch 2086/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 2263.7939 - val_loss: 2135.0107\n",
      "Epoch 2087/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 2263.2659 - val_loss: 2134.4805\n",
      "Epoch 2088/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 2262.7373 - val_loss: 2133.9502\n",
      "Epoch 2089/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 2262.2095 - val_loss: 2133.4199\n",
      "Epoch 2090/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 2261.6814 - val_loss: 2132.8899\n",
      "Epoch 2091/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 2261.1541 - val_loss: 2132.3604\n",
      "Epoch 2092/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 2260.6262 - val_loss: 2131.8303\n",
      "Epoch 2093/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 2260.0991 - val_loss: 2131.3010\n",
      "Epoch 2094/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 2259.5720 - val_loss: 2130.7717\n",
      "Epoch 2095/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 2259.0449 - val_loss: 2130.2424\n",
      "Epoch 2096/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 2258.5183 - val_loss: 2129.7139\n",
      "Epoch 2097/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 2257.9917 - val_loss: 2129.1851\n",
      "Epoch 2098/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 2257.4651 - val_loss: 2128.6565\n",
      "Epoch 2099/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 2256.9392 - val_loss: 2128.1282\n",
      "Epoch 2100/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 2256.4131 - val_loss: 2127.5999\n",
      "Epoch 2101/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 2255.8872 - val_loss: 2127.0720\n",
      "Epoch 2102/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 2255.3616 - val_loss: 2126.5439\n",
      "Epoch 2103/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 2254.8359 - val_loss: 2126.0164\n",
      "Epoch 2104/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 2254.3103 - val_loss: 2125.4888\n",
      "Epoch 2105/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 2253.7854 - val_loss: 2124.9617\n",
      "Epoch 2106/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 2253.2603 - val_loss: 2124.4346\n",
      "Epoch 2107/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 2252.7356 - val_loss: 2123.9072\n",
      "Epoch 2108/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 2252.2107 - val_loss: 2123.3806\n",
      "Epoch 2109/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 2251.6860 - val_loss: 2122.8540\n",
      "Epoch 2110/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 2251.1621 - val_loss: 2122.3279\n",
      "Epoch 2111/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 2250.6379 - val_loss: 2121.8015\n",
      "Epoch 2112/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 2250.1140 - val_loss: 2121.2756\n",
      "Epoch 2113/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 2249.5906 - val_loss: 2120.7498\n",
      "Epoch 2114/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 2249.0667 - val_loss: 2120.2241\n",
      "Epoch 2115/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 2248.5432 - val_loss: 2119.6985\n",
      "Epoch 2116/100000\n",
      "11/11 [==============================] - 0s 588us/step - loss: 2248.0203 - val_loss: 2119.1729\n",
      "Epoch 2117/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2247.4971 - val_loss: 2118.6482\n",
      "Epoch 2118/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 2246.9741 - val_loss: 2118.1230\n",
      "Epoch 2119/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 2246.4519 - val_loss: 2117.5984\n",
      "Epoch 2120/100000\n",
      "11/11 [==============================] - 0s 816us/step - loss: 2245.9294 - val_loss: 2117.0735\n",
      "Epoch 2121/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 2245.4070 - val_loss: 2116.5488\n",
      "Epoch 2122/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 2244.8845 - val_loss: 2116.0249\n",
      "Epoch 2123/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2244.3628 - val_loss: 2115.5005\n",
      "Epoch 2124/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 2243.8408 - val_loss: 2114.9766\n",
      "Epoch 2125/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 2243.3193 - val_loss: 2114.4529\n",
      "Epoch 2126/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2242.7981 - val_loss: 2113.9294\n",
      "Epoch 2127/100000\n",
      "11/11 [==============================] - 0s 974us/step - loss: 2242.2766 - val_loss: 2113.4062\n",
      "Epoch 2128/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 2241.7554 - val_loss: 2112.8831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2129/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2241.2344 - val_loss: 2112.3596\n",
      "Epoch 2130/100000\n",
      "11/11 [==============================] - 0s 780us/step - loss: 2240.7139 - val_loss: 2111.8369\n",
      "Epoch 2131/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2240.1931 - val_loss: 2111.3142\n",
      "Epoch 2132/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 2239.6729 - val_loss: 2110.7920\n",
      "Epoch 2133/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 2239.1526 - val_loss: 2110.2695\n",
      "Epoch 2134/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 2238.6328 - val_loss: 2109.7476\n",
      "Epoch 2135/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 2238.1130 - val_loss: 2109.2256\n",
      "Epoch 2136/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 2237.5930 - val_loss: 2108.7034\n",
      "Epoch 2137/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 2237.0740 - val_loss: 2108.1819\n",
      "Epoch 2138/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 2236.5544 - val_loss: 2107.6604\n",
      "Epoch 2139/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 2236.0354 - val_loss: 2107.1392\n",
      "Epoch 2140/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 2235.5164 - val_loss: 2106.6182\n",
      "Epoch 2141/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 2234.9978 - val_loss: 2106.0974\n",
      "Epoch 2142/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 2234.4790 - val_loss: 2105.5764\n",
      "Epoch 2143/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 2233.9604 - val_loss: 2105.0562\n",
      "Epoch 2144/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 2233.4424 - val_loss: 2104.5354\n",
      "Epoch 2145/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 2232.9241 - val_loss: 2104.0154\n",
      "Epoch 2146/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 2232.4062 - val_loss: 2103.4954\n",
      "Epoch 2147/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 2231.8884 - val_loss: 2102.9756\n",
      "Epoch 2148/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 2231.3711 - val_loss: 2102.4561\n",
      "Epoch 2149/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 2230.8538 - val_loss: 2101.9365\n",
      "Epoch 2150/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 2230.3364 - val_loss: 2101.4170\n",
      "Epoch 2151/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 2229.8193 - val_loss: 2100.8982\n",
      "Epoch 2152/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 2229.3030 - val_loss: 2100.3789\n",
      "Epoch 2153/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 2228.7859 - val_loss: 2099.8604\n",
      "Epoch 2154/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 2228.2695 - val_loss: 2099.3416\n",
      "Epoch 2155/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 2227.7532 - val_loss: 2098.8232\n",
      "Epoch 2156/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 2227.2368 - val_loss: 2098.3049\n",
      "Epoch 2157/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 2226.7209 - val_loss: 2097.7869\n",
      "Epoch 2158/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 2226.2053 - val_loss: 2097.2688\n",
      "Epoch 2159/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 2225.6897 - val_loss: 2096.7510\n",
      "Epoch 2160/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 2225.1743 - val_loss: 2096.2336\n",
      "Epoch 2161/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 2224.6592 - val_loss: 2095.7163\n",
      "Epoch 2162/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 2224.1438 - val_loss: 2095.1990\n",
      "Epoch 2163/100000\n",
      "11/11 [==============================] - 0s 618us/step - loss: 2223.6289 - val_loss: 2094.6819\n",
      "Epoch 2164/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 2223.1143 - val_loss: 2094.1650\n",
      "Epoch 2165/100000\n",
      "11/11 [==============================] - 0s 710us/step - loss: 2222.5996 - val_loss: 2093.6484\n",
      "Epoch 2166/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 2222.0852 - val_loss: 2093.1318\n",
      "Epoch 2167/100000\n",
      "11/11 [==============================] - 0s 633us/step - loss: 2221.5708 - val_loss: 2092.6155\n",
      "Epoch 2168/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 2221.0569 - val_loss: 2092.0994\n",
      "Epoch 2169/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 2220.5430 - val_loss: 2091.5835\n",
      "Epoch 2170/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 2220.0293 - val_loss: 2091.0676\n",
      "Epoch 2171/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 2219.5159 - val_loss: 2090.5518\n",
      "Epoch 2172/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 2219.0022 - val_loss: 2090.0366\n",
      "Epoch 2173/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 2218.4893 - val_loss: 2089.5210\n",
      "Epoch 2174/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 2217.9763 - val_loss: 2089.0061\n",
      "Epoch 2175/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 2217.4631 - val_loss: 2088.4912\n",
      "Epoch 2176/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 2216.9507 - val_loss: 2087.9763\n",
      "Epoch 2177/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 2216.4382 - val_loss: 2087.4614\n",
      "Epoch 2178/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 2215.9258 - val_loss: 2086.9470\n",
      "Epoch 2179/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 2215.4138 - val_loss: 2086.4331\n",
      "Epoch 2180/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 2214.9021 - val_loss: 2085.9189\n",
      "Epoch 2181/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 2214.3901 - val_loss: 2085.4050\n",
      "Epoch 2182/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 2213.8784 - val_loss: 2084.8909\n",
      "Epoch 2183/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 2213.3669 - val_loss: 2084.3777\n",
      "Epoch 2184/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 2212.8555 - val_loss: 2083.8640\n",
      "Epoch 2185/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 2212.3445 - val_loss: 2083.3513\n",
      "Epoch 2186/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 2211.8337 - val_loss: 2082.8379\n",
      "Epoch 2187/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 2211.3228 - val_loss: 2082.3250\n",
      "Epoch 2188/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 2210.8123 - val_loss: 2081.8125\n",
      "Epoch 2189/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 2210.3018 - val_loss: 2081.2998\n",
      "Epoch 2190/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 2209.7913 - val_loss: 2080.7874\n",
      "Epoch 2191/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 2209.2815 - val_loss: 2080.2751\n",
      "Epoch 2192/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 2208.7715 - val_loss: 2079.7634\n",
      "Epoch 2193/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 2208.2617 - val_loss: 2079.2512\n",
      "Epoch 2194/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 2207.7524 - val_loss: 2078.7397\n",
      "Epoch 2195/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 2207.2429 - val_loss: 2078.2283\n",
      "Epoch 2196/100000\n",
      "11/11 [==============================] - 0s 611us/step - loss: 2206.7336 - val_loss: 2077.7168\n",
      "Epoch 2197/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 2206.2246 - val_loss: 2077.2053\n",
      "Epoch 2198/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2205.7156 - val_loss: 2076.6948\n",
      "Epoch 2199/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 2205.2068 - val_loss: 2076.1838\n",
      "Epoch 2200/100000\n",
      "11/11 [==============================] - 0s 900us/step - loss: 2204.6985 - val_loss: 2075.6733\n",
      "Epoch 2201/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2204.1904 - val_loss: 2075.1631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2202/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 2203.6819 - val_loss: 2074.6526\n",
      "Epoch 2203/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2203.1741 - val_loss: 2074.1426\n",
      "Epoch 2204/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2202.6663 - val_loss: 2073.6326\n",
      "Epoch 2205/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 2202.1587 - val_loss: 2073.1228\n",
      "Epoch 2206/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2201.6514 - val_loss: 2072.6133\n",
      "Epoch 2207/100000\n",
      "11/11 [==============================] - 0s 898us/step - loss: 2201.1438 - val_loss: 2072.1038\n",
      "Epoch 2208/100000\n",
      "11/11 [==============================] - 0s 793us/step - loss: 2200.6367 - val_loss: 2071.5945\n",
      "Epoch 2209/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 2200.1294 - val_loss: 2071.0857\n",
      "Epoch 2210/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 2199.6228 - val_loss: 2070.5764\n",
      "Epoch 2211/100000\n",
      "11/11 [==============================] - 0s 996us/step - loss: 2199.1162 - val_loss: 2070.0681\n",
      "Epoch 2212/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 2198.6096 - val_loss: 2069.5593\n",
      "Epoch 2213/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 2198.1038 - val_loss: 2069.0510\n",
      "Epoch 2214/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 2197.5977 - val_loss: 2068.5427\n",
      "Epoch 2215/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 2197.0918 - val_loss: 2068.0349\n",
      "Epoch 2216/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2196.5859 - val_loss: 2067.5269\n",
      "Epoch 2217/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 2196.0801 - val_loss: 2067.0193\n",
      "Epoch 2218/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 2195.5750 - val_loss: 2066.5117\n",
      "Epoch 2219/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 2195.0693 - val_loss: 2066.0042\n",
      "Epoch 2220/100000\n",
      "11/11 [==============================] - 0s 991us/step - loss: 2194.5645 - val_loss: 2065.4971\n",
      "Epoch 2221/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 2194.0596 - val_loss: 2064.9900\n",
      "Epoch 2222/100000\n",
      "11/11 [==============================] - 0s 785us/step - loss: 2193.5549 - val_loss: 2064.4834\n",
      "Epoch 2223/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2193.0503 - val_loss: 2063.9766\n",
      "Epoch 2224/100000\n",
      "11/11 [==============================] - 0s 927us/step - loss: 2192.5459 - val_loss: 2063.4697\n",
      "Epoch 2225/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2192.0420 - val_loss: 2062.9639\n",
      "Epoch 2226/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2191.5376 - val_loss: 2062.4575\n",
      "Epoch 2227/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2191.0339 - val_loss: 2061.9514\n",
      "Epoch 2228/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 2190.5300 - val_loss: 2061.4456\n",
      "Epoch 2229/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 2190.0266 - val_loss: 2060.9404\n",
      "Epoch 2230/100000\n",
      "11/11 [==============================] - 0s 678us/step - loss: 2189.5234 - val_loss: 2060.4346\n",
      "Epoch 2231/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2189.0200 - val_loss: 2059.9294\n",
      "Epoch 2232/100000\n",
      "11/11 [==============================] - 0s 827us/step - loss: 2188.5171 - val_loss: 2059.4241\n",
      "Epoch 2233/100000\n",
      "11/11 [==============================] - 0s 841us/step - loss: 2188.0139 - val_loss: 2058.9197\n",
      "Epoch 2234/100000\n",
      "11/11 [==============================] - 0s 723us/step - loss: 2187.5115 - val_loss: 2058.4146\n",
      "Epoch 2235/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 2187.0090 - val_loss: 2057.9099\n",
      "Epoch 2236/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 2186.5066 - val_loss: 2057.4053\n",
      "Epoch 2237/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 2186.0046 - val_loss: 2056.9014\n",
      "Epoch 2238/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 2185.5022 - val_loss: 2056.3970\n",
      "Epoch 2239/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 2185.0007 - val_loss: 2055.8931\n",
      "Epoch 2240/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 2184.4990 - val_loss: 2055.3892\n",
      "Epoch 2241/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 2183.9976 - val_loss: 2054.8857\n",
      "Epoch 2242/100000\n",
      "11/11 [==============================] - 0s 644us/step - loss: 2183.4961 - val_loss: 2054.3823\n",
      "Epoch 2243/100000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2182.9951 - val_loss: 2053.8789\n",
      "Epoch 2244/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 2182.4944 - val_loss: 2053.3760\n",
      "Epoch 2245/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2181.9932 - val_loss: 2052.8730\n",
      "Epoch 2246/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2181.4924 - val_loss: 2052.3701\n",
      "Epoch 2247/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 2180.9922 - val_loss: 2051.8677\n",
      "Epoch 2248/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 2180.4919 - val_loss: 2051.3652\n",
      "Epoch 2249/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 2179.9919 - val_loss: 2050.8630\n",
      "Epoch 2250/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 2179.4919 - val_loss: 2050.3611\n",
      "Epoch 2251/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 2178.9922 - val_loss: 2049.8591\n",
      "Epoch 2252/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2178.4924 - val_loss: 2049.3572\n",
      "Epoch 2253/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 2177.9927 - val_loss: 2048.8557\n",
      "Epoch 2254/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 2177.4934 - val_loss: 2048.3545\n",
      "Epoch 2255/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 2176.9941 - val_loss: 2047.8531\n",
      "Epoch 2256/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 2176.4954 - val_loss: 2047.3523\n",
      "Epoch 2257/100000\n",
      "11/11 [==============================] - 0s 943us/step - loss: 2175.9968 - val_loss: 2046.8512\n",
      "Epoch 2258/100000\n",
      "11/11 [==============================] - 0s 796us/step - loss: 2175.4983 - val_loss: 2046.3505\n",
      "Epoch 2259/100000\n",
      "11/11 [==============================] - 0s 777us/step - loss: 2174.9998 - val_loss: 2045.8500\n",
      "Epoch 2260/100000\n",
      "11/11 [==============================] - 0s 818us/step - loss: 2174.5012 - val_loss: 2045.3495\n",
      "Epoch 2261/100000\n",
      "11/11 [==============================] - 0s 695us/step - loss: 2174.0034 - val_loss: 2044.8496\n",
      "Epoch 2262/100000\n",
      "11/11 [==============================] - 0s 747us/step - loss: 2173.5051 - val_loss: 2044.3495\n",
      "Epoch 2263/100000\n",
      "11/11 [==============================] - 0s 608us/step - loss: 2173.0076 - val_loss: 2043.8495\n",
      "Epoch 2264/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 2172.5100 - val_loss: 2043.3500\n",
      "Epoch 2265/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2172.0125 - val_loss: 2042.8505\n",
      "Epoch 2266/100000\n",
      "11/11 [==============================] - 0s 978us/step - loss: 2171.5154 - val_loss: 2042.3508\n",
      "Epoch 2267/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 2171.0183 - val_loss: 2041.8517\n",
      "Epoch 2268/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 2170.5212 - val_loss: 2041.3528\n",
      "Epoch 2269/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2170.0244 - val_loss: 2040.8539\n",
      "Epoch 2270/100000\n",
      "11/11 [==============================] - 0s 631us/step - loss: 2169.5278 - val_loss: 2040.3551\n",
      "Epoch 2271/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 2169.0315 - val_loss: 2039.8566\n",
      "Epoch 2272/100000\n",
      "11/11 [==============================] - 0s 980us/step - loss: 2168.5354 - val_loss: 2039.3582\n",
      "Epoch 2273/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 2168.0393 - val_loss: 2038.8601\n",
      "Epoch 2274/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 2167.5435 - val_loss: 2038.3622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2275/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2167.0476 - val_loss: 2037.8644\n",
      "Epoch 2276/100000\n",
      "11/11 [==============================] - 0s 735us/step - loss: 2166.5518 - val_loss: 2037.3667\n",
      "Epoch 2277/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2166.0564 - val_loss: 2036.8693\n",
      "Epoch 2278/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2165.5615 - val_loss: 2036.3719\n",
      "Epoch 2279/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2165.0664 - val_loss: 2035.8746\n",
      "Epoch 2280/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 2164.5713 - val_loss: 2035.3777\n",
      "Epoch 2281/100000\n",
      "11/11 [==============================] - 0s 713us/step - loss: 2164.0767 - val_loss: 2034.8809\n",
      "Epoch 2282/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 2163.5823 - val_loss: 2034.3840\n",
      "Epoch 2283/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 2163.0876 - val_loss: 2033.8875\n",
      "Epoch 2284/100000\n",
      "11/11 [==============================] - 0s 791us/step - loss: 2162.5935 - val_loss: 2033.3914\n",
      "Epoch 2285/100000\n",
      "11/11 [==============================] - 0s 564us/step - loss: 2162.0996 - val_loss: 2032.8953\n",
      "Epoch 2286/100000\n",
      "11/11 [==============================] - 0s 648us/step - loss: 2161.6055 - val_loss: 2032.3993\n",
      "Epoch 2287/100000\n",
      "11/11 [==============================] - 0s 733us/step - loss: 2161.1116 - val_loss: 2031.9031\n",
      "Epoch 2288/100000\n",
      "11/11 [==============================] - 0s 630us/step - loss: 2160.6179 - val_loss: 2031.4077\n",
      "Epoch 2289/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2160.1248 - val_loss: 2030.9121\n",
      "Epoch 2290/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 2159.6316 - val_loss: 2030.4169\n",
      "Epoch 2291/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 2159.1384 - val_loss: 2029.9215\n",
      "Epoch 2292/100000\n",
      "11/11 [==============================] - 0s 636us/step - loss: 2158.6455 - val_loss: 2029.4266\n",
      "Epoch 2293/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2158.1526 - val_loss: 2028.9318\n",
      "Epoch 2294/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2157.6602 - val_loss: 2028.4371\n",
      "Epoch 2295/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2157.1677 - val_loss: 2027.9425\n",
      "Epoch 2296/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 2156.6755 - val_loss: 2027.4481\n",
      "Epoch 2297/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 2156.1836 - val_loss: 2026.9542\n",
      "Epoch 2298/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2155.6914 - val_loss: 2026.4602\n",
      "Epoch 2299/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2155.1997 - val_loss: 2025.9663\n",
      "Epoch 2300/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2154.7083 - val_loss: 2025.4725\n",
      "Epoch 2301/100000\n",
      "11/11 [==============================] - 0s 973us/step - loss: 2154.2168 - val_loss: 2024.9790\n",
      "Epoch 2302/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2153.7258 - val_loss: 2024.4858\n",
      "Epoch 2303/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2153.2346 - val_loss: 2023.9926\n",
      "Epoch 2304/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2152.7439 - val_loss: 2023.4995\n",
      "Epoch 2305/100000\n",
      "11/11 [==============================] - 0s 747us/step - loss: 2152.2529 - val_loss: 2023.0067\n",
      "Epoch 2306/100000\n",
      "11/11 [==============================] - 0s 812us/step - loss: 2151.7622 - val_loss: 2022.5142\n",
      "Epoch 2307/100000\n",
      "11/11 [==============================] - 0s 876us/step - loss: 2151.2720 - val_loss: 2022.0215\n",
      "Epoch 2308/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 2150.7820 - val_loss: 2021.5293\n",
      "Epoch 2309/100000\n",
      "11/11 [==============================] - 0s 675us/step - loss: 2150.2917 - val_loss: 2021.0372\n",
      "Epoch 2310/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 2149.8020 - val_loss: 2020.5450\n",
      "Epoch 2311/100000\n",
      "11/11 [==============================] - 0s 897us/step - loss: 2149.3123 - val_loss: 2020.0532\n",
      "Epoch 2312/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 2148.8228 - val_loss: 2019.5614\n",
      "Epoch 2313/100000\n",
      "11/11 [==============================] - 0s 620us/step - loss: 2148.3330 - val_loss: 2019.0702\n",
      "Epoch 2314/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2147.8440 - val_loss: 2018.5789\n",
      "Epoch 2315/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2147.3550 - val_loss: 2018.0879\n",
      "Epoch 2316/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 2146.8657 - val_loss: 2017.5966\n",
      "Epoch 2317/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 2146.3772 - val_loss: 2017.1058\n",
      "Epoch 2318/100000\n",
      "11/11 [==============================] - 0s 693us/step - loss: 2145.8889 - val_loss: 2016.6152\n",
      "Epoch 2319/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 2145.4001 - val_loss: 2016.1249\n",
      "Epoch 2320/100000\n",
      "11/11 [==============================] - 0s 623us/step - loss: 2144.9121 - val_loss: 2015.6346\n",
      "Epoch 2321/100000\n",
      "11/11 [==============================] - 0s 874us/step - loss: 2144.4241 - val_loss: 2015.1444\n",
      "Epoch 2322/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 2143.9360 - val_loss: 2014.6543\n",
      "Epoch 2323/100000\n",
      "11/11 [==============================] - 0s 640us/step - loss: 2143.4482 - val_loss: 2014.1642\n",
      "Epoch 2324/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 2142.9609 - val_loss: 2013.6747\n",
      "Epoch 2325/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 2142.4734 - val_loss: 2013.1854\n",
      "Epoch 2326/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 2141.9861 - val_loss: 2012.6957\n",
      "Epoch 2327/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2141.4990 - val_loss: 2012.2069\n",
      "Epoch 2328/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2141.0122 - val_loss: 2011.7180\n",
      "Epoch 2329/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 2140.5256 - val_loss: 2011.2290\n",
      "Epoch 2330/100000\n",
      "11/11 [==============================] - 0s 667us/step - loss: 2140.0388 - val_loss: 2010.7406\n",
      "Epoch 2331/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2139.5525 - val_loss: 2010.2518\n",
      "Epoch 2332/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2139.0662 - val_loss: 2009.7635\n",
      "Epoch 2333/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2138.5801 - val_loss: 2009.2755\n",
      "Epoch 2334/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2138.0940 - val_loss: 2008.7875\n",
      "Epoch 2335/100000\n",
      "11/11 [==============================] - 0s 810us/step - loss: 2137.6084 - val_loss: 2008.2996\n",
      "Epoch 2336/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 2137.1228 - val_loss: 2007.8116\n",
      "Epoch 2337/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 2136.6372 - val_loss: 2007.3243\n",
      "Epoch 2338/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 2136.1521 - val_loss: 2006.8370\n",
      "Epoch 2339/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2135.6670 - val_loss: 2006.3497\n",
      "Epoch 2340/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2135.1821 - val_loss: 2005.8628\n",
      "Epoch 2341/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 2134.6975 - val_loss: 2005.3759\n",
      "Epoch 2342/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 2134.2129 - val_loss: 2004.8892\n",
      "Epoch 2343/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2133.7283 - val_loss: 2004.4027\n",
      "Epoch 2344/100000\n",
      "11/11 [==============================] - 0s 918us/step - loss: 2133.2439 - val_loss: 2003.9164\n",
      "Epoch 2345/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 2132.7598 - val_loss: 2003.4301\n",
      "Epoch 2346/100000\n",
      "11/11 [==============================] - 0s 846us/step - loss: 2132.2761 - val_loss: 2002.9441\n",
      "Epoch 2347/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 2131.7922 - val_loss: 2002.4581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2348/100000\n",
      "11/11 [==============================] - 0s 791us/step - loss: 2131.3086 - val_loss: 2001.9725\n",
      "Epoch 2349/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 2130.8252 - val_loss: 2001.4871\n",
      "Epoch 2350/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 2130.3420 - val_loss: 2001.0015\n",
      "Epoch 2351/100000\n",
      "11/11 [==============================] - 0s 723us/step - loss: 2129.8591 - val_loss: 2000.5164\n",
      "Epoch 2352/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 2129.3757 - val_loss: 2000.0312\n",
      "Epoch 2353/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 2128.8933 - val_loss: 1999.5464\n",
      "Epoch 2354/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 2128.4104 - val_loss: 1999.0618\n",
      "Epoch 2355/100000\n",
      "11/11 [==============================] - 0s 599us/step - loss: 2127.9280 - val_loss: 1998.5773\n",
      "Epoch 2356/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 2127.4456 - val_loss: 1998.0927\n",
      "Epoch 2357/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 2126.9634 - val_loss: 1997.6089\n",
      "Epoch 2358/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 2126.4814 - val_loss: 1997.1245\n",
      "Epoch 2359/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 2125.9998 - val_loss: 1996.6406\n",
      "Epoch 2360/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 2125.5181 - val_loss: 1996.1571\n",
      "Epoch 2361/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 2125.0369 - val_loss: 1995.6733\n",
      "Epoch 2362/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 2124.5554 - val_loss: 1995.1898\n",
      "Epoch 2363/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 2124.0742 - val_loss: 1994.7067\n",
      "Epoch 2364/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 2123.5930 - val_loss: 1994.2239\n",
      "Epoch 2365/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 2123.1123 - val_loss: 1993.7407\n",
      "Epoch 2366/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 2122.6316 - val_loss: 1993.2582\n",
      "Epoch 2367/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 2122.1514 - val_loss: 1992.7753\n",
      "Epoch 2368/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 2121.6709 - val_loss: 1992.2928\n",
      "Epoch 2369/100000\n",
      "11/11 [==============================] - 0s 723us/step - loss: 2121.1907 - val_loss: 1991.8107\n",
      "Epoch 2370/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 2120.7107 - val_loss: 1991.3286\n",
      "Epoch 2371/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 2120.2307 - val_loss: 1990.8468\n",
      "Epoch 2372/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 2119.7512 - val_loss: 1990.3651\n",
      "Epoch 2373/100000\n",
      "11/11 [==============================] - 0s 725us/step - loss: 2119.2715 - val_loss: 1989.8833\n",
      "Epoch 2374/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 2118.7920 - val_loss: 1989.4019\n",
      "Epoch 2375/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 2118.3127 - val_loss: 1988.9207\n",
      "Epoch 2376/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 2117.8337 - val_loss: 1988.4396\n",
      "Epoch 2377/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 2117.3550 - val_loss: 1987.9583\n",
      "Epoch 2378/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 2116.8765 - val_loss: 1987.4777\n",
      "Epoch 2379/100000\n",
      "11/11 [==============================] - 0s 661us/step - loss: 2116.3982 - val_loss: 1986.9968\n",
      "Epoch 2380/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 2115.9194 - val_loss: 1986.5165\n",
      "Epoch 2381/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 2115.4412 - val_loss: 1986.0363\n",
      "Epoch 2382/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 2114.9631 - val_loss: 1985.5559\n",
      "Epoch 2383/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 2114.4851 - val_loss: 1985.0760\n",
      "Epoch 2384/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 2114.0076 - val_loss: 1984.5961\n",
      "Epoch 2385/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 2113.5298 - val_loss: 1984.1165\n",
      "Epoch 2386/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 2113.0525 - val_loss: 1983.6371\n",
      "Epoch 2387/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 2112.5752 - val_loss: 1983.1578\n",
      "Epoch 2388/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 2112.0984 - val_loss: 1982.6786\n",
      "Epoch 2389/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 2111.6213 - val_loss: 1982.1997\n",
      "Epoch 2390/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 2111.1443 - val_loss: 1981.7208\n",
      "Epoch 2391/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 2110.6680 - val_loss: 1981.2421\n",
      "Epoch 2392/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 2110.1917 - val_loss: 1980.7635\n",
      "Epoch 2393/100000\n",
      "11/11 [==============================] - 0s 940us/step - loss: 2109.7151 - val_loss: 1980.2850\n",
      "Epoch 2394/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 2109.2390 - val_loss: 1979.8068\n",
      "Epoch 2395/100000\n",
      "11/11 [==============================] - 0s 686us/step - loss: 2108.7632 - val_loss: 1979.3289\n",
      "Epoch 2396/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 2108.2874 - val_loss: 1978.8508\n",
      "Epoch 2397/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 2107.8115 - val_loss: 1978.3730\n",
      "Epoch 2398/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 2107.3362 - val_loss: 1977.8961\n",
      "Epoch 2399/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 2106.8611 - val_loss: 1977.4183\n",
      "Epoch 2400/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 2106.3857 - val_loss: 1976.9413\n",
      "Epoch 2401/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 2105.9109 - val_loss: 1976.4641\n",
      "Epoch 2402/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 2105.4358 - val_loss: 1975.9872\n",
      "Epoch 2403/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 2104.9614 - val_loss: 1975.5106\n",
      "Epoch 2404/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 2104.4868 - val_loss: 1975.0337\n",
      "Epoch 2405/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 2104.0125 - val_loss: 1974.5575\n",
      "Epoch 2406/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 2103.5381 - val_loss: 1974.0813\n",
      "Epoch 2407/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 2103.0645 - val_loss: 1973.6051\n",
      "Epoch 2408/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 2102.5903 - val_loss: 1973.1290\n",
      "Epoch 2409/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 2102.1169 - val_loss: 1972.6534\n",
      "Epoch 2410/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 2101.6431 - val_loss: 1972.1779\n",
      "Epoch 2411/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 2101.1697 - val_loss: 1971.7026\n",
      "Epoch 2412/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 2100.6965 - val_loss: 1971.2271\n",
      "Epoch 2413/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 2100.2236 - val_loss: 1970.7520\n",
      "Epoch 2414/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 2099.7507 - val_loss: 1970.2770\n",
      "Epoch 2415/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 2099.2778 - val_loss: 1969.8022\n",
      "Epoch 2416/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 2098.8052 - val_loss: 1969.3276\n",
      "Epoch 2417/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 2098.3330 - val_loss: 1968.8530\n",
      "Epoch 2418/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 2097.8608 - val_loss: 1968.3788\n",
      "Epoch 2419/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 2097.3889 - val_loss: 1967.9043\n",
      "Epoch 2420/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 2096.9170 - val_loss: 1967.4305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2421/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 2096.4451 - val_loss: 1966.9570\n",
      "Epoch 2422/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 2095.9734 - val_loss: 1966.4829\n",
      "Epoch 2423/100000\n",
      "11/11 [==============================] - 0s 630us/step - loss: 2095.5022 - val_loss: 1966.0098\n",
      "Epoch 2424/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 2095.0310 - val_loss: 1965.5366\n",
      "Epoch 2425/100000\n",
      "11/11 [==============================] - 0s 784us/step - loss: 2094.5596 - val_loss: 1965.0629\n",
      "Epoch 2426/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 2094.0884 - val_loss: 1964.5898\n",
      "Epoch 2427/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 2093.6179 - val_loss: 1964.1171\n",
      "Epoch 2428/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 2093.1472 - val_loss: 1963.6444\n",
      "Epoch 2429/100000\n",
      "11/11 [==============================] - 0s 628us/step - loss: 2092.6765 - val_loss: 1963.1719\n",
      "Epoch 2430/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 2092.2065 - val_loss: 1962.6996\n",
      "Epoch 2431/100000\n",
      "11/11 [==============================] - 0s 564us/step - loss: 2091.7361 - val_loss: 1962.2273\n",
      "Epoch 2432/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 2091.2659 - val_loss: 1961.7551\n",
      "Epoch 2433/100000\n",
      "11/11 [==============================] - 0s 742us/step - loss: 2090.7966 - val_loss: 1961.2832\n",
      "Epoch 2434/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 2090.3267 - val_loss: 1960.8116\n",
      "Epoch 2435/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 2089.8572 - val_loss: 1960.3400\n",
      "Epoch 2436/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 2089.3879 - val_loss: 1959.8687\n",
      "Epoch 2437/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 2088.9185 - val_loss: 1959.3973\n",
      "Epoch 2438/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 2088.4497 - val_loss: 1958.9263\n",
      "Epoch 2439/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 2087.9807 - val_loss: 1958.4554\n",
      "Epoch 2440/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 2087.5120 - val_loss: 1957.9844\n",
      "Epoch 2441/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 2087.0435 - val_loss: 1957.5138\n",
      "Epoch 2442/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 2086.5752 - val_loss: 1957.0433\n",
      "Epoch 2443/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 2086.1069 - val_loss: 1956.5731\n",
      "Epoch 2444/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 2085.6389 - val_loss: 1956.1030\n",
      "Epoch 2445/100000\n",
      "11/11 [==============================] - 0s 590us/step - loss: 2085.1709 - val_loss: 1955.6328\n",
      "Epoch 2446/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 2084.7031 - val_loss: 1955.1630\n",
      "Epoch 2447/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 2084.2354 - val_loss: 1954.6932\n",
      "Epoch 2448/100000\n",
      "11/11 [==============================] - 0s 703us/step - loss: 2083.7681 - val_loss: 1954.2241\n",
      "Epoch 2449/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 2083.3008 - val_loss: 1953.7546\n",
      "Epoch 2450/100000\n",
      "11/11 [==============================] - 0s 677us/step - loss: 2082.8337 - val_loss: 1953.2852\n",
      "Epoch 2451/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 2082.3667 - val_loss: 1952.8163\n",
      "Epoch 2452/100000\n",
      "11/11 [==============================] - 0s 633us/step - loss: 2081.8999 - val_loss: 1952.3475\n",
      "Epoch 2453/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 2081.4331 - val_loss: 1951.8785\n",
      "Epoch 2454/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 2080.9666 - val_loss: 1951.4098\n",
      "Epoch 2455/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 2080.5007 - val_loss: 1950.9415\n",
      "Epoch 2456/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 2080.0342 - val_loss: 1950.4735\n",
      "Epoch 2457/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 2079.5681 - val_loss: 1950.0055\n",
      "Epoch 2458/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 2079.1023 - val_loss: 1949.5375\n",
      "Epoch 2459/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 2078.6365 - val_loss: 1949.0698\n",
      "Epoch 2460/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 2078.1709 - val_loss: 1948.6019\n",
      "Epoch 2461/100000\n",
      "11/11 [==============================] - 0s 682us/step - loss: 2077.7056 - val_loss: 1948.1348\n",
      "Epoch 2462/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 2077.2405 - val_loss: 1947.6672\n",
      "Epoch 2463/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 2076.7756 - val_loss: 1947.2003\n",
      "Epoch 2464/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 2076.3108 - val_loss: 1946.7329\n",
      "Epoch 2465/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 2075.8457 - val_loss: 1946.2665\n",
      "Epoch 2466/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 2075.3811 - val_loss: 1945.7999\n",
      "Epoch 2467/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 2074.9167 - val_loss: 1945.3333\n",
      "Epoch 2468/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 2074.4526 - val_loss: 1944.8671\n",
      "Epoch 2469/100000\n",
      "11/11 [==============================] - 0s 640us/step - loss: 2073.9885 - val_loss: 1944.4009\n",
      "Epoch 2470/100000\n",
      "11/11 [==============================] - 0s 591us/step - loss: 2073.5244 - val_loss: 1943.9348\n",
      "Epoch 2471/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 2073.0608 - val_loss: 1943.4689\n",
      "Epoch 2472/100000\n",
      "11/11 [==============================] - 0s 659us/step - loss: 2072.5972 - val_loss: 1943.0032\n",
      "Epoch 2473/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 2072.1335 - val_loss: 1942.5376\n",
      "Epoch 2474/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 2071.6704 - val_loss: 1942.0723\n",
      "Epoch 2475/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 2071.2070 - val_loss: 1941.6073\n",
      "Epoch 2476/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 2070.7441 - val_loss: 1941.1418\n",
      "Epoch 2477/100000\n",
      "11/11 [==============================] - 0s 765us/step - loss: 2070.2815 - val_loss: 1940.6770\n",
      "Epoch 2478/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 2069.8186 - val_loss: 1940.2124\n",
      "Epoch 2479/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 2069.3562 - val_loss: 1939.7479\n",
      "Epoch 2480/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 2068.8938 - val_loss: 1939.2836\n",
      "Epoch 2481/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 2068.4316 - val_loss: 1938.8192\n",
      "Epoch 2482/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 2067.9697 - val_loss: 1938.3550\n",
      "Epoch 2483/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 2067.5078 - val_loss: 1937.8910\n",
      "Epoch 2484/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 2067.0459 - val_loss: 1937.4270\n",
      "Epoch 2485/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 2066.5842 - val_loss: 1936.9636\n",
      "Epoch 2486/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 2066.1228 - val_loss: 1936.5001\n",
      "Epoch 2487/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 2065.6619 - val_loss: 1936.0370\n",
      "Epoch 2488/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 2065.2004 - val_loss: 1935.5735\n",
      "Epoch 2489/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 2064.7397 - val_loss: 1935.1105\n",
      "Epoch 2490/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 2064.2791 - val_loss: 1934.6479\n",
      "Epoch 2491/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 2063.8181 - val_loss: 1934.1851\n",
      "Epoch 2492/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 2063.3577 - val_loss: 1933.7227\n",
      "Epoch 2493/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 2062.8972 - val_loss: 1933.2599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2494/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 2062.4373 - val_loss: 1932.7977\n",
      "Epoch 2495/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 2061.9768 - val_loss: 1932.3358\n",
      "Epoch 2496/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 2061.5173 - val_loss: 1931.8738\n",
      "Epoch 2497/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 2061.0576 - val_loss: 1931.4122\n",
      "Epoch 2498/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 2060.5981 - val_loss: 1930.9507\n",
      "Epoch 2499/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 2060.1389 - val_loss: 1930.4890\n",
      "Epoch 2500/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 2059.6794 - val_loss: 1930.0277\n",
      "Epoch 2501/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 2059.2205 - val_loss: 1929.5665\n",
      "Epoch 2502/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 2058.7615 - val_loss: 1929.1058\n",
      "Epoch 2503/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 2058.3027 - val_loss: 1928.6449\n",
      "Epoch 2504/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 2057.8440 - val_loss: 1928.1843\n",
      "Epoch 2505/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 2057.3857 - val_loss: 1927.7238\n",
      "Epoch 2506/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 2056.9275 - val_loss: 1927.2633\n",
      "Epoch 2507/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2056.4697 - val_loss: 1926.8032\n",
      "Epoch 2508/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 2056.0115 - val_loss: 1926.3433\n",
      "Epoch 2509/100000\n",
      "11/11 [==============================] - 0s 675us/step - loss: 2055.5537 - val_loss: 1925.8833\n",
      "Epoch 2510/100000\n",
      "11/11 [==============================] - 0s 758us/step - loss: 2055.0959 - val_loss: 1925.4235\n",
      "Epoch 2511/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 2054.6389 - val_loss: 1924.9644\n",
      "Epoch 2512/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2054.1812 - val_loss: 1924.5046\n",
      "Epoch 2513/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 2053.7241 - val_loss: 1924.0454\n",
      "Epoch 2514/100000\n",
      "11/11 [==============================] - 0s 819us/step - loss: 2053.2671 - val_loss: 1923.5864\n",
      "Epoch 2515/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 2052.8103 - val_loss: 1923.1273\n",
      "Epoch 2516/100000\n",
      "11/11 [==============================] - 0s 905us/step - loss: 2052.3535 - val_loss: 1922.6687\n",
      "Epoch 2517/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 2051.8967 - val_loss: 1922.2101\n",
      "Epoch 2518/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 2051.4404 - val_loss: 1921.7516\n",
      "Epoch 2519/100000\n",
      "11/11 [==============================] - 0s 594us/step - loss: 2050.9841 - val_loss: 1921.2933\n",
      "Epoch 2520/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 2050.5283 - val_loss: 1920.8352\n",
      "Epoch 2521/100000\n",
      "11/11 [==============================] - 0s 744us/step - loss: 2050.0720 - val_loss: 1920.3771\n",
      "Epoch 2522/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 2049.6165 - val_loss: 1919.9192\n",
      "Epoch 2523/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 2049.1609 - val_loss: 1919.4617\n",
      "Epoch 2524/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 2048.7053 - val_loss: 1919.0039\n",
      "Epoch 2525/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 2048.2498 - val_loss: 1918.5469\n",
      "Epoch 2526/100000\n",
      "11/11 [==============================] - 0s 669us/step - loss: 2047.7948 - val_loss: 1918.0895\n",
      "Epoch 2527/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 2047.3398 - val_loss: 1917.6324\n",
      "Epoch 2528/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 2046.8849 - val_loss: 1917.1754\n",
      "Epoch 2529/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 2046.4304 - val_loss: 1916.7188\n",
      "Epoch 2530/100000\n",
      "11/11 [==============================] - 0s 635us/step - loss: 2045.9758 - val_loss: 1916.2622\n",
      "Epoch 2531/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 2045.5211 - val_loss: 1915.8058\n",
      "Epoch 2532/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 2045.0673 - val_loss: 1915.3495\n",
      "Epoch 2533/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 2044.6133 - val_loss: 1914.8933\n",
      "Epoch 2534/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 2044.1593 - val_loss: 1914.4375\n",
      "Epoch 2535/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 2043.7054 - val_loss: 1913.9816\n",
      "Epoch 2536/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 2043.2520 - val_loss: 1913.5259\n",
      "Epoch 2537/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 2042.7985 - val_loss: 1913.0703\n",
      "Epoch 2538/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 2042.3453 - val_loss: 1912.6151\n",
      "Epoch 2539/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 2041.8921 - val_loss: 1912.1600\n",
      "Epoch 2540/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 2041.4391 - val_loss: 1911.7050\n",
      "Epoch 2541/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 2040.9863 - val_loss: 1911.2501\n",
      "Epoch 2542/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 2040.5336 - val_loss: 1910.7954\n",
      "Epoch 2543/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 2040.0812 - val_loss: 1910.3407\n",
      "Epoch 2544/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 2039.6289 - val_loss: 1909.8864\n",
      "Epoch 2545/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 2039.1769 - val_loss: 1909.4320\n",
      "Epoch 2546/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 2038.7245 - val_loss: 1908.9780\n",
      "Epoch 2547/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 2038.2726 - val_loss: 1908.5242\n",
      "Epoch 2548/100000\n",
      "11/11 [==============================] - 0s 614us/step - loss: 2037.8208 - val_loss: 1908.0702\n",
      "Epoch 2549/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 2037.3695 - val_loss: 1907.6167\n",
      "Epoch 2550/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 2036.9180 - val_loss: 1907.1630\n",
      "Epoch 2551/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 2036.4667 - val_loss: 1906.7098\n",
      "Epoch 2552/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 2036.0156 - val_loss: 1906.2567\n",
      "Epoch 2553/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 2035.5646 - val_loss: 1905.8038\n",
      "Epoch 2554/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 2035.1138 - val_loss: 1905.3511\n",
      "Epoch 2555/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 2034.6633 - val_loss: 1904.8983\n",
      "Epoch 2556/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 2034.2128 - val_loss: 1904.4457\n",
      "Epoch 2557/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 2033.7626 - val_loss: 1903.9933\n",
      "Epoch 2558/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 2033.3124 - val_loss: 1903.5410\n",
      "Epoch 2559/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 2032.8622 - val_loss: 1903.0890\n",
      "Epoch 2560/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 2032.4125 - val_loss: 1902.6371\n",
      "Epoch 2561/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 2031.9625 - val_loss: 1902.1854\n",
      "Epoch 2562/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 2031.5129 - val_loss: 1901.7336\n",
      "Epoch 2563/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 2031.0636 - val_loss: 1901.2823\n",
      "Epoch 2564/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 2030.6141 - val_loss: 1900.8308\n",
      "Epoch 2565/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 2030.1655 - val_loss: 1900.3796\n",
      "Epoch 2566/100000\n",
      "11/11 [==============================] - 0s 747us/step - loss: 2029.7163 - val_loss: 1899.9288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2567/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 2029.2675 - val_loss: 1899.4780\n",
      "Epoch 2568/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 2028.8188 - val_loss: 1899.0273\n",
      "Epoch 2569/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 2028.3704 - val_loss: 1898.5765\n",
      "Epoch 2570/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 2027.9220 - val_loss: 1898.1265\n",
      "Epoch 2571/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 2027.4739 - val_loss: 1897.6761\n",
      "Epoch 2572/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 2027.0259 - val_loss: 1897.2261\n",
      "Epoch 2573/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 2026.5778 - val_loss: 1896.7761\n",
      "Epoch 2574/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 2026.1301 - val_loss: 1896.3262\n",
      "Epoch 2575/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 2025.6829 - val_loss: 1895.8768\n",
      "Epoch 2576/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 2025.2355 - val_loss: 1895.4272\n",
      "Epoch 2577/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 2024.7880 - val_loss: 1894.9780\n",
      "Epoch 2578/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 2024.3409 - val_loss: 1894.5288\n",
      "Epoch 2579/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 2023.8942 - val_loss: 1894.0800\n",
      "Epoch 2580/100000\n",
      "11/11 [==============================] - 0s 739us/step - loss: 2023.4471 - val_loss: 1893.6309\n",
      "Epoch 2581/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 2023.0007 - val_loss: 1893.1820\n",
      "Epoch 2582/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 2022.5540 - val_loss: 1892.7336\n",
      "Epoch 2583/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 2022.1079 - val_loss: 1892.2855\n",
      "Epoch 2584/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 2021.6617 - val_loss: 1891.8374\n",
      "Epoch 2585/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 2021.2157 - val_loss: 1891.3890\n",
      "Epoch 2586/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 2020.7697 - val_loss: 1890.9413\n",
      "Epoch 2587/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 2020.3241 - val_loss: 1890.4933\n",
      "Epoch 2588/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 2019.8785 - val_loss: 1890.0458\n",
      "Epoch 2589/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 2019.4332 - val_loss: 1889.5980\n",
      "Epoch 2590/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 2018.9879 - val_loss: 1889.1511\n",
      "Epoch 2591/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 2018.5426 - val_loss: 1888.7039\n",
      "Epoch 2592/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 2018.0977 - val_loss: 1888.2570\n",
      "Epoch 2593/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 2017.6531 - val_loss: 1887.8101\n",
      "Epoch 2594/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 2017.2085 - val_loss: 1887.3633\n",
      "Epoch 2595/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 2016.7638 - val_loss: 1886.9167\n",
      "Epoch 2596/100000\n",
      "11/11 [==============================] - 0s 667us/step - loss: 2016.3195 - val_loss: 1886.4703\n",
      "Epoch 2597/100000\n",
      "11/11 [==============================] - 0s 696us/step - loss: 2015.8754 - val_loss: 1886.0242\n",
      "Epoch 2598/100000\n",
      "11/11 [==============================] - 0s 618us/step - loss: 2015.4313 - val_loss: 1885.5780\n",
      "Epoch 2599/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 2014.9872 - val_loss: 1885.1321\n",
      "Epoch 2600/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 2014.5437 - val_loss: 1884.6864\n",
      "Epoch 2601/100000\n",
      "11/11 [==============================] - 0s 740us/step - loss: 2014.1003 - val_loss: 1884.2407\n",
      "Epoch 2602/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 2013.6566 - val_loss: 1883.7950\n",
      "Epoch 2603/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 2013.2133 - val_loss: 1883.3501\n",
      "Epoch 2604/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 2012.7704 - val_loss: 1882.9048\n",
      "Epoch 2605/100000\n",
      "11/11 [==============================] - 0s 821us/step - loss: 2012.3274 - val_loss: 1882.4597\n",
      "Epoch 2606/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 2011.8846 - val_loss: 1882.0151\n",
      "Epoch 2607/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 2011.4419 - val_loss: 1881.5702\n",
      "Epoch 2608/100000\n",
      "11/11 [==============================] - 0s 677us/step - loss: 2010.9993 - val_loss: 1881.1257\n",
      "Epoch 2609/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 2010.5570 - val_loss: 1880.6813\n",
      "Epoch 2610/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 2010.1149 - val_loss: 1880.2371\n",
      "Epoch 2611/100000\n",
      "11/11 [==============================] - 0s 615us/step - loss: 2009.6727 - val_loss: 1879.7930\n",
      "Epoch 2612/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2009.2308 - val_loss: 1879.3491\n",
      "Epoch 2613/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 2008.7891 - val_loss: 1878.9050\n",
      "Epoch 2614/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2008.3473 - val_loss: 1878.4614\n",
      "Epoch 2615/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2007.9062 - val_loss: 1878.0181\n",
      "Epoch 2616/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2007.4647 - val_loss: 1877.5746\n",
      "Epoch 2617/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2007.0236 - val_loss: 1877.1313\n",
      "Epoch 2618/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2006.5825 - val_loss: 1876.6886\n",
      "Epoch 2619/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2006.1421 - val_loss: 1876.2456\n",
      "Epoch 2620/100000\n",
      "11/11 [==============================] - 0s 754us/step - loss: 2005.7010 - val_loss: 1875.8027\n",
      "Epoch 2621/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 2005.2605 - val_loss: 1875.3602\n",
      "Epoch 2622/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 2004.8202 - val_loss: 1874.9178\n",
      "Epoch 2623/100000\n",
      "11/11 [==============================] - 0s 961us/step - loss: 2004.3800 - val_loss: 1874.4757\n",
      "Epoch 2624/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2003.9398 - val_loss: 1874.0336\n",
      "Epoch 2625/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 2003.5000 - val_loss: 1873.5918\n",
      "Epoch 2626/100000\n",
      "11/11 [==============================] - 0s 893us/step - loss: 2003.0604 - val_loss: 1873.1499\n",
      "Epoch 2627/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2002.6207 - val_loss: 1872.7081\n",
      "Epoch 2628/100000\n",
      "11/11 [==============================] - 0s 981us/step - loss: 2002.1813 - val_loss: 1872.2665\n",
      "Epoch 2629/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2001.7421 - val_loss: 1871.8254\n",
      "Epoch 2630/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2001.3026 - val_loss: 1871.3840\n",
      "Epoch 2631/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2000.8636 - val_loss: 1870.9429\n",
      "Epoch 2632/100000\n",
      "11/11 [==============================] - 0s 693us/step - loss: 2000.4249 - val_loss: 1870.5020\n",
      "Epoch 2633/100000\n",
      "11/11 [==============================] - 0s 630us/step - loss: 1999.9862 - val_loss: 1870.0614\n",
      "Epoch 2634/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1999.5474 - val_loss: 1869.6206\n",
      "Epoch 2635/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 1999.1093 - val_loss: 1869.1802\n",
      "Epoch 2636/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1998.6708 - val_loss: 1868.7401\n",
      "Epoch 2637/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1998.2329 - val_loss: 1868.2999\n",
      "Epoch 2638/100000\n",
      "11/11 [==============================] - 0s 885us/step - loss: 1997.7948 - val_loss: 1867.8599\n",
      "Epoch 2639/100000\n",
      "11/11 [==============================] - 0s 647us/step - loss: 1997.3573 - val_loss: 1867.4200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2640/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1996.9196 - val_loss: 1866.9803\n",
      "Epoch 2641/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1996.4819 - val_loss: 1866.5409\n",
      "Epoch 2642/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 1996.0446 - val_loss: 1866.1014\n",
      "Epoch 2643/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 1995.6074 - val_loss: 1865.6622\n",
      "Epoch 2644/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1995.1703 - val_loss: 1865.2230\n",
      "Epoch 2645/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 1994.7333 - val_loss: 1864.7841\n",
      "Epoch 2646/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1994.2969 - val_loss: 1864.3453\n",
      "Epoch 2647/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1993.8601 - val_loss: 1863.9066\n",
      "Epoch 2648/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 1993.4238 - val_loss: 1863.4684\n",
      "Epoch 2649/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 1992.9875 - val_loss: 1863.0300\n",
      "Epoch 2650/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1992.5513 - val_loss: 1862.5919\n",
      "Epoch 2651/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 1992.1152 - val_loss: 1862.1538\n",
      "Epoch 2652/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 1991.6797 - val_loss: 1861.7159\n",
      "Epoch 2653/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 1991.2437 - val_loss: 1861.2781\n",
      "Epoch 2654/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 1990.8085 - val_loss: 1860.8406\n",
      "Epoch 2655/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 1990.3730 - val_loss: 1860.4031\n",
      "Epoch 2656/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 1989.9376 - val_loss: 1859.9661\n",
      "Epoch 2657/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1989.5027 - val_loss: 1859.5289\n",
      "Epoch 2658/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 1989.0679 - val_loss: 1859.0919\n",
      "Epoch 2659/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1988.6332 - val_loss: 1858.6548\n",
      "Epoch 2660/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1988.1984 - val_loss: 1858.2186\n",
      "Epoch 2661/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 1987.7640 - val_loss: 1857.7817\n",
      "Epoch 2662/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1987.3296 - val_loss: 1857.3456\n",
      "Epoch 2663/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1986.8956 - val_loss: 1856.9094\n",
      "Epoch 2664/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1986.4614 - val_loss: 1856.4735\n",
      "Epoch 2665/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 1986.0275 - val_loss: 1856.0376\n",
      "Epoch 2666/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1985.5938 - val_loss: 1855.6017\n",
      "Epoch 2667/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1985.1602 - val_loss: 1855.1660\n",
      "Epoch 2668/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 1984.7266 - val_loss: 1854.7305\n",
      "Epoch 2669/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1984.2935 - val_loss: 1854.2953\n",
      "Epoch 2670/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 1983.8605 - val_loss: 1853.8601\n",
      "Epoch 2671/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 1983.4274 - val_loss: 1853.4253\n",
      "Epoch 2672/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 1982.9946 - val_loss: 1852.9901\n",
      "Epoch 2673/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 1982.5620 - val_loss: 1852.5555\n",
      "Epoch 2674/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 1982.1293 - val_loss: 1852.1210\n",
      "Epoch 2675/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1981.6969 - val_loss: 1851.6866\n",
      "Epoch 2676/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 1981.2648 - val_loss: 1851.2521\n",
      "Epoch 2677/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 1980.8328 - val_loss: 1850.8182\n",
      "Epoch 2678/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1980.4008 - val_loss: 1850.3843\n",
      "Epoch 2679/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 1979.9689 - val_loss: 1849.9504\n",
      "Epoch 2680/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 1979.5372 - val_loss: 1849.5167\n",
      "Epoch 2681/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 1979.1058 - val_loss: 1849.0831\n",
      "Epoch 2682/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 1978.6746 - val_loss: 1848.6497\n",
      "Epoch 2683/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1978.2430 - val_loss: 1848.2167\n",
      "Epoch 2684/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 1977.8125 - val_loss: 1847.7837\n",
      "Epoch 2685/100000\n",
      "11/11 [==============================] - 0s 604us/step - loss: 1977.3813 - val_loss: 1847.3507\n",
      "Epoch 2686/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1976.9507 - val_loss: 1846.9180\n",
      "Epoch 2687/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1976.5203 - val_loss: 1846.4852\n",
      "Epoch 2688/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1976.0897 - val_loss: 1846.0529\n",
      "Epoch 2689/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1975.6593 - val_loss: 1845.6206\n",
      "Epoch 2690/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 1975.2292 - val_loss: 1845.1882\n",
      "Epoch 2691/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 1974.7996 - val_loss: 1844.7563\n",
      "Epoch 2692/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1974.3695 - val_loss: 1844.3243\n",
      "Epoch 2693/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 1973.9399 - val_loss: 1843.8927\n",
      "Epoch 2694/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1973.5105 - val_loss: 1843.4613\n",
      "Epoch 2695/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 1973.0809 - val_loss: 1843.0297\n",
      "Epoch 2696/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 1972.6516 - val_loss: 1842.5985\n",
      "Epoch 2697/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 1972.2225 - val_loss: 1842.1675\n",
      "Epoch 2698/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 1971.7937 - val_loss: 1841.7365\n",
      "Epoch 2699/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1971.3651 - val_loss: 1841.3058\n",
      "Epoch 2700/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1970.9363 - val_loss: 1840.8751\n",
      "Epoch 2701/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1970.5078 - val_loss: 1840.4446\n",
      "Epoch 2702/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1970.0793 - val_loss: 1840.0142\n",
      "Epoch 2703/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 1969.6512 - val_loss: 1839.5840\n",
      "Epoch 2704/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 1969.2231 - val_loss: 1839.1539\n",
      "Epoch 2705/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 1968.7954 - val_loss: 1838.7239\n",
      "Epoch 2706/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1968.3676 - val_loss: 1838.2941\n",
      "Epoch 2707/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1967.9399 - val_loss: 1837.8645\n",
      "Epoch 2708/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 1967.5128 - val_loss: 1837.4352\n",
      "Epoch 2709/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1967.0854 - val_loss: 1837.0059\n",
      "Epoch 2710/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1966.6581 - val_loss: 1836.5763\n",
      "Epoch 2711/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1966.2310 - val_loss: 1836.1476\n",
      "Epoch 2712/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1965.8043 - val_loss: 1835.7186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2713/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1965.3774 - val_loss: 1835.2898\n",
      "Epoch 2714/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 1964.9512 - val_loss: 1834.8613\n",
      "Epoch 2715/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 1964.5247 - val_loss: 1834.4331\n",
      "Epoch 2716/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1964.0984 - val_loss: 1834.0044\n",
      "Epoch 2717/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 1963.6720 - val_loss: 1833.5762\n",
      "Epoch 2718/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 1963.2461 - val_loss: 1833.1484\n",
      "Epoch 2719/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1962.8203 - val_loss: 1832.7206\n",
      "Epoch 2720/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 1962.3947 - val_loss: 1832.2928\n",
      "Epoch 2721/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1961.9692 - val_loss: 1831.8654\n",
      "Epoch 2722/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1961.5438 - val_loss: 1831.4380\n",
      "Epoch 2723/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1961.1188 - val_loss: 1831.0106\n",
      "Epoch 2724/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1960.6935 - val_loss: 1830.5835\n",
      "Epoch 2725/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1960.2684 - val_loss: 1830.1566\n",
      "Epoch 2726/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 1959.8439 - val_loss: 1829.7297\n",
      "Epoch 2727/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1959.4192 - val_loss: 1829.3032\n",
      "Epoch 2728/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1958.9946 - val_loss: 1828.8766\n",
      "Epoch 2729/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1958.5704 - val_loss: 1828.4503\n",
      "Epoch 2730/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 1958.1461 - val_loss: 1828.0242\n",
      "Epoch 2731/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 1957.7222 - val_loss: 1827.5980\n",
      "Epoch 2732/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1957.2983 - val_loss: 1827.1720\n",
      "Epoch 2733/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 1956.8745 - val_loss: 1826.7462\n",
      "Epoch 2734/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1956.4510 - val_loss: 1826.3207\n",
      "Epoch 2735/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1956.0275 - val_loss: 1825.8953\n",
      "Epoch 2736/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1955.6042 - val_loss: 1825.4700\n",
      "Epoch 2737/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 1955.1812 - val_loss: 1825.0448\n",
      "Epoch 2738/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 1954.7582 - val_loss: 1824.6199\n",
      "Epoch 2739/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 1954.3352 - val_loss: 1824.1948\n",
      "Epoch 2740/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1953.9126 - val_loss: 1823.7699\n",
      "Epoch 2741/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1953.4901 - val_loss: 1823.3457\n",
      "Epoch 2742/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1953.0676 - val_loss: 1822.9211\n",
      "Epoch 2743/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1952.6454 - val_loss: 1822.4968\n",
      "Epoch 2744/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1952.2231 - val_loss: 1822.0726\n",
      "Epoch 2745/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1951.8013 - val_loss: 1821.6486\n",
      "Epoch 2746/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1951.3794 - val_loss: 1821.2247\n",
      "Epoch 2747/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 1950.9578 - val_loss: 1820.8011\n",
      "Epoch 2748/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 1950.5363 - val_loss: 1820.3774\n",
      "Epoch 2749/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1950.1147 - val_loss: 1819.9542\n",
      "Epoch 2750/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1949.6935 - val_loss: 1819.5309\n",
      "Epoch 2751/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 1949.2723 - val_loss: 1819.1078\n",
      "Epoch 2752/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1948.8517 - val_loss: 1818.6848\n",
      "Epoch 2753/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1948.4305 - val_loss: 1818.2621\n",
      "Epoch 2754/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 1948.0103 - val_loss: 1817.8394\n",
      "Epoch 2755/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1947.5897 - val_loss: 1817.4169\n",
      "Epoch 2756/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1947.1694 - val_loss: 1816.9945\n",
      "Epoch 2757/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 1946.7489 - val_loss: 1816.5723\n",
      "Epoch 2758/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1946.3290 - val_loss: 1816.1503\n",
      "Epoch 2759/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1945.9091 - val_loss: 1815.7284\n",
      "Epoch 2760/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1945.4894 - val_loss: 1815.3065\n",
      "Epoch 2761/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1945.0698 - val_loss: 1814.8848\n",
      "Epoch 2762/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1944.6504 - val_loss: 1814.4630\n",
      "Epoch 2763/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 1944.2310 - val_loss: 1814.0419\n",
      "Epoch 2764/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1943.8116 - val_loss: 1813.6207\n",
      "Epoch 2765/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1943.3929 - val_loss: 1813.1997\n",
      "Epoch 2766/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1942.9739 - val_loss: 1812.7788\n",
      "Epoch 2767/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1942.5552 - val_loss: 1812.3582\n",
      "Epoch 2768/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1942.1366 - val_loss: 1811.9375\n",
      "Epoch 2769/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 1941.7180 - val_loss: 1811.5171\n",
      "Epoch 2770/100000\n",
      "11/11 [==============================] - 0s 661us/step - loss: 1941.2999 - val_loss: 1811.0969\n",
      "Epoch 2771/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 1940.8820 - val_loss: 1810.6765\n",
      "Epoch 2772/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1940.4637 - val_loss: 1810.2567\n",
      "Epoch 2773/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1940.0458 - val_loss: 1809.8367\n",
      "Epoch 2774/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1939.6282 - val_loss: 1809.4171\n",
      "Epoch 2775/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1939.2106 - val_loss: 1808.9973\n",
      "Epoch 2776/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 1938.7933 - val_loss: 1808.5780\n",
      "Epoch 2777/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1938.3759 - val_loss: 1808.1587\n",
      "Epoch 2778/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 1937.9589 - val_loss: 1807.7394\n",
      "Epoch 2779/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 1937.5419 - val_loss: 1807.3207\n",
      "Epoch 2780/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1937.1250 - val_loss: 1806.9016\n",
      "Epoch 2781/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1936.7085 - val_loss: 1806.4828\n",
      "Epoch 2782/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 1936.2919 - val_loss: 1806.0643\n",
      "Epoch 2783/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 1935.8754 - val_loss: 1805.6460\n",
      "Epoch 2784/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1935.4591 - val_loss: 1805.2278\n",
      "Epoch 2785/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 1935.0431 - val_loss: 1804.8097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2786/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1934.6271 - val_loss: 1804.3917\n",
      "Epoch 2787/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1934.2113 - val_loss: 1803.9738\n",
      "Epoch 2788/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1933.7957 - val_loss: 1803.5562\n",
      "Epoch 2789/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 1933.3800 - val_loss: 1803.1385\n",
      "Epoch 2790/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1932.9648 - val_loss: 1802.7212\n",
      "Epoch 2791/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1932.5497 - val_loss: 1802.3040\n",
      "Epoch 2792/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 1932.1344 - val_loss: 1801.8868\n",
      "Epoch 2793/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1931.7195 - val_loss: 1801.4700\n",
      "Epoch 2794/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 1931.3047 - val_loss: 1801.0532\n",
      "Epoch 2795/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1930.8901 - val_loss: 1800.6364\n",
      "Epoch 2796/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1930.4755 - val_loss: 1800.2200\n",
      "Epoch 2797/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1930.0613 - val_loss: 1799.8036\n",
      "Epoch 2798/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 1929.6469 - val_loss: 1799.3875\n",
      "Epoch 2799/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1929.2329 - val_loss: 1798.9714\n",
      "Epoch 2800/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1928.8191 - val_loss: 1798.5554\n",
      "Epoch 2801/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1928.4054 - val_loss: 1798.1398\n",
      "Epoch 2802/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 1927.9918 - val_loss: 1797.7241\n",
      "Epoch 2803/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1927.5780 - val_loss: 1797.3086\n",
      "Epoch 2804/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 1927.1652 - val_loss: 1796.8933\n",
      "Epoch 2805/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1926.7516 - val_loss: 1796.4780\n",
      "Epoch 2806/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 1926.3387 - val_loss: 1796.0629\n",
      "Epoch 2807/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 1925.9258 - val_loss: 1795.6481\n",
      "Epoch 2808/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 1925.5129 - val_loss: 1795.2333\n",
      "Epoch 2809/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1925.1003 - val_loss: 1794.8185\n",
      "Epoch 2810/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 1924.6880 - val_loss: 1794.4042\n",
      "Epoch 2811/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1924.2754 - val_loss: 1793.9897\n",
      "Epoch 2812/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1923.8634 - val_loss: 1793.5757\n",
      "Epoch 2813/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 1923.4512 - val_loss: 1793.1616\n",
      "Epoch 2814/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 1923.0398 - val_loss: 1792.7476\n",
      "Epoch 2815/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1922.6277 - val_loss: 1792.3339\n",
      "Epoch 2816/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 1922.2163 - val_loss: 1791.9203\n",
      "Epoch 2817/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 1921.8048 - val_loss: 1791.5067\n",
      "Epoch 2818/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1921.3933 - val_loss: 1791.0934\n",
      "Epoch 2819/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 1920.9823 - val_loss: 1790.6802\n",
      "Epoch 2820/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 1920.5714 - val_loss: 1790.2675\n",
      "Epoch 2821/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 1920.1603 - val_loss: 1789.8542\n",
      "Epoch 2822/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1919.7496 - val_loss: 1789.4415\n",
      "Epoch 2823/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 1919.3390 - val_loss: 1789.0289\n",
      "Epoch 2824/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 1918.9286 - val_loss: 1788.6167\n",
      "Epoch 2825/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 1918.5181 - val_loss: 1788.2043\n",
      "Epoch 2826/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 1918.1083 - val_loss: 1787.7921\n",
      "Epoch 2827/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 1917.6981 - val_loss: 1787.3800\n",
      "Epoch 2828/100000\n",
      "11/11 [==============================] - 0s 735us/step - loss: 1917.2882 - val_loss: 1786.9683\n",
      "Epoch 2829/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1916.8785 - val_loss: 1786.5563\n",
      "Epoch 2830/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 1916.4691 - val_loss: 1786.1449\n",
      "Epoch 2831/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1916.0597 - val_loss: 1785.7333\n",
      "Epoch 2832/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 1915.6504 - val_loss: 1785.3221\n",
      "Epoch 2833/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1915.2413 - val_loss: 1784.9110\n",
      "Epoch 2834/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 1914.8322 - val_loss: 1784.5000\n",
      "Epoch 2835/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 1914.4233 - val_loss: 1784.0891\n",
      "Epoch 2836/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 1914.0145 - val_loss: 1783.6786\n",
      "Epoch 2837/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 1913.6060 - val_loss: 1783.2677\n",
      "Epoch 2838/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1913.1976 - val_loss: 1782.8575\n",
      "Epoch 2839/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 1912.7894 - val_loss: 1782.4473\n",
      "Epoch 2840/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1912.3810 - val_loss: 1782.0370\n",
      "Epoch 2841/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1911.9731 - val_loss: 1781.6271\n",
      "Epoch 2842/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1911.5653 - val_loss: 1781.2172\n",
      "Epoch 2843/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1911.1577 - val_loss: 1780.8077\n",
      "Epoch 2844/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 1910.7501 - val_loss: 1780.3977\n",
      "Epoch 2845/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 1910.3427 - val_loss: 1779.9884\n",
      "Epoch 2846/100000\n",
      "11/11 [==============================] - 0s 622us/step - loss: 1909.9357 - val_loss: 1779.5792\n",
      "Epoch 2847/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1909.5282 - val_loss: 1779.1700\n",
      "Epoch 2848/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1909.1215 - val_loss: 1778.7610\n",
      "Epoch 2849/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 1908.7145 - val_loss: 1778.3523\n",
      "Epoch 2850/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 1908.3079 - val_loss: 1777.9435\n",
      "Epoch 2851/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1907.9012 - val_loss: 1777.5350\n",
      "Epoch 2852/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 1907.4950 - val_loss: 1777.1268\n",
      "Epoch 2853/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1907.0887 - val_loss: 1776.7184\n",
      "Epoch 2854/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1906.6827 - val_loss: 1776.3104\n",
      "Epoch 2855/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 1906.2766 - val_loss: 1775.9023\n",
      "Epoch 2856/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 1905.8707 - val_loss: 1775.4945\n",
      "Epoch 2857/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 1905.4650 - val_loss: 1775.0867\n",
      "Epoch 2858/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 1905.0597 - val_loss: 1774.6793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2859/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 1904.6543 - val_loss: 1774.2719\n",
      "Epoch 2860/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1904.2489 - val_loss: 1773.8645\n",
      "Epoch 2861/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 1903.8438 - val_loss: 1773.4574\n",
      "Epoch 2862/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1903.4391 - val_loss: 1773.0507\n",
      "Epoch 2863/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1903.0341 - val_loss: 1772.6437\n",
      "Epoch 2864/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1902.6293 - val_loss: 1772.2368\n",
      "Epoch 2865/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1902.2250 - val_loss: 1771.8304\n",
      "Epoch 2866/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1901.8204 - val_loss: 1771.4238\n",
      "Epoch 2867/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1901.4161 - val_loss: 1771.0179\n",
      "Epoch 2868/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1901.0121 - val_loss: 1770.6115\n",
      "Epoch 2869/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1900.6083 - val_loss: 1770.2056\n",
      "Epoch 2870/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1900.2046 - val_loss: 1769.7999\n",
      "Epoch 2871/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 1899.8008 - val_loss: 1769.3942\n",
      "Epoch 2872/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 1899.3972 - val_loss: 1768.9886\n",
      "Epoch 2873/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 1898.9937 - val_loss: 1768.5833\n",
      "Epoch 2874/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1898.5903 - val_loss: 1768.1779\n",
      "Epoch 2875/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1898.1875 - val_loss: 1767.7729\n",
      "Epoch 2876/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 1897.7844 - val_loss: 1767.3679\n",
      "Epoch 2877/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1897.3817 - val_loss: 1766.9630\n",
      "Epoch 2878/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 1896.9789 - val_loss: 1766.5585\n",
      "Epoch 2879/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 1896.5763 - val_loss: 1766.1542\n",
      "Epoch 2880/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 1896.1742 - val_loss: 1765.7496\n",
      "Epoch 2881/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 1895.7716 - val_loss: 1765.3452\n",
      "Epoch 2882/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1895.3696 - val_loss: 1764.9410\n",
      "Epoch 2883/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1894.9675 - val_loss: 1764.5371\n",
      "Epoch 2884/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 1894.5660 - val_loss: 1764.1333\n",
      "Epoch 2885/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 1894.1641 - val_loss: 1763.7296\n",
      "Epoch 2886/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1893.7626 - val_loss: 1763.3262\n",
      "Epoch 2887/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1893.3613 - val_loss: 1762.9226\n",
      "Epoch 2888/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 1892.9601 - val_loss: 1762.5194\n",
      "Epoch 2889/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 1892.5586 - val_loss: 1762.1165\n",
      "Epoch 2890/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 1892.1578 - val_loss: 1761.7133\n",
      "Epoch 2891/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 1891.7571 - val_loss: 1761.3107\n",
      "Epoch 2892/100000\n",
      "11/11 [==============================] - 0s 770us/step - loss: 1891.3563 - val_loss: 1760.9078\n",
      "Epoch 2893/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 1890.9558 - val_loss: 1760.5055\n",
      "Epoch 2894/100000\n",
      "11/11 [==============================] - 0s 564us/step - loss: 1890.5558 - val_loss: 1760.1030\n",
      "Epoch 2895/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1890.1552 - val_loss: 1759.7007\n",
      "Epoch 2896/100000\n",
      "11/11 [==============================] - 0s 695us/step - loss: 1889.7550 - val_loss: 1759.2987\n",
      "Epoch 2897/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1889.3555 - val_loss: 1758.8966\n",
      "Epoch 2898/100000\n",
      "11/11 [==============================] - 0s 608us/step - loss: 1888.9556 - val_loss: 1758.4949\n",
      "Epoch 2899/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1888.5558 - val_loss: 1758.0930\n",
      "Epoch 2900/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1888.1561 - val_loss: 1757.6918\n",
      "Epoch 2901/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 1887.7567 - val_loss: 1757.2902\n",
      "Epoch 2902/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 1887.3575 - val_loss: 1756.8888\n",
      "Epoch 2903/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 1886.9581 - val_loss: 1756.4878\n",
      "Epoch 2904/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 1886.5593 - val_loss: 1756.0868\n",
      "Epoch 2905/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 1886.1605 - val_loss: 1755.6860\n",
      "Epoch 2906/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 1885.7621 - val_loss: 1755.2852\n",
      "Epoch 2907/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1885.3633 - val_loss: 1754.8846\n",
      "Epoch 2908/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1884.9648 - val_loss: 1754.4843\n",
      "Epoch 2909/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 1884.5665 - val_loss: 1754.0841\n",
      "Epoch 2910/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 1884.1685 - val_loss: 1753.6841\n",
      "Epoch 2911/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 1883.7704 - val_loss: 1753.2839\n",
      "Epoch 2912/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1883.3726 - val_loss: 1752.8840\n",
      "Epoch 2913/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1882.9750 - val_loss: 1752.4844\n",
      "Epoch 2914/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1882.5774 - val_loss: 1752.0848\n",
      "Epoch 2915/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 1882.1798 - val_loss: 1751.6854\n",
      "Epoch 2916/100000\n",
      "11/11 [==============================] - 0s 728us/step - loss: 1881.7827 - val_loss: 1751.2863\n",
      "Epoch 2917/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 1881.3856 - val_loss: 1750.8872\n",
      "Epoch 2918/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 1880.9886 - val_loss: 1750.4882\n",
      "Epoch 2919/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1880.5918 - val_loss: 1750.0891\n",
      "Epoch 2920/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1880.1949 - val_loss: 1749.6907\n",
      "Epoch 2921/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1879.7987 - val_loss: 1749.2919\n",
      "Epoch 2922/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 1879.4022 - val_loss: 1748.8937\n",
      "Epoch 2923/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 1879.0059 - val_loss: 1748.4954\n",
      "Epoch 2924/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1878.6097 - val_loss: 1748.0973\n",
      "Epoch 2925/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 1878.2137 - val_loss: 1747.6992\n",
      "Epoch 2926/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 1877.8179 - val_loss: 1747.3015\n",
      "Epoch 2927/100000\n",
      "11/11 [==============================] - 0s 608us/step - loss: 1877.4222 - val_loss: 1746.9036\n",
      "Epoch 2928/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 1877.0265 - val_loss: 1746.5060\n",
      "Epoch 2929/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 1876.6310 - val_loss: 1746.1086\n",
      "Epoch 2930/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 1876.2358 - val_loss: 1745.7113\n",
      "Epoch 2931/100000\n",
      "11/11 [==============================] - 0s 662us/step - loss: 1875.8406 - val_loss: 1745.3143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2932/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 1875.4457 - val_loss: 1744.9172\n",
      "Epoch 2933/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 1875.0509 - val_loss: 1744.5203\n",
      "Epoch 2934/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 1874.6561 - val_loss: 1744.1235\n",
      "Epoch 2935/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1874.2614 - val_loss: 1743.7271\n",
      "Epoch 2936/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 1873.8671 - val_loss: 1743.3306\n",
      "Epoch 2937/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 1873.4727 - val_loss: 1742.9343\n",
      "Epoch 2938/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1873.0785 - val_loss: 1742.5382\n",
      "Epoch 2939/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 1872.6844 - val_loss: 1742.1422\n",
      "Epoch 2940/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1872.2909 - val_loss: 1741.7465\n",
      "Epoch 2941/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 1871.8970 - val_loss: 1741.3507\n",
      "Epoch 2942/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 1871.5032 - val_loss: 1740.9550\n",
      "Epoch 2943/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 1871.1099 - val_loss: 1740.5597\n",
      "Epoch 2944/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 1870.7167 - val_loss: 1740.1641\n",
      "Epoch 2945/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1870.3235 - val_loss: 1739.7690\n",
      "Epoch 2946/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 1869.9304 - val_loss: 1739.3741\n",
      "Epoch 2947/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 1869.5375 - val_loss: 1738.9792\n",
      "Epoch 2948/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 1869.1447 - val_loss: 1738.5844\n",
      "Epoch 2949/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1868.7521 - val_loss: 1738.1896\n",
      "Epoch 2950/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 1868.3595 - val_loss: 1737.7954\n",
      "Epoch 2951/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 1867.9673 - val_loss: 1737.4009\n",
      "Epoch 2952/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 1867.5751 - val_loss: 1737.0067\n",
      "Epoch 2953/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1867.1832 - val_loss: 1736.6129\n",
      "Epoch 2954/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 1866.7910 - val_loss: 1736.2189\n",
      "Epoch 2955/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 1866.3995 - val_loss: 1735.8251\n",
      "Epoch 2956/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 1866.0078 - val_loss: 1735.4315\n",
      "Epoch 2957/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 1865.6163 - val_loss: 1735.0380\n",
      "Epoch 2958/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1865.2250 - val_loss: 1734.6445\n",
      "Epoch 2959/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1864.8339 - val_loss: 1734.2516\n",
      "Epoch 2960/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1864.4429 - val_loss: 1733.8585\n",
      "Epoch 2961/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 1864.0519 - val_loss: 1733.4653\n",
      "Epoch 2962/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1863.6609 - val_loss: 1733.0728\n",
      "Epoch 2963/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1863.2704 - val_loss: 1732.6801\n",
      "Epoch 2964/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1862.8796 - val_loss: 1732.2876\n",
      "Epoch 2965/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 1862.4894 - val_loss: 1731.8953\n",
      "Epoch 2966/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 1862.0991 - val_loss: 1731.5031\n",
      "Epoch 2967/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 1861.7091 - val_loss: 1731.1110\n",
      "Epoch 2968/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1861.3192 - val_loss: 1730.7191\n",
      "Epoch 2969/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 1860.9293 - val_loss: 1730.3273\n",
      "Epoch 2970/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 1860.5396 - val_loss: 1729.9355\n",
      "Epoch 2971/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1860.1500 - val_loss: 1729.5441\n",
      "Epoch 2972/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 1859.7609 - val_loss: 1729.1527\n",
      "Epoch 2973/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1859.3715 - val_loss: 1728.7614\n",
      "Epoch 2974/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 1858.9824 - val_loss: 1728.3702\n",
      "Epoch 2975/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1858.5934 - val_loss: 1727.9792\n",
      "Epoch 2976/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 1858.2046 - val_loss: 1727.5886\n",
      "Epoch 2977/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1857.8159 - val_loss: 1727.1978\n",
      "Epoch 2978/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 1857.4272 - val_loss: 1726.8071\n",
      "Epoch 2979/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1857.0389 - val_loss: 1726.4169\n",
      "Epoch 2980/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1856.6508 - val_loss: 1726.0266\n",
      "Epoch 2981/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1856.2626 - val_loss: 1725.6366\n",
      "Epoch 2982/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 1855.8746 - val_loss: 1725.2466\n",
      "Epoch 2983/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 1855.4867 - val_loss: 1724.8567\n",
      "Epoch 2984/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 1855.0991 - val_loss: 1724.4669\n",
      "Epoch 2985/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 1854.7114 - val_loss: 1724.0774\n",
      "Epoch 2986/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1854.3241 - val_loss: 1723.6880\n",
      "Epoch 2987/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 1853.9366 - val_loss: 1723.2987\n",
      "Epoch 2988/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1853.5496 - val_loss: 1722.9094\n",
      "Epoch 2989/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1853.1625 - val_loss: 1722.5206\n",
      "Epoch 2990/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 1852.7758 - val_loss: 1722.1317\n",
      "Epoch 2991/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 1852.3888 - val_loss: 1721.7429\n",
      "Epoch 2992/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1852.0023 - val_loss: 1721.3544\n",
      "Epoch 2993/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 1851.6160 - val_loss: 1720.9659\n",
      "Epoch 2994/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 1851.2297 - val_loss: 1720.5776\n",
      "Epoch 2995/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1850.8434 - val_loss: 1720.1895\n",
      "Epoch 2996/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 1850.4572 - val_loss: 1719.8013\n",
      "Epoch 2997/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1850.0712 - val_loss: 1719.4136\n",
      "Epoch 2998/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 1849.6857 - val_loss: 1719.0255\n",
      "Epoch 2999/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 1849.2997 - val_loss: 1718.6382\n",
      "Epoch 3000/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1848.9142 - val_loss: 1718.2507\n",
      "Epoch 3001/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1848.5293 - val_loss: 1717.8633\n",
      "Epoch 3002/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 1848.1440 - val_loss: 1717.4762\n",
      "Epoch 3003/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 1847.7587 - val_loss: 1717.0891\n",
      "Epoch 3004/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 1847.3741 - val_loss: 1716.7023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3005/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 1846.9891 - val_loss: 1716.3153\n",
      "Epoch 3006/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 1846.6044 - val_loss: 1715.9288\n",
      "Epoch 3007/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1846.2198 - val_loss: 1715.5422\n",
      "Epoch 3008/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 1845.8356 - val_loss: 1715.1559\n",
      "Epoch 3009/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1845.4513 - val_loss: 1714.7697\n",
      "Epoch 3010/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 1845.0671 - val_loss: 1714.3837\n",
      "Epoch 3011/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 1844.6832 - val_loss: 1713.9976\n",
      "Epoch 3012/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1844.2993 - val_loss: 1713.6118\n",
      "Epoch 3013/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1843.9159 - val_loss: 1713.2261\n",
      "Epoch 3014/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 1843.5320 - val_loss: 1712.8406\n",
      "Epoch 3015/100000\n",
      "11/11 [==============================] - 0s 674us/step - loss: 1843.1486 - val_loss: 1712.4551\n",
      "Epoch 3016/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1842.7653 - val_loss: 1712.0699\n",
      "Epoch 3017/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1842.3823 - val_loss: 1711.6848\n",
      "Epoch 3018/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1841.9993 - val_loss: 1711.2999\n",
      "Epoch 3019/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 1841.6165 - val_loss: 1710.9149\n",
      "Epoch 3020/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1841.2336 - val_loss: 1710.5302\n",
      "Epoch 3021/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 1840.8508 - val_loss: 1710.1458\n",
      "Epoch 3022/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1840.4688 - val_loss: 1709.7614\n",
      "Epoch 3023/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 1840.0864 - val_loss: 1709.3771\n",
      "Epoch 3024/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1839.7042 - val_loss: 1708.9929\n",
      "Epoch 3025/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 1839.3223 - val_loss: 1708.6089\n",
      "Epoch 3026/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 1838.9403 - val_loss: 1708.2250\n",
      "Epoch 3027/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 1838.5586 - val_loss: 1707.8413\n",
      "Epoch 3028/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1838.1769 - val_loss: 1707.4578\n",
      "Epoch 3029/100000\n",
      "11/11 [==============================] - 0s 193us/step - loss: 1837.7954 - val_loss: 1707.0742\n",
      "Epoch 3030/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 1837.4144 - val_loss: 1706.6909\n",
      "Epoch 3031/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 1837.0328 - val_loss: 1706.3077\n",
      "Epoch 3032/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1836.6520 - val_loss: 1705.9247\n",
      "Epoch 3033/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 1836.2710 - val_loss: 1705.5419\n",
      "Epoch 3034/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1835.8903 - val_loss: 1705.1591\n",
      "Epoch 3035/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 1835.5096 - val_loss: 1704.7766\n",
      "Epoch 3036/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1835.1290 - val_loss: 1704.3938\n",
      "Epoch 3037/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 1834.7488 - val_loss: 1704.0117\n",
      "Epoch 3038/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1834.3684 - val_loss: 1703.6293\n",
      "Epoch 3039/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 1833.9883 - val_loss: 1703.2472\n",
      "Epoch 3040/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 1833.6083 - val_loss: 1702.8654\n",
      "Epoch 3041/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 1833.2286 - val_loss: 1702.4836\n",
      "Epoch 3042/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1832.8489 - val_loss: 1702.1017\n",
      "Epoch 3043/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1832.4692 - val_loss: 1701.7206\n",
      "Epoch 3044/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 1832.0900 - val_loss: 1701.3390\n",
      "Epoch 3045/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 1831.7108 - val_loss: 1700.9578\n",
      "Epoch 3046/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1831.3317 - val_loss: 1700.5767\n",
      "Epoch 3047/100000\n",
      "11/11 [==============================] - 0s 654us/step - loss: 1830.9526 - val_loss: 1700.1957\n",
      "Epoch 3048/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1830.5739 - val_loss: 1699.8148\n",
      "Epoch 3049/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 1830.1949 - val_loss: 1699.4343\n",
      "Epoch 3050/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1829.8164 - val_loss: 1699.0536\n",
      "Epoch 3051/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 1829.4379 - val_loss: 1698.6733\n",
      "Epoch 3052/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 1829.0597 - val_loss: 1698.2930\n",
      "Epoch 3053/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 1828.6816 - val_loss: 1697.9126\n",
      "Epoch 3054/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 1828.3035 - val_loss: 1697.5328\n",
      "Epoch 3055/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1827.9257 - val_loss: 1697.1531\n",
      "Epoch 3056/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 1827.5481 - val_loss: 1696.7733\n",
      "Epoch 3057/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1827.1703 - val_loss: 1696.3937\n",
      "Epoch 3058/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 1826.7928 - val_loss: 1696.0142\n",
      "Epoch 3059/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 1826.4155 - val_loss: 1695.6348\n",
      "Epoch 3060/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 1826.0383 - val_loss: 1695.2557\n",
      "Epoch 3061/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 1825.6613 - val_loss: 1694.8768\n",
      "Epoch 3062/100000\n",
      "11/11 [==============================] - 0s 619us/step - loss: 1825.2843 - val_loss: 1694.4979\n",
      "Epoch 3063/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1824.9077 - val_loss: 1694.1191\n",
      "Epoch 3064/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1824.5309 - val_loss: 1693.7404\n",
      "Epoch 3065/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1824.1544 - val_loss: 1693.3618\n",
      "Epoch 3066/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1823.7781 - val_loss: 1692.9836\n",
      "Epoch 3067/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1823.4019 - val_loss: 1692.6053\n",
      "Epoch 3068/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 1823.0255 - val_loss: 1692.2273\n",
      "Epoch 3069/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1822.6497 - val_loss: 1691.8492\n",
      "Epoch 3070/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 1822.2738 - val_loss: 1691.4716\n",
      "Epoch 3071/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 1821.8981 - val_loss: 1691.0938\n",
      "Epoch 3072/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 1821.5223 - val_loss: 1690.7163\n",
      "Epoch 3073/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 1821.1472 - val_loss: 1690.3390\n",
      "Epoch 3074/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 1820.7719 - val_loss: 1689.9617\n",
      "Epoch 3075/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 1820.3969 - val_loss: 1689.5845\n",
      "Epoch 3076/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1820.0216 - val_loss: 1689.2074\n",
      "Epoch 3077/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 1819.6469 - val_loss: 1688.8308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3078/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 1819.2722 - val_loss: 1688.4540\n",
      "Epoch 3079/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 1818.8976 - val_loss: 1688.0774\n",
      "Epoch 3080/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 1818.5231 - val_loss: 1687.7010\n",
      "Epoch 3081/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 1818.1488 - val_loss: 1687.3246\n",
      "Epoch 3082/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 1817.7745 - val_loss: 1686.9485\n",
      "Epoch 3083/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 1817.4005 - val_loss: 1686.5724\n",
      "Epoch 3084/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1817.0265 - val_loss: 1686.1968\n",
      "Epoch 3085/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 1816.6528 - val_loss: 1685.8208\n",
      "Epoch 3086/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 1816.2792 - val_loss: 1685.4452\n",
      "Epoch 3087/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 1815.9055 - val_loss: 1685.0698\n",
      "Epoch 3088/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1815.5323 - val_loss: 1684.6945\n",
      "Epoch 3089/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 1815.1589 - val_loss: 1684.3192\n",
      "Epoch 3090/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 1814.7859 - val_loss: 1683.9441\n",
      "Epoch 3091/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 1814.4126 - val_loss: 1683.5692\n",
      "Epoch 3092/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 1814.0402 - val_loss: 1683.1946\n",
      "Epoch 3093/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 1813.6675 - val_loss: 1682.8198\n",
      "Epoch 3094/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1813.2949 - val_loss: 1682.4452\n",
      "Epoch 3095/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 1812.9226 - val_loss: 1682.0708\n",
      "Epoch 3096/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 1812.5504 - val_loss: 1681.6965\n",
      "Epoch 3097/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1812.1781 - val_loss: 1681.3224\n",
      "Epoch 3098/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1811.8059 - val_loss: 1680.9485\n",
      "Epoch 3099/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 1811.4343 - val_loss: 1680.5746\n",
      "Epoch 3100/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 1811.0626 - val_loss: 1680.2010\n",
      "Epoch 3101/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1810.6909 - val_loss: 1679.8273\n",
      "Epoch 3102/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1810.3192 - val_loss: 1679.4540\n",
      "Epoch 3103/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 1809.9481 - val_loss: 1679.0806\n",
      "Epoch 3104/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1809.5767 - val_loss: 1678.7074\n",
      "Epoch 3105/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 1809.2058 - val_loss: 1678.3345\n",
      "Epoch 3106/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1808.8348 - val_loss: 1677.9617\n",
      "Epoch 3107/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 1808.4641 - val_loss: 1677.5887\n",
      "Epoch 3108/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 1808.0934 - val_loss: 1677.2163\n",
      "Epoch 3109/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1807.7230 - val_loss: 1676.8438\n",
      "Epoch 3110/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1807.3524 - val_loss: 1676.4714\n",
      "Epoch 3111/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 1806.9821 - val_loss: 1676.0991\n",
      "Epoch 3112/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1806.6122 - val_loss: 1675.7271\n",
      "Epoch 3113/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 1806.2422 - val_loss: 1675.3551\n",
      "Epoch 3114/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1805.8723 - val_loss: 1674.9833\n",
      "Epoch 3115/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1805.5027 - val_loss: 1674.6115\n",
      "Epoch 3116/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 1805.1332 - val_loss: 1674.2401\n",
      "Epoch 3117/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 1804.7637 - val_loss: 1673.8688\n",
      "Epoch 3118/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 1804.3944 - val_loss: 1673.4976\n",
      "Epoch 3119/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 1804.0253 - val_loss: 1673.1262\n",
      "Epoch 3120/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 1803.6562 - val_loss: 1672.7554\n",
      "Epoch 3121/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 1803.2872 - val_loss: 1672.3844\n",
      "Epoch 3122/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 1802.9183 - val_loss: 1672.0138\n",
      "Epoch 3123/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 1802.5499 - val_loss: 1671.6433\n",
      "Epoch 3124/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1802.1815 - val_loss: 1671.2729\n",
      "Epoch 3125/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 1801.8132 - val_loss: 1670.9023\n",
      "Epoch 3126/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 1801.4448 - val_loss: 1670.5323\n",
      "Epoch 3127/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1801.0767 - val_loss: 1670.1622\n",
      "Epoch 3128/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1800.7090 - val_loss: 1669.7922\n",
      "Epoch 3129/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1800.3409 - val_loss: 1669.4226\n",
      "Epoch 3130/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1799.9734 - val_loss: 1669.0529\n",
      "Epoch 3131/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1799.6058 - val_loss: 1668.6835\n",
      "Epoch 3132/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1799.2386 - val_loss: 1668.3141\n",
      "Epoch 3133/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1798.8711 - val_loss: 1667.9448\n",
      "Epoch 3134/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 1798.5039 - val_loss: 1667.5757\n",
      "Epoch 3135/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1798.1371 - val_loss: 1667.2069\n",
      "Epoch 3136/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 1797.7704 - val_loss: 1666.8380\n",
      "Epoch 3137/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1797.4036 - val_loss: 1666.4695\n",
      "Epoch 3138/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 1797.0370 - val_loss: 1666.1008\n",
      "Epoch 3139/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 1796.6704 - val_loss: 1665.7323\n",
      "Epoch 3140/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1796.3042 - val_loss: 1665.3640\n",
      "Epoch 3141/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 1795.9382 - val_loss: 1664.9960\n",
      "Epoch 3142/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 1795.5719 - val_loss: 1664.6278\n",
      "Epoch 3143/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1795.2059 - val_loss: 1664.2601\n",
      "Epoch 3144/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 1794.8402 - val_loss: 1663.8921\n",
      "Epoch 3145/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1794.4745 - val_loss: 1663.5245\n",
      "Epoch 3146/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1794.1090 - val_loss: 1663.1570\n",
      "Epoch 3147/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 1793.7437 - val_loss: 1662.7898\n",
      "Epoch 3148/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1793.3785 - val_loss: 1662.4226\n",
      "Epoch 3149/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 1793.0132 - val_loss: 1662.0555\n",
      "Epoch 3150/100000\n",
      "11/11 [==============================] - 0s 636us/step - loss: 1792.6484 - val_loss: 1661.6887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3151/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1792.2836 - val_loss: 1661.3218\n",
      "Epoch 3152/100000\n",
      "11/11 [==============================] - 0s 591us/step - loss: 1791.9188 - val_loss: 1660.9551\n",
      "Epoch 3153/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 1791.5540 - val_loss: 1660.5886\n",
      "Epoch 3154/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 1791.1896 - val_loss: 1660.2223\n",
      "Epoch 3155/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 1790.8254 - val_loss: 1659.8558\n",
      "Epoch 3156/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 1790.4613 - val_loss: 1659.4897\n",
      "Epoch 3157/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 1790.0973 - val_loss: 1659.1239\n",
      "Epoch 3158/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1789.7336 - val_loss: 1658.7578\n",
      "Epoch 3159/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1789.3696 - val_loss: 1658.3921\n",
      "Epoch 3160/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 1789.0059 - val_loss: 1658.0269\n",
      "Epoch 3161/100000\n",
      "11/11 [==============================] - 0s 619us/step - loss: 1788.6425 - val_loss: 1657.6610\n",
      "Epoch 3162/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1788.2792 - val_loss: 1657.2960\n",
      "Epoch 3163/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 1787.9159 - val_loss: 1656.9308\n",
      "Epoch 3164/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1787.5527 - val_loss: 1656.5657\n",
      "Epoch 3165/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 1787.1898 - val_loss: 1656.2007\n",
      "Epoch 3166/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1786.8270 - val_loss: 1655.8359\n",
      "Epoch 3167/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 1786.4644 - val_loss: 1655.4712\n",
      "Epoch 3168/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 1786.1017 - val_loss: 1655.1069\n",
      "Epoch 3169/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1785.7394 - val_loss: 1654.7423\n",
      "Epoch 3170/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 1785.3771 - val_loss: 1654.3782\n",
      "Epoch 3171/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1785.0149 - val_loss: 1654.0140\n",
      "Epoch 3172/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 1784.6528 - val_loss: 1653.6503\n",
      "Epoch 3173/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1784.2911 - val_loss: 1653.2864\n",
      "Epoch 3174/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 1783.9292 - val_loss: 1652.9226\n",
      "Epoch 3175/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 1783.5675 - val_loss: 1652.5590\n",
      "Epoch 3176/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1783.2062 - val_loss: 1652.1954\n",
      "Epoch 3177/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1782.8446 - val_loss: 1651.8322\n",
      "Epoch 3178/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1782.4836 - val_loss: 1651.4691\n",
      "Epoch 3179/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 1782.1226 - val_loss: 1651.1058\n",
      "Epoch 3180/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1781.7616 - val_loss: 1650.7433\n",
      "Epoch 3181/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1781.4009 - val_loss: 1650.3804\n",
      "Epoch 3182/100000\n",
      "11/11 [==============================] - 0s 202us/step - loss: 1781.0402 - val_loss: 1650.0177\n",
      "Epoch 3183/100000\n",
      "11/11 [==============================] - 0s 633us/step - loss: 1780.6796 - val_loss: 1649.6552\n",
      "Epoch 3184/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 1780.3191 - val_loss: 1649.2928\n",
      "Epoch 3185/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 1779.9589 - val_loss: 1648.9305\n",
      "Epoch 3186/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1779.5988 - val_loss: 1648.5685\n",
      "Epoch 3187/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 1779.2386 - val_loss: 1648.2063\n",
      "Epoch 3188/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1778.8788 - val_loss: 1647.8446\n",
      "Epoch 3189/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 1778.5190 - val_loss: 1647.4829\n",
      "Epoch 3190/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 1778.1597 - val_loss: 1647.1215\n",
      "Epoch 3191/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1777.8000 - val_loss: 1646.7601\n",
      "Epoch 3192/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1777.4407 - val_loss: 1646.3986\n",
      "Epoch 3193/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 1777.0813 - val_loss: 1646.0376\n",
      "Epoch 3194/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1776.7225 - val_loss: 1645.6765\n",
      "Epoch 3195/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1776.3633 - val_loss: 1645.3156\n",
      "Epoch 3196/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 1776.0046 - val_loss: 1644.9547\n",
      "Epoch 3197/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 1775.6458 - val_loss: 1644.5941\n",
      "Epoch 3198/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 1775.2872 - val_loss: 1644.2336\n",
      "Epoch 3199/100000\n",
      "11/11 [==============================] - 0s 662us/step - loss: 1774.9290 - val_loss: 1643.8732\n",
      "Epoch 3200/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1774.5707 - val_loss: 1643.5132\n",
      "Epoch 3201/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 1774.2125 - val_loss: 1643.1531\n",
      "Epoch 3202/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 1773.8546 - val_loss: 1642.7930\n",
      "Epoch 3203/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 1773.4966 - val_loss: 1642.4332\n",
      "Epoch 3204/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1773.1388 - val_loss: 1642.0735\n",
      "Epoch 3205/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 1772.7812 - val_loss: 1641.7140\n",
      "Epoch 3206/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1772.4240 - val_loss: 1641.3544\n",
      "Epoch 3207/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 1772.0665 - val_loss: 1640.9952\n",
      "Epoch 3208/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1771.7091 - val_loss: 1640.6360\n",
      "Epoch 3209/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1771.3521 - val_loss: 1640.2770\n",
      "Epoch 3210/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 1770.9952 - val_loss: 1639.9181\n",
      "Epoch 3211/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1770.6385 - val_loss: 1639.5593\n",
      "Epoch 3212/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1770.2816 - val_loss: 1639.2007\n",
      "Epoch 3213/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1769.9250 - val_loss: 1638.8422\n",
      "Epoch 3214/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 1769.5687 - val_loss: 1638.4839\n",
      "Epoch 3215/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1769.2125 - val_loss: 1638.1257\n",
      "Epoch 3216/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 1768.8563 - val_loss: 1637.7676\n",
      "Epoch 3217/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1768.5005 - val_loss: 1637.4097\n",
      "Epoch 3218/100000\n",
      "11/11 [==============================] - 0s 658us/step - loss: 1768.1445 - val_loss: 1637.0516\n",
      "Epoch 3219/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1767.7887 - val_loss: 1636.6941\n",
      "Epoch 3220/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 1767.4331 - val_loss: 1636.3364\n",
      "Epoch 3221/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1767.0776 - val_loss: 1635.9790\n",
      "Epoch 3222/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1766.7223 - val_loss: 1635.6216\n",
      "Epoch 3223/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 1766.3672 - val_loss: 1635.2645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3224/100000\n",
      "11/11 [==============================] - 0s 731us/step - loss: 1766.0118 - val_loss: 1634.9075\n",
      "Epoch 3225/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1765.6570 - val_loss: 1634.5504\n",
      "Epoch 3226/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1765.3020 - val_loss: 1634.1938\n",
      "Epoch 3227/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 1764.9474 - val_loss: 1633.8372\n",
      "Epoch 3228/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 1764.5929 - val_loss: 1633.4806\n",
      "Epoch 3229/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 1764.2386 - val_loss: 1633.1243\n",
      "Epoch 3230/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1763.8843 - val_loss: 1632.7681\n",
      "Epoch 3231/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1763.5300 - val_loss: 1632.4120\n",
      "Epoch 3232/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1763.1761 - val_loss: 1632.0559\n",
      "Epoch 3233/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 1762.8221 - val_loss: 1631.7003\n",
      "Epoch 3234/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 1762.4684 - val_loss: 1631.3445\n",
      "Epoch 3235/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 1762.1147 - val_loss: 1630.9888\n",
      "Epoch 3236/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 1761.7612 - val_loss: 1630.6332\n",
      "Epoch 3237/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 1761.4077 - val_loss: 1630.2781\n",
      "Epoch 3238/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 1761.0547 - val_loss: 1629.9230\n",
      "Epoch 3239/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 1760.7015 - val_loss: 1629.5676\n",
      "Epoch 3240/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1760.3485 - val_loss: 1629.2129\n",
      "Epoch 3241/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 1759.9956 - val_loss: 1628.8582\n",
      "Epoch 3242/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 1759.6429 - val_loss: 1628.5034\n",
      "Epoch 3243/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 1759.2905 - val_loss: 1628.1489\n",
      "Epoch 3244/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1758.9380 - val_loss: 1627.7946\n",
      "Epoch 3245/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 1758.5856 - val_loss: 1627.4402\n",
      "Epoch 3246/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1758.2335 - val_loss: 1627.0861\n",
      "Epoch 3247/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 1757.8813 - val_loss: 1626.7323\n",
      "Epoch 3248/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1757.5294 - val_loss: 1626.3782\n",
      "Epoch 3249/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1757.1777 - val_loss: 1626.0245\n",
      "Epoch 3250/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1756.8260 - val_loss: 1625.6708\n",
      "Epoch 3251/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1756.4745 - val_loss: 1625.3175\n",
      "Epoch 3252/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1756.1232 - val_loss: 1624.9641\n",
      "Epoch 3253/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1755.7719 - val_loss: 1624.6110\n",
      "Epoch 3254/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 1755.4208 - val_loss: 1624.2578\n",
      "Epoch 3255/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1755.0698 - val_loss: 1623.9048\n",
      "Epoch 3256/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 1754.7188 - val_loss: 1623.5522\n",
      "Epoch 3257/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1754.3680 - val_loss: 1623.1996\n",
      "Epoch 3258/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 1754.0176 - val_loss: 1622.8469\n",
      "Epoch 3259/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1753.6671 - val_loss: 1622.4945\n",
      "Epoch 3260/100000\n",
      "11/11 [==============================] - 0s 586us/step - loss: 1753.3168 - val_loss: 1622.1422\n",
      "Epoch 3261/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 1752.9667 - val_loss: 1621.7902\n",
      "Epoch 3262/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 1752.6165 - val_loss: 1621.4380\n",
      "Epoch 3263/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 1752.2667 - val_loss: 1621.0861\n",
      "Epoch 3264/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 1751.9169 - val_loss: 1620.7344\n",
      "Epoch 3265/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1751.5668 - val_loss: 1620.3828\n",
      "Epoch 3266/100000\n",
      "11/11 [==============================] - 0s 706us/step - loss: 1751.2177 - val_loss: 1620.0312\n",
      "Epoch 3267/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 1750.8683 - val_loss: 1619.6801\n",
      "Epoch 3268/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 1750.5188 - val_loss: 1619.3286\n",
      "Epoch 3269/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1750.1698 - val_loss: 1618.9777\n",
      "Epoch 3270/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 1749.8207 - val_loss: 1618.6268\n",
      "Epoch 3271/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1749.4719 - val_loss: 1618.2758\n",
      "Epoch 3272/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1749.1232 - val_loss: 1617.9250\n",
      "Epoch 3273/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 1748.7743 - val_loss: 1617.5746\n",
      "Epoch 3274/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1748.4259 - val_loss: 1617.2241\n",
      "Epoch 3275/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 1748.0776 - val_loss: 1616.8738\n",
      "Epoch 3276/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1747.7292 - val_loss: 1616.5236\n",
      "Epoch 3277/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 1747.3812 - val_loss: 1616.1737\n",
      "Epoch 3278/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1747.0333 - val_loss: 1615.8235\n",
      "Epoch 3279/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 1746.6854 - val_loss: 1615.4739\n",
      "Epoch 3280/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 1746.3378 - val_loss: 1615.1243\n",
      "Epoch 3281/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 1745.9901 - val_loss: 1614.7749\n",
      "Epoch 3282/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1745.6426 - val_loss: 1614.4254\n",
      "Epoch 3283/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 1745.2954 - val_loss: 1614.0762\n",
      "Epoch 3284/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1744.9481 - val_loss: 1613.7269\n",
      "Epoch 3285/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 1744.6011 - val_loss: 1613.3778\n",
      "Epoch 3286/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1744.2540 - val_loss: 1613.0292\n",
      "Epoch 3287/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 1743.9071 - val_loss: 1612.6802\n",
      "Epoch 3288/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 1743.5605 - val_loss: 1612.3319\n",
      "Epoch 3289/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1743.2141 - val_loss: 1611.9833\n",
      "Epoch 3290/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 1742.8677 - val_loss: 1611.6349\n",
      "Epoch 3291/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 1742.5215 - val_loss: 1611.2867\n",
      "Epoch 3292/100000\n",
      "11/11 [==============================] - 0s 660us/step - loss: 1742.1754 - val_loss: 1610.9387\n",
      "Epoch 3293/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1741.8292 - val_loss: 1610.5907\n",
      "Epoch 3294/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 1741.4835 - val_loss: 1610.2429\n",
      "Epoch 3295/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 1741.1376 - val_loss: 1609.8953\n",
      "Epoch 3296/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 1740.7922 - val_loss: 1609.5476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3297/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 1740.4465 - val_loss: 1609.2001\n",
      "Epoch 3298/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 1740.1012 - val_loss: 1608.8530\n",
      "Epoch 3299/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1739.7560 - val_loss: 1608.5057\n",
      "Epoch 3300/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 1739.4109 - val_loss: 1608.1587\n",
      "Epoch 3301/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1739.0659 - val_loss: 1607.8118\n",
      "Epoch 3302/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1738.7212 - val_loss: 1607.4648\n",
      "Epoch 3303/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1738.3765 - val_loss: 1607.1183\n",
      "Epoch 3304/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1738.0317 - val_loss: 1606.7720\n",
      "Epoch 3305/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1737.6875 - val_loss: 1606.4254\n",
      "Epoch 3306/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 1737.3430 - val_loss: 1606.0792\n",
      "Epoch 3307/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 1736.9991 - val_loss: 1605.7332\n",
      "Epoch 3308/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1736.6548 - val_loss: 1605.3871\n",
      "Epoch 3309/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 1736.3107 - val_loss: 1605.0411\n",
      "Epoch 3310/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 1735.9672 - val_loss: 1604.6957\n",
      "Epoch 3311/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 1735.6235 - val_loss: 1604.3500\n",
      "Epoch 3312/100000\n",
      "11/11 [==============================] - 0s 677us/step - loss: 1735.2802 - val_loss: 1604.0043\n",
      "Epoch 3313/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1734.9364 - val_loss: 1603.6591\n",
      "Epoch 3314/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 1734.5934 - val_loss: 1603.3140\n",
      "Epoch 3315/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1734.2500 - val_loss: 1602.9688\n",
      "Epoch 3316/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 1733.9071 - val_loss: 1602.6239\n",
      "Epoch 3317/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 1733.5643 - val_loss: 1602.2792\n",
      "Epoch 3318/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1733.2214 - val_loss: 1601.9344\n",
      "Epoch 3319/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1732.8788 - val_loss: 1601.5898\n",
      "Epoch 3320/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 1732.5363 - val_loss: 1601.2454\n",
      "Epoch 3321/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1732.1938 - val_loss: 1600.9011\n",
      "Epoch 3322/100000\n",
      "11/11 [==============================] - 0s 649us/step - loss: 1731.8519 - val_loss: 1600.5571\n",
      "Epoch 3323/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1731.5098 - val_loss: 1600.2128\n",
      "Epoch 3324/100000\n",
      "11/11 [==============================] - 0s 717us/step - loss: 1731.1676 - val_loss: 1599.8690\n",
      "Epoch 3325/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1730.8258 - val_loss: 1599.5253\n",
      "Epoch 3326/100000\n",
      "11/11 [==============================] - 0s 615us/step - loss: 1730.4840 - val_loss: 1599.1816\n",
      "Epoch 3327/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 1730.1426 - val_loss: 1598.8380\n",
      "Epoch 3328/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 1729.8011 - val_loss: 1598.4946\n",
      "Epoch 3329/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1729.4597 - val_loss: 1598.1515\n",
      "Epoch 3330/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 1729.1187 - val_loss: 1597.8082\n",
      "Epoch 3331/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 1728.7775 - val_loss: 1597.4652\n",
      "Epoch 3332/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 1728.4364 - val_loss: 1597.1223\n",
      "Epoch 3333/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1728.0957 - val_loss: 1596.7797\n",
      "Epoch 3334/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 1727.7554 - val_loss: 1596.4371\n",
      "Epoch 3335/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 1727.4146 - val_loss: 1596.0946\n",
      "Epoch 3336/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 1727.0741 - val_loss: 1595.7523\n",
      "Epoch 3337/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 1726.7336 - val_loss: 1595.4102\n",
      "Epoch 3338/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 1726.3938 - val_loss: 1595.0680\n",
      "Epoch 3339/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 1726.0536 - val_loss: 1594.7261\n",
      "Epoch 3340/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1725.7137 - val_loss: 1594.3843\n",
      "Epoch 3341/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 1725.3738 - val_loss: 1594.0425\n",
      "Epoch 3342/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 1725.0344 - val_loss: 1593.7010\n",
      "Epoch 3343/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1724.6949 - val_loss: 1593.3595\n",
      "Epoch 3344/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 1724.3555 - val_loss: 1593.0183\n",
      "Epoch 3345/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 1724.0164 - val_loss: 1592.6770\n",
      "Epoch 3346/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 1723.6772 - val_loss: 1592.3359\n",
      "Epoch 3347/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1723.3380 - val_loss: 1591.9952\n",
      "Epoch 3348/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1722.9993 - val_loss: 1591.6543\n",
      "Epoch 3349/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1722.6605 - val_loss: 1591.3137\n",
      "Epoch 3350/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 1722.3221 - val_loss: 1590.9730\n",
      "Epoch 3351/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 1721.9835 - val_loss: 1590.6327\n",
      "Epoch 3352/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 1721.6453 - val_loss: 1590.2925\n",
      "Epoch 3353/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 1721.3068 - val_loss: 1589.9523\n",
      "Epoch 3354/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 1720.9688 - val_loss: 1589.6122\n",
      "Epoch 3355/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 1720.6310 - val_loss: 1589.2723\n",
      "Epoch 3356/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1720.2931 - val_loss: 1588.9327\n",
      "Epoch 3357/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 1719.9552 - val_loss: 1588.5930\n",
      "Epoch 3358/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 1719.6177 - val_loss: 1588.2535\n",
      "Epoch 3359/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1719.2802 - val_loss: 1587.9141\n",
      "Epoch 3360/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 1718.9430 - val_loss: 1587.5747\n",
      "Epoch 3361/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 1718.6058 - val_loss: 1587.2358\n",
      "Epoch 3362/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1718.2688 - val_loss: 1586.8969\n",
      "Epoch 3363/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1717.9318 - val_loss: 1586.5579\n",
      "Epoch 3364/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 1717.5952 - val_loss: 1586.2191\n",
      "Epoch 3365/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 1717.2583 - val_loss: 1585.8807\n",
      "Epoch 3366/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 1716.9219 - val_loss: 1585.5421\n",
      "Epoch 3367/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 1716.5854 - val_loss: 1585.2036\n",
      "Epoch 3368/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 1716.2491 - val_loss: 1584.8656\n",
      "Epoch 3369/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1715.9130 - val_loss: 1584.5275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3370/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1715.5769 - val_loss: 1584.1896\n",
      "Epoch 3371/100000\n",
      "11/11 [==============================] - 0s 609us/step - loss: 1715.2411 - val_loss: 1583.8517\n",
      "Epoch 3372/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1714.9054 - val_loss: 1583.5142\n",
      "Epoch 3373/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 1714.5696 - val_loss: 1583.1765\n",
      "Epoch 3374/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 1714.2343 - val_loss: 1582.8390\n",
      "Epoch 3375/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1713.8988 - val_loss: 1582.5018\n",
      "Epoch 3376/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 1713.5636 - val_loss: 1582.1646\n",
      "Epoch 3377/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 1713.2285 - val_loss: 1581.8274\n",
      "Epoch 3378/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 1712.8934 - val_loss: 1581.4904\n",
      "Epoch 3379/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1712.5586 - val_loss: 1581.1538\n",
      "Epoch 3380/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 1712.2241 - val_loss: 1580.8171\n",
      "Epoch 3381/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 1711.8894 - val_loss: 1580.4805\n",
      "Epoch 3382/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 1711.5547 - val_loss: 1580.1442\n",
      "Epoch 3383/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1711.2206 - val_loss: 1579.8079\n",
      "Epoch 3384/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 1710.8864 - val_loss: 1579.4718\n",
      "Epoch 3385/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 1710.5522 - val_loss: 1579.1356\n",
      "Epoch 3386/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1710.2180 - val_loss: 1578.7997\n",
      "Epoch 3387/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 1709.8843 - val_loss: 1578.4641\n",
      "Epoch 3388/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 1709.5504 - val_loss: 1578.1285\n",
      "Epoch 3389/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 1709.2172 - val_loss: 1577.7930\n",
      "Epoch 3390/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 1708.8837 - val_loss: 1577.4575\n",
      "Epoch 3391/100000\n",
      "11/11 [==============================] - 0s 609us/step - loss: 1708.5500 - val_loss: 1577.1223\n",
      "Epoch 3392/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1708.2169 - val_loss: 1576.7871\n",
      "Epoch 3393/100000\n",
      "11/11 [==============================] - 0s 685us/step - loss: 1707.8840 - val_loss: 1576.4524\n",
      "Epoch 3394/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 1707.5511 - val_loss: 1576.1176\n",
      "Epoch 3395/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1707.2184 - val_loss: 1575.7827\n",
      "Epoch 3396/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1706.8855 - val_loss: 1575.4480\n",
      "Epoch 3397/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 1706.5529 - val_loss: 1575.1134\n",
      "Epoch 3398/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 1706.2206 - val_loss: 1574.7792\n",
      "Epoch 3399/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 1705.8883 - val_loss: 1574.4452\n",
      "Epoch 3400/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1705.5562 - val_loss: 1574.1108\n",
      "Epoch 3401/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1705.2239 - val_loss: 1573.7770\n",
      "Epoch 3402/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 1704.8921 - val_loss: 1573.4430\n",
      "Epoch 3403/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 1704.5605 - val_loss: 1573.1094\n",
      "Epoch 3404/100000\n",
      "11/11 [==============================] - 0s 686us/step - loss: 1704.2286 - val_loss: 1572.7758\n",
      "Epoch 3405/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 1703.8973 - val_loss: 1572.4423\n",
      "Epoch 3406/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 1703.5659 - val_loss: 1572.1093\n",
      "Epoch 3407/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1703.2345 - val_loss: 1571.7759\n",
      "Epoch 3408/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1702.9034 - val_loss: 1571.4429\n",
      "Epoch 3409/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 1702.5724 - val_loss: 1571.1099\n",
      "Epoch 3410/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1702.2415 - val_loss: 1570.7772\n",
      "Epoch 3411/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 1701.9106 - val_loss: 1570.4445\n",
      "Epoch 3412/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1701.5801 - val_loss: 1570.1118\n",
      "Epoch 3413/100000\n",
      "11/11 [==============================] - 0s 656us/step - loss: 1701.2496 - val_loss: 1569.7794\n",
      "Epoch 3414/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1700.9192 - val_loss: 1569.4469\n",
      "Epoch 3415/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 1700.5890 - val_loss: 1569.1149\n",
      "Epoch 3416/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1700.2587 - val_loss: 1568.7828\n",
      "Epoch 3417/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1699.9288 - val_loss: 1568.4510\n",
      "Epoch 3418/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1699.5988 - val_loss: 1568.1191\n",
      "Epoch 3419/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1699.2692 - val_loss: 1567.7875\n",
      "Epoch 3420/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 1698.9395 - val_loss: 1567.4559\n",
      "Epoch 3421/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 1698.6101 - val_loss: 1567.1245\n",
      "Epoch 3422/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 1698.2808 - val_loss: 1566.7933\n",
      "Epoch 3423/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1697.9515 - val_loss: 1566.4620\n",
      "Epoch 3424/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 1697.6223 - val_loss: 1566.1312\n",
      "Epoch 3425/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 1697.2933 - val_loss: 1565.8003\n",
      "Epoch 3426/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 1696.9645 - val_loss: 1565.4695\n",
      "Epoch 3427/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 1696.6360 - val_loss: 1565.1388\n",
      "Epoch 3428/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1696.3071 - val_loss: 1564.8082\n",
      "Epoch 3429/100000\n",
      "11/11 [==============================] - 0s 594us/step - loss: 1695.9785 - val_loss: 1564.4780\n",
      "Epoch 3430/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 1695.6504 - val_loss: 1564.1477\n",
      "Epoch 3431/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1695.3221 - val_loss: 1563.8175\n",
      "Epoch 3432/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1694.9940 - val_loss: 1563.4874\n",
      "Epoch 3433/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1694.6660 - val_loss: 1563.1577\n",
      "Epoch 3434/100000\n",
      "11/11 [==============================] - 0s 663us/step - loss: 1694.3384 - val_loss: 1562.8278\n",
      "Epoch 3435/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 1694.0105 - val_loss: 1562.4982\n",
      "Epoch 3436/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 1693.6831 - val_loss: 1562.1687\n",
      "Epoch 3437/100000\n",
      "11/11 [==============================] - 0s 675us/step - loss: 1693.3556 - val_loss: 1561.8394\n",
      "Epoch 3438/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 1693.0282 - val_loss: 1561.5101\n",
      "Epoch 3439/100000\n",
      "11/11 [==============================] - 0s 654us/step - loss: 1692.7010 - val_loss: 1561.1809\n",
      "Epoch 3440/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1692.3739 - val_loss: 1560.8521\n",
      "Epoch 3441/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 1692.0469 - val_loss: 1560.5231\n",
      "Epoch 3442/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1691.7202 - val_loss: 1560.1945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3443/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1691.3934 - val_loss: 1559.8660\n",
      "Epoch 3444/100000\n",
      "11/11 [==============================] - 0s 591us/step - loss: 1691.0669 - val_loss: 1559.5372\n",
      "Epoch 3445/100000\n",
      "11/11 [==============================] - 0s 862us/step - loss: 1690.7404 - val_loss: 1559.2090\n",
      "Epoch 3446/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 1690.4141 - val_loss: 1558.8809\n",
      "Epoch 3447/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 1690.0880 - val_loss: 1558.5526\n",
      "Epoch 3448/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1689.7618 - val_loss: 1558.2247\n",
      "Epoch 3449/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1689.4360 - val_loss: 1557.8966\n",
      "Epoch 3450/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1689.1101 - val_loss: 1557.5692\n",
      "Epoch 3451/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 1688.7844 - val_loss: 1557.2415\n",
      "Epoch 3452/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1688.4590 - val_loss: 1556.9141\n",
      "Epoch 3453/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 1688.1335 - val_loss: 1556.5868\n",
      "Epoch 3454/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1687.8082 - val_loss: 1556.2594\n",
      "Epoch 3455/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 1687.4832 - val_loss: 1555.9325\n",
      "Epoch 3456/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 1687.1581 - val_loss: 1555.6055\n",
      "Epoch 3457/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1686.8331 - val_loss: 1555.2786\n",
      "Epoch 3458/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 1686.5082 - val_loss: 1554.9519\n",
      "Epoch 3459/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 1686.1836 - val_loss: 1554.6254\n",
      "Epoch 3460/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1685.8594 - val_loss: 1554.2988\n",
      "Epoch 3461/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 1685.5348 - val_loss: 1553.9725\n",
      "Epoch 3462/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1685.2102 - val_loss: 1553.6464\n",
      "Epoch 3463/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 1684.8862 - val_loss: 1553.3203\n",
      "Epoch 3464/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 1684.5621 - val_loss: 1552.9943\n",
      "Epoch 3465/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 1684.2382 - val_loss: 1552.6685\n",
      "Epoch 3466/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1683.9144 - val_loss: 1552.3429\n",
      "Epoch 3467/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1683.5907 - val_loss: 1552.0172\n",
      "Epoch 3468/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 1683.2672 - val_loss: 1551.6918\n",
      "Epoch 3469/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1682.9441 - val_loss: 1551.3665\n",
      "Epoch 3470/100000\n",
      "11/11 [==============================] - 0s 782us/step - loss: 1682.6207 - val_loss: 1551.0414\n",
      "Epoch 3471/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1682.2974 - val_loss: 1550.7163\n",
      "Epoch 3472/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 1681.9745 - val_loss: 1550.3911\n",
      "Epoch 3473/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1681.6516 - val_loss: 1550.0665\n",
      "Epoch 3474/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1681.3289 - val_loss: 1549.7418\n",
      "Epoch 3475/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1681.0062 - val_loss: 1549.4175\n",
      "Epoch 3476/100000\n",
      "11/11 [==============================] - 0s 949us/step - loss: 1680.6836 - val_loss: 1549.0929\n",
      "Epoch 3477/100000\n",
      "11/11 [==============================] - 0s 716us/step - loss: 1680.3612 - val_loss: 1548.7687\n",
      "Epoch 3478/100000\n",
      "11/11 [==============================] - 0s 599us/step - loss: 1680.0391 - val_loss: 1548.4445\n",
      "Epoch 3479/100000\n",
      "11/11 [==============================] - 0s 987us/step - loss: 1679.7168 - val_loss: 1548.1204\n",
      "Epoch 3480/100000\n",
      "11/11 [==============================] - 0s 987us/step - loss: 1679.3947 - val_loss: 1547.7965\n",
      "Epoch 3481/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 1679.0731 - val_loss: 1547.4727\n",
      "Epoch 3482/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 1678.7512 - val_loss: 1547.1488\n",
      "Epoch 3483/100000\n",
      "11/11 [==============================] - 0s 671us/step - loss: 1678.4296 - val_loss: 1546.8253\n",
      "Epoch 3484/100000\n",
      "11/11 [==============================] - 0s 667us/step - loss: 1678.1082 - val_loss: 1546.5020\n",
      "Epoch 3485/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1677.7866 - val_loss: 1546.1786\n",
      "Epoch 3486/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 1677.4652 - val_loss: 1545.8553\n",
      "Epoch 3487/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 1677.1444 - val_loss: 1545.5323\n",
      "Epoch 3488/100000\n",
      "11/11 [==============================] - 0s 797us/step - loss: 1676.8231 - val_loss: 1545.2094\n",
      "Epoch 3489/100000\n",
      "11/11 [==============================] - 0s 655us/step - loss: 1676.5023 - val_loss: 1544.8867\n",
      "Epoch 3490/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1676.1816 - val_loss: 1544.5641\n",
      "Epoch 3491/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1675.8610 - val_loss: 1544.2415\n",
      "Epoch 3492/100000\n",
      "11/11 [==============================] - 0s 955us/step - loss: 1675.5405 - val_loss: 1543.9191\n",
      "Epoch 3493/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 1675.2202 - val_loss: 1543.5969\n",
      "Epoch 3494/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1674.8999 - val_loss: 1543.2745\n",
      "Epoch 3495/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 1674.5796 - val_loss: 1542.9526\n",
      "Epoch 3496/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 1674.2598 - val_loss: 1542.6307\n",
      "Epoch 3497/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1673.9398 - val_loss: 1542.3090\n",
      "Epoch 3498/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 1673.6200 - val_loss: 1541.9874\n",
      "Epoch 3499/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 1673.3004 - val_loss: 1541.6656\n",
      "Epoch 3500/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 1672.9808 - val_loss: 1541.3442\n",
      "Epoch 3501/100000\n",
      "11/11 [==============================] - 0s 659us/step - loss: 1672.6616 - val_loss: 1541.0231\n",
      "Epoch 3502/100000\n",
      "11/11 [==============================] - 0s 580us/step - loss: 1672.3423 - val_loss: 1540.7019\n",
      "Epoch 3503/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 1672.0231 - val_loss: 1540.3809\n",
      "Epoch 3504/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 1671.7040 - val_loss: 1540.0601\n",
      "Epoch 3505/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 1671.3851 - val_loss: 1539.7394\n",
      "Epoch 3506/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 1671.0664 - val_loss: 1539.4185\n",
      "Epoch 3507/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 1670.7479 - val_loss: 1539.0980\n",
      "Epoch 3508/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1670.4293 - val_loss: 1538.7777\n",
      "Epoch 3509/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 1670.1110 - val_loss: 1538.4574\n",
      "Epoch 3510/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 1669.7930 - val_loss: 1538.1371\n",
      "Epoch 3511/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 1669.4747 - val_loss: 1537.8171\n",
      "Epoch 3512/100000\n",
      "11/11 [==============================] - 0s 755us/step - loss: 1669.1566 - val_loss: 1537.4973\n",
      "Epoch 3513/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 1668.8387 - val_loss: 1537.1776\n",
      "Epoch 3514/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1668.5211 - val_loss: 1536.8579\n",
      "Epoch 3515/100000\n",
      "11/11 [==============================] - 0s 726us/step - loss: 1668.2035 - val_loss: 1536.5383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3516/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 1667.8860 - val_loss: 1536.2188\n",
      "Epoch 3517/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 1667.5685 - val_loss: 1535.8997\n",
      "Epoch 3518/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1667.2515 - val_loss: 1535.5802\n",
      "Epoch 3519/100000\n",
      "11/11 [==============================] - 0s 716us/step - loss: 1666.9343 - val_loss: 1535.2614\n",
      "Epoch 3520/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 1666.6172 - val_loss: 1534.9426\n",
      "Epoch 3521/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 1666.3004 - val_loss: 1534.6239\n",
      "Epoch 3522/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1665.9836 - val_loss: 1534.3051\n",
      "Epoch 3523/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1665.6669 - val_loss: 1533.9865\n",
      "Epoch 3524/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 1665.3505 - val_loss: 1533.6680\n",
      "Epoch 3525/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 1665.0341 - val_loss: 1533.3500\n",
      "Epoch 3526/100000\n",
      "11/11 [==============================] - 0s 792us/step - loss: 1664.7179 - val_loss: 1533.0316\n",
      "Epoch 3527/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 1664.4019 - val_loss: 1532.7136\n",
      "Epoch 3528/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 1664.0859 - val_loss: 1532.3960\n",
      "Epoch 3529/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 1663.7699 - val_loss: 1532.0781\n",
      "Epoch 3530/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 1663.4542 - val_loss: 1531.7605\n",
      "Epoch 3531/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1663.1385 - val_loss: 1531.4429\n",
      "Epoch 3532/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 1662.8231 - val_loss: 1531.1254\n",
      "Epoch 3533/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 1662.5077 - val_loss: 1530.8082\n",
      "Epoch 3534/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 1662.1923 - val_loss: 1530.4911\n",
      "Epoch 3535/100000\n",
      "11/11 [==============================] - 0s 199us/step - loss: 1661.8773 - val_loss: 1530.1740\n",
      "Epoch 3536/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 1661.5624 - val_loss: 1529.8573\n",
      "Epoch 3537/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 1661.2473 - val_loss: 1529.5405\n",
      "Epoch 3538/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 1660.9325 - val_loss: 1529.2235\n",
      "Epoch 3539/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 1660.6179 - val_loss: 1528.9071\n",
      "Epoch 3540/100000\n",
      "11/11 [==============================] - 0s 787us/step - loss: 1660.3035 - val_loss: 1528.5907\n",
      "Epoch 3541/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 1659.9890 - val_loss: 1528.2745\n",
      "Epoch 3542/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1659.6747 - val_loss: 1527.9583\n",
      "Epoch 3543/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1659.3606 - val_loss: 1527.6425\n",
      "Epoch 3544/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 1659.0468 - val_loss: 1527.3263\n",
      "Epoch 3545/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 1658.7328 - val_loss: 1527.0106\n",
      "Epoch 3546/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 1658.4191 - val_loss: 1526.6949\n",
      "Epoch 3547/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1658.1055 - val_loss: 1526.3794\n",
      "Epoch 3548/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 1657.7919 - val_loss: 1526.0641\n",
      "Epoch 3549/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 1657.4785 - val_loss: 1525.7489\n",
      "Epoch 3550/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 1657.1655 - val_loss: 1525.4336\n",
      "Epoch 3551/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1656.8523 - val_loss: 1525.1187\n",
      "Epoch 3552/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 1656.5391 - val_loss: 1524.8036\n",
      "Epoch 3553/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1656.2264 - val_loss: 1524.4888\n",
      "Epoch 3554/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 1655.9133 - val_loss: 1524.1743\n",
      "Epoch 3555/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1655.6011 - val_loss: 1523.8597\n",
      "Epoch 3556/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 1655.2883 - val_loss: 1523.5454\n",
      "Epoch 3557/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1654.9758 - val_loss: 1523.2308\n",
      "Epoch 3558/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 1654.6636 - val_loss: 1522.9167\n",
      "Epoch 3559/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 1654.3516 - val_loss: 1522.6028\n",
      "Epoch 3560/100000\n",
      "11/11 [==============================] - 0s 659us/step - loss: 1654.0396 - val_loss: 1522.2891\n",
      "Epoch 3561/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 1653.7278 - val_loss: 1521.9751\n",
      "Epoch 3562/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 1653.4159 - val_loss: 1521.6613\n",
      "Epoch 3563/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 1653.1040 - val_loss: 1521.3478\n",
      "Epoch 3564/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 1652.7925 - val_loss: 1521.0344\n",
      "Epoch 3565/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 1652.4816 - val_loss: 1520.7212\n",
      "Epoch 3566/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 1652.1700 - val_loss: 1520.4081\n",
      "Epoch 3567/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 1651.8590 - val_loss: 1520.0948\n",
      "Epoch 3568/100000\n",
      "11/11 [==============================] - 0s 738us/step - loss: 1651.5477 - val_loss: 1519.7820\n",
      "Epoch 3569/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 1651.2368 - val_loss: 1519.4692\n",
      "Epoch 3570/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1650.9261 - val_loss: 1519.1566\n",
      "Epoch 3571/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1650.6156 - val_loss: 1518.8441\n",
      "Epoch 3572/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 1650.3051 - val_loss: 1518.5314\n",
      "Epoch 3573/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 1649.9946 - val_loss: 1518.2191\n",
      "Epoch 3574/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 1649.6843 - val_loss: 1517.9070\n",
      "Epoch 3575/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 1649.3741 - val_loss: 1517.5952\n",
      "Epoch 3576/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1649.0641 - val_loss: 1517.2831\n",
      "Epoch 3577/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 1648.7543 - val_loss: 1516.9712\n",
      "Epoch 3578/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1648.4445 - val_loss: 1516.6598\n",
      "Epoch 3579/100000\n",
      "11/11 [==============================] - 0s 661us/step - loss: 1648.1348 - val_loss: 1516.3481\n",
      "Epoch 3580/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 1647.8253 - val_loss: 1516.0366\n",
      "Epoch 3581/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 1647.5160 - val_loss: 1515.7253\n",
      "Epoch 3582/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1647.2065 - val_loss: 1515.4142\n",
      "Epoch 3583/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 1646.8972 - val_loss: 1515.1030\n",
      "Epoch 3584/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1646.5883 - val_loss: 1514.7921\n",
      "Epoch 3585/100000\n",
      "11/11 [==============================] - 0s 706us/step - loss: 1646.2794 - val_loss: 1514.4813\n",
      "Epoch 3586/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1645.9706 - val_loss: 1514.1707\n",
      "Epoch 3587/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1645.6617 - val_loss: 1513.8601\n",
      "Epoch 3588/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 1645.3534 - val_loss: 1513.5496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3589/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 1645.0448 - val_loss: 1513.2394\n",
      "Epoch 3590/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 1644.7367 - val_loss: 1512.9292\n",
      "Epoch 3591/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1644.4285 - val_loss: 1512.6190\n",
      "Epoch 3592/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 1644.1204 - val_loss: 1512.3090\n",
      "Epoch 3593/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1643.8124 - val_loss: 1511.9993\n",
      "Epoch 3594/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 1643.5046 - val_loss: 1511.6895\n",
      "Epoch 3595/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1643.1969 - val_loss: 1511.3800\n",
      "Epoch 3596/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1642.8890 - val_loss: 1511.0704\n",
      "Epoch 3597/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1642.5817 - val_loss: 1510.7612\n",
      "Epoch 3598/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1642.2745 - val_loss: 1510.4520\n",
      "Epoch 3599/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1641.9672 - val_loss: 1510.1429\n",
      "Epoch 3600/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1641.6602 - val_loss: 1509.8340\n",
      "Epoch 3601/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1641.3534 - val_loss: 1509.5250\n",
      "Epoch 3602/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1641.0464 - val_loss: 1509.2161\n",
      "Epoch 3603/100000\n",
      "11/11 [==============================] - 0s 706us/step - loss: 1640.7397 - val_loss: 1508.9077\n",
      "Epoch 3604/100000\n",
      "11/11 [==============================] - 0s 958us/step - loss: 1640.4332 - val_loss: 1508.5992\n",
      "Epoch 3605/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 1640.1266 - val_loss: 1508.2909\n",
      "Epoch 3606/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 1639.8202 - val_loss: 1507.9825\n",
      "Epoch 3607/100000\n",
      "11/11 [==============================] - 0s 802us/step - loss: 1639.5142 - val_loss: 1507.6746\n",
      "Epoch 3608/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 1639.2081 - val_loss: 1507.3667\n",
      "Epoch 3609/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 1638.9020 - val_loss: 1507.0587\n",
      "Epoch 3610/100000\n",
      "11/11 [==============================] - 0s 818us/step - loss: 1638.5962 - val_loss: 1506.7511\n",
      "Epoch 3611/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 1638.2905 - val_loss: 1506.4434\n",
      "Epoch 3612/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1637.9849 - val_loss: 1506.1359\n",
      "Epoch 3613/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1637.6793 - val_loss: 1505.8285\n",
      "Epoch 3614/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1637.3741 - val_loss: 1505.5211\n",
      "Epoch 3615/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1637.0688 - val_loss: 1505.2141\n",
      "Epoch 3616/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1636.7635 - val_loss: 1504.9071\n",
      "Epoch 3617/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 1636.4586 - val_loss: 1504.6001\n",
      "Epoch 3618/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1636.1538 - val_loss: 1504.2933\n",
      "Epoch 3619/100000\n",
      "11/11 [==============================] - 0s 747us/step - loss: 1635.8492 - val_loss: 1503.9868\n",
      "Epoch 3620/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1635.5444 - val_loss: 1503.6802\n",
      "Epoch 3621/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1635.2399 - val_loss: 1503.3739\n",
      "Epoch 3622/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1634.9357 - val_loss: 1503.0676\n",
      "Epoch 3623/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 1634.6313 - val_loss: 1502.7616\n",
      "Epoch 3624/100000\n",
      "11/11 [==============================] - 0s 810us/step - loss: 1634.3273 - val_loss: 1502.4556\n",
      "Epoch 3625/100000\n",
      "11/11 [==============================] - 0s 882us/step - loss: 1634.0234 - val_loss: 1502.1495\n",
      "Epoch 3626/100000\n",
      "11/11 [==============================] - 0s 951us/step - loss: 1633.7195 - val_loss: 1501.8439\n",
      "Epoch 3627/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1633.4156 - val_loss: 1501.5383\n",
      "Epoch 3628/100000\n",
      "11/11 [==============================] - 0s 977us/step - loss: 1633.1121 - val_loss: 1501.2328\n",
      "Epoch 3629/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1632.8086 - val_loss: 1500.9272\n",
      "Epoch 3630/100000\n",
      "11/11 [==============================] - 0s 853us/step - loss: 1632.5050 - val_loss: 1500.6219\n",
      "Epoch 3631/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1632.2017 - val_loss: 1500.3169\n",
      "Epoch 3632/100000\n",
      "11/11 [==============================] - 0s 817us/step - loss: 1631.8986 - val_loss: 1500.0117\n",
      "Epoch 3633/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1631.5956 - val_loss: 1499.7070\n",
      "Epoch 3634/100000\n",
      "11/11 [==============================] - 0s 726us/step - loss: 1631.2926 - val_loss: 1499.4020\n",
      "Epoch 3635/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1630.9899 - val_loss: 1499.0977\n",
      "Epoch 3636/100000\n",
      "11/11 [==============================] - 0s 834us/step - loss: 1630.6874 - val_loss: 1498.7930\n",
      "Epoch 3637/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1630.3848 - val_loss: 1498.4884\n",
      "Epoch 3638/100000\n",
      "11/11 [==============================] - 0s 991us/step - loss: 1630.0824 - val_loss: 1498.1843\n",
      "Epoch 3639/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1629.7800 - val_loss: 1497.8800\n",
      "Epoch 3640/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1629.4780 - val_loss: 1497.5760\n",
      "Epoch 3641/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1629.1758 - val_loss: 1497.2720\n",
      "Epoch 3642/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1628.8735 - val_loss: 1496.9683\n",
      "Epoch 3643/100000\n",
      "11/11 [==============================] - 0s 681us/step - loss: 1628.5719 - val_loss: 1496.6646\n",
      "Epoch 3644/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1628.2703 - val_loss: 1496.3610\n",
      "Epoch 3645/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1627.9688 - val_loss: 1496.0574\n",
      "Epoch 3646/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1627.6672 - val_loss: 1495.7539\n",
      "Epoch 3647/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1627.3660 - val_loss: 1495.4510\n",
      "Epoch 3648/100000\n",
      "11/11 [==============================] - 0s 705us/step - loss: 1627.0648 - val_loss: 1495.1479\n",
      "Epoch 3649/100000\n",
      "11/11 [==============================] - 0s 974us/step - loss: 1626.7637 - val_loss: 1494.8450\n",
      "Epoch 3650/100000\n",
      "11/11 [==============================] - 0s 629us/step - loss: 1626.4628 - val_loss: 1494.5421\n",
      "Epoch 3651/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1626.1620 - val_loss: 1494.2394\n",
      "Epoch 3652/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1625.8612 - val_loss: 1493.9368\n",
      "Epoch 3653/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 1625.5605 - val_loss: 1493.6344\n",
      "Epoch 3654/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 1625.2603 - val_loss: 1493.3320\n",
      "Epoch 3655/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 1624.9598 - val_loss: 1493.0297\n",
      "Epoch 3656/100000\n",
      "11/11 [==============================] - 0s 756us/step - loss: 1624.6597 - val_loss: 1492.7278\n",
      "Epoch 3657/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1624.3594 - val_loss: 1492.4257\n",
      "Epoch 3658/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1624.0597 - val_loss: 1492.1238\n",
      "Epoch 3659/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1623.7596 - val_loss: 1491.8221\n",
      "Epoch 3660/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1623.4598 - val_loss: 1491.5206\n",
      "Epoch 3661/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1623.1605 - val_loss: 1491.2189\n",
      "Epoch 3662/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step - loss: 1622.8608 - val_loss: 1490.9176\n",
      "Epoch 3663/100000\n",
      "11/11 [==============================] - 0s 886us/step - loss: 1622.5616 - val_loss: 1490.6165\n",
      "Epoch 3664/100000\n",
      "11/11 [==============================] - 0s 644us/step - loss: 1622.2621 - val_loss: 1490.3153\n",
      "Epoch 3665/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1621.9630 - val_loss: 1490.0142\n",
      "Epoch 3666/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 1621.6641 - val_loss: 1489.7133\n",
      "Epoch 3667/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 1621.3652 - val_loss: 1489.4126\n",
      "Epoch 3668/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 1621.0665 - val_loss: 1489.1118\n",
      "Epoch 3669/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1620.7677 - val_loss: 1488.8114\n",
      "Epoch 3670/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1620.4692 - val_loss: 1488.5109\n",
      "Epoch 3671/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1620.1708 - val_loss: 1488.2108\n",
      "Epoch 3672/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1619.8727 - val_loss: 1487.9106\n",
      "Epoch 3673/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 1619.5743 - val_loss: 1487.6106\n",
      "Epoch 3674/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 1619.2766 - val_loss: 1487.3107\n",
      "Epoch 3675/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 1618.9786 - val_loss: 1487.0110\n",
      "Epoch 3676/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 1618.6808 - val_loss: 1486.7113\n",
      "Epoch 3677/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1618.3832 - val_loss: 1486.4116\n",
      "Epoch 3678/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 1618.0856 - val_loss: 1486.1122\n",
      "Epoch 3679/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1617.7880 - val_loss: 1485.8129\n",
      "Epoch 3680/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1617.4907 - val_loss: 1485.5137\n",
      "Epoch 3681/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 1617.1935 - val_loss: 1485.2147\n",
      "Epoch 3682/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 1616.8965 - val_loss: 1484.9159\n",
      "Epoch 3683/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1616.5997 - val_loss: 1484.6171\n",
      "Epoch 3684/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 1616.3029 - val_loss: 1484.3181\n",
      "Epoch 3685/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1616.0060 - val_loss: 1484.0195\n",
      "Epoch 3686/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1615.7095 - val_loss: 1483.7212\n",
      "Epoch 3687/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 1615.4128 - val_loss: 1483.4227\n",
      "Epoch 3688/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 1615.1168 - val_loss: 1483.1245\n",
      "Epoch 3689/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1614.8207 - val_loss: 1482.8267\n",
      "Epoch 3690/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 1614.5245 - val_loss: 1482.5287\n",
      "Epoch 3691/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 1614.2284 - val_loss: 1482.2308\n",
      "Epoch 3692/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 1613.9325 - val_loss: 1481.9331\n",
      "Epoch 3693/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1613.6367 - val_loss: 1481.6355\n",
      "Epoch 3694/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1613.3409 - val_loss: 1481.3380\n",
      "Epoch 3695/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 1613.0457 - val_loss: 1481.0405\n",
      "Epoch 3696/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1612.7501 - val_loss: 1480.7433\n",
      "Epoch 3697/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 1612.4551 - val_loss: 1480.4462\n",
      "Epoch 3698/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 1612.1600 - val_loss: 1480.1490\n",
      "Epoch 3699/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 1611.8651 - val_loss: 1479.8522\n",
      "Epoch 3700/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1611.5699 - val_loss: 1479.5555\n",
      "Epoch 3701/100000\n",
      "11/11 [==============================] - 0s 203us/step - loss: 1611.2753 - val_loss: 1479.2589\n",
      "Epoch 3702/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1610.9806 - val_loss: 1478.9624\n",
      "Epoch 3703/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1610.6860 - val_loss: 1478.6659\n",
      "Epoch 3704/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 1610.3917 - val_loss: 1478.3696\n",
      "Epoch 3705/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1610.0975 - val_loss: 1478.0735\n",
      "Epoch 3706/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 1609.8032 - val_loss: 1477.7775\n",
      "Epoch 3707/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1609.5093 - val_loss: 1477.4816\n",
      "Epoch 3708/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1609.2152 - val_loss: 1477.1857\n",
      "Epoch 3709/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1608.9215 - val_loss: 1476.8901\n",
      "Epoch 3710/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 1608.6278 - val_loss: 1476.5945\n",
      "Epoch 3711/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 1608.3341 - val_loss: 1476.2992\n",
      "Epoch 3712/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 1608.0409 - val_loss: 1476.0038\n",
      "Epoch 3713/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 1607.7473 - val_loss: 1475.7085\n",
      "Epoch 3714/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 1607.4542 - val_loss: 1475.4136\n",
      "Epoch 3715/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 1607.1613 - val_loss: 1475.1187\n",
      "Epoch 3716/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 1606.8683 - val_loss: 1474.8239\n",
      "Epoch 3717/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 1606.5757 - val_loss: 1474.5291\n",
      "Epoch 3718/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 1606.2827 - val_loss: 1474.2344\n",
      "Epoch 3719/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 1605.9901 - val_loss: 1473.9398\n",
      "Epoch 3720/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1605.6974 - val_loss: 1473.6455\n",
      "Epoch 3721/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 1605.4052 - val_loss: 1473.3514\n",
      "Epoch 3722/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1605.1129 - val_loss: 1473.0571\n",
      "Epoch 3723/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 1604.8208 - val_loss: 1472.7632\n",
      "Epoch 3724/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1604.5289 - val_loss: 1472.4696\n",
      "Epoch 3725/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 1604.2371 - val_loss: 1472.1757\n",
      "Epoch 3726/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1603.9453 - val_loss: 1471.8821\n",
      "Epoch 3727/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 1603.6538 - val_loss: 1471.5886\n",
      "Epoch 3728/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 1603.3621 - val_loss: 1471.2953\n",
      "Epoch 3729/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1603.0708 - val_loss: 1471.0020\n",
      "Epoch 3730/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 1602.7794 - val_loss: 1470.7089\n",
      "Epoch 3731/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 1602.4883 - val_loss: 1470.4159\n",
      "Epoch 3732/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1602.1973 - val_loss: 1470.1229\n",
      "Epoch 3733/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 1601.9064 - val_loss: 1469.8301\n",
      "Epoch 3734/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 1601.6156 - val_loss: 1469.5374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3735/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 1601.3247 - val_loss: 1469.2449\n",
      "Epoch 3736/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1601.0344 - val_loss: 1468.9524\n",
      "Epoch 3737/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1600.7440 - val_loss: 1468.6602\n",
      "Epoch 3738/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1600.4535 - val_loss: 1468.3680\n",
      "Epoch 3739/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 1600.1633 - val_loss: 1468.0759\n",
      "Epoch 3740/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 1599.8734 - val_loss: 1467.7839\n",
      "Epoch 3741/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 1599.5833 - val_loss: 1467.4922\n",
      "Epoch 3742/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 1599.2933 - val_loss: 1467.2004\n",
      "Epoch 3743/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 1599.0038 - val_loss: 1466.9089\n",
      "Epoch 3744/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 1598.7141 - val_loss: 1466.6173\n",
      "Epoch 3745/100000\n",
      "11/11 [==============================] - 0s 652us/step - loss: 1598.4247 - val_loss: 1466.3260\n",
      "Epoch 3746/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 1598.1355 - val_loss: 1466.0347\n",
      "Epoch 3747/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 1597.8461 - val_loss: 1465.7437\n",
      "Epoch 3748/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1597.5570 - val_loss: 1465.4526\n",
      "Epoch 3749/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 1597.2679 - val_loss: 1465.1617\n",
      "Epoch 3750/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1596.9792 - val_loss: 1464.8712\n",
      "Epoch 3751/100000\n",
      "11/11 [==============================] - 0s 902us/step - loss: 1596.6903 - val_loss: 1464.5804\n",
      "Epoch 3752/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1596.4016 - val_loss: 1464.2899\n",
      "Epoch 3753/100000\n",
      "11/11 [==============================] - 0s 723us/step - loss: 1596.1132 - val_loss: 1463.9995\n",
      "Epoch 3754/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 1595.8247 - val_loss: 1463.7092\n",
      "Epoch 3755/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1595.5366 - val_loss: 1463.4192\n",
      "Epoch 3756/100000\n",
      "11/11 [==============================] - 0s 698us/step - loss: 1595.2482 - val_loss: 1463.1293\n",
      "Epoch 3757/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1594.9602 - val_loss: 1462.8394\n",
      "Epoch 3758/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 1594.6724 - val_loss: 1462.5494\n",
      "Epoch 3759/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 1594.3846 - val_loss: 1462.2598\n",
      "Epoch 3760/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1594.0969 - val_loss: 1461.9702\n",
      "Epoch 3761/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1593.8093 - val_loss: 1461.6808\n",
      "Epoch 3762/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1593.5219 - val_loss: 1461.3915\n",
      "Epoch 3763/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1593.2347 - val_loss: 1461.1023\n",
      "Epoch 3764/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 1592.9474 - val_loss: 1460.8132\n",
      "Epoch 3765/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1592.6603 - val_loss: 1460.5242\n",
      "Epoch 3766/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1592.3734 - val_loss: 1460.2355\n",
      "Epoch 3767/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1592.0864 - val_loss: 1459.9468\n",
      "Epoch 3768/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 1591.7997 - val_loss: 1459.6581\n",
      "Epoch 3769/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1591.5128 - val_loss: 1459.3698\n",
      "Epoch 3770/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1591.2266 - val_loss: 1459.0813\n",
      "Epoch 3771/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 1590.9402 - val_loss: 1458.7931\n",
      "Epoch 3772/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1590.6539 - val_loss: 1458.5049\n",
      "Epoch 3773/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 1590.3679 - val_loss: 1458.2169\n",
      "Epoch 3774/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 1590.0819 - val_loss: 1457.9290\n",
      "Epoch 3775/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 1589.7960 - val_loss: 1457.6415\n",
      "Epoch 3776/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 1589.5101 - val_loss: 1457.3536\n",
      "Epoch 3777/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1589.2245 - val_loss: 1457.0663\n",
      "Epoch 3778/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1588.9387 - val_loss: 1456.7786\n",
      "Epoch 3779/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 1588.6534 - val_loss: 1456.4915\n",
      "Epoch 3780/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1588.3683 - val_loss: 1456.2042\n",
      "Epoch 3781/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1588.0829 - val_loss: 1455.9171\n",
      "Epoch 3782/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 1587.7980 - val_loss: 1455.6304\n",
      "Epoch 3783/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 1587.5129 - val_loss: 1455.3436\n",
      "Epoch 3784/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1587.2280 - val_loss: 1455.0568\n",
      "Epoch 3785/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 1586.9434 - val_loss: 1454.7703\n",
      "Epoch 3786/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 1586.6587 - val_loss: 1454.4838\n",
      "Epoch 3787/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1586.3745 - val_loss: 1454.1974\n",
      "Epoch 3788/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 1586.0902 - val_loss: 1453.9113\n",
      "Epoch 3789/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1585.8058 - val_loss: 1453.6251\n",
      "Epoch 3790/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1585.5219 - val_loss: 1453.3394\n",
      "Epoch 3791/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 1585.2378 - val_loss: 1453.0532\n",
      "Epoch 3792/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1584.9539 - val_loss: 1452.7676\n",
      "Epoch 3793/100000\n",
      "11/11 [==============================] - 0s 782us/step - loss: 1584.6699 - val_loss: 1452.4819\n",
      "Epoch 3794/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1584.3864 - val_loss: 1452.1964\n",
      "Epoch 3795/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1584.1030 - val_loss: 1451.9110\n",
      "Epoch 3796/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1583.8195 - val_loss: 1451.6259\n",
      "Epoch 3797/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1583.5363 - val_loss: 1451.3407\n",
      "Epoch 3798/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1583.2531 - val_loss: 1451.0555\n",
      "Epoch 3799/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1582.9700 - val_loss: 1450.7708\n",
      "Epoch 3800/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1582.6870 - val_loss: 1450.4858\n",
      "Epoch 3801/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 1582.4042 - val_loss: 1450.2013\n",
      "Epoch 3802/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1582.1215 - val_loss: 1449.9167\n",
      "Epoch 3803/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 1581.8390 - val_loss: 1449.6322\n",
      "Epoch 3804/100000\n",
      "11/11 [==============================] - 0s 589us/step - loss: 1581.5565 - val_loss: 1449.3481\n",
      "Epoch 3805/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1581.2739 - val_loss: 1449.0637\n",
      "Epoch 3806/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 1580.9918 - val_loss: 1448.7797\n",
      "Epoch 3807/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 1580.7097 - val_loss: 1448.4957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3808/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1580.4279 - val_loss: 1448.2120\n",
      "Epoch 3809/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 1580.1460 - val_loss: 1447.9282\n",
      "Epoch 3810/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 1579.8641 - val_loss: 1447.6445\n",
      "Epoch 3811/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1579.5824 - val_loss: 1447.3611\n",
      "Epoch 3812/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 1579.3009 - val_loss: 1447.0778\n",
      "Epoch 3813/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1579.0195 - val_loss: 1446.7944\n",
      "Epoch 3814/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 1578.7383 - val_loss: 1446.5114\n",
      "Epoch 3815/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1578.4570 - val_loss: 1446.2284\n",
      "Epoch 3816/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 1578.1759 - val_loss: 1445.9454\n",
      "Epoch 3817/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 1577.8954 - val_loss: 1445.6628\n",
      "Epoch 3818/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 1577.6145 - val_loss: 1445.3800\n",
      "Epoch 3819/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1577.3339 - val_loss: 1445.0975\n",
      "Epoch 3820/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 1577.0531 - val_loss: 1444.8149\n",
      "Epoch 3821/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 1576.7726 - val_loss: 1444.5328\n",
      "Epoch 3822/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 1576.4923 - val_loss: 1444.2505\n",
      "Epoch 3823/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1576.2124 - val_loss: 1443.9686\n",
      "Epoch 3824/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1575.9321 - val_loss: 1443.6865\n",
      "Epoch 3825/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 1575.6522 - val_loss: 1443.4049\n",
      "Epoch 3826/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 1575.3723 - val_loss: 1443.1230\n",
      "Epoch 3827/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1575.0927 - val_loss: 1442.8414\n",
      "Epoch 3828/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 1574.8129 - val_loss: 1442.5598\n",
      "Epoch 3829/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 1574.5333 - val_loss: 1442.2786\n",
      "Epoch 3830/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1574.2540 - val_loss: 1441.9973\n",
      "Epoch 3831/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 1573.9747 - val_loss: 1441.7162\n",
      "Epoch 3832/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 1573.6954 - val_loss: 1441.4351\n",
      "Epoch 3833/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1573.4164 - val_loss: 1441.1544\n",
      "Epoch 3834/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 1573.1376 - val_loss: 1440.8735\n",
      "Epoch 3835/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1572.8589 - val_loss: 1440.5930\n",
      "Epoch 3836/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 1572.5801 - val_loss: 1440.3124\n",
      "Epoch 3837/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 1572.3015 - val_loss: 1440.0321\n",
      "Epoch 3838/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 1572.0231 - val_loss: 1439.7517\n",
      "Epoch 3839/100000\n",
      "11/11 [==============================] - 0s 773us/step - loss: 1571.7446 - val_loss: 1439.4716\n",
      "Epoch 3840/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 1571.4667 - val_loss: 1439.1914\n",
      "Epoch 3841/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 1571.1886 - val_loss: 1438.9115\n",
      "Epoch 3842/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 1570.9105 - val_loss: 1438.6317\n",
      "Epoch 3843/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1570.6327 - val_loss: 1438.3519\n",
      "Epoch 3844/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 1570.3547 - val_loss: 1438.0724\n",
      "Epoch 3845/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1570.0773 - val_loss: 1437.7928\n",
      "Epoch 3846/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 1569.7997 - val_loss: 1437.5134\n",
      "Epoch 3847/100000\n",
      "11/11 [==============================] - 0s 683us/step - loss: 1569.5223 - val_loss: 1437.2344\n",
      "Epoch 3848/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 1569.2450 - val_loss: 1436.9551\n",
      "Epoch 3849/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 1568.9680 - val_loss: 1436.6761\n",
      "Epoch 3850/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 1568.6910 - val_loss: 1436.3973\n",
      "Epoch 3851/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 1568.4141 - val_loss: 1436.1184\n",
      "Epoch 3852/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 1568.1375 - val_loss: 1435.8398\n",
      "Epoch 3853/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 1567.8605 - val_loss: 1435.5614\n",
      "Epoch 3854/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1567.5840 - val_loss: 1435.2828\n",
      "Epoch 3855/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1567.3075 - val_loss: 1435.0045\n",
      "Epoch 3856/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 1567.0312 - val_loss: 1434.7264\n",
      "Epoch 3857/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 1566.7550 - val_loss: 1434.4484\n",
      "Epoch 3858/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 1566.4789 - val_loss: 1434.1703\n",
      "Epoch 3859/100000\n",
      "11/11 [==============================] - 0s 609us/step - loss: 1566.2028 - val_loss: 1433.8926\n",
      "Epoch 3860/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 1565.9272 - val_loss: 1433.6147\n",
      "Epoch 3861/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1565.6512 - val_loss: 1433.3374\n",
      "Epoch 3862/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 1565.3757 - val_loss: 1433.0597\n",
      "Epoch 3863/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1565.1001 - val_loss: 1432.7825\n",
      "Epoch 3864/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1564.8246 - val_loss: 1432.5051\n",
      "Epoch 3865/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 1564.5493 - val_loss: 1432.2280\n",
      "Epoch 3866/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1564.2743 - val_loss: 1431.9510\n",
      "Epoch 3867/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 1563.9993 - val_loss: 1431.6742\n",
      "Epoch 3868/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 1563.7242 - val_loss: 1431.3976\n",
      "Epoch 3869/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 1563.4496 - val_loss: 1431.1207\n",
      "Epoch 3870/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1563.1747 - val_loss: 1430.8441\n",
      "Epoch 3871/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1562.9003 - val_loss: 1430.5677\n",
      "Epoch 3872/100000\n",
      "11/11 [==============================] - 0s 593us/step - loss: 1562.6257 - val_loss: 1430.2914\n",
      "Epoch 3873/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 1562.3514 - val_loss: 1430.0153\n",
      "Epoch 3874/100000\n",
      "11/11 [==============================] - 0s 853us/step - loss: 1562.0773 - val_loss: 1429.7391\n",
      "Epoch 3875/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 1561.8031 - val_loss: 1429.4633\n",
      "Epoch 3876/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 1561.5292 - val_loss: 1429.1874\n",
      "Epoch 3877/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1561.2551 - val_loss: 1428.9117\n",
      "Epoch 3878/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 1560.9813 - val_loss: 1428.6361\n",
      "Epoch 3879/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 1560.7075 - val_loss: 1428.3606\n",
      "Epoch 3880/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1560.4343 - val_loss: 1428.0852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3881/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1560.1609 - val_loss: 1427.8098\n",
      "Epoch 3882/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 1559.8876 - val_loss: 1427.5348\n",
      "Epoch 3883/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1559.6144 - val_loss: 1427.2598\n",
      "Epoch 3884/100000\n",
      "11/11 [==============================] - 0s 674us/step - loss: 1559.3413 - val_loss: 1426.9849\n",
      "Epoch 3885/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1559.0684 - val_loss: 1426.7101\n",
      "Epoch 3886/100000\n",
      "11/11 [==============================] - 0s 630us/step - loss: 1558.7954 - val_loss: 1426.4354\n",
      "Epoch 3887/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 1558.5227 - val_loss: 1426.1608\n",
      "Epoch 3888/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1558.2504 - val_loss: 1425.8865\n",
      "Epoch 3889/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 1557.9778 - val_loss: 1425.6122\n",
      "Epoch 3890/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1557.7052 - val_loss: 1425.3378\n",
      "Epoch 3891/100000\n",
      "11/11 [==============================] - 0s 648us/step - loss: 1557.4331 - val_loss: 1425.0637\n",
      "Epoch 3892/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1557.1609 - val_loss: 1424.7898\n",
      "Epoch 3893/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 1556.8888 - val_loss: 1424.5160\n",
      "Epoch 3894/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1556.6172 - val_loss: 1424.2423\n",
      "Epoch 3895/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 1556.3452 - val_loss: 1423.9686\n",
      "Epoch 3896/100000\n",
      "11/11 [==============================] - 0s 801us/step - loss: 1556.0735 - val_loss: 1423.6949\n",
      "Epoch 3897/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1555.8020 - val_loss: 1423.4218\n",
      "Epoch 3898/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 1555.5305 - val_loss: 1423.1484\n",
      "Epoch 3899/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1555.2593 - val_loss: 1422.8751\n",
      "Epoch 3900/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 1554.9882 - val_loss: 1422.6022\n",
      "Epoch 3901/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 1554.7169 - val_loss: 1422.3293\n",
      "Epoch 3902/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 1554.4460 - val_loss: 1422.0566\n",
      "Epoch 3903/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 1554.1753 - val_loss: 1421.7841\n",
      "Epoch 3904/100000\n",
      "11/11 [==============================] - 0s 593us/step - loss: 1553.9044 - val_loss: 1421.5112\n",
      "Epoch 3905/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 1553.6339 - val_loss: 1421.2388\n",
      "Epoch 3906/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 1553.3633 - val_loss: 1420.9664\n",
      "Epoch 3907/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 1553.0929 - val_loss: 1420.6942\n",
      "Epoch 3908/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 1552.8226 - val_loss: 1420.4220\n",
      "Epoch 3909/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 1552.5526 - val_loss: 1420.1500\n",
      "Epoch 3910/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 1552.2825 - val_loss: 1419.8781\n",
      "Epoch 3911/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 1552.0126 - val_loss: 1419.6063\n",
      "Epoch 3912/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1551.7429 - val_loss: 1419.3348\n",
      "Epoch 3913/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 1551.4730 - val_loss: 1419.0631\n",
      "Epoch 3914/100000\n",
      "11/11 [==============================] - 0s 914us/step - loss: 1551.2035 - val_loss: 1418.7919\n",
      "Epoch 3915/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1550.9340 - val_loss: 1418.5206\n",
      "Epoch 3916/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1550.6646 - val_loss: 1418.2494\n",
      "Epoch 3917/100000\n",
      "11/11 [==============================] - 0s 642us/step - loss: 1550.3954 - val_loss: 1417.9783\n",
      "Epoch 3918/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1550.1262 - val_loss: 1417.7073\n",
      "Epoch 3919/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1549.8573 - val_loss: 1417.4364\n",
      "Epoch 3920/100000\n",
      "11/11 [==============================] - 0s 839us/step - loss: 1549.5886 - val_loss: 1417.1659\n",
      "Epoch 3921/100000\n",
      "11/11 [==============================] - 0s 777us/step - loss: 1549.3196 - val_loss: 1416.8953\n",
      "Epoch 3922/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 1549.0509 - val_loss: 1416.6248\n",
      "Epoch 3923/100000\n",
      "11/11 [==============================] - 0s 712us/step - loss: 1548.7827 - val_loss: 1416.3544\n",
      "Epoch 3924/100000\n",
      "11/11 [==============================] - 0s 772us/step - loss: 1548.5142 - val_loss: 1416.0841\n",
      "Epoch 3925/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 1548.2457 - val_loss: 1415.8140\n",
      "Epoch 3926/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 1547.9777 - val_loss: 1415.5438\n",
      "Epoch 3927/100000\n",
      "11/11 [==============================] - 0s 926us/step - loss: 1547.7094 - val_loss: 1415.2739\n",
      "Epoch 3928/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1547.4415 - val_loss: 1415.0043\n",
      "Epoch 3929/100000\n",
      "11/11 [==============================] - 0s 619us/step - loss: 1547.1737 - val_loss: 1414.7345\n",
      "Epoch 3930/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1546.9059 - val_loss: 1414.4650\n",
      "Epoch 3931/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1546.6383 - val_loss: 1414.1954\n",
      "Epoch 3932/100000\n",
      "11/11 [==============================] - 0s 999us/step - loss: 1546.3710 - val_loss: 1413.9261\n",
      "Epoch 3933/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1546.1035 - val_loss: 1413.6570\n",
      "Epoch 3934/100000\n",
      "11/11 [==============================] - 0s 943us/step - loss: 1545.8363 - val_loss: 1413.3878\n",
      "Epoch 3935/100000\n",
      "11/11 [==============================] - 0s 652us/step - loss: 1545.5691 - val_loss: 1413.1190\n",
      "Epoch 3936/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1545.3020 - val_loss: 1412.8500\n",
      "Epoch 3937/100000\n",
      "11/11 [==============================] - 0s 873us/step - loss: 1545.0352 - val_loss: 1412.5813\n",
      "Epoch 3938/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1544.7684 - val_loss: 1412.3126\n",
      "Epoch 3939/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1544.5016 - val_loss: 1412.0441\n",
      "Epoch 3940/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1544.2351 - val_loss: 1411.7758\n",
      "Epoch 3941/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1543.9688 - val_loss: 1411.5073\n",
      "Epoch 3942/100000\n",
      "11/11 [==============================] - 0s 837us/step - loss: 1543.7023 - val_loss: 1411.2393\n",
      "Epoch 3943/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1543.4363 - val_loss: 1410.9712\n",
      "Epoch 3944/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 1543.1698 - val_loss: 1410.7032\n",
      "Epoch 3945/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 1542.9038 - val_loss: 1410.4354\n",
      "Epoch 3946/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1542.6383 - val_loss: 1410.1676\n",
      "Epoch 3947/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 1542.3723 - val_loss: 1409.9001\n",
      "Epoch 3948/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1542.1066 - val_loss: 1409.6327\n",
      "Epoch 3949/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 1541.8409 - val_loss: 1409.3654\n",
      "Epoch 3950/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1541.5757 - val_loss: 1409.0980\n",
      "Epoch 3951/100000\n",
      "11/11 [==============================] - 0s 842us/step - loss: 1541.3104 - val_loss: 1408.8312\n",
      "Epoch 3952/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1541.0450 - val_loss: 1408.5638\n",
      "Epoch 3953/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1540.7802 - val_loss: 1408.2970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3954/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 1540.5151 - val_loss: 1408.0302\n",
      "Epoch 3955/100000\n",
      "11/11 [==============================] - 0s 699us/step - loss: 1540.2504 - val_loss: 1407.7634\n",
      "Epoch 3956/100000\n",
      "11/11 [==============================] - 0s 987us/step - loss: 1539.9855 - val_loss: 1407.4969\n",
      "Epoch 3957/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 1539.7208 - val_loss: 1407.2305\n",
      "Epoch 3958/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1539.4565 - val_loss: 1406.9644\n",
      "Epoch 3959/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 1539.1921 - val_loss: 1406.6979\n",
      "Epoch 3960/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1538.9277 - val_loss: 1406.4318\n",
      "Epoch 3961/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 1538.6637 - val_loss: 1406.1659\n",
      "Epoch 3962/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 1538.3995 - val_loss: 1405.8999\n",
      "Epoch 3963/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1538.1356 - val_loss: 1405.6343\n",
      "Epoch 3964/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 1537.8718 - val_loss: 1405.3687\n",
      "Epoch 3965/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 1537.6079 - val_loss: 1405.1030\n",
      "Epoch 3966/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1537.3446 - val_loss: 1404.8378\n",
      "Epoch 3967/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1537.0812 - val_loss: 1404.5723\n",
      "Epoch 3968/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 1536.8176 - val_loss: 1404.3071\n",
      "Epoch 3969/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1536.5546 - val_loss: 1404.0421\n",
      "Epoch 3970/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1536.2914 - val_loss: 1403.7772\n",
      "Epoch 3971/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1536.0282 - val_loss: 1403.5125\n",
      "Epoch 3972/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1535.7655 - val_loss: 1403.2478\n",
      "Epoch 3973/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1535.5027 - val_loss: 1402.9829\n",
      "Epoch 3974/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1535.2401 - val_loss: 1402.7185\n",
      "Epoch 3975/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1534.9774 - val_loss: 1402.4540\n",
      "Epoch 3976/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 1534.7150 - val_loss: 1402.1899\n",
      "Epoch 3977/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1534.4526 - val_loss: 1401.9257\n",
      "Epoch 3978/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 1534.1903 - val_loss: 1401.6616\n",
      "Epoch 3979/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1533.9285 - val_loss: 1401.3977\n",
      "Epoch 3980/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1533.6665 - val_loss: 1401.1339\n",
      "Epoch 3981/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 1533.4044 - val_loss: 1400.8702\n",
      "Epoch 3982/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 1533.1427 - val_loss: 1400.6068\n",
      "Epoch 3983/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 1532.8813 - val_loss: 1400.3433\n",
      "Epoch 3984/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 1532.6196 - val_loss: 1400.0800\n",
      "Epoch 3985/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 1532.3585 - val_loss: 1399.8165\n",
      "Epoch 3986/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 1532.0969 - val_loss: 1399.5536\n",
      "Epoch 3987/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1531.8359 - val_loss: 1399.2903\n",
      "Epoch 3988/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 1531.5747 - val_loss: 1399.0275\n",
      "Epoch 3989/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1531.3137 - val_loss: 1398.7649\n",
      "Epoch 3990/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1531.0531 - val_loss: 1398.5023\n",
      "Epoch 3991/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1530.7922 - val_loss: 1398.2395\n",
      "Epoch 3992/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 1530.5316 - val_loss: 1397.9772\n",
      "Epoch 3993/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1530.2714 - val_loss: 1397.7148\n",
      "Epoch 3994/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 1530.0106 - val_loss: 1397.4526\n",
      "Epoch 3995/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1529.7504 - val_loss: 1397.1906\n",
      "Epoch 3996/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 1529.4902 - val_loss: 1396.9287\n",
      "Epoch 3997/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1529.2303 - val_loss: 1396.6669\n",
      "Epoch 3998/100000\n",
      "11/11 [==============================] - 0s 203us/step - loss: 1528.9706 - val_loss: 1396.4052\n",
      "Epoch 3999/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 1528.7106 - val_loss: 1396.1434\n",
      "Epoch 4000/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1528.4510 - val_loss: 1395.8820\n",
      "Epoch 4001/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1528.1914 - val_loss: 1395.6204\n",
      "Epoch 4002/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1527.9316 - val_loss: 1395.3593\n",
      "Epoch 4003/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 1527.6724 - val_loss: 1395.0980\n",
      "Epoch 4004/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 1527.4132 - val_loss: 1394.8370\n",
      "Epoch 4005/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1527.1542 - val_loss: 1394.5758\n",
      "Epoch 4006/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 1526.8950 - val_loss: 1394.3152\n",
      "Epoch 4007/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1526.6362 - val_loss: 1394.0543\n",
      "Epoch 4008/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 1526.3773 - val_loss: 1393.7938\n",
      "Epoch 4009/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1526.1187 - val_loss: 1393.5333\n",
      "Epoch 4010/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1525.8602 - val_loss: 1393.2731\n",
      "Epoch 4011/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1525.6017 - val_loss: 1393.0128\n",
      "Epoch 4012/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1525.3434 - val_loss: 1392.7524\n",
      "Epoch 4013/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 1525.0851 - val_loss: 1392.4927\n",
      "Epoch 4014/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1524.8273 - val_loss: 1392.2325\n",
      "Epoch 4015/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 1524.5691 - val_loss: 1391.9727\n",
      "Epoch 4016/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1524.3113 - val_loss: 1391.7131\n",
      "Epoch 4017/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1524.0536 - val_loss: 1391.4536\n",
      "Epoch 4018/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 1523.7958 - val_loss: 1391.1941\n",
      "Epoch 4019/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1523.5383 - val_loss: 1390.9347\n",
      "Epoch 4020/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 1523.2809 - val_loss: 1390.6755\n",
      "Epoch 4021/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 1523.0236 - val_loss: 1390.4164\n",
      "Epoch 4022/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 1522.7664 - val_loss: 1390.1572\n",
      "Epoch 4023/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 1522.5094 - val_loss: 1389.8984\n",
      "Epoch 4024/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1522.2524 - val_loss: 1389.6398\n",
      "Epoch 4025/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 1521.9954 - val_loss: 1389.3810\n",
      "Epoch 4026/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1521.7386 - val_loss: 1389.1224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4027/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1521.4823 - val_loss: 1388.8641\n",
      "Epoch 4028/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1521.2257 - val_loss: 1388.6056\n",
      "Epoch 4029/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1520.9691 - val_loss: 1388.3474\n",
      "Epoch 4030/100000\n",
      "11/11 [==============================] - 0s 644us/step - loss: 1520.7129 - val_loss: 1388.0894\n",
      "Epoch 4031/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1520.4565 - val_loss: 1387.8313\n",
      "Epoch 4032/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 1520.2007 - val_loss: 1387.5734\n",
      "Epoch 4033/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 1519.9446 - val_loss: 1387.3156\n",
      "Epoch 4034/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 1519.6887 - val_loss: 1387.0581\n",
      "Epoch 4035/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 1519.4332 - val_loss: 1386.8004\n",
      "Epoch 4036/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 1519.1774 - val_loss: 1386.5428\n",
      "Epoch 4037/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1518.9220 - val_loss: 1386.2856\n",
      "Epoch 4038/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 1518.6665 - val_loss: 1386.0286\n",
      "Epoch 4039/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 1518.4114 - val_loss: 1385.7715\n",
      "Epoch 4040/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 1518.1562 - val_loss: 1385.5146\n",
      "Epoch 4041/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1517.9011 - val_loss: 1385.2577\n",
      "Epoch 4042/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1517.6461 - val_loss: 1385.0011\n",
      "Epoch 4043/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1517.3915 - val_loss: 1384.7443\n",
      "Epoch 4044/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 1517.1367 - val_loss: 1384.4878\n",
      "Epoch 4045/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 1516.8823 - val_loss: 1384.2313\n",
      "Epoch 4046/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1516.6278 - val_loss: 1383.9751\n",
      "Epoch 4047/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 1516.3734 - val_loss: 1383.7188\n",
      "Epoch 4048/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1516.1191 - val_loss: 1383.4628\n",
      "Epoch 4049/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 1515.8649 - val_loss: 1383.2069\n",
      "Epoch 4050/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1515.6108 - val_loss: 1382.9509\n",
      "Epoch 4051/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 1515.3571 - val_loss: 1382.6952\n",
      "Epoch 4052/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 1515.1031 - val_loss: 1382.4396\n",
      "Epoch 4053/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1514.8495 - val_loss: 1382.1841\n",
      "Epoch 4054/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1514.5958 - val_loss: 1381.9288\n",
      "Epoch 4055/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 1514.3427 - val_loss: 1381.6737\n",
      "Epoch 4056/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 1514.0891 - val_loss: 1381.4183\n",
      "Epoch 4057/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 1513.8359 - val_loss: 1381.1635\n",
      "Epoch 4058/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 1513.5828 - val_loss: 1380.9083\n",
      "Epoch 4059/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 1513.3297 - val_loss: 1380.6534\n",
      "Epoch 4060/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 1513.0769 - val_loss: 1380.3987\n",
      "Epoch 4061/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1512.8241 - val_loss: 1380.1443\n",
      "Epoch 4062/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 1512.5715 - val_loss: 1379.8898\n",
      "Epoch 4063/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1512.3188 - val_loss: 1379.6354\n",
      "Epoch 4064/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 1512.0664 - val_loss: 1379.3811\n",
      "Epoch 4065/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 1511.8140 - val_loss: 1379.1270\n",
      "Epoch 4066/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1511.5618 - val_loss: 1378.8730\n",
      "Epoch 4067/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1511.3098 - val_loss: 1378.6190\n",
      "Epoch 4068/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 1511.0579 - val_loss: 1378.3652\n",
      "Epoch 4069/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1510.8058 - val_loss: 1378.1115\n",
      "Epoch 4070/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1510.5542 - val_loss: 1377.8578\n",
      "Epoch 4071/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 1510.3024 - val_loss: 1377.6046\n",
      "Epoch 4072/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 1510.0511 - val_loss: 1377.3512\n",
      "Epoch 4073/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 1509.7996 - val_loss: 1377.0978\n",
      "Epoch 4074/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 1509.5481 - val_loss: 1376.8447\n",
      "Epoch 4075/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 1509.2970 - val_loss: 1376.5918\n",
      "Epoch 4076/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 1509.0458 - val_loss: 1376.3390\n",
      "Epoch 4077/100000\n",
      "11/11 [==============================] - 0s 718us/step - loss: 1508.7950 - val_loss: 1376.0861\n",
      "Epoch 4078/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1508.5441 - val_loss: 1375.8333\n",
      "Epoch 4079/100000\n",
      "11/11 [==============================] - 0s 644us/step - loss: 1508.2931 - val_loss: 1375.5808\n",
      "Epoch 4080/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 1508.0425 - val_loss: 1375.3282\n",
      "Epoch 4081/100000\n",
      "11/11 [==============================] - 0s 589us/step - loss: 1507.7922 - val_loss: 1375.0760\n",
      "Epoch 4082/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 1507.5415 - val_loss: 1374.8239\n",
      "Epoch 4083/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 1507.2914 - val_loss: 1374.5718\n",
      "Epoch 4084/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1507.0410 - val_loss: 1374.3195\n",
      "Epoch 4085/100000\n",
      "11/11 [==============================] - 0s 914us/step - loss: 1506.7910 - val_loss: 1374.0679\n",
      "Epoch 4086/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 1506.5411 - val_loss: 1373.8159\n",
      "Epoch 4087/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 1506.2911 - val_loss: 1373.5643\n",
      "Epoch 4088/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1506.0415 - val_loss: 1373.3126\n",
      "Epoch 4089/100000\n",
      "11/11 [==============================] - 0s 865us/step - loss: 1505.7917 - val_loss: 1373.0613\n",
      "Epoch 4090/100000\n",
      "11/11 [==============================] - 0s 953us/step - loss: 1505.5422 - val_loss: 1372.8101\n",
      "Epoch 4091/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1505.2928 - val_loss: 1372.5587\n",
      "Epoch 4092/100000\n",
      "11/11 [==============================] - 0s 780us/step - loss: 1505.0435 - val_loss: 1372.3075\n",
      "Epoch 4093/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 1504.7944 - val_loss: 1372.0566\n",
      "Epoch 4094/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 1504.5453 - val_loss: 1371.8055\n",
      "Epoch 4095/100000\n",
      "11/11 [==============================] - 0s 686us/step - loss: 1504.2964 - val_loss: 1371.5548\n",
      "Epoch 4096/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 1504.0474 - val_loss: 1371.3042\n",
      "Epoch 4097/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 1503.7987 - val_loss: 1371.0538\n",
      "Epoch 4098/100000\n",
      "11/11 [==============================] - 0s 973us/step - loss: 1503.5500 - val_loss: 1370.8032\n",
      "Epoch 4099/100000\n",
      "11/11 [==============================] - 0s 779us/step - loss: 1503.3016 - val_loss: 1370.5530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4100/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 1503.0531 - val_loss: 1370.3026\n",
      "Epoch 4101/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1502.8048 - val_loss: 1370.0526\n",
      "Epoch 4102/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 1502.5565 - val_loss: 1369.8026\n",
      "Epoch 4103/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 1502.3085 - val_loss: 1369.5527\n",
      "Epoch 4104/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 1502.0605 - val_loss: 1369.3029\n",
      "Epoch 4105/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 1501.8126 - val_loss: 1369.0533\n",
      "Epoch 4106/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 1501.5649 - val_loss: 1368.8037\n",
      "Epoch 4107/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 1501.3173 - val_loss: 1368.5542\n",
      "Epoch 4108/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 1501.0696 - val_loss: 1368.3051\n",
      "Epoch 4109/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 1500.8224 - val_loss: 1368.0558\n",
      "Epoch 4110/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 1500.5751 - val_loss: 1367.8068\n",
      "Epoch 4111/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 1500.3280 - val_loss: 1367.5576\n",
      "Epoch 4112/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 1500.0808 - val_loss: 1367.3087\n",
      "Epoch 4113/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1499.8339 - val_loss: 1367.0601\n",
      "Epoch 4114/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1499.5870 - val_loss: 1366.8114\n",
      "Epoch 4115/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 1499.3403 - val_loss: 1366.5629\n",
      "Epoch 4116/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1499.0938 - val_loss: 1366.3145\n",
      "Epoch 4117/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1498.8473 - val_loss: 1366.0663\n",
      "Epoch 4118/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 1498.6007 - val_loss: 1365.8180\n",
      "Epoch 4119/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 1498.3546 - val_loss: 1365.5698\n",
      "Epoch 4120/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1498.1083 - val_loss: 1365.3218\n",
      "Epoch 4121/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 1497.8624 - val_loss: 1365.0741\n",
      "Epoch 4122/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 1497.6163 - val_loss: 1364.8262\n",
      "Epoch 4123/100000\n",
      "11/11 [==============================] - 0s 632us/step - loss: 1497.3704 - val_loss: 1364.5786\n",
      "Epoch 4124/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1497.1246 - val_loss: 1364.3309\n",
      "Epoch 4125/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 1496.8790 - val_loss: 1364.0836\n",
      "Epoch 4126/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 1496.6337 - val_loss: 1363.8363\n",
      "Epoch 4127/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 1496.3883 - val_loss: 1363.5894\n",
      "Epoch 4128/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1496.1429 - val_loss: 1363.3420\n",
      "Epoch 4129/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 1495.8977 - val_loss: 1363.0951\n",
      "Epoch 4130/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 1495.6527 - val_loss: 1362.8481\n",
      "Epoch 4131/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1495.4077 - val_loss: 1362.6016\n",
      "Epoch 4132/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 1495.1626 - val_loss: 1362.3547\n",
      "Epoch 4133/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1494.9181 - val_loss: 1362.1082\n",
      "Epoch 4134/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 1494.6737 - val_loss: 1361.8617\n",
      "Epoch 4135/100000\n",
      "11/11 [==============================] - 0s 198us/step - loss: 1494.4290 - val_loss: 1361.6156\n",
      "Epoch 4136/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1494.1844 - val_loss: 1361.3694\n",
      "Epoch 4137/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1493.9402 - val_loss: 1361.1232\n",
      "Epoch 4138/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 1493.6962 - val_loss: 1360.8772\n",
      "Epoch 4139/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1493.4520 - val_loss: 1360.6313\n",
      "Epoch 4140/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 1493.2081 - val_loss: 1360.3856\n",
      "Epoch 4141/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1492.9644 - val_loss: 1360.1399\n",
      "Epoch 4142/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 1492.7206 - val_loss: 1359.8945\n",
      "Epoch 4143/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 1492.4767 - val_loss: 1359.6489\n",
      "Epoch 4144/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1492.2335 - val_loss: 1359.4038\n",
      "Epoch 4145/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1491.9901 - val_loss: 1359.1586\n",
      "Epoch 4146/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 1491.7466 - val_loss: 1358.9135\n",
      "Epoch 4147/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1491.5035 - val_loss: 1358.6685\n",
      "Epoch 4148/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1491.2603 - val_loss: 1358.4237\n",
      "Epoch 4149/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1491.0175 - val_loss: 1358.1790\n",
      "Epoch 4150/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1490.7747 - val_loss: 1357.9341\n",
      "Epoch 4151/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1490.5321 - val_loss: 1357.6897\n",
      "Epoch 4152/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1490.2894 - val_loss: 1357.4453\n",
      "Epoch 4153/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 1490.0469 - val_loss: 1357.2010\n",
      "Epoch 4154/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1489.8042 - val_loss: 1356.9567\n",
      "Epoch 4155/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1489.5621 - val_loss: 1356.7126\n",
      "Epoch 4156/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1489.3198 - val_loss: 1356.4686\n",
      "Epoch 4157/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 1489.0778 - val_loss: 1356.2247\n",
      "Epoch 4158/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1488.8358 - val_loss: 1355.9811\n",
      "Epoch 4159/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1488.5939 - val_loss: 1355.7373\n",
      "Epoch 4160/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 1488.3522 - val_loss: 1355.4940\n",
      "Epoch 4161/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1488.1106 - val_loss: 1355.2505\n",
      "Epoch 4162/100000\n",
      "11/11 [==============================] - 0s 751us/step - loss: 1487.8691 - val_loss: 1355.0071\n",
      "Epoch 4163/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 1487.6277 - val_loss: 1354.7640\n",
      "Epoch 4164/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 1487.3866 - val_loss: 1354.5210\n",
      "Epoch 4165/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1487.1453 - val_loss: 1354.2778\n",
      "Epoch 4166/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 1486.9043 - val_loss: 1354.0350\n",
      "Epoch 4167/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 1486.6632 - val_loss: 1353.7921\n",
      "Epoch 4168/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1486.4224 - val_loss: 1353.5496\n",
      "Epoch 4169/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 1486.1814 - val_loss: 1353.3071\n",
      "Epoch 4170/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1485.9409 - val_loss: 1353.0646\n",
      "Epoch 4171/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1485.7003 - val_loss: 1352.8224\n",
      "Epoch 4172/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 1485.4598 - val_loss: 1352.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4173/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 1485.2196 - val_loss: 1352.3381\n",
      "Epoch 4174/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 1484.9795 - val_loss: 1352.0961\n",
      "Epoch 4175/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1484.7394 - val_loss: 1351.8541\n",
      "Epoch 4176/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1484.4995 - val_loss: 1351.6124\n",
      "Epoch 4177/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1484.2596 - val_loss: 1351.3706\n",
      "Epoch 4178/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 1484.0197 - val_loss: 1351.1290\n",
      "Epoch 4179/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1483.7800 - val_loss: 1350.8878\n",
      "Epoch 4180/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1483.5405 - val_loss: 1350.6465\n",
      "Epoch 4181/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1483.3013 - val_loss: 1350.4050\n",
      "Epoch 4182/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 1483.0616 - val_loss: 1350.1641\n",
      "Epoch 4183/100000\n",
      "11/11 [==============================] - 0s 674us/step - loss: 1482.8225 - val_loss: 1349.9230\n",
      "Epoch 4184/100000\n",
      "11/11 [==============================] - 0s 828us/step - loss: 1482.5836 - val_loss: 1349.6821\n",
      "Epoch 4185/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1482.3446 - val_loss: 1349.4414\n",
      "Epoch 4186/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 1482.1056 - val_loss: 1349.2007\n",
      "Epoch 4187/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1481.8668 - val_loss: 1348.9601\n",
      "Epoch 4188/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 1481.6282 - val_loss: 1348.7196\n",
      "Epoch 4189/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 1481.3896 - val_loss: 1348.4795\n",
      "Epoch 4190/100000\n",
      "11/11 [==============================] - 0s 678us/step - loss: 1481.1512 - val_loss: 1348.2391\n",
      "Epoch 4191/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 1480.9130 - val_loss: 1347.9989\n",
      "Epoch 4192/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 1480.6748 - val_loss: 1347.7589\n",
      "Epoch 4193/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1480.4365 - val_loss: 1347.5192\n",
      "Epoch 4194/100000\n",
      "11/11 [==============================] - 0s 624us/step - loss: 1480.1985 - val_loss: 1347.2793\n",
      "Epoch 4195/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1479.9608 - val_loss: 1347.0398\n",
      "Epoch 4196/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 1479.7229 - val_loss: 1346.8000\n",
      "Epoch 4197/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 1479.4854 - val_loss: 1346.5607\n",
      "Epoch 4198/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1479.2476 - val_loss: 1346.3213\n",
      "Epoch 4199/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 1479.0101 - val_loss: 1346.0819\n",
      "Epoch 4200/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 1478.7726 - val_loss: 1345.8429\n",
      "Epoch 4201/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1478.5355 - val_loss: 1345.6040\n",
      "Epoch 4202/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1478.2985 - val_loss: 1345.3651\n",
      "Epoch 4203/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 1478.0616 - val_loss: 1345.1262\n",
      "Epoch 4204/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1477.8247 - val_loss: 1344.8875\n",
      "Epoch 4205/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 1477.5879 - val_loss: 1344.6489\n",
      "Epoch 4206/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1477.3511 - val_loss: 1344.4103\n",
      "Epoch 4207/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 1477.1144 - val_loss: 1344.1721\n",
      "Epoch 4208/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1476.8781 - val_loss: 1343.9341\n",
      "Epoch 4209/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1476.6417 - val_loss: 1343.6957\n",
      "Epoch 4210/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 1476.4058 - val_loss: 1343.4579\n",
      "Epoch 4211/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1476.1694 - val_loss: 1343.2196\n",
      "Epoch 4212/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 1475.9335 - val_loss: 1342.9821\n",
      "Epoch 4213/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1475.6973 - val_loss: 1342.7443\n",
      "Epoch 4214/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1475.4617 - val_loss: 1342.5067\n",
      "Epoch 4215/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 1475.2261 - val_loss: 1342.2690\n",
      "Epoch 4216/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1474.9904 - val_loss: 1342.0317\n",
      "Epoch 4217/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 1474.7548 - val_loss: 1341.7944\n",
      "Epoch 4218/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1474.5194 - val_loss: 1341.5575\n",
      "Epoch 4219/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 1474.2842 - val_loss: 1341.3203\n",
      "Epoch 4220/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1474.0490 - val_loss: 1341.0836\n",
      "Epoch 4221/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 1473.8140 - val_loss: 1340.8466\n",
      "Epoch 4222/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1473.5792 - val_loss: 1340.6099\n",
      "Epoch 4223/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1473.3442 - val_loss: 1340.3732\n",
      "Epoch 4224/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 1473.1095 - val_loss: 1340.1367\n",
      "Epoch 4225/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1472.8751 - val_loss: 1339.9003\n",
      "Epoch 4226/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 1472.6404 - val_loss: 1339.6641\n",
      "Epoch 4227/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 1472.4059 - val_loss: 1339.4279\n",
      "Epoch 4228/100000\n",
      "11/11 [==============================] - 0s 670us/step - loss: 1472.1718 - val_loss: 1339.1917\n",
      "Epoch 4229/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1471.9376 - val_loss: 1338.9559\n",
      "Epoch 4230/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1471.7036 - val_loss: 1338.7200\n",
      "Epoch 4231/100000\n",
      "11/11 [==============================] - 0s 905us/step - loss: 1471.4696 - val_loss: 1338.4844\n",
      "Epoch 4232/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1471.2358 - val_loss: 1338.2487\n",
      "Epoch 4233/100000\n",
      "11/11 [==============================] - 0s 698us/step - loss: 1471.0020 - val_loss: 1338.0132\n",
      "Epoch 4234/100000\n",
      "11/11 [==============================] - 0s 888us/step - loss: 1470.7684 - val_loss: 1337.7778\n",
      "Epoch 4235/100000\n",
      "11/11 [==============================] - 0s 815us/step - loss: 1470.5350 - val_loss: 1337.5425\n",
      "Epoch 4236/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 1470.3015 - val_loss: 1337.3071\n",
      "Epoch 4237/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1470.0682 - val_loss: 1337.0723\n",
      "Epoch 4238/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1469.8351 - val_loss: 1336.8374\n",
      "Epoch 4239/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1469.6018 - val_loss: 1336.6024\n",
      "Epoch 4240/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1469.3690 - val_loss: 1336.3677\n",
      "Epoch 4241/100000\n",
      "11/11 [==============================] - 0s 723us/step - loss: 1469.1360 - val_loss: 1336.1331\n",
      "Epoch 4242/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1468.9032 - val_loss: 1335.8986\n",
      "Epoch 4243/100000\n",
      "11/11 [==============================] - 0s 838us/step - loss: 1468.6707 - val_loss: 1335.6641\n",
      "Epoch 4244/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 1468.4381 - val_loss: 1335.4296\n",
      "Epoch 4245/100000\n",
      "11/11 [==============================] - 0s 759us/step - loss: 1468.2054 - val_loss: 1335.1954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4246/100000\n",
      "11/11 [==============================] - 0s 843us/step - loss: 1467.9733 - val_loss: 1334.9613\n",
      "Epoch 4247/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 1467.7411 - val_loss: 1334.7274\n",
      "Epoch 4248/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 1467.5089 - val_loss: 1334.4934\n",
      "Epoch 4249/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 1467.2769 - val_loss: 1334.2598\n",
      "Epoch 4250/100000\n",
      "11/11 [==============================] - 0s 799us/step - loss: 1467.0453 - val_loss: 1334.0261\n",
      "Epoch 4251/100000\n",
      "11/11 [==============================] - 0s 621us/step - loss: 1466.8134 - val_loss: 1333.7925\n",
      "Epoch 4252/100000\n",
      "11/11 [==============================] - 0s 903us/step - loss: 1466.5817 - val_loss: 1333.5590\n",
      "Epoch 4253/100000\n",
      "11/11 [==============================] - 0s 974us/step - loss: 1466.3501 - val_loss: 1333.3257\n",
      "Epoch 4254/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1466.1187 - val_loss: 1333.0923\n",
      "Epoch 4255/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 1465.8873 - val_loss: 1332.8594\n",
      "Epoch 4256/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1465.6559 - val_loss: 1332.6265\n",
      "Epoch 4257/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1465.4250 - val_loss: 1332.3934\n",
      "Epoch 4258/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 1465.1938 - val_loss: 1332.1606\n",
      "Epoch 4259/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 1464.9630 - val_loss: 1331.9280\n",
      "Epoch 4260/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 1464.7322 - val_loss: 1331.6953\n",
      "Epoch 4261/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1464.5013 - val_loss: 1331.4630\n",
      "Epoch 4262/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1464.2710 - val_loss: 1331.2306\n",
      "Epoch 4263/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 1464.0404 - val_loss: 1330.9983\n",
      "Epoch 4264/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1463.8101 - val_loss: 1330.7662\n",
      "Epoch 4265/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1463.5800 - val_loss: 1330.5341\n",
      "Epoch 4266/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1463.3497 - val_loss: 1330.3022\n",
      "Epoch 4267/100000\n",
      "11/11 [==============================] - 0s 920us/step - loss: 1463.1196 - val_loss: 1330.0703\n",
      "Epoch 4268/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 1462.8898 - val_loss: 1329.8385\n",
      "Epoch 4269/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1462.6598 - val_loss: 1329.6072\n",
      "Epoch 4270/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1462.4301 - val_loss: 1329.3755\n",
      "Epoch 4271/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1462.2004 - val_loss: 1329.1440\n",
      "Epoch 4272/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1461.9711 - val_loss: 1328.9130\n",
      "Epoch 4273/100000\n",
      "11/11 [==============================] - 0s 757us/step - loss: 1461.7416 - val_loss: 1328.6816\n",
      "Epoch 4274/100000\n",
      "11/11 [==============================] - 0s 866us/step - loss: 1461.5122 - val_loss: 1328.4507\n",
      "Epoch 4275/100000\n",
      "11/11 [==============================] - 0s 947us/step - loss: 1461.2830 - val_loss: 1328.2196\n",
      "Epoch 4276/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 1461.0541 - val_loss: 1327.9888\n",
      "Epoch 4277/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 1460.8251 - val_loss: 1327.7581\n",
      "Epoch 4278/100000\n",
      "11/11 [==============================] - 0s 904us/step - loss: 1460.5963 - val_loss: 1327.5275\n",
      "Epoch 4279/100000\n",
      "11/11 [==============================] - 0s 635us/step - loss: 1460.3676 - val_loss: 1327.2970\n",
      "Epoch 4280/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1460.1387 - val_loss: 1327.0664\n",
      "Epoch 4281/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 1459.9103 - val_loss: 1326.8362\n",
      "Epoch 4282/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1459.6818 - val_loss: 1326.6058\n",
      "Epoch 4283/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1459.4536 - val_loss: 1326.3759\n",
      "Epoch 4284/100000\n",
      "11/11 [==============================] - 0s 816us/step - loss: 1459.2252 - val_loss: 1326.1460\n",
      "Epoch 4285/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 1458.9973 - val_loss: 1325.9161\n",
      "Epoch 4286/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1458.7693 - val_loss: 1325.6863\n",
      "Epoch 4287/100000\n",
      "11/11 [==============================] - 0s 851us/step - loss: 1458.5414 - val_loss: 1325.4565\n",
      "Epoch 4288/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 1458.3136 - val_loss: 1325.2271\n",
      "Epoch 4289/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1458.0859 - val_loss: 1324.9977\n",
      "Epoch 4290/100000\n",
      "11/11 [==============================] - 0s 929us/step - loss: 1457.8583 - val_loss: 1324.7683\n",
      "Epoch 4291/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 1457.6309 - val_loss: 1324.5391\n",
      "Epoch 4292/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1457.4036 - val_loss: 1324.3101\n",
      "Epoch 4293/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 1457.1761 - val_loss: 1324.0809\n",
      "Epoch 4294/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1456.9491 - val_loss: 1323.8519\n",
      "Epoch 4295/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 1456.7220 - val_loss: 1323.6232\n",
      "Epoch 4296/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1456.4952 - val_loss: 1323.3945\n",
      "Epoch 4297/100000\n",
      "11/11 [==============================] - 0s 564us/step - loss: 1456.2684 - val_loss: 1323.1659\n",
      "Epoch 4298/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1456.0415 - val_loss: 1322.9374\n",
      "Epoch 4299/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1455.8149 - val_loss: 1322.7090\n",
      "Epoch 4300/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1455.5885 - val_loss: 1322.4806\n",
      "Epoch 4301/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1455.3622 - val_loss: 1322.2527\n",
      "Epoch 4302/100000\n",
      "11/11 [==============================] - 0s 970us/step - loss: 1455.1357 - val_loss: 1322.0245\n",
      "Epoch 4303/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1454.9097 - val_loss: 1321.7968\n",
      "Epoch 4304/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 1454.6837 - val_loss: 1321.5688\n",
      "Epoch 4305/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1454.4578 - val_loss: 1321.3411\n",
      "Epoch 4306/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1454.2319 - val_loss: 1321.1134\n",
      "Epoch 4307/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1454.0062 - val_loss: 1320.8859\n",
      "Epoch 4308/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1453.7805 - val_loss: 1320.6583\n",
      "Epoch 4309/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1453.5547 - val_loss: 1320.4315\n",
      "Epoch 4310/100000\n",
      "11/11 [==============================] - 0s 728us/step - loss: 1453.3296 - val_loss: 1320.2043\n",
      "Epoch 4311/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 1453.1042 - val_loss: 1319.9771\n",
      "Epoch 4312/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 1452.8790 - val_loss: 1319.7501\n",
      "Epoch 4313/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1452.6541 - val_loss: 1319.5234\n",
      "Epoch 4314/100000\n",
      "11/11 [==============================] - 0s 816us/step - loss: 1452.4290 - val_loss: 1319.2964\n",
      "Epoch 4315/100000\n",
      "11/11 [==============================] - 0s 736us/step - loss: 1452.2040 - val_loss: 1319.0698\n",
      "Epoch 4316/100000\n",
      "11/11 [==============================] - 0s 682us/step - loss: 1451.9794 - val_loss: 1318.8434\n",
      "Epoch 4317/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1451.7544 - val_loss: 1318.6167\n",
      "Epoch 4318/100000\n",
      "11/11 [==============================] - 0s 957us/step - loss: 1451.5302 - val_loss: 1318.3905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4319/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1451.3055 - val_loss: 1318.1642\n",
      "Epoch 4320/100000\n",
      "11/11 [==============================] - 0s 916us/step - loss: 1451.0813 - val_loss: 1317.9381\n",
      "Epoch 4321/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1450.8569 - val_loss: 1317.7120\n",
      "Epoch 4322/100000\n",
      "11/11 [==============================] - 0s 803us/step - loss: 1450.6327 - val_loss: 1317.4861\n",
      "Epoch 4323/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1450.4087 - val_loss: 1317.2604\n",
      "Epoch 4324/100000\n",
      "11/11 [==============================] - 0s 677us/step - loss: 1450.1851 - val_loss: 1317.0347\n",
      "Epoch 4325/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1449.9609 - val_loss: 1316.8092\n",
      "Epoch 4326/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1449.7372 - val_loss: 1316.5839\n",
      "Epoch 4327/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 1449.5138 - val_loss: 1316.3583\n",
      "Epoch 4328/100000\n",
      "11/11 [==============================] - 0s 994us/step - loss: 1449.2902 - val_loss: 1316.1332\n",
      "Epoch 4329/100000\n",
      "11/11 [==============================] - 0s 743us/step - loss: 1449.0668 - val_loss: 1315.9078\n",
      "Epoch 4330/100000\n",
      "11/11 [==============================] - 0s 677us/step - loss: 1448.8434 - val_loss: 1315.6829\n",
      "Epoch 4331/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1448.6204 - val_loss: 1315.4580\n",
      "Epoch 4332/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1448.3973 - val_loss: 1315.2329\n",
      "Epoch 4333/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 1448.1743 - val_loss: 1315.0083\n",
      "Epoch 4334/100000\n",
      "11/11 [==============================] - 0s 831us/step - loss: 1447.9515 - val_loss: 1314.7837\n",
      "Epoch 4335/100000\n",
      "11/11 [==============================] - 0s 952us/step - loss: 1447.7288 - val_loss: 1314.5593\n",
      "Epoch 4336/100000\n",
      "11/11 [==============================] - 0s 877us/step - loss: 1447.5061 - val_loss: 1314.3348\n",
      "Epoch 4337/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 1447.2837 - val_loss: 1314.1106\n",
      "Epoch 4338/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1447.0612 - val_loss: 1313.8864\n",
      "Epoch 4339/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1446.8389 - val_loss: 1313.6622\n",
      "Epoch 4340/100000\n",
      "11/11 [==============================] - 0s 953us/step - loss: 1446.6167 - val_loss: 1313.4384\n",
      "Epoch 4341/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1446.3945 - val_loss: 1313.2144\n",
      "Epoch 4342/100000\n",
      "11/11 [==============================] - 0s 976us/step - loss: 1446.1725 - val_loss: 1312.9907\n",
      "Epoch 4343/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1445.9507 - val_loss: 1312.7671\n",
      "Epoch 4344/100000\n",
      "11/11 [==============================] - 0s 818us/step - loss: 1445.7288 - val_loss: 1312.5433\n",
      "Epoch 4345/100000\n",
      "11/11 [==============================] - 0s 755us/step - loss: 1445.5073 - val_loss: 1312.3201\n",
      "Epoch 4346/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1445.2856 - val_loss: 1312.0966\n",
      "Epoch 4347/100000\n",
      "11/11 [==============================] - 0s 695us/step - loss: 1445.0641 - val_loss: 1311.8734\n",
      "Epoch 4348/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1444.8427 - val_loss: 1311.6504\n",
      "Epoch 4349/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1444.6216 - val_loss: 1311.4274\n",
      "Epoch 4350/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 1444.4003 - val_loss: 1311.2045\n",
      "Epoch 4351/100000\n",
      "11/11 [==============================] - 0s 726us/step - loss: 1444.1793 - val_loss: 1310.9814\n",
      "Epoch 4352/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 1443.9585 - val_loss: 1310.7589\n",
      "Epoch 4353/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 1443.7375 - val_loss: 1310.5363\n",
      "Epoch 4354/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1443.5167 - val_loss: 1310.3140\n",
      "Epoch 4355/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 1443.2961 - val_loss: 1310.0917\n",
      "Epoch 4356/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 1443.0758 - val_loss: 1309.8691\n",
      "Epoch 4357/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 1442.8553 - val_loss: 1309.6471\n",
      "Epoch 4358/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1442.6349 - val_loss: 1309.4249\n",
      "Epoch 4359/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 1442.4148 - val_loss: 1309.2030\n",
      "Epoch 4360/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1442.1947 - val_loss: 1308.9812\n",
      "Epoch 4361/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1441.9747 - val_loss: 1308.7595\n",
      "Epoch 4362/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 1441.7548 - val_loss: 1308.5378\n",
      "Epoch 4363/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1441.5350 - val_loss: 1308.3163\n",
      "Epoch 4364/100000\n",
      "11/11 [==============================] - 0s 674us/step - loss: 1441.3153 - val_loss: 1308.0950\n",
      "Epoch 4365/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1441.0961 - val_loss: 1307.8735\n",
      "Epoch 4366/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1440.8765 - val_loss: 1307.6523\n",
      "Epoch 4367/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1440.6570 - val_loss: 1307.4313\n",
      "Epoch 4368/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1440.4380 - val_loss: 1307.2102\n",
      "Epoch 4369/100000\n",
      "11/11 [==============================] - 0s 691us/step - loss: 1440.2188 - val_loss: 1306.9894\n",
      "Epoch 4370/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1439.9999 - val_loss: 1306.7687\n",
      "Epoch 4371/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 1439.7808 - val_loss: 1306.5480\n",
      "Epoch 4372/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 1439.5619 - val_loss: 1306.3274\n",
      "Epoch 4373/100000\n",
      "11/11 [==============================] - 0s 656us/step - loss: 1439.3433 - val_loss: 1306.1069\n",
      "Epoch 4374/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1439.1246 - val_loss: 1305.8867\n",
      "Epoch 4375/100000\n",
      "11/11 [==============================] - 0s 994us/step - loss: 1438.9061 - val_loss: 1305.6664\n",
      "Epoch 4376/100000\n",
      "11/11 [==============================] - 0s 828us/step - loss: 1438.6877 - val_loss: 1305.4462\n",
      "Epoch 4377/100000\n",
      "11/11 [==============================] - 0s 629us/step - loss: 1438.4695 - val_loss: 1305.2261\n",
      "Epoch 4378/100000\n",
      "11/11 [==============================] - 0s 782us/step - loss: 1438.2513 - val_loss: 1305.0062\n",
      "Epoch 4379/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1438.0332 - val_loss: 1304.7864\n",
      "Epoch 4380/100000\n",
      "11/11 [==============================] - 0s 658us/step - loss: 1437.8153 - val_loss: 1304.5668\n",
      "Epoch 4381/100000\n",
      "11/11 [==============================] - 0s 680us/step - loss: 1437.5977 - val_loss: 1304.3470\n",
      "Epoch 4382/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1437.3796 - val_loss: 1304.1274\n",
      "Epoch 4383/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 1437.1622 - val_loss: 1303.9083\n",
      "Epoch 4384/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 1436.9445 - val_loss: 1303.6887\n",
      "Epoch 4385/100000\n",
      "11/11 [==============================] - 0s 678us/step - loss: 1436.7271 - val_loss: 1303.4697\n",
      "Epoch 4386/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 1436.5096 - val_loss: 1303.2506\n",
      "Epoch 4387/100000\n",
      "11/11 [==============================] - 0s 678us/step - loss: 1436.2925 - val_loss: 1303.0316\n",
      "Epoch 4388/100000\n",
      "11/11 [==============================] - 0s 768us/step - loss: 1436.0753 - val_loss: 1302.8125\n",
      "Epoch 4389/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1435.8583 - val_loss: 1302.5939\n",
      "Epoch 4390/100000\n",
      "11/11 [==============================] - 0s 718us/step - loss: 1435.6415 - val_loss: 1302.3751\n",
      "Epoch 4391/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1435.4247 - val_loss: 1302.1567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4392/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 1435.2079 - val_loss: 1301.9382\n",
      "Epoch 4393/100000\n",
      "11/11 [==============================] - 0s 949us/step - loss: 1434.9913 - val_loss: 1301.7200\n",
      "Epoch 4394/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1434.7749 - val_loss: 1301.5017\n",
      "Epoch 4395/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 1434.5583 - val_loss: 1301.2836\n",
      "Epoch 4396/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 1434.3422 - val_loss: 1301.0656\n",
      "Epoch 4397/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1434.1260 - val_loss: 1300.8475\n",
      "Epoch 4398/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 1433.9098 - val_loss: 1300.6298\n",
      "Epoch 4399/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1433.6938 - val_loss: 1300.4121\n",
      "Epoch 4400/100000\n",
      "11/11 [==============================] - 0s 941us/step - loss: 1433.4780 - val_loss: 1300.1945\n",
      "Epoch 4401/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1433.2623 - val_loss: 1299.9769\n",
      "Epoch 4402/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 1433.0468 - val_loss: 1299.7596\n",
      "Epoch 4403/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 1432.8312 - val_loss: 1299.5422\n",
      "Epoch 4404/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 1432.6157 - val_loss: 1299.3252\n",
      "Epoch 4405/100000\n",
      "11/11 [==============================] - 0s 614us/step - loss: 1432.4003 - val_loss: 1299.1079\n",
      "Epoch 4406/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1432.1851 - val_loss: 1298.8910\n",
      "Epoch 4407/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1431.9698 - val_loss: 1298.6740\n",
      "Epoch 4408/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 1431.7550 - val_loss: 1298.4575\n",
      "Epoch 4409/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 1431.5399 - val_loss: 1298.2406\n",
      "Epoch 4410/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1431.3252 - val_loss: 1298.0242\n",
      "Epoch 4411/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 1431.1106 - val_loss: 1297.8076\n",
      "Epoch 4412/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1430.8960 - val_loss: 1297.5913\n",
      "Epoch 4413/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1430.6815 - val_loss: 1297.3751\n",
      "Epoch 4414/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1430.4672 - val_loss: 1297.1587\n",
      "Epoch 4415/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1430.2528 - val_loss: 1296.9431\n",
      "Epoch 4416/100000\n",
      "11/11 [==============================] - 0s 715us/step - loss: 1430.0386 - val_loss: 1296.7271\n",
      "Epoch 4417/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1429.8245 - val_loss: 1296.5112\n",
      "Epoch 4418/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1429.6105 - val_loss: 1296.2954\n",
      "Epoch 4419/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1429.3966 - val_loss: 1296.0800\n",
      "Epoch 4420/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1429.1830 - val_loss: 1295.8644\n",
      "Epoch 4421/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 1428.9695 - val_loss: 1295.6489\n",
      "Epoch 4422/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1428.7557 - val_loss: 1295.4336\n",
      "Epoch 4423/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 1428.5425 - val_loss: 1295.2185\n",
      "Epoch 4424/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1428.3289 - val_loss: 1295.0034\n",
      "Epoch 4425/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 1428.1158 - val_loss: 1294.7886\n",
      "Epoch 4426/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 1427.9026 - val_loss: 1294.5736\n",
      "Epoch 4427/100000\n",
      "11/11 [==============================] - 0s 917us/step - loss: 1427.6896 - val_loss: 1294.3586\n",
      "Epoch 4428/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 1427.4766 - val_loss: 1294.1442\n",
      "Epoch 4429/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1427.2638 - val_loss: 1293.9297\n",
      "Epoch 4430/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 1427.0510 - val_loss: 1293.7152\n",
      "Epoch 4431/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1426.8385 - val_loss: 1293.5009\n",
      "Epoch 4432/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 1426.6260 - val_loss: 1293.2867\n",
      "Epoch 4433/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 1426.4137 - val_loss: 1293.0724\n",
      "Epoch 4434/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1426.2012 - val_loss: 1292.8584\n",
      "Epoch 4435/100000\n",
      "11/11 [==============================] - 0s 724us/step - loss: 1425.9891 - val_loss: 1292.6445\n",
      "Epoch 4436/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 1425.7770 - val_loss: 1292.4308\n",
      "Epoch 4437/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1425.5653 - val_loss: 1292.2168\n",
      "Epoch 4438/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 1425.3531 - val_loss: 1292.0032\n",
      "Epoch 4439/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 1425.1415 - val_loss: 1291.7899\n",
      "Epoch 4440/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 1424.9298 - val_loss: 1291.5764\n",
      "Epoch 4441/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 1424.7184 - val_loss: 1291.3632\n",
      "Epoch 4442/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1424.5068 - val_loss: 1291.1499\n",
      "Epoch 4443/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 1424.2954 - val_loss: 1290.9366\n",
      "Epoch 4444/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 1424.0841 - val_loss: 1290.7238\n",
      "Epoch 4445/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 1423.8729 - val_loss: 1290.5109\n",
      "Epoch 4446/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 1423.6620 - val_loss: 1290.2981\n",
      "Epoch 4447/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 1423.4510 - val_loss: 1290.0854\n",
      "Epoch 4448/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 1423.2401 - val_loss: 1289.8729\n",
      "Epoch 4449/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1423.0294 - val_loss: 1289.6604\n",
      "Epoch 4450/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 1422.8187 - val_loss: 1289.4481\n",
      "Epoch 4451/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1422.6083 - val_loss: 1289.2358\n",
      "Epoch 4452/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1422.3981 - val_loss: 1289.0236\n",
      "Epoch 4453/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1422.1876 - val_loss: 1288.8116\n",
      "Epoch 4454/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1421.9774 - val_loss: 1288.5996\n",
      "Epoch 4455/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 1421.7672 - val_loss: 1288.3878\n",
      "Epoch 4456/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1421.5574 - val_loss: 1288.1759\n",
      "Epoch 4457/100000\n",
      "11/11 [==============================] - 0s 927us/step - loss: 1421.3474 - val_loss: 1287.9645\n",
      "Epoch 4458/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 1421.1378 - val_loss: 1287.7528\n",
      "Epoch 4459/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1420.9279 - val_loss: 1287.5415\n",
      "Epoch 4460/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1420.7183 - val_loss: 1287.3301\n",
      "Epoch 4461/100000\n",
      "11/11 [==============================] - 0s 687us/step - loss: 1420.5088 - val_loss: 1287.1190\n",
      "Epoch 4462/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1420.2996 - val_loss: 1286.9077\n",
      "Epoch 4463/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1420.0901 - val_loss: 1286.6969\n",
      "Epoch 4464/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1419.8810 - val_loss: 1286.4860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4465/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 1419.6720 - val_loss: 1286.2751\n",
      "Epoch 4466/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1419.4630 - val_loss: 1286.0645\n",
      "Epoch 4467/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 1419.2540 - val_loss: 1285.8539\n",
      "Epoch 4468/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1419.0454 - val_loss: 1285.6433\n",
      "Epoch 4469/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1418.8368 - val_loss: 1285.4330\n",
      "Epoch 4470/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1418.6282 - val_loss: 1285.2227\n",
      "Epoch 4471/100000\n",
      "11/11 [==============================] - 0s 774us/step - loss: 1418.4198 - val_loss: 1285.0126\n",
      "Epoch 4472/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1418.2114 - val_loss: 1284.8024\n",
      "Epoch 4473/100000\n",
      "11/11 [==============================] - 0s 703us/step - loss: 1418.0032 - val_loss: 1284.5925\n",
      "Epoch 4474/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 1417.7950 - val_loss: 1284.3827\n",
      "Epoch 4475/100000\n",
      "11/11 [==============================] - 0s 634us/step - loss: 1417.5870 - val_loss: 1284.1730\n",
      "Epoch 4476/100000\n",
      "11/11 [==============================] - 0s 891us/step - loss: 1417.3792 - val_loss: 1283.9631\n",
      "Epoch 4477/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1417.1711 - val_loss: 1283.7535\n",
      "Epoch 4478/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 1416.9636 - val_loss: 1283.5441\n",
      "Epoch 4479/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1416.7561 - val_loss: 1283.3348\n",
      "Epoch 4480/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1416.5485 - val_loss: 1283.1256\n",
      "Epoch 4481/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1416.3411 - val_loss: 1282.9165\n",
      "Epoch 4482/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1416.1339 - val_loss: 1282.7073\n",
      "Epoch 4483/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1415.9265 - val_loss: 1282.4984\n",
      "Epoch 4484/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 1415.7196 - val_loss: 1282.2896\n",
      "Epoch 4485/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 1415.5126 - val_loss: 1282.0809\n",
      "Epoch 4486/100000\n",
      "11/11 [==============================] - 0s 737us/step - loss: 1415.3055 - val_loss: 1281.8722\n",
      "Epoch 4487/100000\n",
      "11/11 [==============================] - 0s 192us/step - loss: 1415.0988 - val_loss: 1281.6636\n",
      "Epoch 4488/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1414.8922 - val_loss: 1281.4553\n",
      "Epoch 4489/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1414.6855 - val_loss: 1281.2469\n",
      "Epoch 4490/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 1414.4790 - val_loss: 1281.0389\n",
      "Epoch 4491/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1414.2728 - val_loss: 1280.8307\n",
      "Epoch 4492/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 1414.0665 - val_loss: 1280.6227\n",
      "Epoch 4493/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 1413.8602 - val_loss: 1280.4148\n",
      "Epoch 4494/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1413.6542 - val_loss: 1280.2070\n",
      "Epoch 4495/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1413.4482 - val_loss: 1279.9993\n",
      "Epoch 4496/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 1413.2423 - val_loss: 1279.7916\n",
      "Epoch 4497/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 1413.0365 - val_loss: 1279.5842\n",
      "Epoch 4498/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1412.8309 - val_loss: 1279.3768\n",
      "Epoch 4499/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1412.6255 - val_loss: 1279.1697\n",
      "Epoch 4500/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1412.4200 - val_loss: 1278.9624\n",
      "Epoch 4501/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 1412.2147 - val_loss: 1278.7554\n",
      "Epoch 4502/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1412.0095 - val_loss: 1278.5483\n",
      "Epoch 4503/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1411.8042 - val_loss: 1278.3416\n",
      "Epoch 4504/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1411.5992 - val_loss: 1278.1348\n",
      "Epoch 4505/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 1411.3944 - val_loss: 1277.9281\n",
      "Epoch 4506/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 1411.1893 - val_loss: 1277.7214\n",
      "Epoch 4507/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1410.9847 - val_loss: 1277.5151\n",
      "Epoch 4508/100000\n",
      "11/11 [==============================] - 0s 756us/step - loss: 1410.7802 - val_loss: 1277.3087\n",
      "Epoch 4509/100000\n",
      "11/11 [==============================] - 0s 681us/step - loss: 1410.5756 - val_loss: 1277.1024\n",
      "Epoch 4510/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 1410.3711 - val_loss: 1276.8964\n",
      "Epoch 4511/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1410.1670 - val_loss: 1276.6903\n",
      "Epoch 4512/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 1409.9628 - val_loss: 1276.4844\n",
      "Epoch 4513/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1409.7587 - val_loss: 1276.2786\n",
      "Epoch 4514/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1409.5547 - val_loss: 1276.0728\n",
      "Epoch 4515/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1409.3506 - val_loss: 1275.8672\n",
      "Epoch 4516/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 1409.1469 - val_loss: 1275.6619\n",
      "Epoch 4517/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 1408.9432 - val_loss: 1275.4563\n",
      "Epoch 4518/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 1408.7397 - val_loss: 1275.2510\n",
      "Epoch 4519/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1408.5363 - val_loss: 1275.0458\n",
      "Epoch 4520/100000\n",
      "11/11 [==============================] - 0s 719us/step - loss: 1408.3329 - val_loss: 1274.8407\n",
      "Epoch 4521/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 1408.1295 - val_loss: 1274.6356\n",
      "Epoch 4522/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1407.9263 - val_loss: 1274.4308\n",
      "Epoch 4523/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1407.7234 - val_loss: 1274.2258\n",
      "Epoch 4524/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1407.5204 - val_loss: 1274.0214\n",
      "Epoch 4525/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1407.3175 - val_loss: 1273.8165\n",
      "Epoch 4526/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 1407.1145 - val_loss: 1273.6122\n",
      "Epoch 4527/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1406.9120 - val_loss: 1273.4078\n",
      "Epoch 4528/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1406.7094 - val_loss: 1273.2032\n",
      "Epoch 4529/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1406.5070 - val_loss: 1272.9991\n",
      "Epoch 4530/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1406.3046 - val_loss: 1272.7953\n",
      "Epoch 4531/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1406.1023 - val_loss: 1272.5913\n",
      "Epoch 4532/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1405.9003 - val_loss: 1272.3872\n",
      "Epoch 4533/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1405.6981 - val_loss: 1272.1835\n",
      "Epoch 4534/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1405.4961 - val_loss: 1271.9797\n",
      "Epoch 4535/100000\n",
      "11/11 [==============================] - 0s 697us/step - loss: 1405.2943 - val_loss: 1271.7762\n",
      "Epoch 4536/100000\n",
      "11/11 [==============================] - 0s 624us/step - loss: 1405.0927 - val_loss: 1271.5728\n",
      "Epoch 4537/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1404.8907 - val_loss: 1271.3693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4538/100000\n",
      "11/11 [==============================] - 0s 968us/step - loss: 1404.6893 - val_loss: 1271.1661\n",
      "Epoch 4539/100000\n",
      "11/11 [==============================] - 0s 764us/step - loss: 1404.4878 - val_loss: 1270.9629\n",
      "Epoch 4540/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1404.2865 - val_loss: 1270.7599\n",
      "Epoch 4541/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1404.0854 - val_loss: 1270.5568\n",
      "Epoch 4542/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1403.8843 - val_loss: 1270.3541\n",
      "Epoch 4543/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 1403.6831 - val_loss: 1270.1512\n",
      "Epoch 4544/100000\n",
      "11/11 [==============================] - 0s 705us/step - loss: 1403.4821 - val_loss: 1269.9487\n",
      "Epoch 4545/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1403.2815 - val_loss: 1269.7462\n",
      "Epoch 4546/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1403.0804 - val_loss: 1269.5437\n",
      "Epoch 4547/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 1402.8800 - val_loss: 1269.3413\n",
      "Epoch 4548/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 1402.6796 - val_loss: 1269.1390\n",
      "Epoch 4549/100000\n",
      "11/11 [==============================] - 0s 992us/step - loss: 1402.4789 - val_loss: 1268.9370\n",
      "Epoch 4550/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1402.2786 - val_loss: 1268.7349\n",
      "Epoch 4551/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 1402.0786 - val_loss: 1268.5331\n",
      "Epoch 4552/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1401.8784 - val_loss: 1268.3312\n",
      "Epoch 4553/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1401.6782 - val_loss: 1268.1294\n",
      "Epoch 4554/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 1401.4785 - val_loss: 1267.9279\n",
      "Epoch 4555/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1401.2787 - val_loss: 1267.7263\n",
      "Epoch 4556/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1401.0790 - val_loss: 1267.5250\n",
      "Epoch 4557/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1400.8794 - val_loss: 1267.3235\n",
      "Epoch 4558/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1400.6798 - val_loss: 1267.1222\n",
      "Epoch 4559/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1400.4805 - val_loss: 1266.9211\n",
      "Epoch 4560/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1400.2811 - val_loss: 1266.7202\n",
      "Epoch 4561/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1400.0820 - val_loss: 1266.5194\n",
      "Epoch 4562/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 1399.8831 - val_loss: 1266.3185\n",
      "Epoch 4563/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1399.6838 - val_loss: 1266.1177\n",
      "Epoch 4564/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 1399.4850 - val_loss: 1265.9172\n",
      "Epoch 4565/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 1399.2863 - val_loss: 1265.7167\n",
      "Epoch 4566/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1399.0874 - val_loss: 1265.5162\n",
      "Epoch 4567/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 1398.8890 - val_loss: 1265.3159\n",
      "Epoch 4568/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 1398.6906 - val_loss: 1265.1157\n",
      "Epoch 4569/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 1398.4921 - val_loss: 1264.9155\n",
      "Epoch 4570/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1398.2938 - val_loss: 1264.7156\n",
      "Epoch 4571/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1398.0957 - val_loss: 1264.5157\n",
      "Epoch 4572/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1397.8976 - val_loss: 1264.3160\n",
      "Epoch 4573/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1397.6996 - val_loss: 1264.1163\n",
      "Epoch 4574/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 1397.5018 - val_loss: 1263.9166\n",
      "Epoch 4575/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 1397.3038 - val_loss: 1263.7172\n",
      "Epoch 4576/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1397.1063 - val_loss: 1263.5179\n",
      "Epoch 4577/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 1396.9087 - val_loss: 1263.3185\n",
      "Epoch 4578/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1396.7112 - val_loss: 1263.1194\n",
      "Epoch 4579/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1396.5138 - val_loss: 1262.9203\n",
      "Epoch 4580/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1396.3165 - val_loss: 1262.7213\n",
      "Epoch 4581/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 1396.1196 - val_loss: 1262.5222\n",
      "Epoch 4582/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1395.9224 - val_loss: 1262.3237\n",
      "Epoch 4583/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1395.7253 - val_loss: 1262.1249\n",
      "Epoch 4584/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 1395.5287 - val_loss: 1261.9264\n",
      "Epoch 4585/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 1395.3317 - val_loss: 1261.7279\n",
      "Epoch 4586/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 1395.1353 - val_loss: 1261.5297\n",
      "Epoch 4587/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1394.9386 - val_loss: 1261.3312\n",
      "Epoch 4588/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 1394.7422 - val_loss: 1261.1332\n",
      "Epoch 4589/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 1394.5458 - val_loss: 1260.9351\n",
      "Epoch 4590/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 1394.3495 - val_loss: 1260.7368\n",
      "Epoch 4591/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 1394.1533 - val_loss: 1260.5392\n",
      "Epoch 4592/100000\n",
      "11/11 [==============================] - 0s 607us/step - loss: 1393.9572 - val_loss: 1260.3414\n",
      "Epoch 4593/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1393.7612 - val_loss: 1260.1436\n",
      "Epoch 4594/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 1393.5654 - val_loss: 1259.9463\n",
      "Epoch 4595/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1393.3698 - val_loss: 1259.7489\n",
      "Epoch 4596/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1393.1740 - val_loss: 1259.5514\n",
      "Epoch 4597/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 1392.9785 - val_loss: 1259.3542\n",
      "Epoch 4598/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 1392.7831 - val_loss: 1259.1570\n",
      "Epoch 4599/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 1392.5878 - val_loss: 1258.9598\n",
      "Epoch 4600/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 1392.3925 - val_loss: 1258.7628\n",
      "Epoch 4601/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1392.1974 - val_loss: 1258.5663\n",
      "Epoch 4602/100000\n",
      "11/11 [==============================] - 0s 830us/step - loss: 1392.0023 - val_loss: 1258.3693\n",
      "Epoch 4603/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 1391.8074 - val_loss: 1258.1725\n",
      "Epoch 4604/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 1391.6124 - val_loss: 1257.9762\n",
      "Epoch 4605/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1391.4178 - val_loss: 1257.7797\n",
      "Epoch 4606/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1391.2233 - val_loss: 1257.5835\n",
      "Epoch 4607/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 1391.0287 - val_loss: 1257.3871\n",
      "Epoch 4608/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 1390.8341 - val_loss: 1257.1909\n",
      "Epoch 4609/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1390.6398 - val_loss: 1256.9949\n",
      "Epoch 4610/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 1390.4456 - val_loss: 1256.7990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4611/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1390.2515 - val_loss: 1256.6030\n",
      "Epoch 4612/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1390.0575 - val_loss: 1256.4073\n",
      "Epoch 4613/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 1389.8636 - val_loss: 1256.2117\n",
      "Epoch 4614/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1389.6696 - val_loss: 1256.0164\n",
      "Epoch 4615/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 1389.4761 - val_loss: 1255.8208\n",
      "Epoch 4616/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 1389.2821 - val_loss: 1255.6254\n",
      "Epoch 4617/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 1389.0887 - val_loss: 1255.4302\n",
      "Epoch 4618/100000\n",
      "11/11 [==============================] - 0s 599us/step - loss: 1388.8953 - val_loss: 1255.2349\n",
      "Epoch 4619/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 1388.7020 - val_loss: 1255.0399\n",
      "Epoch 4620/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 1388.5088 - val_loss: 1254.8450\n",
      "Epoch 4621/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 1388.3156 - val_loss: 1254.6503\n",
      "Epoch 4622/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1388.1227 - val_loss: 1254.4553\n",
      "Epoch 4623/100000\n",
      "11/11 [==============================] - 0s 907us/step - loss: 1387.9296 - val_loss: 1254.2609\n",
      "Epoch 4624/100000\n",
      "11/11 [==============================] - 0s 818us/step - loss: 1387.7368 - val_loss: 1254.0663\n",
      "Epoch 4625/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1387.5441 - val_loss: 1253.8718\n",
      "Epoch 4626/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 1387.3514 - val_loss: 1253.6774\n",
      "Epoch 4627/100000\n",
      "11/11 [==============================] - 0s 628us/step - loss: 1387.1588 - val_loss: 1253.4833\n",
      "Epoch 4628/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1386.9664 - val_loss: 1253.2891\n",
      "Epoch 4629/100000\n",
      "11/11 [==============================] - 0s 740us/step - loss: 1386.7743 - val_loss: 1253.0950\n",
      "Epoch 4630/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 1386.5820 - val_loss: 1252.9011\n",
      "Epoch 4631/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1386.3896 - val_loss: 1252.7073\n",
      "Epoch 4632/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1386.1978 - val_loss: 1252.5135\n",
      "Epoch 4633/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1386.0059 - val_loss: 1252.3199\n",
      "Epoch 4634/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 1385.8140 - val_loss: 1252.1263\n",
      "Epoch 4635/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 1385.6222 - val_loss: 1251.9329\n",
      "Epoch 4636/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1385.4308 - val_loss: 1251.7397\n",
      "Epoch 4637/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 1385.2391 - val_loss: 1251.5464\n",
      "Epoch 4638/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 1385.0477 - val_loss: 1251.3534\n",
      "Epoch 4639/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 1384.8564 - val_loss: 1251.1602\n",
      "Epoch 4640/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 1384.6649 - val_loss: 1250.9673\n",
      "Epoch 4641/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 1384.4740 - val_loss: 1250.7743\n",
      "Epoch 4642/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 1384.2831 - val_loss: 1250.5817\n",
      "Epoch 4643/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 1384.0919 - val_loss: 1250.3892\n",
      "Epoch 4644/100000\n",
      "11/11 [==============================] - 0s 693us/step - loss: 1383.9012 - val_loss: 1250.1967\n",
      "Epoch 4645/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1383.7104 - val_loss: 1250.0040\n",
      "Epoch 4646/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 1383.5198 - val_loss: 1249.8119\n",
      "Epoch 4647/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 1383.3292 - val_loss: 1249.6196\n",
      "Epoch 4648/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1383.1390 - val_loss: 1249.4275\n",
      "Epoch 4649/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1382.9485 - val_loss: 1249.2355\n",
      "Epoch 4650/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 1382.7583 - val_loss: 1249.0435\n",
      "Epoch 4651/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1382.5682 - val_loss: 1248.8517\n",
      "Epoch 4652/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 1382.3781 - val_loss: 1248.6600\n",
      "Epoch 4653/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 1382.1884 - val_loss: 1248.4683\n",
      "Epoch 4654/100000\n",
      "11/11 [==============================] - 0s 894us/step - loss: 1381.9982 - val_loss: 1248.2769\n",
      "Epoch 4655/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 1381.8086 - val_loss: 1248.0854\n",
      "Epoch 4656/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1381.6191 - val_loss: 1247.8940\n",
      "Epoch 4657/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 1381.4296 - val_loss: 1247.7028\n",
      "Epoch 4658/100000\n",
      "11/11 [==============================] - 0s 817us/step - loss: 1381.2402 - val_loss: 1247.5116\n",
      "Epoch 4659/100000\n",
      "11/11 [==============================] - 0s 752us/step - loss: 1381.0508 - val_loss: 1247.3207\n",
      "Epoch 4660/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1380.8615 - val_loss: 1247.1296\n",
      "Epoch 4661/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 1380.6722 - val_loss: 1246.9388\n",
      "Epoch 4662/100000\n",
      "11/11 [==============================] - 0s 790us/step - loss: 1380.4834 - val_loss: 1246.7482\n",
      "Epoch 4663/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1380.2944 - val_loss: 1246.5575\n",
      "Epoch 4664/100000\n",
      "11/11 [==============================] - 0s 725us/step - loss: 1380.1057 - val_loss: 1246.3669\n",
      "Epoch 4665/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1379.9167 - val_loss: 1246.1766\n",
      "Epoch 4666/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1379.7283 - val_loss: 1245.9861\n",
      "Epoch 4667/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 1379.5397 - val_loss: 1245.7960\n",
      "Epoch 4668/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1379.3512 - val_loss: 1245.6060\n",
      "Epoch 4669/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1379.1628 - val_loss: 1245.4158\n",
      "Epoch 4670/100000\n",
      "11/11 [==============================] - 0s 743us/step - loss: 1378.9746 - val_loss: 1245.2258\n",
      "Epoch 4671/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 1378.7865 - val_loss: 1245.0360\n",
      "Epoch 4672/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1378.5985 - val_loss: 1244.8464\n",
      "Epoch 4673/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 1378.4105 - val_loss: 1244.6566\n",
      "Epoch 4674/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 1378.2227 - val_loss: 1244.4672\n",
      "Epoch 4675/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 1378.0350 - val_loss: 1244.2777\n",
      "Epoch 4676/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1377.8473 - val_loss: 1244.0884\n",
      "Epoch 4677/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 1377.6598 - val_loss: 1243.8993\n",
      "Epoch 4678/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 1377.4724 - val_loss: 1243.7101\n",
      "Epoch 4679/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1377.2849 - val_loss: 1243.5210\n",
      "Epoch 4680/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 1377.0978 - val_loss: 1243.3320\n",
      "Epoch 4681/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1376.9106 - val_loss: 1243.1431\n",
      "Epoch 4682/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1376.7235 - val_loss: 1242.9543\n",
      "Epoch 4683/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 1376.5366 - val_loss: 1242.7657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4684/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1376.3497 - val_loss: 1242.5774\n",
      "Epoch 4685/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 1376.1631 - val_loss: 1242.3888\n",
      "Epoch 4686/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 1375.9764 - val_loss: 1242.2004\n",
      "Epoch 4687/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1375.7899 - val_loss: 1242.0122\n",
      "Epoch 4688/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1375.6034 - val_loss: 1241.8241\n",
      "Epoch 4689/100000\n",
      "11/11 [==============================] - 0s 933us/step - loss: 1375.4171 - val_loss: 1241.6360\n",
      "Epoch 4690/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1375.2310 - val_loss: 1241.4481\n",
      "Epoch 4691/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1375.0444 - val_loss: 1241.2601\n",
      "Epoch 4692/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1374.8585 - val_loss: 1241.0725\n",
      "Epoch 4693/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 1374.6725 - val_loss: 1240.8849\n",
      "Epoch 4694/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1374.4868 - val_loss: 1240.6973\n",
      "Epoch 4695/100000\n",
      "11/11 [==============================] - 0s 678us/step - loss: 1374.3009 - val_loss: 1240.5099\n",
      "Epoch 4696/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 1374.1154 - val_loss: 1240.3224\n",
      "Epoch 4697/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1373.9298 - val_loss: 1240.1353\n",
      "Epoch 4698/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 1373.7443 - val_loss: 1239.9480\n",
      "Epoch 4699/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 1373.5587 - val_loss: 1239.7610\n",
      "Epoch 4700/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 1373.3735 - val_loss: 1239.5741\n",
      "Epoch 4701/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 1373.1884 - val_loss: 1239.3871\n",
      "Epoch 4702/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1373.0034 - val_loss: 1239.2006\n",
      "Epoch 4703/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1372.8185 - val_loss: 1239.0137\n",
      "Epoch 4704/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 1372.6334 - val_loss: 1238.8273\n",
      "Epoch 4705/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1372.4487 - val_loss: 1238.6406\n",
      "Epoch 4706/100000\n",
      "11/11 [==============================] - 0s 671us/step - loss: 1372.2642 - val_loss: 1238.4543\n",
      "Epoch 4707/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1372.0796 - val_loss: 1238.2682\n",
      "Epoch 4708/100000\n",
      "11/11 [==============================] - 0s 691us/step - loss: 1371.8950 - val_loss: 1238.0820\n",
      "Epoch 4709/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 1371.7107 - val_loss: 1237.8959\n",
      "Epoch 4710/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 1371.5264 - val_loss: 1237.7098\n",
      "Epoch 4711/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1371.3422 - val_loss: 1237.5240\n",
      "Epoch 4712/100000\n",
      "11/11 [==============================] - 0s 690us/step - loss: 1371.1582 - val_loss: 1237.3384\n",
      "Epoch 4713/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1370.9741 - val_loss: 1237.1527\n",
      "Epoch 4714/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 1370.7903 - val_loss: 1236.9672\n",
      "Epoch 4715/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 1370.6066 - val_loss: 1236.7815\n",
      "Epoch 4716/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 1370.4227 - val_loss: 1236.5962\n",
      "Epoch 4717/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 1370.2391 - val_loss: 1236.4110\n",
      "Epoch 4718/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1370.0557 - val_loss: 1236.2257\n",
      "Epoch 4719/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1369.8722 - val_loss: 1236.0405\n",
      "Epoch 4720/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1369.6890 - val_loss: 1235.8556\n",
      "Epoch 4721/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1369.5057 - val_loss: 1235.6707\n",
      "Epoch 4722/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 1369.3226 - val_loss: 1235.4862\n",
      "Epoch 4723/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1369.1398 - val_loss: 1235.3014\n",
      "Epoch 4724/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 1368.9569 - val_loss: 1235.1167\n",
      "Epoch 4725/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 1368.7740 - val_loss: 1234.9323\n",
      "Epoch 4726/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 1368.5913 - val_loss: 1234.7479\n",
      "Epoch 4727/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1368.4087 - val_loss: 1234.5636\n",
      "Epoch 4728/100000\n",
      "11/11 [==============================] - 0s 840us/step - loss: 1368.2261 - val_loss: 1234.3794\n",
      "Epoch 4729/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 1368.0438 - val_loss: 1234.1952\n",
      "Epoch 4730/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1367.8615 - val_loss: 1234.0112\n",
      "Epoch 4731/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1367.6793 - val_loss: 1233.8275\n",
      "Epoch 4732/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1367.4971 - val_loss: 1233.6437\n",
      "Epoch 4733/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 1367.3149 - val_loss: 1233.4598\n",
      "Epoch 4734/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1367.1329 - val_loss: 1233.2762\n",
      "Epoch 4735/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 1366.9512 - val_loss: 1233.0927\n",
      "Epoch 4736/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 1366.7695 - val_loss: 1232.9093\n",
      "Epoch 4737/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1366.5878 - val_loss: 1232.7261\n",
      "Epoch 4738/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 1366.4064 - val_loss: 1232.5427\n",
      "Epoch 4739/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1366.2249 - val_loss: 1232.3597\n",
      "Epoch 4740/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1366.0437 - val_loss: 1232.1766\n",
      "Epoch 4741/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1365.8622 - val_loss: 1231.9938\n",
      "Epoch 4742/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1365.6813 - val_loss: 1231.8109\n",
      "Epoch 4743/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1365.5001 - val_loss: 1231.6281\n",
      "Epoch 4744/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 1365.3192 - val_loss: 1231.4454\n",
      "Epoch 4745/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1365.1383 - val_loss: 1231.2629\n",
      "Epoch 4746/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 1364.9575 - val_loss: 1231.0806\n",
      "Epoch 4747/100000\n",
      "11/11 [==============================] - 0s 620us/step - loss: 1364.7770 - val_loss: 1230.8981\n",
      "Epoch 4748/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1364.5963 - val_loss: 1230.7159\n",
      "Epoch 4749/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1364.4159 - val_loss: 1230.5339\n",
      "Epoch 4750/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1364.2355 - val_loss: 1230.3517\n",
      "Epoch 4751/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1364.0552 - val_loss: 1230.1699\n",
      "Epoch 4752/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1363.8750 - val_loss: 1229.9879\n",
      "Epoch 4753/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 1363.6949 - val_loss: 1229.8063\n",
      "Epoch 4754/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1363.5149 - val_loss: 1229.6245\n",
      "Epoch 4755/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 1363.3351 - val_loss: 1229.4430\n",
      "Epoch 4756/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 1363.1555 - val_loss: 1229.2616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4757/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1362.9757 - val_loss: 1229.0802\n",
      "Epoch 4758/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1362.7960 - val_loss: 1228.8989\n",
      "Epoch 4759/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 1362.6167 - val_loss: 1228.7177\n",
      "Epoch 4760/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 1362.4373 - val_loss: 1228.5367\n",
      "Epoch 4761/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1362.2578 - val_loss: 1228.3557\n",
      "Epoch 4762/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 1362.0787 - val_loss: 1228.1750\n",
      "Epoch 4763/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 1361.8997 - val_loss: 1227.9941\n",
      "Epoch 4764/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1361.7207 - val_loss: 1227.8134\n",
      "Epoch 4765/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 1361.5416 - val_loss: 1227.6328\n",
      "Epoch 4766/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1361.3628 - val_loss: 1227.4524\n",
      "Epoch 4767/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 1361.1841 - val_loss: 1227.2719\n",
      "Epoch 4768/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1361.0057 - val_loss: 1227.0918\n",
      "Epoch 4769/100000\n",
      "11/11 [==============================] - 0s 197us/step - loss: 1360.8271 - val_loss: 1226.9114\n",
      "Epoch 4770/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1360.6487 - val_loss: 1226.7312\n",
      "Epoch 4771/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 1360.4703 - val_loss: 1226.5515\n",
      "Epoch 4772/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 1360.2921 - val_loss: 1226.3716\n",
      "Epoch 4773/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 1360.1141 - val_loss: 1226.1918\n",
      "Epoch 4774/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 1359.9359 - val_loss: 1226.0121\n",
      "Epoch 4775/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1359.7581 - val_loss: 1225.8324\n",
      "Epoch 4776/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1359.5802 - val_loss: 1225.6528\n",
      "Epoch 4777/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 1359.4023 - val_loss: 1225.4735\n",
      "Epoch 4778/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 1359.2247 - val_loss: 1225.2942\n",
      "Epoch 4779/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1359.0472 - val_loss: 1225.1149\n",
      "Epoch 4780/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 1358.8698 - val_loss: 1224.9359\n",
      "Epoch 4781/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1358.6926 - val_loss: 1224.7570\n",
      "Epoch 4782/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1358.5153 - val_loss: 1224.5779\n",
      "Epoch 4783/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 1358.3381 - val_loss: 1224.3990\n",
      "Epoch 4784/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1358.1610 - val_loss: 1224.2203\n",
      "Epoch 4785/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1357.9839 - val_loss: 1224.0419\n",
      "Epoch 4786/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1357.8071 - val_loss: 1223.8632\n",
      "Epoch 4787/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 1357.6305 - val_loss: 1223.6847\n",
      "Epoch 4788/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 1357.4536 - val_loss: 1223.5063\n",
      "Epoch 4789/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 1357.2772 - val_loss: 1223.3281\n",
      "Epoch 4790/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 1357.1007 - val_loss: 1223.1499\n",
      "Epoch 4791/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1356.9243 - val_loss: 1222.9719\n",
      "Epoch 4792/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1356.7480 - val_loss: 1222.7939\n",
      "Epoch 4793/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1356.5718 - val_loss: 1222.6161\n",
      "Epoch 4794/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 1356.3958 - val_loss: 1222.4384\n",
      "Epoch 4795/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1356.2197 - val_loss: 1222.2606\n",
      "Epoch 4796/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1356.0438 - val_loss: 1222.0831\n",
      "Epoch 4797/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 1355.8680 - val_loss: 1221.9056\n",
      "Epoch 4798/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 1355.6923 - val_loss: 1221.7281\n",
      "Epoch 4799/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1355.5167 - val_loss: 1221.5509\n",
      "Epoch 4800/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1355.3411 - val_loss: 1221.3738\n",
      "Epoch 4801/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 1355.1659 - val_loss: 1221.1967\n",
      "Epoch 4802/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 1354.9904 - val_loss: 1221.0197\n",
      "Epoch 4803/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1354.8153 - val_loss: 1220.8429\n",
      "Epoch 4804/100000\n",
      "11/11 [==============================] - 0s 703us/step - loss: 1354.6401 - val_loss: 1220.6660\n",
      "Epoch 4805/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1354.4651 - val_loss: 1220.4893\n",
      "Epoch 4806/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 1354.2899 - val_loss: 1220.3126\n",
      "Epoch 4807/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1354.1152 - val_loss: 1220.1362\n",
      "Epoch 4808/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 1353.9406 - val_loss: 1219.9598\n",
      "Epoch 4809/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 1353.7660 - val_loss: 1219.7833\n",
      "Epoch 4810/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1353.5913 - val_loss: 1219.6073\n",
      "Epoch 4811/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 1353.4169 - val_loss: 1219.4310\n",
      "Epoch 4812/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 1353.2423 - val_loss: 1219.2551\n",
      "Epoch 4813/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 1353.0684 - val_loss: 1219.0792\n",
      "Epoch 4814/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 1352.8940 - val_loss: 1218.9033\n",
      "Epoch 4815/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1352.7198 - val_loss: 1218.7277\n",
      "Epoch 4816/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1352.5460 - val_loss: 1218.5519\n",
      "Epoch 4817/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1352.3722 - val_loss: 1218.3765\n",
      "Epoch 4818/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1352.1982 - val_loss: 1218.2010\n",
      "Epoch 4819/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 1352.0247 - val_loss: 1218.0255\n",
      "Epoch 4820/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1351.8511 - val_loss: 1217.8503\n",
      "Epoch 4821/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 1351.6776 - val_loss: 1217.6753\n",
      "Epoch 4822/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1351.5042 - val_loss: 1217.5000\n",
      "Epoch 4823/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1351.3309 - val_loss: 1217.3251\n",
      "Epoch 4824/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1351.1577 - val_loss: 1217.1503\n",
      "Epoch 4825/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 1350.9847 - val_loss: 1216.9755\n",
      "Epoch 4826/100000\n",
      "11/11 [==============================] - 0s 674us/step - loss: 1350.8114 - val_loss: 1216.8009\n",
      "Epoch 4827/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1350.6387 - val_loss: 1216.6262\n",
      "Epoch 4828/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 1350.4657 - val_loss: 1216.4517\n",
      "Epoch 4829/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1350.2930 - val_loss: 1216.2773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4830/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1350.1206 - val_loss: 1216.1030\n",
      "Epoch 4831/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 1349.9480 - val_loss: 1215.9286\n",
      "Epoch 4832/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 1349.7755 - val_loss: 1215.7548\n",
      "Epoch 4833/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1349.6030 - val_loss: 1215.5808\n",
      "Epoch 4834/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 1349.4308 - val_loss: 1215.4070\n",
      "Epoch 4835/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 1349.2587 - val_loss: 1215.2330\n",
      "Epoch 4836/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1349.0865 - val_loss: 1215.0594\n",
      "Epoch 4837/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 1348.9148 - val_loss: 1214.8857\n",
      "Epoch 4838/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 1348.7428 - val_loss: 1214.7122\n",
      "Epoch 4839/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 1348.5710 - val_loss: 1214.5387\n",
      "Epoch 4840/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 1348.3994 - val_loss: 1214.3654\n",
      "Epoch 4841/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 1348.2278 - val_loss: 1214.1923\n",
      "Epoch 4842/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1348.0562 - val_loss: 1214.0192\n",
      "Epoch 4843/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 1347.8849 - val_loss: 1213.8458\n",
      "Epoch 4844/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 1347.7137 - val_loss: 1213.6730\n",
      "Epoch 4845/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1347.5425 - val_loss: 1213.5001\n",
      "Epoch 4846/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 1347.3712 - val_loss: 1213.3273\n",
      "Epoch 4847/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1347.2003 - val_loss: 1213.1547\n",
      "Epoch 4848/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 1347.0294 - val_loss: 1212.9823\n",
      "Epoch 4849/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1346.8585 - val_loss: 1212.8096\n",
      "Epoch 4850/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1346.6876 - val_loss: 1212.6372\n",
      "Epoch 4851/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 1346.5172 - val_loss: 1212.4650\n",
      "Epoch 4852/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1346.3468 - val_loss: 1212.2930\n",
      "Epoch 4853/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1346.1763 - val_loss: 1212.1207\n",
      "Epoch 4854/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1346.0060 - val_loss: 1211.9489\n",
      "Epoch 4855/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1345.8356 - val_loss: 1211.7769\n",
      "Epoch 4856/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1345.6655 - val_loss: 1211.6050\n",
      "Epoch 4857/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1345.4954 - val_loss: 1211.4332\n",
      "Epoch 4858/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1345.3256 - val_loss: 1211.2616\n",
      "Epoch 4859/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 1345.1556 - val_loss: 1211.0902\n",
      "Epoch 4860/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 1344.9858 - val_loss: 1210.9187\n",
      "Epoch 4861/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 1344.8162 - val_loss: 1210.7473\n",
      "Epoch 4862/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 1344.6466 - val_loss: 1210.5760\n",
      "Epoch 4863/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1344.4772 - val_loss: 1210.4050\n",
      "Epoch 4864/100000\n",
      "11/11 [==============================] - 0s 678us/step - loss: 1344.3077 - val_loss: 1210.2340\n",
      "Epoch 4865/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1344.1385 - val_loss: 1210.0630\n",
      "Epoch 4866/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1343.9692 - val_loss: 1209.8922\n",
      "Epoch 4867/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 1343.8003 - val_loss: 1209.7216\n",
      "Epoch 4868/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 1343.6312 - val_loss: 1209.5509\n",
      "Epoch 4869/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 1343.4622 - val_loss: 1209.3801\n",
      "Epoch 4870/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1343.2932 - val_loss: 1209.2098\n",
      "Epoch 4871/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1343.1248 - val_loss: 1209.0396\n",
      "Epoch 4872/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 1342.9559 - val_loss: 1208.8690\n",
      "Epoch 4873/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1342.7875 - val_loss: 1208.6991\n",
      "Epoch 4874/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 1342.6190 - val_loss: 1208.5288\n",
      "Epoch 4875/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1342.4507 - val_loss: 1208.3589\n",
      "Epoch 4876/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1342.2823 - val_loss: 1208.1890\n",
      "Epoch 4877/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1342.1144 - val_loss: 1208.0190\n",
      "Epoch 4878/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1341.9462 - val_loss: 1207.8494\n",
      "Epoch 4879/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1341.7782 - val_loss: 1207.6798\n",
      "Epoch 4880/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 1341.6104 - val_loss: 1207.5103\n",
      "Epoch 4881/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1341.4427 - val_loss: 1207.3408\n",
      "Epoch 4882/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1341.2749 - val_loss: 1207.1714\n",
      "Epoch 4883/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 1341.1073 - val_loss: 1207.0023\n",
      "Epoch 4884/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1340.9398 - val_loss: 1206.8333\n",
      "Epoch 4885/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 1340.7726 - val_loss: 1206.6641\n",
      "Epoch 4886/100000\n",
      "11/11 [==============================] - 0s 625us/step - loss: 1340.6050 - val_loss: 1206.4950\n",
      "Epoch 4887/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 1340.4380 - val_loss: 1206.3262\n",
      "Epoch 4888/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 1340.2708 - val_loss: 1206.1575\n",
      "Epoch 4889/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1340.1036 - val_loss: 1205.9888\n",
      "Epoch 4890/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 1339.9368 - val_loss: 1205.8202\n",
      "Epoch 4891/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1339.7700 - val_loss: 1205.6519\n",
      "Epoch 4892/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 1339.6033 - val_loss: 1205.4833\n",
      "Epoch 4893/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 1339.4366 - val_loss: 1205.3149\n",
      "Epoch 4894/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1339.2699 - val_loss: 1205.1469\n",
      "Epoch 4895/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 1339.1035 - val_loss: 1204.9786\n",
      "Epoch 4896/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1338.9373 - val_loss: 1204.8108\n",
      "Epoch 4897/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 1338.7710 - val_loss: 1204.6428\n",
      "Epoch 4898/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1338.6049 - val_loss: 1204.4751\n",
      "Epoch 4899/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 1338.4386 - val_loss: 1204.3071\n",
      "Epoch 4900/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 1338.2727 - val_loss: 1204.1395\n",
      "Epoch 4901/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1338.1069 - val_loss: 1203.9722\n",
      "Epoch 4902/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1337.9410 - val_loss: 1203.8047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4903/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1337.7753 - val_loss: 1203.6372\n",
      "Epoch 4904/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 1337.6097 - val_loss: 1203.4700\n",
      "Epoch 4905/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1337.4442 - val_loss: 1203.3029\n",
      "Epoch 4906/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1337.2788 - val_loss: 1203.1359\n",
      "Epoch 4907/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 1337.1134 - val_loss: 1202.9689\n",
      "Epoch 4908/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1336.9482 - val_loss: 1202.8019\n",
      "Epoch 4909/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1336.7831 - val_loss: 1202.6353\n",
      "Epoch 4910/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 1336.6180 - val_loss: 1202.4686\n",
      "Epoch 4911/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 1336.4532 - val_loss: 1202.3019\n",
      "Epoch 4912/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1336.2882 - val_loss: 1202.1356\n",
      "Epoch 4913/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1336.1234 - val_loss: 1201.9691\n",
      "Epoch 4914/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 1335.9589 - val_loss: 1201.8026\n",
      "Epoch 4915/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 1335.7943 - val_loss: 1201.6366\n",
      "Epoch 4916/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1335.6298 - val_loss: 1201.4702\n",
      "Epoch 4917/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1335.4653 - val_loss: 1201.3044\n",
      "Epoch 4918/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1335.3011 - val_loss: 1201.1383\n",
      "Epoch 4919/100000\n",
      "11/11 [==============================] - 0s 614us/step - loss: 1335.1368 - val_loss: 1200.9725\n",
      "Epoch 4920/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1334.9728 - val_loss: 1200.8068\n",
      "Epoch 4921/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1334.8087 - val_loss: 1200.6411\n",
      "Epoch 4922/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 1334.6448 - val_loss: 1200.4755\n",
      "Epoch 4923/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1334.4808 - val_loss: 1200.3102\n",
      "Epoch 4924/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1334.3171 - val_loss: 1200.1447\n",
      "Epoch 4925/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1334.1536 - val_loss: 1199.9794\n",
      "Epoch 4926/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 1333.9901 - val_loss: 1199.8142\n",
      "Epoch 4927/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 1333.8267 - val_loss: 1199.6493\n",
      "Epoch 4928/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 1333.6633 - val_loss: 1199.4843\n",
      "Epoch 4929/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 1333.5000 - val_loss: 1199.3195\n",
      "Epoch 4930/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 1333.3368 - val_loss: 1199.1544\n",
      "Epoch 4931/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 1333.1737 - val_loss: 1198.9897\n",
      "Epoch 4932/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1333.0107 - val_loss: 1198.8252\n",
      "Epoch 4933/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 1332.8478 - val_loss: 1198.6605\n",
      "Epoch 4934/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1332.6851 - val_loss: 1198.4962\n",
      "Epoch 4935/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 1332.5223 - val_loss: 1198.3319\n",
      "Epoch 4936/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 1332.3599 - val_loss: 1198.1676\n",
      "Epoch 4937/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1332.1973 - val_loss: 1198.0033\n",
      "Epoch 4938/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1332.0349 - val_loss: 1197.8394\n",
      "Epoch 4939/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 1331.8726 - val_loss: 1197.6753\n",
      "Epoch 4940/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 1331.7101 - val_loss: 1197.5114\n",
      "Epoch 4941/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 1331.5481 - val_loss: 1197.3477\n",
      "Epoch 4942/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1331.3860 - val_loss: 1197.1840\n",
      "Epoch 4943/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 1331.2240 - val_loss: 1197.0204\n",
      "Epoch 4944/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1331.0621 - val_loss: 1196.8569\n",
      "Epoch 4945/100000\n",
      "11/11 [==============================] - 0s 639us/step - loss: 1330.9004 - val_loss: 1196.6935\n",
      "Epoch 4946/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1330.7388 - val_loss: 1196.5300\n",
      "Epoch 4947/100000\n",
      "11/11 [==============================] - 0s 590us/step - loss: 1330.5771 - val_loss: 1196.3668\n",
      "Epoch 4948/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1330.4155 - val_loss: 1196.2039\n",
      "Epoch 4949/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1330.2543 - val_loss: 1196.0409\n",
      "Epoch 4950/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 1330.0929 - val_loss: 1195.8779\n",
      "Epoch 4951/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1329.9318 - val_loss: 1195.7150\n",
      "Epoch 4952/100000\n",
      "11/11 [==============================] - 0s 804us/step - loss: 1329.7706 - val_loss: 1195.5522\n",
      "Epoch 4953/100000\n",
      "11/11 [==============================] - 0s 664us/step - loss: 1329.6097 - val_loss: 1195.3896\n",
      "Epoch 4954/100000\n",
      "11/11 [==============================] - 0s 652us/step - loss: 1329.4487 - val_loss: 1195.2271\n",
      "Epoch 4955/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 1329.2880 - val_loss: 1195.0646\n",
      "Epoch 4956/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 1329.1271 - val_loss: 1194.9022\n",
      "Epoch 4957/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 1328.9663 - val_loss: 1194.7399\n",
      "Epoch 4958/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 1328.8058 - val_loss: 1194.5776\n",
      "Epoch 4959/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1328.6455 - val_loss: 1194.4155\n",
      "Epoch 4960/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 1328.4851 - val_loss: 1194.2535\n",
      "Epoch 4961/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1328.3247 - val_loss: 1194.0917\n",
      "Epoch 4962/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 1328.1646 - val_loss: 1193.9297\n",
      "Epoch 4963/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1328.0045 - val_loss: 1193.7682\n",
      "Epoch 4964/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1327.8444 - val_loss: 1193.6063\n",
      "Epoch 4965/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1327.6846 - val_loss: 1193.4449\n",
      "Epoch 4966/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 1327.5248 - val_loss: 1193.2833\n",
      "Epoch 4967/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 1327.3651 - val_loss: 1193.1222\n",
      "Epoch 4968/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1327.2056 - val_loss: 1192.9608\n",
      "Epoch 4969/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 1327.0458 - val_loss: 1192.7997\n",
      "Epoch 4970/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1326.8864 - val_loss: 1192.6385\n",
      "Epoch 4971/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 1326.7271 - val_loss: 1192.4777\n",
      "Epoch 4972/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 1326.5676 - val_loss: 1192.3168\n",
      "Epoch 4973/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 1326.4086 - val_loss: 1192.1558\n",
      "Epoch 4974/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1326.2494 - val_loss: 1191.9951\n",
      "Epoch 4975/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1326.0906 - val_loss: 1191.8345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4976/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 1325.9315 - val_loss: 1191.6741\n",
      "Epoch 4977/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 1325.7728 - val_loss: 1191.5137\n",
      "Epoch 4978/100000\n",
      "11/11 [==============================] - 0s 590us/step - loss: 1325.6141 - val_loss: 1191.3533\n",
      "Epoch 4979/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1325.4556 - val_loss: 1191.1931\n",
      "Epoch 4980/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1325.2969 - val_loss: 1191.0328\n",
      "Epoch 4981/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 1325.1387 - val_loss: 1190.8729\n",
      "Epoch 4982/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 1324.9801 - val_loss: 1190.7128\n",
      "Epoch 4983/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 1324.8220 - val_loss: 1190.5530\n",
      "Epoch 4984/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 1324.6637 - val_loss: 1190.3931\n",
      "Epoch 4985/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 1324.5059 - val_loss: 1190.2335\n",
      "Epoch 4986/100000\n",
      "11/11 [==============================] - 0s 693us/step - loss: 1324.3478 - val_loss: 1190.0740\n",
      "Epoch 4987/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1324.1898 - val_loss: 1189.9144\n",
      "Epoch 4988/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 1324.0321 - val_loss: 1189.7548\n",
      "Epoch 4989/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 1323.8744 - val_loss: 1189.5957\n",
      "Epoch 4990/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1323.7168 - val_loss: 1189.4364\n",
      "Epoch 4991/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1323.5593 - val_loss: 1189.2772\n",
      "Epoch 4992/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 1323.4019 - val_loss: 1189.1180\n",
      "Epoch 4993/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 1323.2446 - val_loss: 1188.9591\n",
      "Epoch 4994/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 1323.0874 - val_loss: 1188.8004\n",
      "Epoch 4995/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 1322.9301 - val_loss: 1188.6417\n",
      "Epoch 4996/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 1322.7731 - val_loss: 1188.4829\n",
      "Epoch 4997/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 1322.6160 - val_loss: 1188.3243\n",
      "Epoch 4998/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1322.4591 - val_loss: 1188.1659\n",
      "Epoch 4999/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 1322.3026 - val_loss: 1188.0077\n",
      "Epoch 5000/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 1322.1458 - val_loss: 1187.8491\n",
      "Epoch 5001/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1321.9891 - val_loss: 1187.6910\n",
      "Epoch 5002/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1321.8328 - val_loss: 1187.5328\n",
      "Epoch 5003/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 1321.6763 - val_loss: 1187.3748\n",
      "Epoch 5004/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1321.5199 - val_loss: 1187.2169\n",
      "Epoch 5005/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1321.3636 - val_loss: 1187.0591\n",
      "Epoch 5006/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1321.2076 - val_loss: 1186.9012\n",
      "Epoch 5007/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1321.0516 - val_loss: 1186.7434\n",
      "Epoch 5008/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1320.8955 - val_loss: 1186.5861\n",
      "Epoch 5009/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1320.7397 - val_loss: 1186.4286\n",
      "Epoch 5010/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1320.5841 - val_loss: 1186.2711\n",
      "Epoch 5011/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1320.4283 - val_loss: 1186.1139\n",
      "Epoch 5012/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 1320.2727 - val_loss: 1185.9567\n",
      "Epoch 5013/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1320.1172 - val_loss: 1185.7996\n",
      "Epoch 5014/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1319.9618 - val_loss: 1185.6426\n",
      "Epoch 5015/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1319.8065 - val_loss: 1185.4856\n",
      "Epoch 5016/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1319.6512 - val_loss: 1185.3286\n",
      "Epoch 5017/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 1319.4961 - val_loss: 1185.1720\n",
      "Epoch 5018/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1319.3411 - val_loss: 1185.0153\n",
      "Epoch 5019/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 1319.1863 - val_loss: 1184.8589\n",
      "Epoch 5020/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 1319.0314 - val_loss: 1184.7024\n",
      "Epoch 5021/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1318.8766 - val_loss: 1184.5459\n",
      "Epoch 5022/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1318.7218 - val_loss: 1184.3895\n",
      "Epoch 5023/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 1318.5671 - val_loss: 1184.2333\n",
      "Epoch 5024/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1318.4127 - val_loss: 1184.0774\n",
      "Epoch 5025/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 1318.2583 - val_loss: 1183.9213\n",
      "Epoch 5026/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 1318.1040 - val_loss: 1183.7654\n",
      "Epoch 5027/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1317.9500 - val_loss: 1183.6096\n",
      "Epoch 5028/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 1317.7958 - val_loss: 1183.4539\n",
      "Epoch 5029/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 1317.6417 - val_loss: 1183.2981\n",
      "Epoch 5030/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1317.4878 - val_loss: 1183.1426\n",
      "Epoch 5031/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 1317.3340 - val_loss: 1182.9872\n",
      "Epoch 5032/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 1317.1802 - val_loss: 1182.8319\n",
      "Epoch 5033/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 1317.0265 - val_loss: 1182.6765\n",
      "Epoch 5034/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 1316.8730 - val_loss: 1182.5212\n",
      "Epoch 5035/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1316.7195 - val_loss: 1182.3661\n",
      "Epoch 5036/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1316.5660 - val_loss: 1182.2111\n",
      "Epoch 5037/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 1316.4127 - val_loss: 1182.0562\n",
      "Epoch 5038/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 1316.2596 - val_loss: 1181.9015\n",
      "Epoch 5039/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 1316.1063 - val_loss: 1181.7466\n",
      "Epoch 5040/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 1315.9532 - val_loss: 1181.5920\n",
      "Epoch 5041/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 1315.8004 - val_loss: 1181.4374\n",
      "Epoch 5042/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 1315.6476 - val_loss: 1181.2828\n",
      "Epoch 5043/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 1315.4948 - val_loss: 1181.1288\n",
      "Epoch 5044/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1315.3422 - val_loss: 1180.9742\n",
      "Epoch 5045/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 1315.1896 - val_loss: 1180.8201\n",
      "Epoch 5046/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 1315.0370 - val_loss: 1180.6659\n",
      "Epoch 5047/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 1314.8846 - val_loss: 1180.5121\n",
      "Epoch 5048/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1314.7323 - val_loss: 1180.3582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5049/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1314.5801 - val_loss: 1180.2043\n",
      "Epoch 5050/100000\n",
      "11/11 [==============================] - 0s 594us/step - loss: 1314.4280 - val_loss: 1180.0505\n",
      "Epoch 5051/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1314.2760 - val_loss: 1179.8969\n",
      "Epoch 5052/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 1314.1240 - val_loss: 1179.7432\n",
      "Epoch 5053/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1313.9722 - val_loss: 1179.5897\n",
      "Epoch 5054/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1313.8204 - val_loss: 1179.4366\n",
      "Epoch 5055/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 1313.6688 - val_loss: 1179.2831\n",
      "Epoch 5056/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 1313.5172 - val_loss: 1179.1300\n",
      "Epoch 5057/100000\n",
      "11/11 [==============================] - 0s 581us/step - loss: 1313.3657 - val_loss: 1178.9769\n",
      "Epoch 5058/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 1313.2144 - val_loss: 1178.8240\n",
      "Epoch 5059/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 1313.0631 - val_loss: 1178.6710\n",
      "Epoch 5060/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1312.9117 - val_loss: 1178.5183\n",
      "Epoch 5061/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1312.7606 - val_loss: 1178.3656\n",
      "Epoch 5062/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1312.6096 - val_loss: 1178.2129\n",
      "Epoch 5063/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 1312.4586 - val_loss: 1178.0603\n",
      "Epoch 5064/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1312.3077 - val_loss: 1177.9077\n",
      "Epoch 5065/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 1312.1571 - val_loss: 1177.7554\n",
      "Epoch 5066/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 1312.0066 - val_loss: 1177.6034\n",
      "Epoch 5067/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1311.8558 - val_loss: 1177.4510\n",
      "Epoch 5068/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1311.7054 - val_loss: 1177.2990\n",
      "Epoch 5069/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1311.5549 - val_loss: 1177.1470\n",
      "Epoch 5070/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 1311.4048 - val_loss: 1176.9950\n",
      "Epoch 5071/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1311.2544 - val_loss: 1176.8433\n",
      "Epoch 5072/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1311.1042 - val_loss: 1176.6914\n",
      "Epoch 5073/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1310.9542 - val_loss: 1176.5398\n",
      "Epoch 5074/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1310.8043 - val_loss: 1176.3882\n",
      "Epoch 5075/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 1310.6544 - val_loss: 1176.2368\n",
      "Epoch 5076/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1310.5048 - val_loss: 1176.0854\n",
      "Epoch 5077/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1310.3551 - val_loss: 1175.9341\n",
      "Epoch 5078/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 1310.2054 - val_loss: 1175.7828\n",
      "Epoch 5079/100000\n",
      "11/11 [==============================] - 0s 205us/step - loss: 1310.0559 - val_loss: 1175.6318\n",
      "Epoch 5080/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 1309.9066 - val_loss: 1175.4808\n",
      "Epoch 5081/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 1309.7571 - val_loss: 1175.3297\n",
      "Epoch 5082/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 1309.6079 - val_loss: 1175.1790\n",
      "Epoch 5083/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1309.4589 - val_loss: 1175.0283\n",
      "Epoch 5084/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 1309.3098 - val_loss: 1174.8777\n",
      "Epoch 5085/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 1309.1608 - val_loss: 1174.7271\n",
      "Epoch 5086/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1309.0120 - val_loss: 1174.5765\n",
      "Epoch 5087/100000\n",
      "11/11 [==============================] - 0s 625us/step - loss: 1308.8632 - val_loss: 1174.4263\n",
      "Epoch 5088/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 1308.7145 - val_loss: 1174.2759\n",
      "Epoch 5089/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 1308.5659 - val_loss: 1174.1257\n",
      "Epoch 5090/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 1308.4172 - val_loss: 1173.9756\n",
      "Epoch 5091/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 1308.2688 - val_loss: 1173.8254\n",
      "Epoch 5092/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 1308.1204 - val_loss: 1173.6758\n",
      "Epoch 5093/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1307.9724 - val_loss: 1173.5258\n",
      "Epoch 5094/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 1307.8243 - val_loss: 1173.3760\n",
      "Epoch 5095/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1307.6761 - val_loss: 1173.2262\n",
      "Epoch 5096/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 1307.5282 - val_loss: 1173.0768\n",
      "Epoch 5097/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1307.3804 - val_loss: 1172.9272\n",
      "Epoch 5098/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1307.2324 - val_loss: 1172.7781\n",
      "Epoch 5099/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1307.0848 - val_loss: 1172.6287\n",
      "Epoch 5100/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1306.9371 - val_loss: 1172.4794\n",
      "Epoch 5101/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 1306.7896 - val_loss: 1172.3302\n",
      "Epoch 5102/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 1306.6422 - val_loss: 1172.1813\n",
      "Epoch 5103/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 1306.4950 - val_loss: 1172.0321\n",
      "Epoch 5104/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 1306.3475 - val_loss: 1171.8833\n",
      "Epoch 5105/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 1306.2003 - val_loss: 1171.7345\n",
      "Epoch 5106/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 1306.0532 - val_loss: 1171.5859\n",
      "Epoch 5107/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 1305.9062 - val_loss: 1171.4375\n",
      "Epoch 5108/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1305.7594 - val_loss: 1171.2889\n",
      "Epoch 5109/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1305.6125 - val_loss: 1171.1405\n",
      "Epoch 5110/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1305.4657 - val_loss: 1170.9921\n",
      "Epoch 5111/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 1305.3192 - val_loss: 1170.8439\n",
      "Epoch 5112/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 1305.1727 - val_loss: 1170.6958\n",
      "Epoch 5113/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 1305.0265 - val_loss: 1170.5477\n",
      "Epoch 5114/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1304.8800 - val_loss: 1170.3997\n",
      "Epoch 5115/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1304.7338 - val_loss: 1170.2520\n",
      "Epoch 5116/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 1304.5874 - val_loss: 1170.1040\n",
      "Epoch 5117/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1304.4414 - val_loss: 1169.9565\n",
      "Epoch 5118/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 1304.2953 - val_loss: 1169.8087\n",
      "Epoch 5119/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1304.1493 - val_loss: 1169.6611\n",
      "Epoch 5120/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1304.0035 - val_loss: 1169.5138\n",
      "Epoch 5121/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1303.8578 - val_loss: 1169.3665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5122/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1303.7122 - val_loss: 1169.2192\n",
      "Epoch 5123/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 1303.5665 - val_loss: 1169.0720\n",
      "Epoch 5124/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1303.4211 - val_loss: 1168.9249\n",
      "Epoch 5125/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1303.2759 - val_loss: 1168.7781\n",
      "Epoch 5126/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 1303.1305 - val_loss: 1168.6313\n",
      "Epoch 5127/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 1302.9852 - val_loss: 1168.4844\n",
      "Epoch 5128/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 1302.8401 - val_loss: 1168.3376\n",
      "Epoch 5129/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 1302.6951 - val_loss: 1168.1909\n",
      "Epoch 5130/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1302.5503 - val_loss: 1168.0444\n",
      "Epoch 5131/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 1302.4053 - val_loss: 1167.8979\n",
      "Epoch 5132/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 1302.2606 - val_loss: 1167.7518\n",
      "Epoch 5133/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1302.1160 - val_loss: 1167.6053\n",
      "Epoch 5134/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 1301.9712 - val_loss: 1167.4591\n",
      "Epoch 5135/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1301.8267 - val_loss: 1167.3132\n",
      "Epoch 5136/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 1301.6824 - val_loss: 1167.1671\n",
      "Epoch 5137/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 1301.5382 - val_loss: 1167.0212\n",
      "Epoch 5138/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1301.3939 - val_loss: 1166.8755\n",
      "Epoch 5139/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 1301.2496 - val_loss: 1166.7296\n",
      "Epoch 5140/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 1301.1057 - val_loss: 1166.5841\n",
      "Epoch 5141/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1300.9615 - val_loss: 1166.4386\n",
      "Epoch 5142/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1300.8179 - val_loss: 1166.2931\n",
      "Epoch 5143/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 1300.6741 - val_loss: 1166.1476\n",
      "Epoch 5144/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1300.5304 - val_loss: 1166.0022\n",
      "Epoch 5145/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1300.3866 - val_loss: 1165.8571\n",
      "Epoch 5146/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1300.2430 - val_loss: 1165.7120\n",
      "Epoch 5147/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1300.0996 - val_loss: 1165.5673\n",
      "Epoch 5148/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1299.9565 - val_loss: 1165.4220\n",
      "Epoch 5149/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 1299.8131 - val_loss: 1165.2772\n",
      "Epoch 5150/100000\n",
      "11/11 [==============================] - 0s 777us/step - loss: 1299.6700 - val_loss: 1165.1324\n",
      "Epoch 5151/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1299.5270 - val_loss: 1164.9878\n",
      "Epoch 5152/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 1299.3839 - val_loss: 1164.8433\n",
      "Epoch 5153/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1299.2410 - val_loss: 1164.6985\n",
      "Epoch 5154/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 1299.0981 - val_loss: 1164.5542\n",
      "Epoch 5155/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1298.9553 - val_loss: 1164.4100\n",
      "Epoch 5156/100000\n",
      "11/11 [==============================] - 0s 655us/step - loss: 1298.8129 - val_loss: 1164.2659\n",
      "Epoch 5157/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 1298.6700 - val_loss: 1164.1215\n",
      "Epoch 5158/100000\n",
      "11/11 [==============================] - 0s 686us/step - loss: 1298.5278 - val_loss: 1163.9774\n",
      "Epoch 5159/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 1298.3853 - val_loss: 1163.8336\n",
      "Epoch 5160/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 1298.2432 - val_loss: 1163.6896\n",
      "Epoch 5161/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1298.1008 - val_loss: 1163.5460\n",
      "Epoch 5162/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1297.9589 - val_loss: 1163.4022\n",
      "Epoch 5163/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 1297.8168 - val_loss: 1163.2587\n",
      "Epoch 5164/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1297.6747 - val_loss: 1163.1151\n",
      "Epoch 5165/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 1297.5331 - val_loss: 1162.9717\n",
      "Epoch 5166/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1297.3911 - val_loss: 1162.8282\n",
      "Epoch 5167/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1297.2495 - val_loss: 1162.6851\n",
      "Epoch 5168/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1297.1079 - val_loss: 1162.5419\n",
      "Epoch 5169/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 1296.9664 - val_loss: 1162.3989\n",
      "Epoch 5170/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 1296.8251 - val_loss: 1162.2559\n",
      "Epoch 5171/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 1296.6837 - val_loss: 1162.1129\n",
      "Epoch 5172/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1296.5425 - val_loss: 1161.9702\n",
      "Epoch 5173/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1296.4012 - val_loss: 1161.8274\n",
      "Epoch 5174/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 1296.2603 - val_loss: 1161.6847\n",
      "Epoch 5175/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 1296.1193 - val_loss: 1161.5422\n",
      "Epoch 5176/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1295.9785 - val_loss: 1161.4000\n",
      "Epoch 5177/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 1295.8378 - val_loss: 1161.2573\n",
      "Epoch 5178/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 1295.6971 - val_loss: 1161.1151\n",
      "Epoch 5179/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1295.5563 - val_loss: 1160.9728\n",
      "Epoch 5180/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1295.4159 - val_loss: 1160.8308\n",
      "Epoch 5181/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 1295.2755 - val_loss: 1160.6888\n",
      "Epoch 5182/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 1295.1353 - val_loss: 1160.5469\n",
      "Epoch 5183/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 1294.9946 - val_loss: 1160.4048\n",
      "Epoch 5184/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 1294.8546 - val_loss: 1160.2633\n",
      "Epoch 5185/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1294.7145 - val_loss: 1160.1216\n",
      "Epoch 5186/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 1294.5743 - val_loss: 1159.9800\n",
      "Epoch 5187/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1294.4346 - val_loss: 1159.8386\n",
      "Epoch 5188/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 1294.2948 - val_loss: 1159.6971\n",
      "Epoch 5189/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 1294.1549 - val_loss: 1159.5558\n",
      "Epoch 5190/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 1294.0153 - val_loss: 1159.4144\n",
      "Epoch 5191/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1293.8759 - val_loss: 1159.2733\n",
      "Epoch 5192/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 1293.7362 - val_loss: 1159.1323\n",
      "Epoch 5193/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1293.5968 - val_loss: 1158.9913\n",
      "Epoch 5194/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 1293.4578 - val_loss: 1158.8503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5195/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 1293.3184 - val_loss: 1158.7097\n",
      "Epoch 5196/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1293.1792 - val_loss: 1158.5688\n",
      "Epoch 5197/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 1293.0402 - val_loss: 1158.4282\n",
      "Epoch 5198/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1292.9012 - val_loss: 1158.2877\n",
      "Epoch 5199/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1292.7622 - val_loss: 1158.1473\n",
      "Epoch 5200/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1292.6235 - val_loss: 1158.0070\n",
      "Epoch 5201/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 1292.4849 - val_loss: 1157.8666\n",
      "Epoch 5202/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 1292.3462 - val_loss: 1157.7264\n",
      "Epoch 5203/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 1292.2078 - val_loss: 1157.5864\n",
      "Epoch 5204/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1292.0693 - val_loss: 1157.4464\n",
      "Epoch 5205/100000\n",
      "11/11 [==============================] - 0s 695us/step - loss: 1291.9308 - val_loss: 1157.3064\n",
      "Epoch 5206/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 1291.7925 - val_loss: 1157.1666\n",
      "Epoch 5207/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 1291.6545 - val_loss: 1157.0270\n",
      "Epoch 5208/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1291.5165 - val_loss: 1156.8872\n",
      "Epoch 5209/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 1291.3784 - val_loss: 1156.7478\n",
      "Epoch 5210/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 1291.2406 - val_loss: 1156.6082\n",
      "Epoch 5211/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1291.1027 - val_loss: 1156.4688\n",
      "Epoch 5212/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 1290.9648 - val_loss: 1156.3296\n",
      "Epoch 5213/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1290.8273 - val_loss: 1156.1903\n",
      "Epoch 5214/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1290.6898 - val_loss: 1156.0511\n",
      "Epoch 5215/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 1290.5524 - val_loss: 1155.9120\n",
      "Epoch 5216/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 1290.4148 - val_loss: 1155.7731\n",
      "Epoch 5217/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 1290.2775 - val_loss: 1155.6342\n",
      "Epoch 5218/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1290.1404 - val_loss: 1155.4954\n",
      "Epoch 5219/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1290.0032 - val_loss: 1155.3568\n",
      "Epoch 5220/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 1289.8661 - val_loss: 1155.2183\n",
      "Epoch 5221/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 1289.7292 - val_loss: 1155.0796\n",
      "Epoch 5222/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 1289.5923 - val_loss: 1154.9410\n",
      "Epoch 5223/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1289.4556 - val_loss: 1154.8029\n",
      "Epoch 5224/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1289.3188 - val_loss: 1154.6644\n",
      "Epoch 5225/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1289.1824 - val_loss: 1154.5262\n",
      "Epoch 5226/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1289.0458 - val_loss: 1154.3883\n",
      "Epoch 5227/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 1288.9093 - val_loss: 1154.2502\n",
      "Epoch 5228/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1288.7729 - val_loss: 1154.1123\n",
      "Epoch 5229/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1288.6367 - val_loss: 1153.9745\n",
      "Epoch 5230/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 1288.5005 - val_loss: 1153.8365\n",
      "Epoch 5231/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1288.3644 - val_loss: 1153.6991\n",
      "Epoch 5232/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1288.2284 - val_loss: 1153.5614\n",
      "Epoch 5233/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 1288.0925 - val_loss: 1153.4240\n",
      "Epoch 5234/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1287.9565 - val_loss: 1153.2866\n",
      "Epoch 5235/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1287.8208 - val_loss: 1153.1492\n",
      "Epoch 5236/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1287.6853 - val_loss: 1153.0121\n",
      "Epoch 5237/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1287.5496 - val_loss: 1152.8750\n",
      "Epoch 5238/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1287.4142 - val_loss: 1152.7378\n",
      "Epoch 5239/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 1287.2788 - val_loss: 1152.6008\n",
      "Epoch 5240/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1287.1434 - val_loss: 1152.4640\n",
      "Epoch 5241/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 1287.0082 - val_loss: 1152.3270\n",
      "Epoch 5242/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1286.8730 - val_loss: 1152.1903\n",
      "Epoch 5243/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 1286.7380 - val_loss: 1152.0538\n",
      "Epoch 5244/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1286.6030 - val_loss: 1151.9174\n",
      "Epoch 5245/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 1286.4679 - val_loss: 1151.7808\n",
      "Epoch 5246/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 1286.3331 - val_loss: 1151.6445\n",
      "Epoch 5247/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 1286.1985 - val_loss: 1151.5082\n",
      "Epoch 5248/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 1286.0640 - val_loss: 1151.3719\n",
      "Epoch 5249/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1285.9294 - val_loss: 1151.2358\n",
      "Epoch 5250/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1285.7949 - val_loss: 1151.0997\n",
      "Epoch 5251/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 1285.6606 - val_loss: 1150.9640\n",
      "Epoch 5252/100000\n",
      "11/11 [==============================] - 0s 631us/step - loss: 1285.5262 - val_loss: 1150.8280\n",
      "Epoch 5253/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 1285.3921 - val_loss: 1150.6923\n",
      "Epoch 5254/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 1285.2579 - val_loss: 1150.5566\n",
      "Epoch 5255/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1285.1239 - val_loss: 1150.4210\n",
      "Epoch 5256/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 1284.9901 - val_loss: 1150.2856\n",
      "Epoch 5257/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 1284.8563 - val_loss: 1150.1500\n",
      "Epoch 5258/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1284.7223 - val_loss: 1150.0146\n",
      "Epoch 5259/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 1284.5887 - val_loss: 1149.8795\n",
      "Epoch 5260/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1284.4550 - val_loss: 1149.7445\n",
      "Epoch 5261/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 1284.3215 - val_loss: 1149.6093\n",
      "Epoch 5262/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1284.1880 - val_loss: 1149.4745\n",
      "Epoch 5263/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1284.0548 - val_loss: 1149.3394\n",
      "Epoch 5264/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 1283.9215 - val_loss: 1149.2046\n",
      "Epoch 5265/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 1283.7882 - val_loss: 1149.0698\n",
      "Epoch 5266/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 1283.6552 - val_loss: 1148.9351\n",
      "Epoch 5267/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 1283.5222 - val_loss: 1148.8007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5268/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 1283.3894 - val_loss: 1148.6661\n",
      "Epoch 5269/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 1283.2566 - val_loss: 1148.5317\n",
      "Epoch 5270/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1283.1238 - val_loss: 1148.3976\n",
      "Epoch 5271/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1282.9911 - val_loss: 1148.2632\n",
      "Epoch 5272/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1282.8586 - val_loss: 1148.1292\n",
      "Epoch 5273/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 1282.7261 - val_loss: 1147.9952\n",
      "Epoch 5274/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 1282.5938 - val_loss: 1147.8612\n",
      "Epoch 5275/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 1282.4614 - val_loss: 1147.7273\n",
      "Epoch 5276/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1282.3291 - val_loss: 1147.5936\n",
      "Epoch 5277/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 1282.1970 - val_loss: 1147.4598\n",
      "Epoch 5278/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1282.0649 - val_loss: 1147.3262\n",
      "Epoch 5279/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1281.9329 - val_loss: 1147.1925\n",
      "Epoch 5280/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 1281.8010 - val_loss: 1147.0593\n",
      "Epoch 5281/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1281.6693 - val_loss: 1146.9259\n",
      "Epoch 5282/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1281.5376 - val_loss: 1146.7927\n",
      "Epoch 5283/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 1281.4061 - val_loss: 1146.6593\n",
      "Epoch 5284/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1281.2743 - val_loss: 1146.5262\n",
      "Epoch 5285/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 1281.1429 - val_loss: 1146.3932\n",
      "Epoch 5286/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1281.0114 - val_loss: 1146.2603\n",
      "Epoch 5287/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 1280.8801 - val_loss: 1146.1274\n",
      "Epoch 5288/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 1280.7489 - val_loss: 1145.9946\n",
      "Epoch 5289/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1280.6179 - val_loss: 1145.8621\n",
      "Epoch 5290/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1280.4871 - val_loss: 1145.7294\n",
      "Epoch 5291/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1280.3558 - val_loss: 1145.5968\n",
      "Epoch 5292/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1280.2250 - val_loss: 1145.4644\n",
      "Epoch 5293/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 1280.0944 - val_loss: 1145.3320\n",
      "Epoch 5294/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1279.9636 - val_loss: 1145.2000\n",
      "Epoch 5295/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1279.8330 - val_loss: 1145.0677\n",
      "Epoch 5296/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1279.7024 - val_loss: 1144.9355\n",
      "Epoch 5297/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1279.5721 - val_loss: 1144.8035\n",
      "Epoch 5298/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 1279.4415 - val_loss: 1144.6718\n",
      "Epoch 5299/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 1279.3114 - val_loss: 1144.5400\n",
      "Epoch 5300/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 1279.1812 - val_loss: 1144.4081\n",
      "Epoch 5301/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1279.0509 - val_loss: 1144.2765\n",
      "Epoch 5302/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 1278.9210 - val_loss: 1144.1449\n",
      "Epoch 5303/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1278.7909 - val_loss: 1144.0134\n",
      "Epoch 5304/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 1278.6613 - val_loss: 1143.8821\n",
      "Epoch 5305/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1278.5314 - val_loss: 1143.7507\n",
      "Epoch 5306/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 1278.4019 - val_loss: 1143.6195\n",
      "Epoch 5307/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 1278.2723 - val_loss: 1143.4882\n",
      "Epoch 5308/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 1278.1426 - val_loss: 1143.3573\n",
      "Epoch 5309/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 1278.0132 - val_loss: 1143.2263\n",
      "Epoch 5310/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 1277.8838 - val_loss: 1143.0956\n",
      "Epoch 5311/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 1277.7544 - val_loss: 1142.9646\n",
      "Epoch 5312/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1277.6254 - val_loss: 1142.8339\n",
      "Epoch 5313/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1277.4962 - val_loss: 1142.7031\n",
      "Epoch 5314/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1277.3673 - val_loss: 1142.5728\n",
      "Epoch 5315/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1277.2384 - val_loss: 1142.4421\n",
      "Epoch 5316/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 1277.1095 - val_loss: 1142.3118\n",
      "Epoch 5317/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 1276.9807 - val_loss: 1142.1814\n",
      "Epoch 5318/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 1276.8521 - val_loss: 1142.0513\n",
      "Epoch 5319/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 1276.7235 - val_loss: 1141.9211\n",
      "Epoch 5320/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1276.5950 - val_loss: 1141.7910\n",
      "Epoch 5321/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 1276.4666 - val_loss: 1141.6610\n",
      "Epoch 5322/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 1276.3383 - val_loss: 1141.5312\n",
      "Epoch 5323/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1276.2101 - val_loss: 1141.4015\n",
      "Epoch 5324/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 1276.0819 - val_loss: 1141.2719\n",
      "Epoch 5325/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 1275.9539 - val_loss: 1141.1421\n",
      "Epoch 5326/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 1275.8257 - val_loss: 1141.0126\n",
      "Epoch 5327/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 1275.6979 - val_loss: 1140.8832\n",
      "Epoch 5328/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1275.5702 - val_loss: 1140.7538\n",
      "Epoch 5329/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 1275.4423 - val_loss: 1140.6245\n",
      "Epoch 5330/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1275.3148 - val_loss: 1140.4954\n",
      "Epoch 5331/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 1275.1871 - val_loss: 1140.3661\n",
      "Epoch 5332/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 1275.0594 - val_loss: 1140.2372\n",
      "Epoch 5333/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 1274.9321 - val_loss: 1140.1082\n",
      "Epoch 5334/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1274.8047 - val_loss: 1139.9792\n",
      "Epoch 5335/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 1274.6775 - val_loss: 1139.8505\n",
      "Epoch 5336/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 1274.5503 - val_loss: 1139.7218\n",
      "Epoch 5337/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 1274.4233 - val_loss: 1139.5930\n",
      "Epoch 5338/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1274.2964 - val_loss: 1139.4647\n",
      "Epoch 5339/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 1274.1694 - val_loss: 1139.3362\n",
      "Epoch 5340/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1274.0427 - val_loss: 1139.2079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5341/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1273.9159 - val_loss: 1139.0796\n",
      "Epoch 5342/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1273.7892 - val_loss: 1138.9513\n",
      "Epoch 5343/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 1273.6626 - val_loss: 1138.8231\n",
      "Epoch 5344/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 1273.5363 - val_loss: 1138.6952\n",
      "Epoch 5345/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 1273.4098 - val_loss: 1138.5673\n",
      "Epoch 5346/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 1273.2836 - val_loss: 1138.4395\n",
      "Epoch 5347/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 1273.1571 - val_loss: 1138.3116\n",
      "Epoch 5348/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1273.0311 - val_loss: 1138.1840\n",
      "Epoch 5349/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 1272.9050 - val_loss: 1138.0564\n",
      "Epoch 5350/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 1272.7788 - val_loss: 1137.9287\n",
      "Epoch 5351/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 1272.6531 - val_loss: 1137.8014\n",
      "Epoch 5352/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 1272.5272 - val_loss: 1137.6740\n",
      "Epoch 5353/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 1272.4015 - val_loss: 1137.5468\n",
      "Epoch 5354/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 1272.2759 - val_loss: 1137.4196\n",
      "Epoch 5355/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1272.1503 - val_loss: 1137.2924\n",
      "Epoch 5356/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 1272.0247 - val_loss: 1137.1653\n",
      "Epoch 5357/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 1271.8993 - val_loss: 1137.0383\n",
      "Epoch 5358/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 1271.7742 - val_loss: 1136.9116\n",
      "Epoch 5359/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 1271.6489 - val_loss: 1136.7848\n",
      "Epoch 5360/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1271.5238 - val_loss: 1136.6582\n",
      "Epoch 5361/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1271.3987 - val_loss: 1136.5315\n",
      "Epoch 5362/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1271.2736 - val_loss: 1136.4050\n",
      "Epoch 5363/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1271.1487 - val_loss: 1136.2786\n",
      "Epoch 5364/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 1271.0239 - val_loss: 1136.1522\n",
      "Epoch 5365/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1270.8992 - val_loss: 1136.0259\n",
      "Epoch 5366/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1270.7745 - val_loss: 1135.8999\n",
      "Epoch 5367/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1270.6499 - val_loss: 1135.7737\n",
      "Epoch 5368/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 1270.5254 - val_loss: 1135.6476\n",
      "Epoch 5369/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1270.4011 - val_loss: 1135.5216\n",
      "Epoch 5370/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 1270.2766 - val_loss: 1135.3958\n",
      "Epoch 5371/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1270.1525 - val_loss: 1135.2700\n",
      "Epoch 5372/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1270.0284 - val_loss: 1135.1444\n",
      "Epoch 5373/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 1269.9042 - val_loss: 1135.0187\n",
      "Epoch 5374/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1269.7804 - val_loss: 1134.8933\n",
      "Epoch 5375/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1269.6564 - val_loss: 1134.7677\n",
      "Epoch 5376/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1269.5327 - val_loss: 1134.6425\n",
      "Epoch 5377/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 1269.4088 - val_loss: 1134.5171\n",
      "Epoch 5378/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1269.2852 - val_loss: 1134.3921\n",
      "Epoch 5379/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1269.1616 - val_loss: 1134.2668\n",
      "Epoch 5380/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1269.0380 - val_loss: 1134.1418\n",
      "Epoch 5381/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 1268.9148 - val_loss: 1134.0171\n",
      "Epoch 5382/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 1268.7914 - val_loss: 1133.8920\n",
      "Epoch 5383/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1268.6681 - val_loss: 1133.7673\n",
      "Epoch 5384/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 1268.5448 - val_loss: 1133.6425\n",
      "Epoch 5385/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 1268.4219 - val_loss: 1133.5178\n",
      "Epoch 5386/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1268.2987 - val_loss: 1133.3934\n",
      "Epoch 5387/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 1268.1759 - val_loss: 1133.2688\n",
      "Epoch 5388/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 1268.0531 - val_loss: 1133.1445\n",
      "Epoch 5389/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 1267.9304 - val_loss: 1133.0203\n",
      "Epoch 5390/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 1267.8076 - val_loss: 1132.8961\n",
      "Epoch 5391/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1267.6851 - val_loss: 1132.7720\n",
      "Epoch 5392/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1267.5626 - val_loss: 1132.6479\n",
      "Epoch 5393/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 1267.4401 - val_loss: 1132.5242\n",
      "Epoch 5394/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 1267.3179 - val_loss: 1132.4003\n",
      "Epoch 5395/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 1267.1954 - val_loss: 1132.2764\n",
      "Epoch 5396/100000\n",
      "11/11 [==============================] - 0s 633us/step - loss: 1267.0734 - val_loss: 1132.1525\n",
      "Epoch 5397/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 1266.9513 - val_loss: 1132.0292\n",
      "Epoch 5398/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 1266.8291 - val_loss: 1131.9054\n",
      "Epoch 5399/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 1266.7072 - val_loss: 1131.7821\n",
      "Epoch 5400/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1266.5854 - val_loss: 1131.6587\n",
      "Epoch 5401/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1266.4637 - val_loss: 1131.5355\n",
      "Epoch 5402/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1266.3420 - val_loss: 1131.4122\n",
      "Epoch 5403/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1266.2205 - val_loss: 1131.2892\n",
      "Epoch 5404/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 1266.0989 - val_loss: 1131.1661\n",
      "Epoch 5405/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 1265.9774 - val_loss: 1131.0430\n",
      "Epoch 5406/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 1265.8560 - val_loss: 1130.9203\n",
      "Epoch 5407/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 1265.7349 - val_loss: 1130.7974\n",
      "Epoch 5408/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1265.6136 - val_loss: 1130.6747\n",
      "Epoch 5409/100000\n",
      "11/11 [==============================] - 0s 679us/step - loss: 1265.4926 - val_loss: 1130.5520\n",
      "Epoch 5410/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1265.3715 - val_loss: 1130.4296\n",
      "Epoch 5411/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1265.2505 - val_loss: 1130.3070\n",
      "Epoch 5412/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1265.1298 - val_loss: 1130.1847\n",
      "Epoch 5413/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 1265.0090 - val_loss: 1130.0624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5414/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1264.8882 - val_loss: 1129.9401\n",
      "Epoch 5415/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1264.7676 - val_loss: 1129.8182\n",
      "Epoch 5416/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1264.6470 - val_loss: 1129.6960\n",
      "Epoch 5417/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1264.5266 - val_loss: 1129.5741\n",
      "Epoch 5418/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 1264.4064 - val_loss: 1129.4520\n",
      "Epoch 5419/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 1264.2859 - val_loss: 1129.3302\n",
      "Epoch 5420/100000\n",
      "11/11 [==============================] - 0s 581us/step - loss: 1264.1659 - val_loss: 1129.2086\n",
      "Epoch 5421/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 1264.0458 - val_loss: 1129.0870\n",
      "Epoch 5422/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 1263.9255 - val_loss: 1128.9653\n",
      "Epoch 5423/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 1263.8055 - val_loss: 1128.8439\n",
      "Epoch 5424/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1263.6858 - val_loss: 1128.7224\n",
      "Epoch 5425/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 1263.5660 - val_loss: 1128.6012\n",
      "Epoch 5426/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 1263.4463 - val_loss: 1128.4800\n",
      "Epoch 5427/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1263.3267 - val_loss: 1128.3588\n",
      "Epoch 5428/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 1263.2072 - val_loss: 1128.2377\n",
      "Epoch 5429/100000\n",
      "11/11 [==============================] - 0s 803us/step - loss: 1263.0875 - val_loss: 1128.1167\n",
      "Epoch 5430/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 1262.9683 - val_loss: 1127.9957\n",
      "Epoch 5431/100000\n",
      "11/11 [==============================] - 0s 609us/step - loss: 1262.8489 - val_loss: 1127.8750\n",
      "Epoch 5432/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 1262.7297 - val_loss: 1127.7543\n",
      "Epoch 5433/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 1262.6105 - val_loss: 1127.6337\n",
      "Epoch 5434/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1262.4916 - val_loss: 1127.5129\n",
      "Epoch 5435/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 1262.3726 - val_loss: 1127.3925\n",
      "Epoch 5436/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 1262.2537 - val_loss: 1127.2721\n",
      "Epoch 5437/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1262.1349 - val_loss: 1127.1519\n",
      "Epoch 5438/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1262.0161 - val_loss: 1127.0316\n",
      "Epoch 5439/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1261.8973 - val_loss: 1126.9114\n",
      "Epoch 5440/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1261.7788 - val_loss: 1126.7913\n",
      "Epoch 5441/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1261.6603 - val_loss: 1126.6711\n",
      "Epoch 5442/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 1261.5419 - val_loss: 1126.5513\n",
      "Epoch 5443/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 1261.4236 - val_loss: 1126.4315\n",
      "Epoch 5444/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 1261.3054 - val_loss: 1126.3116\n",
      "Epoch 5445/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1261.1870 - val_loss: 1126.1919\n",
      "Epoch 5446/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1261.0692 - val_loss: 1126.0724\n",
      "Epoch 5447/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 1260.9510 - val_loss: 1125.9529\n",
      "Epoch 5448/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 1260.8331 - val_loss: 1125.8335\n",
      "Epoch 5449/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 1260.7153 - val_loss: 1125.7140\n",
      "Epoch 5450/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1260.5974 - val_loss: 1125.5948\n",
      "Epoch 5451/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1260.4800 - val_loss: 1125.4756\n",
      "Epoch 5452/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 1260.3624 - val_loss: 1125.3566\n",
      "Epoch 5453/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 1260.2446 - val_loss: 1125.2374\n",
      "Epoch 5454/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1260.1271 - val_loss: 1125.1185\n",
      "Epoch 5455/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1260.0099 - val_loss: 1124.9995\n",
      "Epoch 5456/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1259.8926 - val_loss: 1124.8809\n",
      "Epoch 5457/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1259.7754 - val_loss: 1124.7622\n",
      "Epoch 5458/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 1259.6583 - val_loss: 1124.6434\n",
      "Epoch 5459/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1259.5411 - val_loss: 1124.5250\n",
      "Epoch 5460/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 1259.4242 - val_loss: 1124.4064\n",
      "Epoch 5461/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1259.3074 - val_loss: 1124.2882\n",
      "Epoch 5462/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 1259.1906 - val_loss: 1124.1698\n",
      "Epoch 5463/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 1259.0739 - val_loss: 1124.0515\n",
      "Epoch 5464/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 1258.9572 - val_loss: 1123.9333\n",
      "Epoch 5465/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1258.8407 - val_loss: 1123.8154\n",
      "Epoch 5466/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1258.7244 - val_loss: 1123.6973\n",
      "Epoch 5467/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 1258.6078 - val_loss: 1123.5796\n",
      "Epoch 5468/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 1258.4915 - val_loss: 1123.4617\n",
      "Epoch 5469/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1258.3754 - val_loss: 1123.3439\n",
      "Epoch 5470/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1258.2593 - val_loss: 1123.2261\n",
      "Epoch 5471/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1258.1431 - val_loss: 1123.1086\n",
      "Epoch 5472/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 1258.0272 - val_loss: 1122.9912\n",
      "Epoch 5473/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1257.9111 - val_loss: 1122.8738\n",
      "Epoch 5474/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 1257.7953 - val_loss: 1122.7565\n",
      "Epoch 5475/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 1257.6796 - val_loss: 1122.6390\n",
      "Epoch 5476/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1257.5640 - val_loss: 1122.5222\n",
      "Epoch 5477/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1257.4484 - val_loss: 1122.4049\n",
      "Epoch 5478/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1257.3329 - val_loss: 1122.2878\n",
      "Epoch 5479/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 1257.2174 - val_loss: 1122.1710\n",
      "Epoch 5480/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 1257.1021 - val_loss: 1122.0542\n",
      "Epoch 5481/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1256.9867 - val_loss: 1121.9374\n",
      "Epoch 5482/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1256.8716 - val_loss: 1121.8207\n",
      "Epoch 5483/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 1256.7565 - val_loss: 1121.7040\n",
      "Epoch 5484/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1256.6415 - val_loss: 1121.5875\n",
      "Epoch 5485/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 1256.5265 - val_loss: 1121.4711\n",
      "Epoch 5486/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1256.4115 - val_loss: 1121.3546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5487/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 1256.2968 - val_loss: 1121.2383\n",
      "Epoch 5488/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 1256.1821 - val_loss: 1121.1222\n",
      "Epoch 5489/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1256.0675 - val_loss: 1121.0060\n",
      "Epoch 5490/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 1255.9530 - val_loss: 1120.8901\n",
      "Epoch 5491/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 1255.8386 - val_loss: 1120.7739\n",
      "Epoch 5492/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 1255.7241 - val_loss: 1120.6581\n",
      "Epoch 5493/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1255.6097 - val_loss: 1120.5424\n",
      "Epoch 5494/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 1255.4956 - val_loss: 1120.4266\n",
      "Epoch 5495/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1255.3813 - val_loss: 1120.3110\n",
      "Epoch 5496/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 1255.2675 - val_loss: 1120.1953\n",
      "Epoch 5497/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 1255.1534 - val_loss: 1120.0800\n",
      "Epoch 5498/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 1255.0394 - val_loss: 1119.9645\n",
      "Epoch 5499/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 1254.9257 - val_loss: 1119.8491\n",
      "Epoch 5500/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1254.8119 - val_loss: 1119.7339\n",
      "Epoch 5501/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1254.6981 - val_loss: 1119.6188\n",
      "Epoch 5502/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 1254.5845 - val_loss: 1119.5037\n",
      "Epoch 5503/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1254.4711 - val_loss: 1119.3885\n",
      "Epoch 5504/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 1254.3575 - val_loss: 1119.2738\n",
      "Epoch 5505/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1254.2444 - val_loss: 1119.1588\n",
      "Epoch 5506/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1254.1310 - val_loss: 1119.0441\n",
      "Epoch 5507/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1254.0177 - val_loss: 1118.9293\n",
      "Epoch 5508/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 1253.9048 - val_loss: 1118.8146\n",
      "Epoch 5509/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1253.7916 - val_loss: 1118.7001\n",
      "Epoch 5510/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1253.6786 - val_loss: 1118.5858\n",
      "Epoch 5511/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 1253.5659 - val_loss: 1118.4714\n",
      "Epoch 5512/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1253.4530 - val_loss: 1118.3572\n",
      "Epoch 5513/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1253.3402 - val_loss: 1118.2429\n",
      "Epoch 5514/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1253.2277 - val_loss: 1118.1288\n",
      "Epoch 5515/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 1253.1151 - val_loss: 1118.0148\n",
      "Epoch 5516/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 1253.0028 - val_loss: 1117.9008\n",
      "Epoch 5517/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1252.8903 - val_loss: 1117.7870\n",
      "Epoch 5518/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1252.7778 - val_loss: 1117.6730\n",
      "Epoch 5519/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1252.6656 - val_loss: 1117.5593\n",
      "Epoch 5520/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 1252.5535 - val_loss: 1117.4457\n",
      "Epoch 5521/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1252.4414 - val_loss: 1117.3322\n",
      "Epoch 5522/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 1252.3295 - val_loss: 1117.2185\n",
      "Epoch 5523/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 1252.2177 - val_loss: 1117.1051\n",
      "Epoch 5524/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1252.1056 - val_loss: 1116.9918\n",
      "Epoch 5525/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1251.9939 - val_loss: 1116.8784\n",
      "Epoch 5526/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 1251.8822 - val_loss: 1116.7655\n",
      "Epoch 5527/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 1251.7706 - val_loss: 1116.6523\n",
      "Epoch 5528/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 1251.6591 - val_loss: 1116.5394\n",
      "Epoch 5529/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1251.5476 - val_loss: 1116.4263\n",
      "Epoch 5530/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 1251.4362 - val_loss: 1116.3134\n",
      "Epoch 5531/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 1251.3250 - val_loss: 1116.2007\n",
      "Epoch 5532/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1251.2137 - val_loss: 1116.0880\n",
      "Epoch 5533/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 1251.1027 - val_loss: 1115.9755\n",
      "Epoch 5534/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 1250.9915 - val_loss: 1115.8628\n",
      "Epoch 5535/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 1250.8807 - val_loss: 1115.7504\n",
      "Epoch 5536/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 1250.7697 - val_loss: 1115.6379\n",
      "Epoch 5537/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 1250.6588 - val_loss: 1115.5256\n",
      "Epoch 5538/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1250.5482 - val_loss: 1115.4136\n",
      "Epoch 5539/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1250.4375 - val_loss: 1115.3013\n",
      "Epoch 5540/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 1250.3269 - val_loss: 1115.1891\n",
      "Epoch 5541/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 1250.2163 - val_loss: 1115.0773\n",
      "Epoch 5542/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1250.1060 - val_loss: 1114.9653\n",
      "Epoch 5543/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1249.9957 - val_loss: 1114.8535\n",
      "Epoch 5544/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 1249.8853 - val_loss: 1114.7417\n",
      "Epoch 5545/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1249.7753 - val_loss: 1114.6300\n",
      "Epoch 5546/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1249.6649 - val_loss: 1114.5184\n",
      "Epoch 5547/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 1249.5551 - val_loss: 1114.4069\n",
      "Epoch 5548/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1249.4451 - val_loss: 1114.2954\n",
      "Epoch 5549/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1249.3351 - val_loss: 1114.1841\n",
      "Epoch 5550/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 1249.2255 - val_loss: 1114.0729\n",
      "Epoch 5551/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1249.1156 - val_loss: 1113.9617\n",
      "Epoch 5552/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 1249.0060 - val_loss: 1113.8505\n",
      "Epoch 5553/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 1248.8964 - val_loss: 1113.7395\n",
      "Epoch 5554/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1248.7870 - val_loss: 1113.6285\n",
      "Epoch 5555/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 1248.6776 - val_loss: 1113.5175\n",
      "Epoch 5556/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 1248.5682 - val_loss: 1113.4067\n",
      "Epoch 5557/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1248.4590 - val_loss: 1113.2960\n",
      "Epoch 5558/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1248.3497 - val_loss: 1113.1854\n",
      "Epoch 5559/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 1248.2407 - val_loss: 1113.0750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5560/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1248.1317 - val_loss: 1112.9644\n",
      "Epoch 5561/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 1248.0227 - val_loss: 1112.8539\n",
      "Epoch 5562/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1247.9137 - val_loss: 1112.7435\n",
      "Epoch 5563/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 1247.8051 - val_loss: 1112.6333\n",
      "Epoch 5564/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1247.6964 - val_loss: 1112.5231\n",
      "Epoch 5565/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1247.5878 - val_loss: 1112.4130\n",
      "Epoch 5566/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 1247.4791 - val_loss: 1112.3029\n",
      "Epoch 5567/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 1247.3710 - val_loss: 1112.1930\n",
      "Epoch 5568/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1247.2625 - val_loss: 1112.0831\n",
      "Epoch 5569/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1247.1541 - val_loss: 1111.9734\n",
      "Epoch 5570/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1247.0458 - val_loss: 1111.8638\n",
      "Epoch 5571/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1246.9375 - val_loss: 1111.7540\n",
      "Epoch 5572/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1246.8296 - val_loss: 1111.6444\n",
      "Epoch 5573/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 1246.7216 - val_loss: 1111.5350\n",
      "Epoch 5574/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1246.6136 - val_loss: 1111.4257\n",
      "Epoch 5575/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1246.5057 - val_loss: 1111.3163\n",
      "Epoch 5576/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1246.3979 - val_loss: 1111.2070\n",
      "Epoch 5577/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 1246.2905 - val_loss: 1111.0978\n",
      "Epoch 5578/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1246.1826 - val_loss: 1110.9886\n",
      "Epoch 5579/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1246.0753 - val_loss: 1110.8798\n",
      "Epoch 5580/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1245.9678 - val_loss: 1110.7706\n",
      "Epoch 5581/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1245.8604 - val_loss: 1110.6620\n",
      "Epoch 5582/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1245.7529 - val_loss: 1110.5531\n",
      "Epoch 5583/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1245.6458 - val_loss: 1110.4442\n",
      "Epoch 5584/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1245.5386 - val_loss: 1110.3358\n",
      "Epoch 5585/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 1245.4316 - val_loss: 1110.2272\n",
      "Epoch 5586/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1245.3246 - val_loss: 1110.1189\n",
      "Epoch 5587/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1245.2177 - val_loss: 1110.0103\n",
      "Epoch 5588/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1245.1110 - val_loss: 1109.9021\n",
      "Epoch 5589/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 1245.0039 - val_loss: 1109.7937\n",
      "Epoch 5590/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 1244.8975 - val_loss: 1109.6857\n",
      "Epoch 5591/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 1244.7908 - val_loss: 1109.5776\n",
      "Epoch 5592/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1244.6843 - val_loss: 1109.4696\n",
      "Epoch 5593/100000\n",
      "11/11 [==============================] - 0s 660us/step - loss: 1244.5778 - val_loss: 1109.3618\n",
      "Epoch 5594/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 1244.4714 - val_loss: 1109.2538\n",
      "Epoch 5595/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 1244.3652 - val_loss: 1109.1460\n",
      "Epoch 5596/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 1244.2589 - val_loss: 1109.0383\n",
      "Epoch 5597/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 1244.1527 - val_loss: 1108.9308\n",
      "Epoch 5598/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 1244.0468 - val_loss: 1108.8232\n",
      "Epoch 5599/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 1243.9408 - val_loss: 1108.7157\n",
      "Epoch 5600/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 1243.8348 - val_loss: 1108.6083\n",
      "Epoch 5601/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1243.7290 - val_loss: 1108.5011\n",
      "Epoch 5602/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 1243.6232 - val_loss: 1108.3938\n",
      "Epoch 5603/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 1243.5176 - val_loss: 1108.2866\n",
      "Epoch 5604/100000\n",
      "11/11 [==============================] - 0s 618us/step - loss: 1243.4121 - val_loss: 1108.1797\n",
      "Epoch 5605/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1243.3065 - val_loss: 1108.0726\n",
      "Epoch 5606/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 1243.2009 - val_loss: 1107.9657\n",
      "Epoch 5607/100000\n",
      "11/11 [==============================] - 0s 658us/step - loss: 1243.0957 - val_loss: 1107.8589\n",
      "Epoch 5608/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 1242.9902 - val_loss: 1107.7521\n",
      "Epoch 5609/100000\n",
      "11/11 [==============================] - 0s 987us/step - loss: 1242.8851 - val_loss: 1107.6454\n",
      "Epoch 5610/100000\n",
      "11/11 [==============================] - 0s 620us/step - loss: 1242.7800 - val_loss: 1107.5387\n",
      "Epoch 5611/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 1242.6749 - val_loss: 1107.4323\n",
      "Epoch 5612/100000\n",
      "11/11 [==============================] - 0s 642us/step - loss: 1242.5699 - val_loss: 1107.3258\n",
      "Epoch 5613/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1242.4648 - val_loss: 1107.2195\n",
      "Epoch 5614/100000\n",
      "11/11 [==============================] - 0s 721us/step - loss: 1242.3601 - val_loss: 1107.1132\n",
      "Epoch 5615/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 1242.2554 - val_loss: 1107.0070\n",
      "Epoch 5616/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1242.1506 - val_loss: 1106.9006\n",
      "Epoch 5617/100000\n",
      "11/11 [==============================] - 0s 659us/step - loss: 1242.0461 - val_loss: 1106.7948\n",
      "Epoch 5618/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1241.9415 - val_loss: 1106.6886\n",
      "Epoch 5619/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 1241.8370 - val_loss: 1106.5828\n",
      "Epoch 5620/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 1241.7328 - val_loss: 1106.4769\n",
      "Epoch 5621/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 1241.6285 - val_loss: 1106.3712\n",
      "Epoch 5622/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1241.5242 - val_loss: 1106.2655\n",
      "Epoch 5623/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 1241.4200 - val_loss: 1106.1600\n",
      "Epoch 5624/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1241.3159 - val_loss: 1106.0544\n",
      "Epoch 5625/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 1241.2120 - val_loss: 1105.9489\n",
      "Epoch 5626/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1241.1080 - val_loss: 1105.8436\n",
      "Epoch 5627/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 1241.0043 - val_loss: 1105.7382\n",
      "Epoch 5628/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1240.9005 - val_loss: 1105.6329\n",
      "Epoch 5629/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 1240.7969 - val_loss: 1105.5277\n",
      "Epoch 5630/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1240.6932 - val_loss: 1105.4227\n",
      "Epoch 5631/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 1240.5897 - val_loss: 1105.3179\n",
      "Epoch 5632/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 1240.4862 - val_loss: 1105.2129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5633/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 1240.3827 - val_loss: 1105.1080\n",
      "Epoch 5634/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 1240.2794 - val_loss: 1105.0032\n",
      "Epoch 5635/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 1240.1763 - val_loss: 1104.8986\n",
      "Epoch 5636/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1240.0731 - val_loss: 1104.7941\n",
      "Epoch 5637/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1239.9702 - val_loss: 1104.6895\n",
      "Epoch 5638/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 1239.8672 - val_loss: 1104.5850\n",
      "Epoch 5639/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1239.7639 - val_loss: 1104.4806\n",
      "Epoch 5640/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1239.6613 - val_loss: 1104.3761\n",
      "Epoch 5641/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1239.5585 - val_loss: 1104.2720\n",
      "Epoch 5642/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 1239.4559 - val_loss: 1104.1678\n",
      "Epoch 5643/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1239.3533 - val_loss: 1104.0638\n",
      "Epoch 5644/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 1239.2506 - val_loss: 1103.9597\n",
      "Epoch 5645/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 1239.1483 - val_loss: 1103.8558\n",
      "Epoch 5646/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1239.0458 - val_loss: 1103.7520\n",
      "Epoch 5647/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1238.9435 - val_loss: 1103.6481\n",
      "Epoch 5648/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 1238.8413 - val_loss: 1103.5446\n",
      "Epoch 5649/100000\n",
      "11/11 [==============================] - 0s 709us/step - loss: 1238.7390 - val_loss: 1103.4409\n",
      "Epoch 5650/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 1238.6368 - val_loss: 1103.3373\n",
      "Epoch 5651/100000\n",
      "11/11 [==============================] - 0s 698us/step - loss: 1238.5350 - val_loss: 1103.2339\n",
      "Epoch 5652/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 1238.4329 - val_loss: 1103.1304\n",
      "Epoch 5653/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1238.3312 - val_loss: 1103.0272\n",
      "Epoch 5654/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1238.2294 - val_loss: 1102.9240\n",
      "Epoch 5655/100000\n",
      "11/11 [==============================] - 0s 651us/step - loss: 1238.1277 - val_loss: 1102.8207\n",
      "Epoch 5656/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 1238.0259 - val_loss: 1102.7177\n",
      "Epoch 5657/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1237.9244 - val_loss: 1102.6145\n",
      "Epoch 5658/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 1237.8230 - val_loss: 1102.5116\n",
      "Epoch 5659/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 1237.7216 - val_loss: 1102.4087\n",
      "Epoch 5660/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 1237.6202 - val_loss: 1102.3059\n",
      "Epoch 5661/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1237.5188 - val_loss: 1102.2032\n",
      "Epoch 5662/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1237.4178 - val_loss: 1102.1007\n",
      "Epoch 5663/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 1237.3165 - val_loss: 1101.9982\n",
      "Epoch 5664/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 1237.2157 - val_loss: 1101.8956\n",
      "Epoch 5665/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1237.1146 - val_loss: 1101.7933\n",
      "Epoch 5666/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1237.0137 - val_loss: 1101.6909\n",
      "Epoch 5667/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1236.9130 - val_loss: 1101.5887\n",
      "Epoch 5668/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 1236.8121 - val_loss: 1101.4865\n",
      "Epoch 5669/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1236.7114 - val_loss: 1101.3844\n",
      "Epoch 5670/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1236.6110 - val_loss: 1101.2822\n",
      "Epoch 5671/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1236.5105 - val_loss: 1101.1804\n",
      "Epoch 5672/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 1236.4102 - val_loss: 1101.0785\n",
      "Epoch 5673/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1236.3097 - val_loss: 1100.9767\n",
      "Epoch 5674/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1236.2094 - val_loss: 1100.8749\n",
      "Epoch 5675/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 1236.1093 - val_loss: 1100.7732\n",
      "Epoch 5676/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1236.0090 - val_loss: 1100.6718\n",
      "Epoch 5677/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1235.9091 - val_loss: 1100.5702\n",
      "Epoch 5678/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1235.8091 - val_loss: 1100.4686\n",
      "Epoch 5679/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1235.7091 - val_loss: 1100.3676\n",
      "Epoch 5680/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 1235.6093 - val_loss: 1100.2661\n",
      "Epoch 5681/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 1235.5096 - val_loss: 1100.1649\n",
      "Epoch 5682/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1235.4097 - val_loss: 1100.0638\n",
      "Epoch 5683/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 1235.3104 - val_loss: 1099.9628\n",
      "Epoch 5684/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1235.2106 - val_loss: 1099.8618\n",
      "Epoch 5685/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 1235.1112 - val_loss: 1099.7609\n",
      "Epoch 5686/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 1235.0118 - val_loss: 1099.6600\n",
      "Epoch 5687/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1234.9125 - val_loss: 1099.5592\n",
      "Epoch 5688/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 1234.8132 - val_loss: 1099.4586\n",
      "Epoch 5689/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1234.7144 - val_loss: 1099.3579\n",
      "Epoch 5690/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 1234.6151 - val_loss: 1099.2573\n",
      "Epoch 5691/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 1234.5160 - val_loss: 1099.1570\n",
      "Epoch 5692/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 1234.4171 - val_loss: 1099.0566\n",
      "Epoch 5693/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1234.3182 - val_loss: 1098.9562\n",
      "Epoch 5694/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 1234.2195 - val_loss: 1098.8562\n",
      "Epoch 5695/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1234.1208 - val_loss: 1098.7560\n",
      "Epoch 5696/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1234.0222 - val_loss: 1098.6558\n",
      "Epoch 5697/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1233.9237 - val_loss: 1098.5559\n",
      "Epoch 5698/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 1233.8251 - val_loss: 1098.4559\n",
      "Epoch 5699/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1233.7267 - val_loss: 1098.3561\n",
      "Epoch 5700/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1233.6284 - val_loss: 1098.2563\n",
      "Epoch 5701/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1233.5302 - val_loss: 1098.1566\n",
      "Epoch 5702/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1233.4319 - val_loss: 1098.0569\n",
      "Epoch 5703/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1233.3339 - val_loss: 1097.9575\n",
      "Epoch 5704/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1233.2358 - val_loss: 1097.8579\n",
      "Epoch 5705/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 1233.1379 - val_loss: 1097.7585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5706/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1233.0399 - val_loss: 1097.6593\n",
      "Epoch 5707/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 1232.9423 - val_loss: 1097.5601\n",
      "Epoch 5708/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 1232.8445 - val_loss: 1097.4608\n",
      "Epoch 5709/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 1232.7466 - val_loss: 1097.3617\n",
      "Epoch 5710/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1232.6492 - val_loss: 1097.2627\n",
      "Epoch 5711/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1232.5519 - val_loss: 1097.1637\n",
      "Epoch 5712/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 1232.4541 - val_loss: 1097.0649\n",
      "Epoch 5713/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 1232.3569 - val_loss: 1096.9659\n",
      "Epoch 5714/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1232.2595 - val_loss: 1096.8673\n",
      "Epoch 5715/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1232.1624 - val_loss: 1096.7686\n",
      "Epoch 5716/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1232.0652 - val_loss: 1096.6699\n",
      "Epoch 5717/100000\n",
      "11/11 [==============================] - 0s 868us/step - loss: 1231.9680 - val_loss: 1096.5717\n",
      "Epoch 5718/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1231.8711 - val_loss: 1096.4731\n",
      "Epoch 5719/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1231.7742 - val_loss: 1096.3746\n",
      "Epoch 5720/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 1231.6772 - val_loss: 1096.2765\n",
      "Epoch 5721/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 1231.5806 - val_loss: 1096.1782\n",
      "Epoch 5722/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1231.4839 - val_loss: 1096.0800\n",
      "Epoch 5723/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 1231.3872 - val_loss: 1095.9821\n",
      "Epoch 5724/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1231.2909 - val_loss: 1095.8842\n",
      "Epoch 5725/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 1231.1942 - val_loss: 1095.7864\n",
      "Epoch 5726/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1231.0978 - val_loss: 1095.6884\n",
      "Epoch 5727/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1231.0015 - val_loss: 1095.5907\n",
      "Epoch 5728/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1230.9053 - val_loss: 1095.4927\n",
      "Epoch 5729/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 1230.8088 - val_loss: 1095.3953\n",
      "Epoch 5730/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 1230.7130 - val_loss: 1095.2977\n",
      "Epoch 5731/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1230.6171 - val_loss: 1095.2002\n",
      "Epoch 5732/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 1230.5210 - val_loss: 1095.1028\n",
      "Epoch 5733/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1230.4249 - val_loss: 1095.0055\n",
      "Epoch 5734/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1230.3292 - val_loss: 1094.9081\n",
      "Epoch 5735/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1230.2334 - val_loss: 1094.8110\n",
      "Epoch 5736/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1230.1376 - val_loss: 1094.7140\n",
      "Epoch 5737/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 1230.0421 - val_loss: 1094.6171\n",
      "Epoch 5738/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 1229.9465 - val_loss: 1094.5200\n",
      "Epoch 5739/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1229.8511 - val_loss: 1094.4230\n",
      "Epoch 5740/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 1229.7557 - val_loss: 1094.3263\n",
      "Epoch 5741/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1229.6605 - val_loss: 1094.2296\n",
      "Epoch 5742/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 1229.5652 - val_loss: 1094.1329\n",
      "Epoch 5743/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1229.4701 - val_loss: 1094.0363\n",
      "Epoch 5744/100000\n",
      "11/11 [==============================] - 0s 677us/step - loss: 1229.3751 - val_loss: 1093.9398\n",
      "Epoch 5745/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 1229.2799 - val_loss: 1093.8433\n",
      "Epoch 5746/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1229.1851 - val_loss: 1093.7469\n",
      "Epoch 5747/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1229.0901 - val_loss: 1093.6508\n",
      "Epoch 5748/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1228.9952 - val_loss: 1093.5543\n",
      "Epoch 5749/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 1228.9005 - val_loss: 1093.4583\n",
      "Epoch 5750/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 1228.8062 - val_loss: 1093.3622\n",
      "Epoch 5751/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1228.7114 - val_loss: 1093.2664\n",
      "Epoch 5752/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 1228.6171 - val_loss: 1093.1703\n",
      "Epoch 5753/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1228.5226 - val_loss: 1093.0743\n",
      "Epoch 5754/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 1228.4282 - val_loss: 1092.9786\n",
      "Epoch 5755/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1228.3339 - val_loss: 1092.8829\n",
      "Epoch 5756/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1228.2397 - val_loss: 1092.7872\n",
      "Epoch 5757/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1228.1456 - val_loss: 1092.6918\n",
      "Epoch 5758/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 1228.0516 - val_loss: 1092.5962\n",
      "Epoch 5759/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1227.9575 - val_loss: 1092.5009\n",
      "Epoch 5760/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 1227.8635 - val_loss: 1092.4055\n",
      "Epoch 5761/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 1227.7697 - val_loss: 1092.3103\n",
      "Epoch 5762/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1227.6761 - val_loss: 1092.2151\n",
      "Epoch 5763/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 1227.5823 - val_loss: 1092.1200\n",
      "Epoch 5764/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 1227.4885 - val_loss: 1092.0249\n",
      "Epoch 5765/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1227.3950 - val_loss: 1091.9299\n",
      "Epoch 5766/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 1227.3018 - val_loss: 1091.8351\n",
      "Epoch 5767/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 1227.2081 - val_loss: 1091.7401\n",
      "Epoch 5768/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1227.1147 - val_loss: 1091.6455\n",
      "Epoch 5769/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1227.0216 - val_loss: 1091.5507\n",
      "Epoch 5770/100000\n",
      "11/11 [==============================] - 0s 622us/step - loss: 1226.9283 - val_loss: 1091.4562\n",
      "Epoch 5771/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1226.8353 - val_loss: 1091.3617\n",
      "Epoch 5772/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1226.7423 - val_loss: 1091.2672\n",
      "Epoch 5773/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1226.6493 - val_loss: 1091.1727\n",
      "Epoch 5774/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 1226.5562 - val_loss: 1091.0784\n",
      "Epoch 5775/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1226.4636 - val_loss: 1090.9841\n",
      "Epoch 5776/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1226.3707 - val_loss: 1090.8901\n",
      "Epoch 5777/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 1226.2781 - val_loss: 1090.7958\n",
      "Epoch 5778/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1226.1855 - val_loss: 1090.7018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5779/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1226.0929 - val_loss: 1090.6078\n",
      "Epoch 5780/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1226.0005 - val_loss: 1090.5140\n",
      "Epoch 5781/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1225.9081 - val_loss: 1090.4200\n",
      "Epoch 5782/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 1225.8158 - val_loss: 1090.3265\n",
      "Epoch 5783/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 1225.7235 - val_loss: 1090.2329\n",
      "Epoch 5784/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1225.6313 - val_loss: 1090.1392\n",
      "Epoch 5785/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 1225.5392 - val_loss: 1090.0458\n",
      "Epoch 5786/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1225.4471 - val_loss: 1089.9523\n",
      "Epoch 5787/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1225.3553 - val_loss: 1089.8588\n",
      "Epoch 5788/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1225.2634 - val_loss: 1089.7656\n",
      "Epoch 5789/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 1225.1715 - val_loss: 1089.6724\n",
      "Epoch 5790/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 1225.0798 - val_loss: 1089.5791\n",
      "Epoch 5791/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1224.9882 - val_loss: 1089.4861\n",
      "Epoch 5792/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 1224.8965 - val_loss: 1089.3932\n",
      "Epoch 5793/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1224.8049 - val_loss: 1089.3003\n",
      "Epoch 5794/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1224.7136 - val_loss: 1089.2072\n",
      "Epoch 5795/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 1224.6222 - val_loss: 1089.1145\n",
      "Epoch 5796/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1224.5308 - val_loss: 1089.0219\n",
      "Epoch 5797/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 1224.4396 - val_loss: 1088.9292\n",
      "Epoch 5798/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 1224.3484 - val_loss: 1088.8365\n",
      "Epoch 5799/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 1224.2573 - val_loss: 1088.7440\n",
      "Epoch 5800/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 1224.1664 - val_loss: 1088.6515\n",
      "Epoch 5801/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1224.0754 - val_loss: 1088.5591\n",
      "Epoch 5802/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1223.9845 - val_loss: 1088.4669\n",
      "Epoch 5803/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 1223.8936 - val_loss: 1088.3746\n",
      "Epoch 5804/100000\n",
      "11/11 [==============================] - 0s 632us/step - loss: 1223.8029 - val_loss: 1088.2827\n",
      "Epoch 5805/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 1223.7122 - val_loss: 1088.1906\n",
      "Epoch 5806/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 1223.6216 - val_loss: 1088.0984\n",
      "Epoch 5807/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 1223.5311 - val_loss: 1088.0066\n",
      "Epoch 5808/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 1223.4406 - val_loss: 1087.9146\n",
      "Epoch 5809/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1223.3503 - val_loss: 1087.8228\n",
      "Epoch 5810/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 1223.2599 - val_loss: 1087.7311\n",
      "Epoch 5811/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 1223.1698 - val_loss: 1087.6395\n",
      "Epoch 5812/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1223.0796 - val_loss: 1087.5480\n",
      "Epoch 5813/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1222.9895 - val_loss: 1087.4563\n",
      "Epoch 5814/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 1222.8994 - val_loss: 1087.3651\n",
      "Epoch 5815/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 1222.8094 - val_loss: 1087.2736\n",
      "Epoch 5816/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1222.7196 - val_loss: 1087.1824\n",
      "Epoch 5817/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1222.6298 - val_loss: 1087.0912\n",
      "Epoch 5818/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 1222.5399 - val_loss: 1087.0000\n",
      "Epoch 5819/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1222.4504 - val_loss: 1086.9089\n",
      "Epoch 5820/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1222.3608 - val_loss: 1086.8179\n",
      "Epoch 5821/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 1222.2711 - val_loss: 1086.7269\n",
      "Epoch 5822/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1222.1818 - val_loss: 1086.6360\n",
      "Epoch 5823/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 1222.0925 - val_loss: 1086.5453\n",
      "Epoch 5824/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 1222.0032 - val_loss: 1086.4546\n",
      "Epoch 5825/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1221.9139 - val_loss: 1086.3639\n",
      "Epoch 5826/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1221.8246 - val_loss: 1086.2733\n",
      "Epoch 5827/100000\n",
      "11/11 [==============================] - 0s 635us/step - loss: 1221.7357 - val_loss: 1086.1827\n",
      "Epoch 5828/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1221.6466 - val_loss: 1086.0925\n",
      "Epoch 5829/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 1221.5576 - val_loss: 1086.0021\n",
      "Epoch 5830/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1221.4689 - val_loss: 1085.9117\n",
      "Epoch 5831/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1221.3800 - val_loss: 1085.8215\n",
      "Epoch 5832/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1221.2911 - val_loss: 1085.7313\n",
      "Epoch 5833/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1221.2025 - val_loss: 1085.6414\n",
      "Epoch 5834/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1221.1138 - val_loss: 1085.5515\n",
      "Epoch 5835/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 1221.0253 - val_loss: 1085.4613\n",
      "Epoch 5836/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 1220.9369 - val_loss: 1085.3716\n",
      "Epoch 5837/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 1220.8485 - val_loss: 1085.2817\n",
      "Epoch 5838/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 1220.7603 - val_loss: 1085.1919\n",
      "Epoch 5839/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1220.6719 - val_loss: 1085.1024\n",
      "Epoch 5840/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 1220.5839 - val_loss: 1085.0128\n",
      "Epoch 5841/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1220.4956 - val_loss: 1084.9233\n",
      "Epoch 5842/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 1220.4075 - val_loss: 1084.8339\n",
      "Epoch 5843/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 1220.3198 - val_loss: 1084.7445\n",
      "Epoch 5844/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 1220.2318 - val_loss: 1084.6553\n",
      "Epoch 5845/100000\n",
      "11/11 [==============================] - 0s 679us/step - loss: 1220.1440 - val_loss: 1084.5659\n",
      "Epoch 5846/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 1220.0562 - val_loss: 1084.4767\n",
      "Epoch 5847/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1219.9685 - val_loss: 1084.3878\n",
      "Epoch 5848/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1219.8810 - val_loss: 1084.2988\n",
      "Epoch 5849/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1219.7933 - val_loss: 1084.2098\n",
      "Epoch 5850/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 1219.7058 - val_loss: 1084.1210\n",
      "Epoch 5851/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 1219.6184 - val_loss: 1084.0321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5852/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 1219.5312 - val_loss: 1083.9434\n",
      "Epoch 5853/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 1219.4438 - val_loss: 1083.8547\n",
      "Epoch 5854/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 1219.3566 - val_loss: 1083.7661\n",
      "Epoch 5855/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 1219.2695 - val_loss: 1083.6776\n",
      "Epoch 5856/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1219.1825 - val_loss: 1083.5891\n",
      "Epoch 5857/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1219.0956 - val_loss: 1083.5009\n",
      "Epoch 5858/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 1219.0087 - val_loss: 1083.4125\n",
      "Epoch 5859/100000\n",
      "11/11 [==============================] - 0s 639us/step - loss: 1218.9218 - val_loss: 1083.3242\n",
      "Epoch 5860/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1218.8350 - val_loss: 1083.2362\n",
      "Epoch 5861/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 1218.7483 - val_loss: 1083.1479\n",
      "Epoch 5862/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 1218.6616 - val_loss: 1083.0598\n",
      "Epoch 5863/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 1218.5751 - val_loss: 1082.9722\n",
      "Epoch 5864/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1218.4886 - val_loss: 1082.8840\n",
      "Epoch 5865/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1218.4022 - val_loss: 1082.7964\n",
      "Epoch 5866/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1218.3160 - val_loss: 1082.7085\n",
      "Epoch 5867/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1218.2296 - val_loss: 1082.6210\n",
      "Epoch 5868/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 1218.1433 - val_loss: 1082.5333\n",
      "Epoch 5869/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 1218.0571 - val_loss: 1082.4457\n",
      "Epoch 5870/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1217.9711 - val_loss: 1082.3583\n",
      "Epoch 5871/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 1217.8851 - val_loss: 1082.2710\n",
      "Epoch 5872/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 1217.7993 - val_loss: 1082.1835\n",
      "Epoch 5873/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1217.7133 - val_loss: 1082.0962\n",
      "Epoch 5874/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1217.6276 - val_loss: 1082.0093\n",
      "Epoch 5875/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1217.5419 - val_loss: 1081.9220\n",
      "Epoch 5876/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 1217.4562 - val_loss: 1081.8351\n",
      "Epoch 5877/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 1217.3706 - val_loss: 1081.7480\n",
      "Epoch 5878/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1217.2850 - val_loss: 1081.6610\n",
      "Epoch 5879/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 1217.1996 - val_loss: 1081.5743\n",
      "Epoch 5880/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 1217.1143 - val_loss: 1081.4875\n",
      "Epoch 5881/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1217.0292 - val_loss: 1081.4008\n",
      "Epoch 5882/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1216.9437 - val_loss: 1081.3142\n",
      "Epoch 5883/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 1216.8585 - val_loss: 1081.2277\n",
      "Epoch 5884/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1216.7734 - val_loss: 1081.1411\n",
      "Epoch 5885/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1216.6886 - val_loss: 1081.0548\n",
      "Epoch 5886/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1216.6035 - val_loss: 1080.9686\n",
      "Epoch 5887/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 1216.5186 - val_loss: 1080.8821\n",
      "Epoch 5888/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 1216.4337 - val_loss: 1080.7959\n",
      "Epoch 5889/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 1216.3490 - val_loss: 1080.7098\n",
      "Epoch 5890/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1216.2643 - val_loss: 1080.6238\n",
      "Epoch 5891/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 1216.1798 - val_loss: 1080.5378\n",
      "Epoch 5892/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1216.0952 - val_loss: 1080.4519\n",
      "Epoch 5893/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 1216.0107 - val_loss: 1080.3660\n",
      "Epoch 5894/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1215.9263 - val_loss: 1080.2802\n",
      "Epoch 5895/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1215.8419 - val_loss: 1080.1946\n",
      "Epoch 5896/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1215.7577 - val_loss: 1080.1089\n",
      "Epoch 5897/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1215.6735 - val_loss: 1080.0233\n",
      "Epoch 5898/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1215.5894 - val_loss: 1079.9377\n",
      "Epoch 5899/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 1215.5054 - val_loss: 1079.8522\n",
      "Epoch 5900/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1215.4213 - val_loss: 1079.7668\n",
      "Epoch 5901/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1215.3374 - val_loss: 1079.6816\n",
      "Epoch 5902/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1215.2535 - val_loss: 1079.5963\n",
      "Epoch 5903/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 1215.1698 - val_loss: 1079.5112\n",
      "Epoch 5904/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 1215.0861 - val_loss: 1079.4261\n",
      "Epoch 5905/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1215.0024 - val_loss: 1079.3409\n",
      "Epoch 5906/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1214.9188 - val_loss: 1079.2562\n",
      "Epoch 5907/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1214.8354 - val_loss: 1079.1713\n",
      "Epoch 5908/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1214.7518 - val_loss: 1079.0864\n",
      "Epoch 5909/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 1214.6685 - val_loss: 1079.0017\n",
      "Epoch 5910/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 1214.5851 - val_loss: 1078.9169\n",
      "Epoch 5911/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1214.5020 - val_loss: 1078.8323\n",
      "Epoch 5912/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 1214.4188 - val_loss: 1078.7477\n",
      "Epoch 5913/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1214.3357 - val_loss: 1078.6632\n",
      "Epoch 5914/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1214.2527 - val_loss: 1078.5790\n",
      "Epoch 5915/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 1214.1698 - val_loss: 1078.4946\n",
      "Epoch 5916/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 1214.0867 - val_loss: 1078.4103\n",
      "Epoch 5917/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1214.0039 - val_loss: 1078.3262\n",
      "Epoch 5918/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 1213.9213 - val_loss: 1078.2421\n",
      "Epoch 5919/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1213.8387 - val_loss: 1078.1581\n",
      "Epoch 5920/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1213.7560 - val_loss: 1078.0741\n",
      "Epoch 5921/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1213.6733 - val_loss: 1077.9901\n",
      "Epoch 5922/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 1213.5909 - val_loss: 1077.9062\n",
      "Epoch 5923/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1213.5084 - val_loss: 1077.8224\n",
      "Epoch 5924/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1213.4263 - val_loss: 1077.7388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5925/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1213.3439 - val_loss: 1077.6552\n",
      "Epoch 5926/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 1213.2616 - val_loss: 1077.5714\n",
      "Epoch 5927/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1213.1796 - val_loss: 1077.4879\n",
      "Epoch 5928/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 1213.0977 - val_loss: 1077.4044\n",
      "Epoch 5929/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 1213.0155 - val_loss: 1077.3212\n",
      "Epoch 5930/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 1212.9336 - val_loss: 1077.2379\n",
      "Epoch 5931/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1212.8517 - val_loss: 1077.1547\n",
      "Epoch 5932/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 1212.7699 - val_loss: 1077.0714\n",
      "Epoch 5933/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 1212.6881 - val_loss: 1076.9884\n",
      "Epoch 5934/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1212.6066 - val_loss: 1076.9054\n",
      "Epoch 5935/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 1212.5250 - val_loss: 1076.8223\n",
      "Epoch 5936/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1212.4434 - val_loss: 1076.7394\n",
      "Epoch 5937/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 1212.3619 - val_loss: 1076.6565\n",
      "Epoch 5938/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 1212.2805 - val_loss: 1076.5740\n",
      "Epoch 5939/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 1212.1991 - val_loss: 1076.4913\n",
      "Epoch 5940/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1212.1179 - val_loss: 1076.4087\n",
      "Epoch 5941/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 1212.0369 - val_loss: 1076.3259\n",
      "Epoch 5942/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 1211.9556 - val_loss: 1076.2437\n",
      "Epoch 5943/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1211.8746 - val_loss: 1076.1611\n",
      "Epoch 5944/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 1211.7937 - val_loss: 1076.0787\n",
      "Epoch 5945/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 1211.7129 - val_loss: 1075.9963\n",
      "Epoch 5946/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 1211.6318 - val_loss: 1075.9142\n",
      "Epoch 5947/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 1211.5509 - val_loss: 1075.8322\n",
      "Epoch 5948/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1211.4703 - val_loss: 1075.7500\n",
      "Epoch 5949/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1211.3898 - val_loss: 1075.6680\n",
      "Epoch 5950/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 1211.3091 - val_loss: 1075.5861\n",
      "Epoch 5951/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1211.2286 - val_loss: 1075.5042\n",
      "Epoch 5952/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 1211.1481 - val_loss: 1075.4224\n",
      "Epoch 5953/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1211.0677 - val_loss: 1075.3406\n",
      "Epoch 5954/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1210.9875 - val_loss: 1075.2589\n",
      "Epoch 5955/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 1210.9072 - val_loss: 1075.1774\n",
      "Epoch 5956/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 1210.8271 - val_loss: 1075.0958\n",
      "Epoch 5957/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1210.7469 - val_loss: 1075.0142\n",
      "Epoch 5958/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1210.6669 - val_loss: 1074.9331\n",
      "Epoch 5959/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 1210.5870 - val_loss: 1074.8517\n",
      "Epoch 5960/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1210.5072 - val_loss: 1074.7704\n",
      "Epoch 5961/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1210.4272 - val_loss: 1074.6892\n",
      "Epoch 5962/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1210.3475 - val_loss: 1074.6082\n",
      "Epoch 5963/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 1210.2677 - val_loss: 1074.5270\n",
      "Epoch 5964/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 1210.1880 - val_loss: 1074.4459\n",
      "Epoch 5965/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 1210.1085 - val_loss: 1074.3651\n",
      "Epoch 5966/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1210.0289 - val_loss: 1074.2843\n",
      "Epoch 5967/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 1209.9496 - val_loss: 1074.2035\n",
      "Epoch 5968/100000\n",
      "11/11 [==============================] - 0s 589us/step - loss: 1209.8702 - val_loss: 1074.1229\n",
      "Epoch 5969/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 1209.7910 - val_loss: 1074.0419\n",
      "Epoch 5970/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1209.7117 - val_loss: 1073.9614\n",
      "Epoch 5971/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 1209.6326 - val_loss: 1073.8809\n",
      "Epoch 5972/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1209.5535 - val_loss: 1073.8004\n",
      "Epoch 5973/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1209.4745 - val_loss: 1073.7200\n",
      "Epoch 5974/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1209.3956 - val_loss: 1073.6398\n",
      "Epoch 5975/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 1209.3165 - val_loss: 1073.5593\n",
      "Epoch 5976/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 1209.2378 - val_loss: 1073.4792\n",
      "Epoch 5977/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 1209.1589 - val_loss: 1073.3993\n",
      "Epoch 5978/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1209.0803 - val_loss: 1073.3191\n",
      "Epoch 5979/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1209.0016 - val_loss: 1073.2391\n",
      "Epoch 5980/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1208.9230 - val_loss: 1073.1593\n",
      "Epoch 5981/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 1208.8446 - val_loss: 1073.0793\n",
      "Epoch 5982/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 1208.7660 - val_loss: 1072.9998\n",
      "Epoch 5983/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1208.6876 - val_loss: 1072.9198\n",
      "Epoch 5984/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1208.6095 - val_loss: 1072.8401\n",
      "Epoch 5985/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1208.5312 - val_loss: 1072.7606\n",
      "Epoch 5986/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 1208.4532 - val_loss: 1072.6812\n",
      "Epoch 5987/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 1208.3750 - val_loss: 1072.6017\n",
      "Epoch 5988/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 1208.2970 - val_loss: 1072.5223\n",
      "Epoch 5989/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 1208.2189 - val_loss: 1072.4429\n",
      "Epoch 5990/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 1208.1411 - val_loss: 1072.3638\n",
      "Epoch 5991/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1208.0634 - val_loss: 1072.2845\n",
      "Epoch 5992/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1207.9855 - val_loss: 1072.2054\n",
      "Epoch 5993/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 1207.9078 - val_loss: 1072.1265\n",
      "Epoch 5994/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 1207.8302 - val_loss: 1072.0474\n",
      "Epoch 5995/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1207.7527 - val_loss: 1071.9684\n",
      "Epoch 5996/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1207.6750 - val_loss: 1071.8898\n",
      "Epoch 5997/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 1207.5977 - val_loss: 1071.8107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5998/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 1207.5204 - val_loss: 1071.7319\n",
      "Epoch 5999/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1207.4430 - val_loss: 1071.6534\n",
      "Epoch 6000/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 1207.3656 - val_loss: 1071.5747\n",
      "Epoch 6001/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 1207.2886 - val_loss: 1071.4965\n",
      "Epoch 6002/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1207.2114 - val_loss: 1071.4178\n",
      "Epoch 6003/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1207.1344 - val_loss: 1071.3395\n",
      "Epoch 6004/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 1207.0574 - val_loss: 1071.2612\n",
      "Epoch 6005/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 1206.9806 - val_loss: 1071.1829\n",
      "Epoch 6006/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 1206.9038 - val_loss: 1071.1047\n",
      "Epoch 6007/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1206.8269 - val_loss: 1071.0266\n",
      "Epoch 6008/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 1206.7501 - val_loss: 1070.9487\n",
      "Epoch 6009/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 1206.6737 - val_loss: 1070.8706\n",
      "Epoch 6010/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 1206.5972 - val_loss: 1070.7926\n",
      "Epoch 6011/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 1206.5206 - val_loss: 1070.7150\n",
      "Epoch 6012/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 1206.4441 - val_loss: 1070.6371\n",
      "Epoch 6013/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 1206.3677 - val_loss: 1070.5594\n",
      "Epoch 6014/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 1206.2915 - val_loss: 1070.4816\n",
      "Epoch 6015/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 1206.2152 - val_loss: 1070.4039\n",
      "Epoch 6016/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 1206.1388 - val_loss: 1070.3267\n",
      "Epoch 6017/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1206.0629 - val_loss: 1070.2490\n",
      "Epoch 6018/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 1205.9868 - val_loss: 1070.1718\n",
      "Epoch 6019/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1205.9106 - val_loss: 1070.0942\n",
      "Epoch 6020/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1205.8348 - val_loss: 1070.0171\n",
      "Epoch 6021/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 1205.7589 - val_loss: 1069.9399\n",
      "Epoch 6022/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 1205.6831 - val_loss: 1069.8628\n",
      "Epoch 6023/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1205.6075 - val_loss: 1069.7856\n",
      "Epoch 6024/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 1205.5319 - val_loss: 1069.7087\n",
      "Epoch 6025/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 1205.4563 - val_loss: 1069.6317\n",
      "Epoch 6026/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1205.3807 - val_loss: 1069.5549\n",
      "Epoch 6027/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 1205.3052 - val_loss: 1069.4780\n",
      "Epoch 6028/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 1205.2300 - val_loss: 1069.4014\n",
      "Epoch 6029/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 1205.1545 - val_loss: 1069.3247\n",
      "Epoch 6030/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1205.0795 - val_loss: 1069.2482\n",
      "Epoch 6031/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1205.0042 - val_loss: 1069.1715\n",
      "Epoch 6032/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1204.9288 - val_loss: 1069.0952\n",
      "Epoch 6033/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1204.8539 - val_loss: 1069.0187\n",
      "Epoch 6034/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 1204.7788 - val_loss: 1068.9424\n",
      "Epoch 6035/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 1204.7040 - val_loss: 1068.8661\n",
      "Epoch 6036/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1204.6290 - val_loss: 1068.7898\n",
      "Epoch 6037/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 1204.5543 - val_loss: 1068.7137\n",
      "Epoch 6038/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1204.4795 - val_loss: 1068.6377\n",
      "Epoch 6039/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1204.4048 - val_loss: 1068.5616\n",
      "Epoch 6040/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 1204.3302 - val_loss: 1068.4857\n",
      "Epoch 6041/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 1204.2557 - val_loss: 1068.4097\n",
      "Epoch 6042/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 1204.1812 - val_loss: 1068.3339\n",
      "Epoch 6043/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 1204.1067 - val_loss: 1068.2582\n",
      "Epoch 6044/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1204.0325 - val_loss: 1068.1825\n",
      "Epoch 6045/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 1203.9581 - val_loss: 1068.1069\n",
      "Epoch 6046/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 1203.8837 - val_loss: 1068.0312\n",
      "Epoch 6047/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1203.8096 - val_loss: 1067.9559\n",
      "Epoch 6048/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 1203.7356 - val_loss: 1067.8805\n",
      "Epoch 6049/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 1203.6616 - val_loss: 1067.8051\n",
      "Epoch 6050/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1203.5875 - val_loss: 1067.7297\n",
      "Epoch 6051/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 1203.5138 - val_loss: 1067.6545\n",
      "Epoch 6052/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 1203.4399 - val_loss: 1067.5793\n",
      "Epoch 6053/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 1203.3661 - val_loss: 1067.5043\n",
      "Epoch 6054/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 1203.2925 - val_loss: 1067.4292\n",
      "Epoch 6055/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 1203.2186 - val_loss: 1067.3542\n",
      "Epoch 6056/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 1203.1453 - val_loss: 1067.2794\n",
      "Epoch 6057/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 1203.0718 - val_loss: 1067.2046\n",
      "Epoch 6058/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 1202.9983 - val_loss: 1067.1298\n",
      "Epoch 6059/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1202.9249 - val_loss: 1067.0551\n",
      "Epoch 6060/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 1202.8516 - val_loss: 1066.9802\n",
      "Epoch 6061/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1202.7784 - val_loss: 1066.9058\n",
      "Epoch 6062/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 1202.7052 - val_loss: 1066.8312\n",
      "Epoch 6063/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1202.6320 - val_loss: 1066.7568\n",
      "Epoch 6064/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 1202.5590 - val_loss: 1066.6824\n",
      "Epoch 6065/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1202.4860 - val_loss: 1066.6080\n",
      "Epoch 6066/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 1202.4130 - val_loss: 1066.5338\n",
      "Epoch 6067/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 1202.3401 - val_loss: 1066.4597\n",
      "Epoch 6068/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1202.2675 - val_loss: 1066.3855\n",
      "Epoch 6069/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 1202.1946 - val_loss: 1066.3114\n",
      "Epoch 6070/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 1202.1219 - val_loss: 1066.2374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6071/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1202.0493 - val_loss: 1066.1636\n",
      "Epoch 6072/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 1201.9767 - val_loss: 1066.0897\n",
      "Epoch 6073/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1201.9042 - val_loss: 1066.0157\n",
      "Epoch 6074/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1201.8317 - val_loss: 1065.9419\n",
      "Epoch 6075/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1201.7595 - val_loss: 1065.8683\n",
      "Epoch 6076/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1201.6871 - val_loss: 1065.7947\n",
      "Epoch 6077/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1201.6149 - val_loss: 1065.7212\n",
      "Epoch 6078/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1201.5427 - val_loss: 1065.6476\n",
      "Epoch 6079/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 1201.4707 - val_loss: 1065.5742\n",
      "Epoch 6080/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 1201.3987 - val_loss: 1065.5009\n",
      "Epoch 6081/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 1201.3267 - val_loss: 1065.4276\n",
      "Epoch 6082/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 1201.2548 - val_loss: 1065.3544\n",
      "Epoch 6083/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1201.1831 - val_loss: 1065.2811\n",
      "Epoch 6084/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1201.1111 - val_loss: 1065.2081\n",
      "Epoch 6085/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 1201.0394 - val_loss: 1065.1350\n",
      "Epoch 6086/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 1200.9678 - val_loss: 1065.0621\n",
      "Epoch 6087/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 1200.8960 - val_loss: 1064.9891\n",
      "Epoch 6088/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 1200.8246 - val_loss: 1064.9164\n",
      "Epoch 6089/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 1200.7531 - val_loss: 1064.8436\n",
      "Epoch 6090/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1200.6818 - val_loss: 1064.7708\n",
      "Epoch 6091/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 1200.6105 - val_loss: 1064.6981\n",
      "Epoch 6092/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 1200.5392 - val_loss: 1064.6256\n",
      "Epoch 6093/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 1200.4678 - val_loss: 1064.5531\n",
      "Epoch 6094/100000\n",
      "11/11 [==============================] - 0s 632us/step - loss: 1200.3966 - val_loss: 1064.4806\n",
      "Epoch 6095/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 1200.3257 - val_loss: 1064.4082\n",
      "Epoch 6096/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 1200.2546 - val_loss: 1064.3359\n",
      "Epoch 6097/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 1200.1837 - val_loss: 1064.2637\n",
      "Epoch 6098/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1200.1129 - val_loss: 1064.1915\n",
      "Epoch 6099/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 1200.0420 - val_loss: 1064.1191\n",
      "Epoch 6100/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 1199.9712 - val_loss: 1064.0470\n",
      "Epoch 6101/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 1199.9005 - val_loss: 1063.9751\n",
      "Epoch 6102/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1199.8300 - val_loss: 1063.9032\n",
      "Epoch 6103/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 1199.7593 - val_loss: 1063.8314\n",
      "Epoch 6104/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 1199.6888 - val_loss: 1063.7595\n",
      "Epoch 6105/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1199.6184 - val_loss: 1063.6876\n",
      "Epoch 6106/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 1199.5480 - val_loss: 1063.6160\n",
      "Epoch 6107/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1199.4777 - val_loss: 1063.5444\n",
      "Epoch 6108/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1199.4075 - val_loss: 1063.4728\n",
      "Epoch 6109/100000\n",
      "11/11 [==============================] - 0s 748us/step - loss: 1199.3372 - val_loss: 1063.4014\n",
      "Epoch 6110/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1199.2670 - val_loss: 1063.3298\n",
      "Epoch 6111/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1199.1969 - val_loss: 1063.2584\n",
      "Epoch 6112/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1199.1271 - val_loss: 1063.1871\n",
      "Epoch 6113/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1199.0570 - val_loss: 1063.1158\n",
      "Epoch 6114/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 1198.9871 - val_loss: 1063.0447\n",
      "Epoch 6115/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1198.9174 - val_loss: 1062.9736\n",
      "Epoch 6116/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1198.8477 - val_loss: 1062.9023\n",
      "Epoch 6117/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1198.7778 - val_loss: 1062.8315\n",
      "Epoch 6118/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 1198.7081 - val_loss: 1062.7604\n",
      "Epoch 6119/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1198.6385 - val_loss: 1062.6897\n",
      "Epoch 6120/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 1198.5692 - val_loss: 1062.6188\n",
      "Epoch 6121/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1198.4996 - val_loss: 1062.5480\n",
      "Epoch 6122/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1198.4304 - val_loss: 1062.4773\n",
      "Epoch 6123/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1198.3612 - val_loss: 1062.4069\n",
      "Epoch 6124/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 1198.2917 - val_loss: 1062.3362\n",
      "Epoch 6125/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1198.2227 - val_loss: 1062.2657\n",
      "Epoch 6126/100000\n",
      "11/11 [==============================] - 0s 580us/step - loss: 1198.1534 - val_loss: 1062.1953\n",
      "Epoch 6127/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 1198.0845 - val_loss: 1062.1249\n",
      "Epoch 6128/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1198.0155 - val_loss: 1062.0546\n",
      "Epoch 6129/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1197.9464 - val_loss: 1061.9844\n",
      "Epoch 6130/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1197.8774 - val_loss: 1061.9141\n",
      "Epoch 6131/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1197.8086 - val_loss: 1061.8440\n",
      "Epoch 6132/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 1197.7399 - val_loss: 1061.7739\n",
      "Epoch 6133/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1197.6714 - val_loss: 1061.7040\n",
      "Epoch 6134/100000\n",
      "11/11 [==============================] - 0s 628us/step - loss: 1197.6027 - val_loss: 1061.6339\n",
      "Epoch 6135/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 1197.5339 - val_loss: 1061.5642\n",
      "Epoch 6136/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 1197.4655 - val_loss: 1061.4943\n",
      "Epoch 6137/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1197.3970 - val_loss: 1061.4246\n",
      "Epoch 6138/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 1197.3286 - val_loss: 1061.3550\n",
      "Epoch 6139/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1197.2603 - val_loss: 1061.2853\n",
      "Epoch 6140/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1197.1921 - val_loss: 1061.2157\n",
      "Epoch 6141/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 1197.1239 - val_loss: 1061.1464\n",
      "Epoch 6142/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 1197.0557 - val_loss: 1061.0767\n",
      "Epoch 6143/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 1196.9878 - val_loss: 1061.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6144/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 1196.9197 - val_loss: 1060.9380\n",
      "Epoch 6145/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 1196.8517 - val_loss: 1060.8688\n",
      "Epoch 6146/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 1196.7839 - val_loss: 1060.7996\n",
      "Epoch 6147/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 1196.7161 - val_loss: 1060.7305\n",
      "Epoch 6148/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1196.6483 - val_loss: 1060.6616\n",
      "Epoch 6149/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1196.5806 - val_loss: 1060.5924\n",
      "Epoch 6150/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 1196.5129 - val_loss: 1060.5234\n",
      "Epoch 6151/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1196.4454 - val_loss: 1060.4547\n",
      "Epoch 6152/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1196.3778 - val_loss: 1060.3859\n",
      "Epoch 6153/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 1196.3104 - val_loss: 1060.3171\n",
      "Epoch 6154/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1196.2430 - val_loss: 1060.2484\n",
      "Epoch 6155/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1196.1757 - val_loss: 1060.1797\n",
      "Epoch 6156/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 1196.1084 - val_loss: 1060.1112\n",
      "Epoch 6157/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 1196.0411 - val_loss: 1060.0428\n",
      "Epoch 6158/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 1195.9741 - val_loss: 1059.9744\n",
      "Epoch 6159/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 1195.9071 - val_loss: 1059.9058\n",
      "Epoch 6160/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1195.8400 - val_loss: 1059.8375\n",
      "Epoch 6161/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 1195.7729 - val_loss: 1059.7694\n",
      "Epoch 6162/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 1195.7061 - val_loss: 1059.7010\n",
      "Epoch 6163/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 1195.6394 - val_loss: 1059.6328\n",
      "Epoch 6164/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1195.5724 - val_loss: 1059.5648\n",
      "Epoch 6165/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 1195.5057 - val_loss: 1059.4967\n",
      "Epoch 6166/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1195.4391 - val_loss: 1059.4288\n",
      "Epoch 6167/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1195.3726 - val_loss: 1059.3610\n",
      "Epoch 6168/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 1195.3059 - val_loss: 1059.2931\n",
      "Epoch 6169/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1195.2395 - val_loss: 1059.2255\n",
      "Epoch 6170/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 1195.1730 - val_loss: 1059.1577\n",
      "Epoch 6171/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1195.1067 - val_loss: 1059.0900\n",
      "Epoch 6172/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 1195.0405 - val_loss: 1059.0225\n",
      "Epoch 6173/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1194.9741 - val_loss: 1058.9550\n",
      "Epoch 6174/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 1194.9081 - val_loss: 1058.8876\n",
      "Epoch 6175/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 1194.8419 - val_loss: 1058.8202\n",
      "Epoch 6176/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 1194.7759 - val_loss: 1058.7528\n",
      "Epoch 6177/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 1194.7098 - val_loss: 1058.6855\n",
      "Epoch 6178/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1194.6440 - val_loss: 1058.6184\n",
      "Epoch 6179/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 1194.5780 - val_loss: 1058.5513\n",
      "Epoch 6180/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1194.5123 - val_loss: 1058.4843\n",
      "Epoch 6181/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1194.4465 - val_loss: 1058.4171\n",
      "Epoch 6182/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1194.3809 - val_loss: 1058.3501\n",
      "Epoch 6183/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 1194.3153 - val_loss: 1058.2832\n",
      "Epoch 6184/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1194.2496 - val_loss: 1058.2163\n",
      "Epoch 6185/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1194.1841 - val_loss: 1058.1495\n",
      "Epoch 6186/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1194.1188 - val_loss: 1058.0829\n",
      "Epoch 6187/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 1194.0535 - val_loss: 1058.0161\n",
      "Epoch 6188/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 1193.9879 - val_loss: 1057.9495\n",
      "Epoch 6189/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 1193.9227 - val_loss: 1057.8829\n",
      "Epoch 6190/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 1193.8575 - val_loss: 1057.8165\n",
      "Epoch 6191/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 1193.7926 - val_loss: 1057.7500\n",
      "Epoch 6192/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 1193.7275 - val_loss: 1057.6838\n",
      "Epoch 6193/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 1193.6625 - val_loss: 1057.6174\n",
      "Epoch 6194/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 1193.5975 - val_loss: 1057.5513\n",
      "Epoch 6195/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1193.5326 - val_loss: 1057.4850\n",
      "Epoch 6196/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1193.4677 - val_loss: 1057.4191\n",
      "Epoch 6197/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 1193.4028 - val_loss: 1057.3530\n",
      "Epoch 6198/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1193.3383 - val_loss: 1057.2870\n",
      "Epoch 6199/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 1193.2736 - val_loss: 1057.2211\n",
      "Epoch 6200/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 1193.2090 - val_loss: 1057.1550\n",
      "Epoch 6201/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1193.1444 - val_loss: 1057.0894\n",
      "Epoch 6202/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 1193.0801 - val_loss: 1057.0236\n",
      "Epoch 6203/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1193.0156 - val_loss: 1056.9579\n",
      "Epoch 6204/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1192.9513 - val_loss: 1056.8922\n",
      "Epoch 6205/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 1192.8870 - val_loss: 1056.8267\n",
      "Epoch 6206/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 1192.8228 - val_loss: 1056.7611\n",
      "Epoch 6207/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 1192.7587 - val_loss: 1056.6957\n",
      "Epoch 6208/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 1192.6945 - val_loss: 1056.6304\n",
      "Epoch 6209/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 1192.6304 - val_loss: 1056.5651\n",
      "Epoch 6210/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1192.5663 - val_loss: 1056.4999\n",
      "Epoch 6211/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 1192.5024 - val_loss: 1056.4346\n",
      "Epoch 6212/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 1192.4386 - val_loss: 1056.3693\n",
      "Epoch 6213/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1192.3749 - val_loss: 1056.3043\n",
      "Epoch 6214/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1192.3110 - val_loss: 1056.2394\n",
      "Epoch 6215/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 1192.2472 - val_loss: 1056.1743\n",
      "Epoch 6216/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1192.1837 - val_loss: 1056.1095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6217/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 1192.1201 - val_loss: 1056.0446\n",
      "Epoch 6218/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 1192.0566 - val_loss: 1055.9797\n",
      "Epoch 6219/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1191.9932 - val_loss: 1055.9152\n",
      "Epoch 6220/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1191.9298 - val_loss: 1055.8503\n",
      "Epoch 6221/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 1191.8666 - val_loss: 1055.7859\n",
      "Epoch 6222/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 1191.8032 - val_loss: 1055.7212\n",
      "Epoch 6223/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 1191.7400 - val_loss: 1055.6567\n",
      "Epoch 6224/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 1191.6769 - val_loss: 1055.5924\n",
      "Epoch 6225/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 1191.6138 - val_loss: 1055.5278\n",
      "Epoch 6226/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 1191.5507 - val_loss: 1055.4636\n",
      "Epoch 6227/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 1191.4878 - val_loss: 1055.3994\n",
      "Epoch 6228/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1191.4249 - val_loss: 1055.3353\n",
      "Epoch 6229/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 1191.3619 - val_loss: 1055.2712\n",
      "Epoch 6230/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 1191.2991 - val_loss: 1055.2069\n",
      "Epoch 6231/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1191.2363 - val_loss: 1055.1429\n",
      "Epoch 6232/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 1191.1737 - val_loss: 1055.0790\n",
      "Epoch 6233/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1191.1112 - val_loss: 1055.0151\n",
      "Epoch 6234/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1191.0485 - val_loss: 1054.9515\n",
      "Epoch 6235/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 1190.9862 - val_loss: 1054.8876\n",
      "Epoch 6236/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 1190.9237 - val_loss: 1054.8239\n",
      "Epoch 6237/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 1190.8613 - val_loss: 1054.7603\n",
      "Epoch 6238/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1190.7990 - val_loss: 1054.6967\n",
      "Epoch 6239/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 1190.7368 - val_loss: 1054.6332\n",
      "Epoch 6240/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 1190.6746 - val_loss: 1054.5697\n",
      "Epoch 6241/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 1190.6124 - val_loss: 1054.5063\n",
      "Epoch 6242/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 1190.5503 - val_loss: 1054.4429\n",
      "Epoch 6243/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 1190.4883 - val_loss: 1054.3798\n",
      "Epoch 6244/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 1190.4264 - val_loss: 1054.3164\n",
      "Epoch 6245/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 1190.3645 - val_loss: 1054.2532\n",
      "Epoch 6246/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 1190.3026 - val_loss: 1054.1902\n",
      "Epoch 6247/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1190.2407 - val_loss: 1054.1271\n",
      "Epoch 6248/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 1190.1791 - val_loss: 1054.0641\n",
      "Epoch 6249/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 1190.1174 - val_loss: 1054.0011\n",
      "Epoch 6250/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 1190.0558 - val_loss: 1053.9382\n",
      "Epoch 6251/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 1189.9941 - val_loss: 1053.8754\n",
      "Epoch 6252/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 1189.9327 - val_loss: 1053.8129\n",
      "Epoch 6253/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1189.8712 - val_loss: 1053.7501\n",
      "Epoch 6254/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1189.8097 - val_loss: 1053.6874\n",
      "Epoch 6255/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1189.7487 - val_loss: 1053.6249\n",
      "Epoch 6256/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1189.6873 - val_loss: 1053.5624\n",
      "Epoch 6257/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 1189.6261 - val_loss: 1053.4999\n",
      "Epoch 6258/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 1189.5649 - val_loss: 1053.4375\n",
      "Epoch 6259/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1189.5039 - val_loss: 1053.3751\n",
      "Epoch 6260/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 1189.4429 - val_loss: 1053.3129\n",
      "Epoch 6261/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1189.3818 - val_loss: 1053.2505\n",
      "Epoch 6262/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1189.3210 - val_loss: 1053.1884\n",
      "Epoch 6263/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 1189.2600 - val_loss: 1053.1263\n",
      "Epoch 6264/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1189.1993 - val_loss: 1053.0642\n",
      "Epoch 6265/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 1189.1388 - val_loss: 1053.0021\n",
      "Epoch 6266/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 1189.0779 - val_loss: 1052.9403\n",
      "Epoch 6267/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1189.0172 - val_loss: 1052.8785\n",
      "Epoch 6268/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 1188.9568 - val_loss: 1052.8165\n",
      "Epoch 6269/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1188.8961 - val_loss: 1052.7550\n",
      "Epoch 6270/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 1188.8358 - val_loss: 1052.6932\n",
      "Epoch 6271/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1188.7754 - val_loss: 1052.6316\n",
      "Epoch 6272/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 1188.7151 - val_loss: 1052.5699\n",
      "Epoch 6273/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 1188.6548 - val_loss: 1052.5083\n",
      "Epoch 6274/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 1188.5946 - val_loss: 1052.4471\n",
      "Epoch 6275/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 1188.5344 - val_loss: 1052.3856\n",
      "Epoch 6276/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 1188.4745 - val_loss: 1052.3242\n",
      "Epoch 6277/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1188.4143 - val_loss: 1052.2628\n",
      "Epoch 6278/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 1188.3542 - val_loss: 1052.2017\n",
      "Epoch 6279/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 1188.2947 - val_loss: 1052.1405\n",
      "Epoch 6280/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1188.2345 - val_loss: 1052.0792\n",
      "Epoch 6281/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 1188.1749 - val_loss: 1052.0184\n",
      "Epoch 6282/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1188.1151 - val_loss: 1051.9574\n",
      "Epoch 6283/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 1188.0552 - val_loss: 1051.8965\n",
      "Epoch 6284/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1187.9956 - val_loss: 1051.8356\n",
      "Epoch 6285/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1187.9360 - val_loss: 1051.7747\n",
      "Epoch 6286/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1187.8765 - val_loss: 1051.7139\n",
      "Epoch 6287/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1187.8173 - val_loss: 1051.6532\n",
      "Epoch 6288/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 1187.7578 - val_loss: 1051.5927\n",
      "Epoch 6289/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1187.6984 - val_loss: 1051.5320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6290/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 1187.6392 - val_loss: 1051.4716\n",
      "Epoch 6291/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1187.5800 - val_loss: 1051.4109\n",
      "Epoch 6292/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 1187.5206 - val_loss: 1051.3505\n",
      "Epoch 6293/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1187.4617 - val_loss: 1051.2902\n",
      "Epoch 6294/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1187.4025 - val_loss: 1051.2300\n",
      "Epoch 6295/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1187.3436 - val_loss: 1051.1696\n",
      "Epoch 6296/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 1187.2847 - val_loss: 1051.1095\n",
      "Epoch 6297/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 1187.2256 - val_loss: 1051.0494\n",
      "Epoch 6298/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1187.1669 - val_loss: 1050.9894\n",
      "Epoch 6299/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1187.1082 - val_loss: 1050.9292\n",
      "Epoch 6300/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1187.0493 - val_loss: 1050.8693\n",
      "Epoch 6301/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1186.9907 - val_loss: 1050.8094\n",
      "Epoch 6302/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1186.9321 - val_loss: 1050.7495\n",
      "Epoch 6303/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 1186.8735 - val_loss: 1050.6898\n",
      "Epoch 6304/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 1186.8152 - val_loss: 1050.6300\n",
      "Epoch 6305/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1186.7567 - val_loss: 1050.5704\n",
      "Epoch 6306/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 1186.6984 - val_loss: 1050.5109\n",
      "Epoch 6307/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1186.6400 - val_loss: 1050.4513\n",
      "Epoch 6308/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 1186.5818 - val_loss: 1050.3917\n",
      "Epoch 6309/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 1186.5236 - val_loss: 1050.3323\n",
      "Epoch 6310/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1186.4655 - val_loss: 1050.2729\n",
      "Epoch 6311/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1186.4073 - val_loss: 1050.2136\n",
      "Epoch 6312/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1186.3491 - val_loss: 1050.1543\n",
      "Epoch 6313/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1186.2914 - val_loss: 1050.0952\n",
      "Epoch 6314/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 1186.2334 - val_loss: 1050.0360\n",
      "Epoch 6315/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1186.1757 - val_loss: 1049.9769\n",
      "Epoch 6316/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 1186.1179 - val_loss: 1049.9178\n",
      "Epoch 6317/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1186.0601 - val_loss: 1049.8589\n",
      "Epoch 6318/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1186.0023 - val_loss: 1049.8000\n",
      "Epoch 6319/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1185.9447 - val_loss: 1049.7411\n",
      "Epoch 6320/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1185.8872 - val_loss: 1049.6823\n",
      "Epoch 6321/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1185.8296 - val_loss: 1049.6235\n",
      "Epoch 6322/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 1185.7722 - val_loss: 1049.5649\n",
      "Epoch 6323/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1185.7148 - val_loss: 1049.5062\n",
      "Epoch 6324/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1185.6573 - val_loss: 1049.4476\n",
      "Epoch 6325/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 1185.6002 - val_loss: 1049.3890\n",
      "Epoch 6326/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 1185.5428 - val_loss: 1049.3306\n",
      "Epoch 6327/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1185.4858 - val_loss: 1049.2722\n",
      "Epoch 6328/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1185.4286 - val_loss: 1049.2140\n",
      "Epoch 6329/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 1185.3716 - val_loss: 1049.1555\n",
      "Epoch 6330/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1185.3146 - val_loss: 1049.0972\n",
      "Epoch 6331/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1185.2577 - val_loss: 1049.0392\n",
      "Epoch 6332/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1185.2008 - val_loss: 1048.9812\n",
      "Epoch 6333/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 1185.1439 - val_loss: 1048.9230\n",
      "Epoch 6334/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 1185.0873 - val_loss: 1048.8647\n",
      "Epoch 6335/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1185.0302 - val_loss: 1048.8070\n",
      "Epoch 6336/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 1184.9738 - val_loss: 1048.7489\n",
      "Epoch 6337/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1184.9171 - val_loss: 1048.6913\n",
      "Epoch 6338/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 1184.8605 - val_loss: 1048.6334\n",
      "Epoch 6339/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1184.8041 - val_loss: 1048.5757\n",
      "Epoch 6340/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 1184.7476 - val_loss: 1048.5181\n",
      "Epoch 6341/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 1184.6913 - val_loss: 1048.4604\n",
      "Epoch 6342/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1184.6349 - val_loss: 1048.4030\n",
      "Epoch 6343/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 1184.5786 - val_loss: 1048.3455\n",
      "Epoch 6344/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1184.5223 - val_loss: 1048.2880\n",
      "Epoch 6345/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1184.4662 - val_loss: 1048.2306\n",
      "Epoch 6346/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 1184.4102 - val_loss: 1048.1732\n",
      "Epoch 6347/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 1184.3540 - val_loss: 1048.1160\n",
      "Epoch 6348/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 1184.2980 - val_loss: 1048.0586\n",
      "Epoch 6349/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1184.2422 - val_loss: 1048.0016\n",
      "Epoch 6350/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1184.1863 - val_loss: 1047.9445\n",
      "Epoch 6351/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1184.1304 - val_loss: 1047.8873\n",
      "Epoch 6352/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 1184.0747 - val_loss: 1047.8304\n",
      "Epoch 6353/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 1184.0189 - val_loss: 1047.7733\n",
      "Epoch 6354/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 1183.9633 - val_loss: 1047.7166\n",
      "Epoch 6355/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1183.9076 - val_loss: 1047.6597\n",
      "Epoch 6356/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 1183.8519 - val_loss: 1047.6029\n",
      "Epoch 6357/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1183.7968 - val_loss: 1047.5461\n",
      "Epoch 6358/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 1183.7411 - val_loss: 1047.4895\n",
      "Epoch 6359/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1183.6857 - val_loss: 1047.4331\n",
      "Epoch 6360/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1183.6304 - val_loss: 1047.3765\n",
      "Epoch 6361/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1183.5751 - val_loss: 1047.3199\n",
      "Epoch 6362/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 1183.5200 - val_loss: 1047.2635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6363/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 1183.4647 - val_loss: 1047.2070\n",
      "Epoch 6364/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 1183.4097 - val_loss: 1047.1506\n",
      "Epoch 6365/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1183.3546 - val_loss: 1047.0946\n",
      "Epoch 6366/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 1183.2997 - val_loss: 1047.0382\n",
      "Epoch 6367/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 1183.2446 - val_loss: 1046.9822\n",
      "Epoch 6368/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 1183.1898 - val_loss: 1046.9259\n",
      "Epoch 6369/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1183.1351 - val_loss: 1046.8699\n",
      "Epoch 6370/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1183.0802 - val_loss: 1046.8138\n",
      "Epoch 6371/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 1183.0254 - val_loss: 1046.7579\n",
      "Epoch 6372/100000\n",
      "11/11 [==============================] - 0s 199us/step - loss: 1182.9708 - val_loss: 1046.7020\n",
      "Epoch 6373/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1182.9160 - val_loss: 1046.6464\n",
      "Epoch 6374/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1182.8617 - val_loss: 1046.5907\n",
      "Epoch 6375/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 1182.8071 - val_loss: 1046.5348\n",
      "Epoch 6376/100000\n",
      "11/11 [==============================] - 0s 590us/step - loss: 1182.7526 - val_loss: 1046.4791\n",
      "Epoch 6377/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1182.6984 - val_loss: 1046.4236\n",
      "Epoch 6378/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 1182.6440 - val_loss: 1046.3680\n",
      "Epoch 6379/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1182.5897 - val_loss: 1046.3125\n",
      "Epoch 6380/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1182.5354 - val_loss: 1046.2571\n",
      "Epoch 6381/100000\n",
      "11/11 [==============================] - 0s 564us/step - loss: 1182.4812 - val_loss: 1046.2015\n",
      "Epoch 6382/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1182.4272 - val_loss: 1046.1464\n",
      "Epoch 6383/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1182.3730 - val_loss: 1046.0909\n",
      "Epoch 6384/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1182.3191 - val_loss: 1046.0358\n",
      "Epoch 6385/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1182.2651 - val_loss: 1045.9806\n",
      "Epoch 6386/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1182.2112 - val_loss: 1045.9257\n",
      "Epoch 6387/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 1182.1573 - val_loss: 1045.8706\n",
      "Epoch 6388/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1182.1035 - val_loss: 1045.8156\n",
      "Epoch 6389/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1182.0498 - val_loss: 1045.7605\n",
      "Epoch 6390/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 1181.9961 - val_loss: 1045.7056\n",
      "Epoch 6391/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 1181.9425 - val_loss: 1045.6508\n",
      "Epoch 6392/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1181.8889 - val_loss: 1045.5961\n",
      "Epoch 6393/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1181.8354 - val_loss: 1045.5414\n",
      "Epoch 6394/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1181.7821 - val_loss: 1045.4865\n",
      "Epoch 6395/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 1181.7286 - val_loss: 1045.4321\n",
      "Epoch 6396/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1181.6753 - val_loss: 1045.3774\n",
      "Epoch 6397/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1181.6219 - val_loss: 1045.3230\n",
      "Epoch 6398/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 1181.5687 - val_loss: 1045.2686\n",
      "Epoch 6399/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1181.5154 - val_loss: 1045.2140\n",
      "Epoch 6400/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 1181.4624 - val_loss: 1045.1597\n",
      "Epoch 6401/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 1181.4093 - val_loss: 1045.1055\n",
      "Epoch 6402/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1181.3562 - val_loss: 1045.0513\n",
      "Epoch 6403/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1181.3033 - val_loss: 1044.9972\n",
      "Epoch 6404/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1181.2504 - val_loss: 1044.9429\n",
      "Epoch 6405/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1181.1974 - val_loss: 1044.8888\n",
      "Epoch 6406/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1181.1448 - val_loss: 1044.8348\n",
      "Epoch 6407/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 1181.0919 - val_loss: 1044.7809\n",
      "Epoch 6408/100000\n",
      "11/11 [==============================] - 0s 586us/step - loss: 1181.0392 - val_loss: 1044.7269\n",
      "Epoch 6409/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 1180.9865 - val_loss: 1044.6730\n",
      "Epoch 6410/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1180.9340 - val_loss: 1044.6193\n",
      "Epoch 6411/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1180.8816 - val_loss: 1044.5656\n",
      "Epoch 6412/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 1180.8290 - val_loss: 1044.5118\n",
      "Epoch 6413/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 1180.7765 - val_loss: 1044.4581\n",
      "Epoch 6414/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1180.7241 - val_loss: 1044.4048\n",
      "Epoch 6415/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1180.6716 - val_loss: 1044.3511\n",
      "Epoch 6416/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1180.6195 - val_loss: 1044.2976\n",
      "Epoch 6417/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 1180.5673 - val_loss: 1044.2441\n",
      "Epoch 6418/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 1180.5151 - val_loss: 1044.1909\n",
      "Epoch 6419/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1180.4630 - val_loss: 1044.1375\n",
      "Epoch 6420/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 1180.4109 - val_loss: 1044.0844\n",
      "Epoch 6421/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 1180.3589 - val_loss: 1044.0311\n",
      "Epoch 6422/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 1180.3070 - val_loss: 1043.9779\n",
      "Epoch 6423/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1180.2551 - val_loss: 1043.9249\n",
      "Epoch 6424/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1180.2034 - val_loss: 1043.8718\n",
      "Epoch 6425/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 1180.1515 - val_loss: 1043.8188\n",
      "Epoch 6426/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 1180.0997 - val_loss: 1043.7657\n",
      "Epoch 6427/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1180.0481 - val_loss: 1043.7129\n",
      "Epoch 6428/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1179.9962 - val_loss: 1043.6603\n",
      "Epoch 6429/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1179.9448 - val_loss: 1043.6074\n",
      "Epoch 6430/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 1179.8932 - val_loss: 1043.5547\n",
      "Epoch 6431/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 1179.8418 - val_loss: 1043.5018\n",
      "Epoch 6432/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1179.7902 - val_loss: 1043.4493\n",
      "Epoch 6433/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1179.7391 - val_loss: 1043.3967\n",
      "Epoch 6434/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1179.6876 - val_loss: 1043.3442\n",
      "Epoch 6435/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1179.6365 - val_loss: 1043.2919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6436/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1179.5852 - val_loss: 1043.2394\n",
      "Epoch 6437/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 1179.5341 - val_loss: 1043.1870\n",
      "Epoch 6438/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 1179.4832 - val_loss: 1043.1349\n",
      "Epoch 6439/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 1179.4318 - val_loss: 1043.0825\n",
      "Epoch 6440/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 1179.3809 - val_loss: 1043.0304\n",
      "Epoch 6441/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 1179.3300 - val_loss: 1042.9781\n",
      "Epoch 6442/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 1179.2792 - val_loss: 1042.9259\n",
      "Epoch 6443/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 1179.2281 - val_loss: 1042.8740\n",
      "Epoch 6444/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1179.1774 - val_loss: 1042.8221\n",
      "Epoch 6445/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1179.1268 - val_loss: 1042.7703\n",
      "Epoch 6446/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 1179.0760 - val_loss: 1042.7183\n",
      "Epoch 6447/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1179.0254 - val_loss: 1042.6666\n",
      "Epoch 6448/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1178.9749 - val_loss: 1042.6147\n",
      "Epoch 6449/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1178.9243 - val_loss: 1042.5631\n",
      "Epoch 6450/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1178.8739 - val_loss: 1042.5115\n",
      "Epoch 6451/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1178.8234 - val_loss: 1042.4597\n",
      "Epoch 6452/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 1178.7731 - val_loss: 1042.4082\n",
      "Epoch 6453/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 1178.7227 - val_loss: 1042.3567\n",
      "Epoch 6454/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 1178.6726 - val_loss: 1042.3053\n",
      "Epoch 6455/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1178.6222 - val_loss: 1042.2539\n",
      "Epoch 6456/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 1178.5721 - val_loss: 1042.2026\n",
      "Epoch 6457/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1178.5221 - val_loss: 1042.1514\n",
      "Epoch 6458/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 1178.4718 - val_loss: 1042.1001\n",
      "Epoch 6459/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 1178.4220 - val_loss: 1042.0488\n",
      "Epoch 6460/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1178.3719 - val_loss: 1041.9978\n",
      "Epoch 6461/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 1178.3223 - val_loss: 1041.9468\n",
      "Epoch 6462/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 1178.2723 - val_loss: 1041.8956\n",
      "Epoch 6463/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 1178.2225 - val_loss: 1041.8447\n",
      "Epoch 6464/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1178.1727 - val_loss: 1041.7937\n",
      "Epoch 6465/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 1178.1229 - val_loss: 1041.7429\n",
      "Epoch 6466/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 1178.0734 - val_loss: 1041.6920\n",
      "Epoch 6467/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1178.0239 - val_loss: 1041.6414\n",
      "Epoch 6468/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1177.9744 - val_loss: 1041.5907\n",
      "Epoch 6469/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1177.9249 - val_loss: 1041.5399\n",
      "Epoch 6470/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1177.8755 - val_loss: 1041.4895\n",
      "Epoch 6471/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1177.8262 - val_loss: 1041.4390\n",
      "Epoch 6472/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 1177.7769 - val_loss: 1041.3884\n",
      "Epoch 6473/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 1177.7274 - val_loss: 1041.3380\n",
      "Epoch 6474/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1177.6782 - val_loss: 1041.2876\n",
      "Epoch 6475/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 1177.6290 - val_loss: 1041.2372\n",
      "Epoch 6476/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 1177.5801 - val_loss: 1041.1869\n",
      "Epoch 6477/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 1177.5309 - val_loss: 1041.1367\n",
      "Epoch 6478/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1177.4821 - val_loss: 1041.0865\n",
      "Epoch 6479/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1177.4330 - val_loss: 1041.0363\n",
      "Epoch 6480/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 1177.3842 - val_loss: 1040.9863\n",
      "Epoch 6481/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 1177.3353 - val_loss: 1040.9364\n",
      "Epoch 6482/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1177.2864 - val_loss: 1040.8862\n",
      "Epoch 6483/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1177.2378 - val_loss: 1040.8364\n",
      "Epoch 6484/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1177.1890 - val_loss: 1040.7865\n",
      "Epoch 6485/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 1177.1403 - val_loss: 1040.7367\n",
      "Epoch 6486/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 1177.0918 - val_loss: 1040.6869\n",
      "Epoch 6487/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1177.0432 - val_loss: 1040.6371\n",
      "Epoch 6488/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1176.9946 - val_loss: 1040.5876\n",
      "Epoch 6489/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 1176.9462 - val_loss: 1040.5378\n",
      "Epoch 6490/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1176.8977 - val_loss: 1040.4883\n",
      "Epoch 6491/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 1176.8495 - val_loss: 1040.4388\n",
      "Epoch 6492/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 1176.8013 - val_loss: 1040.3894\n",
      "Epoch 6493/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 1176.7531 - val_loss: 1040.3400\n",
      "Epoch 6494/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 1176.7050 - val_loss: 1040.2905\n",
      "Epoch 6495/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 1176.6566 - val_loss: 1040.2413\n",
      "Epoch 6496/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1176.6085 - val_loss: 1040.1921\n",
      "Epoch 6497/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1176.5604 - val_loss: 1040.1429\n",
      "Epoch 6498/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 1176.5126 - val_loss: 1040.0938\n",
      "Epoch 6499/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1176.4647 - val_loss: 1040.0444\n",
      "Epoch 6500/100000\n",
      "11/11 [==============================] - 0s 717us/step - loss: 1176.4167 - val_loss: 1039.9956\n",
      "Epoch 6501/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1176.3690 - val_loss: 1039.9464\n",
      "Epoch 6502/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 1176.3212 - val_loss: 1039.8976\n",
      "Epoch 6503/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1176.2734 - val_loss: 1039.8488\n",
      "Epoch 6504/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 1176.2257 - val_loss: 1039.7998\n",
      "Epoch 6505/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1176.1781 - val_loss: 1039.7511\n",
      "Epoch 6506/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1176.1306 - val_loss: 1039.7023\n",
      "Epoch 6507/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 1176.0830 - val_loss: 1039.6536\n",
      "Epoch 6508/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 1176.0356 - val_loss: 1039.6051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6509/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 1175.9882 - val_loss: 1039.5565\n",
      "Epoch 6510/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 1175.9408 - val_loss: 1039.5078\n",
      "Epoch 6511/100000\n",
      "11/11 [==============================] - 0s 608us/step - loss: 1175.8934 - val_loss: 1039.4595\n",
      "Epoch 6512/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1175.8462 - val_loss: 1039.4110\n",
      "Epoch 6513/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1175.7990 - val_loss: 1039.3627\n",
      "Epoch 6514/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1175.7518 - val_loss: 1039.3143\n",
      "Epoch 6515/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1175.7046 - val_loss: 1039.2661\n",
      "Epoch 6516/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1175.6576 - val_loss: 1039.2178\n",
      "Epoch 6517/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1175.6106 - val_loss: 1039.1696\n",
      "Epoch 6518/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 1175.5636 - val_loss: 1039.1216\n",
      "Epoch 6519/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1175.5167 - val_loss: 1039.0735\n",
      "Epoch 6520/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1175.4698 - val_loss: 1039.0254\n",
      "Epoch 6521/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 1175.4230 - val_loss: 1038.9775\n",
      "Epoch 6522/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1175.3762 - val_loss: 1038.9296\n",
      "Epoch 6523/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1175.3295 - val_loss: 1038.8817\n",
      "Epoch 6524/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 1175.2828 - val_loss: 1038.8339\n",
      "Epoch 6525/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1175.2363 - val_loss: 1038.7860\n",
      "Epoch 6526/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1175.1897 - val_loss: 1038.7383\n",
      "Epoch 6527/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 1175.1433 - val_loss: 1038.6907\n",
      "Epoch 6528/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1175.0967 - val_loss: 1038.6431\n",
      "Epoch 6529/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1175.0505 - val_loss: 1038.5955\n",
      "Epoch 6530/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 1175.0040 - val_loss: 1038.5480\n",
      "Epoch 6531/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 1174.9576 - val_loss: 1038.5005\n",
      "Epoch 6532/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 1174.9113 - val_loss: 1038.4531\n",
      "Epoch 6533/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 1174.8651 - val_loss: 1038.4058\n",
      "Epoch 6534/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 1174.8191 - val_loss: 1038.3585\n",
      "Epoch 6535/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1174.7729 - val_loss: 1038.3110\n",
      "Epoch 6536/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 1174.7268 - val_loss: 1038.2640\n",
      "Epoch 6537/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 1174.6808 - val_loss: 1038.2168\n",
      "Epoch 6538/100000\n",
      "11/11 [==============================] - 0s 621us/step - loss: 1174.6348 - val_loss: 1038.1698\n",
      "Epoch 6539/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 1174.5890 - val_loss: 1038.1227\n",
      "Epoch 6540/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 1174.5431 - val_loss: 1038.0756\n",
      "Epoch 6541/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 1174.4973 - val_loss: 1038.0286\n",
      "Epoch 6542/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 1174.4514 - val_loss: 1037.9817\n",
      "Epoch 6543/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 1174.4058 - val_loss: 1037.9348\n",
      "Epoch 6544/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1174.3601 - val_loss: 1037.8879\n",
      "Epoch 6545/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 1174.3143 - val_loss: 1037.8413\n",
      "Epoch 6546/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 1174.2688 - val_loss: 1037.7946\n",
      "Epoch 6547/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1174.2234 - val_loss: 1037.7479\n",
      "Epoch 6548/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 1174.1781 - val_loss: 1037.7013\n",
      "Epoch 6549/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1174.1326 - val_loss: 1037.6547\n",
      "Epoch 6550/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1174.0872 - val_loss: 1037.6082\n",
      "Epoch 6551/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1174.0417 - val_loss: 1037.5618\n",
      "Epoch 6552/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 1173.9966 - val_loss: 1037.5154\n",
      "Epoch 6553/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 1173.9513 - val_loss: 1037.4689\n",
      "Epoch 6554/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1173.9061 - val_loss: 1037.4227\n",
      "Epoch 6555/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 1173.8611 - val_loss: 1037.3765\n",
      "Epoch 6556/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1173.8159 - val_loss: 1037.3302\n",
      "Epoch 6557/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 1173.7710 - val_loss: 1037.2841\n",
      "Epoch 6558/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 1173.7261 - val_loss: 1037.2379\n",
      "Epoch 6559/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 1173.6810 - val_loss: 1037.1917\n",
      "Epoch 6560/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1173.6360 - val_loss: 1037.1459\n",
      "Epoch 6561/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1173.5913 - val_loss: 1037.0997\n",
      "Epoch 6562/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1173.5465 - val_loss: 1037.0540\n",
      "Epoch 6563/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 1173.5018 - val_loss: 1037.0081\n",
      "Epoch 6564/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 1173.4570 - val_loss: 1036.9622\n",
      "Epoch 6565/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 1173.4125 - val_loss: 1036.9165\n",
      "Epoch 6566/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 1173.3679 - val_loss: 1036.8707\n",
      "Epoch 6567/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1173.3232 - val_loss: 1036.8251\n",
      "Epoch 6568/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1173.2788 - val_loss: 1036.7794\n",
      "Epoch 6569/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1173.2345 - val_loss: 1036.7339\n",
      "Epoch 6570/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 1173.1899 - val_loss: 1036.6884\n",
      "Epoch 6571/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1173.1455 - val_loss: 1036.6427\n",
      "Epoch 6572/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1173.1013 - val_loss: 1036.5973\n",
      "Epoch 6573/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 1173.0570 - val_loss: 1036.5520\n",
      "Epoch 6574/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 1173.0128 - val_loss: 1036.5067\n",
      "Epoch 6575/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 1172.9686 - val_loss: 1036.4613\n",
      "Epoch 6576/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1172.9247 - val_loss: 1036.4161\n",
      "Epoch 6577/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 1172.8807 - val_loss: 1036.3710\n",
      "Epoch 6578/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1172.8365 - val_loss: 1036.3258\n",
      "Epoch 6579/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 1172.7926 - val_loss: 1036.2808\n",
      "Epoch 6580/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1172.7489 - val_loss: 1036.2356\n",
      "Epoch 6581/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 1172.7050 - val_loss: 1036.1906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6582/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 1172.6610 - val_loss: 1036.1458\n",
      "Epoch 6583/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1172.6173 - val_loss: 1036.1008\n",
      "Epoch 6584/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1172.5734 - val_loss: 1036.0560\n",
      "Epoch 6585/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 1172.5300 - val_loss: 1036.0112\n",
      "Epoch 6586/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 1172.4862 - val_loss: 1035.9664\n",
      "Epoch 6587/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 1172.4427 - val_loss: 1035.9219\n",
      "Epoch 6588/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 1172.3993 - val_loss: 1035.8771\n",
      "Epoch 6589/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1172.3556 - val_loss: 1035.8325\n",
      "Epoch 6590/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 1172.3124 - val_loss: 1035.7880\n",
      "Epoch 6591/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 1172.2688 - val_loss: 1035.7434\n",
      "Epoch 6592/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1172.2257 - val_loss: 1035.6991\n",
      "Epoch 6593/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1172.1824 - val_loss: 1035.6547\n",
      "Epoch 6594/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 1172.1390 - val_loss: 1035.6102\n",
      "Epoch 6595/100000\n",
      "11/11 [==============================] - 0s 703us/step - loss: 1172.0958 - val_loss: 1035.5659\n",
      "Epoch 6596/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 1172.0527 - val_loss: 1035.5216\n",
      "Epoch 6597/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1172.0095 - val_loss: 1035.4773\n",
      "Epoch 6598/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1171.9666 - val_loss: 1035.4332\n",
      "Epoch 6599/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1171.9235 - val_loss: 1035.3892\n",
      "Epoch 6600/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 1171.8807 - val_loss: 1035.3451\n",
      "Epoch 6601/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 1171.8376 - val_loss: 1035.3009\n",
      "Epoch 6602/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 1171.7948 - val_loss: 1035.2571\n",
      "Epoch 6603/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1171.7521 - val_loss: 1035.2131\n",
      "Epoch 6604/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 1171.7091 - val_loss: 1035.1693\n",
      "Epoch 6605/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1171.6666 - val_loss: 1035.1255\n",
      "Epoch 6606/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1171.6239 - val_loss: 1035.0815\n",
      "Epoch 6607/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 1171.5813 - val_loss: 1035.0380\n",
      "Epoch 6608/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1171.5386 - val_loss: 1034.9943\n",
      "Epoch 6609/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 1171.4962 - val_loss: 1034.9504\n",
      "Epoch 6610/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1171.4537 - val_loss: 1034.9070\n",
      "Epoch 6611/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 1171.4113 - val_loss: 1034.8634\n",
      "Epoch 6612/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 1171.3688 - val_loss: 1034.8199\n",
      "Epoch 6613/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 1171.3265 - val_loss: 1034.7765\n",
      "Epoch 6614/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1171.2841 - val_loss: 1034.7330\n",
      "Epoch 6615/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 1171.2421 - val_loss: 1034.6898\n",
      "Epoch 6616/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 1171.1997 - val_loss: 1034.6464\n",
      "Epoch 6617/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1171.1576 - val_loss: 1034.6030\n",
      "Epoch 6618/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1171.1155 - val_loss: 1034.5599\n",
      "Epoch 6619/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1171.0735 - val_loss: 1034.5167\n",
      "Epoch 6620/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 1171.0314 - val_loss: 1034.4738\n",
      "Epoch 6621/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1170.9895 - val_loss: 1034.4305\n",
      "Epoch 6622/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 1170.9475 - val_loss: 1034.3875\n",
      "Epoch 6623/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 1170.9058 - val_loss: 1034.3446\n",
      "Epoch 6624/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 1170.8639 - val_loss: 1034.3016\n",
      "Epoch 6625/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 1170.8220 - val_loss: 1034.2587\n",
      "Epoch 6626/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 1170.7804 - val_loss: 1034.2159\n",
      "Epoch 6627/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 1170.7388 - val_loss: 1034.1731\n",
      "Epoch 6628/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 1170.6971 - val_loss: 1034.1304\n",
      "Epoch 6629/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1170.6554 - val_loss: 1034.0878\n",
      "Epoch 6630/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1170.6140 - val_loss: 1034.0449\n",
      "Epoch 6631/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 1170.5724 - val_loss: 1034.0024\n",
      "Epoch 6632/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 1170.5310 - val_loss: 1033.9598\n",
      "Epoch 6633/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1170.4897 - val_loss: 1033.9174\n",
      "Epoch 6634/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 1170.4481 - val_loss: 1033.8749\n",
      "Epoch 6635/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 1170.4070 - val_loss: 1033.8325\n",
      "Epoch 6636/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1170.3657 - val_loss: 1033.7902\n",
      "Epoch 6637/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 1170.3246 - val_loss: 1033.7477\n",
      "Epoch 6638/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 1170.2833 - val_loss: 1033.7056\n",
      "Epoch 6639/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 1170.2421 - val_loss: 1033.6632\n",
      "Epoch 6640/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 1170.2010 - val_loss: 1033.6210\n",
      "Epoch 6641/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1170.1600 - val_loss: 1033.5790\n",
      "Epoch 6642/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1170.1190 - val_loss: 1033.5369\n",
      "Epoch 6643/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1170.0781 - val_loss: 1033.4949\n",
      "Epoch 6644/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 1170.0372 - val_loss: 1033.4528\n",
      "Epoch 6645/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 1169.9963 - val_loss: 1033.4109\n",
      "Epoch 6646/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 1169.9556 - val_loss: 1033.3690\n",
      "Epoch 6647/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1169.9148 - val_loss: 1033.3270\n",
      "Epoch 6648/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1169.8741 - val_loss: 1033.2853\n",
      "Epoch 6649/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 1169.8334 - val_loss: 1033.2434\n",
      "Epoch 6650/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 1169.7928 - val_loss: 1033.2017\n",
      "Epoch 6651/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1169.7521 - val_loss: 1033.1600\n",
      "Epoch 6652/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 1169.7114 - val_loss: 1033.1185\n",
      "Epoch 6653/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1169.6711 - val_loss: 1033.0770\n",
      "Epoch 6654/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1169.6309 - val_loss: 1033.0354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6655/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1169.5903 - val_loss: 1032.9939\n",
      "Epoch 6656/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1169.5499 - val_loss: 1032.9525\n",
      "Epoch 6657/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 1169.5098 - val_loss: 1032.9110\n",
      "Epoch 6658/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 1169.4692 - val_loss: 1032.8696\n",
      "Epoch 6659/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 1169.4292 - val_loss: 1032.8284\n",
      "Epoch 6660/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1169.3892 - val_loss: 1032.7871\n",
      "Epoch 6661/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 1169.3489 - val_loss: 1032.7460\n",
      "Epoch 6662/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 1169.3090 - val_loss: 1032.7046\n",
      "Epoch 6663/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 1169.2687 - val_loss: 1032.6636\n",
      "Epoch 6664/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1169.2289 - val_loss: 1032.6224\n",
      "Epoch 6665/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 1169.1890 - val_loss: 1032.5814\n",
      "Epoch 6666/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 1169.1489 - val_loss: 1032.5405\n",
      "Epoch 6667/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 1169.1093 - val_loss: 1032.4996\n",
      "Epoch 6668/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 1169.0693 - val_loss: 1032.4587\n",
      "Epoch 6669/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1169.0294 - val_loss: 1032.4178\n",
      "Epoch 6670/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 1168.9900 - val_loss: 1032.3771\n",
      "Epoch 6671/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 1168.9502 - val_loss: 1032.3362\n",
      "Epoch 6672/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1168.9105 - val_loss: 1032.2957\n",
      "Epoch 6673/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1168.8710 - val_loss: 1032.2548\n",
      "Epoch 6674/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 1168.8314 - val_loss: 1032.2144\n",
      "Epoch 6675/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1168.7920 - val_loss: 1032.1737\n",
      "Epoch 6676/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 1168.7524 - val_loss: 1032.1332\n",
      "Epoch 6677/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 1168.7130 - val_loss: 1032.0925\n",
      "Epoch 6678/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 1168.6737 - val_loss: 1032.0522\n",
      "Epoch 6679/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 1168.6344 - val_loss: 1032.0118\n",
      "Epoch 6680/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 1168.5952 - val_loss: 1031.9714\n",
      "Epoch 6681/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 1168.5560 - val_loss: 1031.9312\n",
      "Epoch 6682/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 1168.5167 - val_loss: 1031.8910\n",
      "Epoch 6683/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 1168.4775 - val_loss: 1031.8507\n",
      "Epoch 6684/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1168.4385 - val_loss: 1031.8105\n",
      "Epoch 6685/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1168.3995 - val_loss: 1031.7704\n",
      "Epoch 6686/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 1168.3605 - val_loss: 1031.7303\n",
      "Epoch 6687/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 1168.3214 - val_loss: 1031.6902\n",
      "Epoch 6688/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 1168.2826 - val_loss: 1031.6503\n",
      "Epoch 6689/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1168.2437 - val_loss: 1031.6104\n",
      "Epoch 6690/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 1168.2050 - val_loss: 1031.5703\n",
      "Epoch 6691/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1168.1660 - val_loss: 1031.5305\n",
      "Epoch 6692/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1168.1273 - val_loss: 1031.4907\n",
      "Epoch 6693/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1168.0886 - val_loss: 1031.4509\n",
      "Epoch 6694/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1168.0499 - val_loss: 1031.4111\n",
      "Epoch 6695/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 1168.0114 - val_loss: 1031.3716\n",
      "Epoch 6696/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 1167.9728 - val_loss: 1031.3319\n",
      "Epoch 6697/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1167.9341 - val_loss: 1031.2921\n",
      "Epoch 6698/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1167.8958 - val_loss: 1031.2528\n",
      "Epoch 6699/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 1167.8574 - val_loss: 1031.2131\n",
      "Epoch 6700/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 1167.8188 - val_loss: 1031.1737\n",
      "Epoch 6701/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1167.7805 - val_loss: 1031.1343\n",
      "Epoch 6702/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1167.7422 - val_loss: 1031.0950\n",
      "Epoch 6703/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 1167.7040 - val_loss: 1031.0555\n",
      "Epoch 6704/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 1167.6656 - val_loss: 1031.0164\n",
      "Epoch 6705/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1167.6274 - val_loss: 1030.9772\n",
      "Epoch 6706/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 1167.5895 - val_loss: 1030.9379\n",
      "Epoch 6707/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 1167.5513 - val_loss: 1030.8988\n",
      "Epoch 6708/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 1167.5132 - val_loss: 1030.8595\n",
      "Epoch 6709/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1167.4753 - val_loss: 1030.8204\n",
      "Epoch 6710/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 1167.4374 - val_loss: 1030.7814\n",
      "Epoch 6711/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 1167.3993 - val_loss: 1030.7426\n",
      "Epoch 6712/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 1167.3616 - val_loss: 1030.7035\n",
      "Epoch 6713/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1167.3237 - val_loss: 1030.6646\n",
      "Epoch 6714/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 1167.2860 - val_loss: 1030.6257\n",
      "Epoch 6715/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1167.2482 - val_loss: 1030.5869\n",
      "Epoch 6716/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 1167.2106 - val_loss: 1030.5481\n",
      "Epoch 6717/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1167.1727 - val_loss: 1030.5095\n",
      "Epoch 6718/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 1167.1353 - val_loss: 1030.4708\n",
      "Epoch 6719/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 1167.0977 - val_loss: 1030.4321\n",
      "Epoch 6720/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 1167.0601 - val_loss: 1030.3934\n",
      "Epoch 6721/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1167.0226 - val_loss: 1030.3550\n",
      "Epoch 6722/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 1166.9849 - val_loss: 1030.3165\n",
      "Epoch 6723/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 1166.9476 - val_loss: 1030.2781\n",
      "Epoch 6724/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 1166.9103 - val_loss: 1030.2396\n",
      "Epoch 6725/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 1166.8729 - val_loss: 1030.2013\n",
      "Epoch 6726/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 1166.8357 - val_loss: 1030.1630\n",
      "Epoch 6727/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1166.7985 - val_loss: 1030.1246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6728/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 1166.7614 - val_loss: 1030.0864\n",
      "Epoch 6729/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 1166.7241 - val_loss: 1030.0481\n",
      "Epoch 6730/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 1166.6870 - val_loss: 1030.0099\n",
      "Epoch 6731/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 1166.6499 - val_loss: 1029.9718\n",
      "Epoch 6732/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 1166.6129 - val_loss: 1029.9337\n",
      "Epoch 6733/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1166.5760 - val_loss: 1029.8956\n",
      "Epoch 6734/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1166.5391 - val_loss: 1029.8577\n",
      "Epoch 6735/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1166.5021 - val_loss: 1029.8198\n",
      "Epoch 6736/100000\n",
      "11/11 [==============================] - 0s 202us/step - loss: 1166.4652 - val_loss: 1029.7820\n",
      "Epoch 6737/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1166.4283 - val_loss: 1029.7439\n",
      "Epoch 6738/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 1166.3915 - val_loss: 1029.7062\n",
      "Epoch 6739/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 1166.3550 - val_loss: 1029.6683\n",
      "Epoch 6740/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 1166.3182 - val_loss: 1029.6307\n",
      "Epoch 6741/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 1166.2814 - val_loss: 1029.5929\n",
      "Epoch 6742/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1166.2450 - val_loss: 1029.5552\n",
      "Epoch 6743/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 1166.2083 - val_loss: 1029.5176\n",
      "Epoch 6744/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1166.1718 - val_loss: 1029.4800\n",
      "Epoch 6745/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 1166.1353 - val_loss: 1029.4425\n",
      "Epoch 6746/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1166.0988 - val_loss: 1029.4050\n",
      "Epoch 6747/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1166.0625 - val_loss: 1029.3676\n",
      "Epoch 6748/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 1166.0261 - val_loss: 1029.3301\n",
      "Epoch 6749/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 1165.9897 - val_loss: 1029.2928\n",
      "Epoch 6750/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 1165.9534 - val_loss: 1029.2554\n",
      "Epoch 6751/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 1165.9171 - val_loss: 1029.2181\n",
      "Epoch 6752/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1165.8810 - val_loss: 1029.1809\n",
      "Epoch 6753/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1165.8448 - val_loss: 1029.1437\n",
      "Epoch 6754/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 1165.8087 - val_loss: 1029.1066\n",
      "Epoch 6755/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1165.7725 - val_loss: 1029.0695\n",
      "Epoch 6756/100000\n",
      "11/11 [==============================] - 0s 652us/step - loss: 1165.7365 - val_loss: 1029.0323\n",
      "Epoch 6757/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 1165.7004 - val_loss: 1028.9951\n",
      "Epoch 6758/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 1165.6644 - val_loss: 1028.9581\n",
      "Epoch 6759/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 1165.6284 - val_loss: 1028.9214\n",
      "Epoch 6760/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 1165.5927 - val_loss: 1028.8843\n",
      "Epoch 6761/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 1165.5566 - val_loss: 1028.8475\n",
      "Epoch 6762/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1165.5210 - val_loss: 1028.8107\n",
      "Epoch 6763/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 1165.4852 - val_loss: 1028.7738\n",
      "Epoch 6764/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1165.4496 - val_loss: 1028.7371\n",
      "Epoch 6765/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 1165.4139 - val_loss: 1028.7003\n",
      "Epoch 6766/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 1165.3782 - val_loss: 1028.6637\n",
      "Epoch 6767/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 1165.3427 - val_loss: 1028.6271\n",
      "Epoch 6768/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1165.3070 - val_loss: 1028.5905\n",
      "Epoch 6769/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1165.2714 - val_loss: 1028.5538\n",
      "Epoch 6770/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 1165.2360 - val_loss: 1028.5175\n",
      "Epoch 6771/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 1165.2004 - val_loss: 1028.4808\n",
      "Epoch 6772/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 1165.1650 - val_loss: 1028.4445\n",
      "Epoch 6773/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 1165.1298 - val_loss: 1028.4081\n",
      "Epoch 6774/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1165.0944 - val_loss: 1028.3716\n",
      "Epoch 6775/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1165.0591 - val_loss: 1028.3353\n",
      "Epoch 6776/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1165.0238 - val_loss: 1028.2990\n",
      "Epoch 6777/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 1164.9886 - val_loss: 1028.2628\n",
      "Epoch 6778/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 1164.9534 - val_loss: 1028.2266\n",
      "Epoch 6779/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 1164.9181 - val_loss: 1028.1903\n",
      "Epoch 6780/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 1164.8831 - val_loss: 1028.1543\n",
      "Epoch 6781/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 1164.8480 - val_loss: 1028.1180\n",
      "Epoch 6782/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1164.8131 - val_loss: 1028.0822\n",
      "Epoch 6783/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1164.7781 - val_loss: 1028.0461\n",
      "Epoch 6784/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 1164.7432 - val_loss: 1028.0101\n",
      "Epoch 6785/100000\n",
      "11/11 [==============================] - 0s 651us/step - loss: 1164.7081 - val_loss: 1027.9742\n",
      "Epoch 6786/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1164.6733 - val_loss: 1027.9384\n",
      "Epoch 6787/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1164.6384 - val_loss: 1027.9025\n",
      "Epoch 6788/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1164.6036 - val_loss: 1027.8667\n",
      "Epoch 6789/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1164.5688 - val_loss: 1027.8309\n",
      "Epoch 6790/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 1164.5343 - val_loss: 1027.7952\n",
      "Epoch 6791/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 1164.4995 - val_loss: 1027.7596\n",
      "Epoch 6792/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 1164.4648 - val_loss: 1027.7238\n",
      "Epoch 6793/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 1164.4302 - val_loss: 1027.6881\n",
      "Epoch 6794/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 1164.3956 - val_loss: 1027.6525\n",
      "Epoch 6795/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 1164.3610 - val_loss: 1027.6171\n",
      "Epoch 6796/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 1164.3265 - val_loss: 1027.5814\n",
      "Epoch 6797/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1164.2921 - val_loss: 1027.5460\n",
      "Epoch 6798/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 1164.2574 - val_loss: 1027.5106\n",
      "Epoch 6799/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 1164.2231 - val_loss: 1027.4751\n",
      "Epoch 6800/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1164.1887 - val_loss: 1027.4398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6801/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 1164.1545 - val_loss: 1027.4044\n",
      "Epoch 6802/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1164.1204 - val_loss: 1027.3693\n",
      "Epoch 6803/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 1164.0861 - val_loss: 1027.3340\n",
      "Epoch 6804/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 1164.0518 - val_loss: 1027.2987\n",
      "Epoch 6805/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 1164.0177 - val_loss: 1027.2635\n",
      "Epoch 6806/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 1163.9833 - val_loss: 1027.2285\n",
      "Epoch 6807/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1163.9492 - val_loss: 1027.1932\n",
      "Epoch 6808/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 1163.9153 - val_loss: 1027.1582\n",
      "Epoch 6809/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 1163.8812 - val_loss: 1027.1230\n",
      "Epoch 6810/100000\n",
      "11/11 [==============================] - 0s 599us/step - loss: 1163.8472 - val_loss: 1027.0883\n",
      "Epoch 6811/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 1163.8132 - val_loss: 1027.0532\n",
      "Epoch 6812/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 1163.7792 - val_loss: 1027.0183\n",
      "Epoch 6813/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 1163.7454 - val_loss: 1026.9834\n",
      "Epoch 6814/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 1163.7114 - val_loss: 1026.9485\n",
      "Epoch 6815/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 1163.6777 - val_loss: 1026.9137\n",
      "Epoch 6816/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 1163.6440 - val_loss: 1026.8790\n",
      "Epoch 6817/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 1163.6100 - val_loss: 1026.8441\n",
      "Epoch 6818/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 1163.5762 - val_loss: 1026.8094\n",
      "Epoch 6819/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1163.5425 - val_loss: 1026.7748\n",
      "Epoch 6820/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 1163.5089 - val_loss: 1026.7401\n",
      "Epoch 6821/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 1163.4753 - val_loss: 1026.7056\n",
      "Epoch 6822/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 1163.4417 - val_loss: 1026.6710\n",
      "Epoch 6823/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 1163.4081 - val_loss: 1026.6364\n",
      "Epoch 6824/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 1163.3745 - val_loss: 1026.6017\n",
      "Epoch 6825/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 1163.3412 - val_loss: 1026.5674\n",
      "Epoch 6826/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1163.3077 - val_loss: 1026.5328\n",
      "Epoch 6827/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 1163.2742 - val_loss: 1026.4984\n",
      "Epoch 6828/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 1163.2407 - val_loss: 1026.4641\n",
      "Epoch 6829/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 1163.2074 - val_loss: 1026.4298\n",
      "Epoch 6830/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1163.1740 - val_loss: 1026.3954\n",
      "Epoch 6831/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 1163.1406 - val_loss: 1026.3611\n",
      "Epoch 6832/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1163.1074 - val_loss: 1026.3269\n",
      "Epoch 6833/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1163.0742 - val_loss: 1026.2928\n",
      "Epoch 6834/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 1163.0409 - val_loss: 1026.2584\n",
      "Epoch 6835/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 1163.0077 - val_loss: 1026.2242\n",
      "Epoch 6836/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 1162.9746 - val_loss: 1026.1902\n",
      "Epoch 6837/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1162.9414 - val_loss: 1026.1561\n",
      "Epoch 6838/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 1162.9083 - val_loss: 1026.1222\n",
      "Epoch 6839/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 1162.8751 - val_loss: 1026.0880\n",
      "Epoch 6840/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1162.8422 - val_loss: 1026.0541\n",
      "Epoch 6841/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 1162.8093 - val_loss: 1026.0203\n",
      "Epoch 6842/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1162.7762 - val_loss: 1025.9862\n",
      "Epoch 6843/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 1162.7433 - val_loss: 1025.9523\n",
      "Epoch 6844/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1162.7102 - val_loss: 1025.9183\n",
      "Epoch 6845/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 1162.6776 - val_loss: 1025.8845\n",
      "Epoch 6846/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 1162.6447 - val_loss: 1025.8507\n",
      "Epoch 6847/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 1162.6118 - val_loss: 1025.8169\n",
      "Epoch 6848/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 1162.5790 - val_loss: 1025.7831\n",
      "Epoch 6849/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1162.5461 - val_loss: 1025.7494\n",
      "Epoch 6850/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1162.5135 - val_loss: 1025.7157\n",
      "Epoch 6851/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1162.4806 - val_loss: 1025.6820\n",
      "Epoch 6852/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 1162.4481 - val_loss: 1025.6483\n",
      "Epoch 6853/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 1162.4153 - val_loss: 1025.6149\n",
      "Epoch 6854/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 1162.3827 - val_loss: 1025.5812\n",
      "Epoch 6855/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 1162.3501 - val_loss: 1025.5475\n",
      "Epoch 6856/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1162.3174 - val_loss: 1025.5140\n",
      "Epoch 6857/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 1162.2847 - val_loss: 1025.4806\n",
      "Epoch 6858/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 1162.2522 - val_loss: 1025.4470\n",
      "Epoch 6859/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 1162.2198 - val_loss: 1025.4136\n",
      "Epoch 6860/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 1162.1871 - val_loss: 1025.3800\n",
      "Epoch 6861/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 1162.1548 - val_loss: 1025.3467\n",
      "Epoch 6862/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 1162.1223 - val_loss: 1025.3134\n",
      "Epoch 6863/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 1162.0897 - val_loss: 1025.2800\n",
      "Epoch 6864/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 1162.0574 - val_loss: 1025.2466\n",
      "Epoch 6865/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 1162.0250 - val_loss: 1025.2134\n",
      "Epoch 6866/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 1161.9926 - val_loss: 1025.1801\n",
      "Epoch 6867/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 1161.9602 - val_loss: 1025.1466\n",
      "Epoch 6868/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 1161.9279 - val_loss: 1025.1134\n",
      "Epoch 6869/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 1161.8956 - val_loss: 1025.0802\n",
      "Epoch 6870/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1161.8633 - val_loss: 1025.0470\n",
      "Epoch 6871/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 1161.8312 - val_loss: 1025.0139\n",
      "Epoch 6872/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1161.7988 - val_loss: 1024.9808\n",
      "Epoch 6873/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 1161.7665 - val_loss: 1024.9476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6874/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 1161.7343 - val_loss: 1024.9146\n",
      "Epoch 6875/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1161.7021 - val_loss: 1024.8812\n",
      "Epoch 6876/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 1161.6698 - val_loss: 1024.8483\n",
      "Epoch 6877/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 1161.6377 - val_loss: 1024.8152\n",
      "Epoch 6878/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 1161.6056 - val_loss: 1024.7821\n",
      "Epoch 6879/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 1161.5734 - val_loss: 1024.7490\n",
      "Epoch 6880/100000\n",
      "11/11 [==============================] - 0s 673us/step - loss: 1161.5411 - val_loss: 1024.7161\n",
      "Epoch 6881/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 1161.5093 - val_loss: 1024.6832\n",
      "Epoch 6882/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 1161.4772 - val_loss: 1024.6500\n",
      "Epoch 6883/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 1161.4448 - val_loss: 1024.6172\n",
      "Epoch 6884/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 1161.4130 - val_loss: 1024.5841\n",
      "Epoch 6885/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 1161.3810 - val_loss: 1024.5513\n",
      "Epoch 6886/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 1161.3488 - val_loss: 1024.5184\n",
      "Epoch 6887/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 1161.3167 - val_loss: 1024.4852\n",
      "Epoch 6888/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 1161.2847 - val_loss: 1024.4526\n",
      "Epoch 6889/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 1161.2526 - val_loss: 1024.4196\n",
      "Epoch 6890/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 1161.2206 - val_loss: 1024.3867\n",
      "Epoch 6891/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1161.1887 - val_loss: 1024.3539\n",
      "Epoch 6892/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 1161.1564 - val_loss: 1024.3209\n",
      "Epoch 6893/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 1161.1245 - val_loss: 1024.2880\n",
      "Epoch 6894/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1161.0925 - val_loss: 1024.2552\n",
      "Epoch 6895/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 1161.0605 - val_loss: 1024.2223\n",
      "Epoch 6896/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 1161.0286 - val_loss: 1024.1896\n",
      "Epoch 6897/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 1160.9966 - val_loss: 1024.1567\n",
      "Epoch 6898/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 1160.9645 - val_loss: 1024.1239\n",
      "Epoch 6899/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 1160.9325 - val_loss: 1024.0911\n",
      "Epoch 6900/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 1160.9005 - val_loss: 1024.0582\n",
      "Epoch 6901/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1160.8687 - val_loss: 1024.0254\n",
      "Epoch 6902/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1160.8365 - val_loss: 1023.9927\n",
      "Epoch 6903/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 1160.8047 - val_loss: 1023.9597\n",
      "Epoch 6904/100000\n",
      "11/11 [==============================] - 0s 670us/step - loss: 1160.7725 - val_loss: 1023.9268\n",
      "Epoch 6905/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 1160.7405 - val_loss: 1023.8941\n",
      "Epoch 6906/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 1160.7085 - val_loss: 1023.8611\n",
      "Epoch 6907/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 1160.6764 - val_loss: 1023.8284\n",
      "Epoch 6908/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 1160.6444 - val_loss: 1023.7953\n",
      "Epoch 6909/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 1160.6124 - val_loss: 1023.7626\n",
      "Epoch 6910/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1160.5802 - val_loss: 1023.7297\n",
      "Epoch 6911/100000\n",
      "11/11 [==============================] - 0s 632us/step - loss: 1160.5481 - val_loss: 1023.6969\n",
      "Epoch 6912/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 1160.5161 - val_loss: 1023.6639\n",
      "Epoch 6913/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 1160.4839 - val_loss: 1023.6309\n",
      "Epoch 6914/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 1160.4519 - val_loss: 1023.5982\n",
      "Epoch 6915/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 1160.4196 - val_loss: 1023.5652\n",
      "Epoch 6916/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 1160.3873 - val_loss: 1023.5320\n",
      "Epoch 6917/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 1160.3553 - val_loss: 1023.4991\n",
      "Epoch 6918/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1160.3228 - val_loss: 1023.4661\n",
      "Epoch 6919/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1160.2905 - val_loss: 1023.4330\n",
      "Epoch 6920/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 1160.2583 - val_loss: 1023.4000\n",
      "Epoch 6921/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 1160.2258 - val_loss: 1023.3669\n",
      "Epoch 6922/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1160.1935 - val_loss: 1023.3338\n",
      "Epoch 6923/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 1160.1613 - val_loss: 1023.3006\n",
      "Epoch 6924/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 1160.1288 - val_loss: 1023.2673\n",
      "Epoch 6925/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 1160.0962 - val_loss: 1023.2341\n",
      "Epoch 6926/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 1160.0634 - val_loss: 1023.2008\n",
      "Epoch 6927/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 1160.0310 - val_loss: 1023.1676\n",
      "Epoch 6928/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 1159.9983 - val_loss: 1023.1342\n",
      "Epoch 6929/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1159.9655 - val_loss: 1023.1006\n",
      "Epoch 6930/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 1159.9329 - val_loss: 1023.0673\n",
      "Epoch 6931/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 1159.9000 - val_loss: 1023.0338\n",
      "Epoch 6932/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 1159.8671 - val_loss: 1023.0002\n",
      "Epoch 6933/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1159.8341 - val_loss: 1022.9666\n",
      "Epoch 6934/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 1159.8011 - val_loss: 1022.9328\n",
      "Epoch 6935/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1159.7681 - val_loss: 1022.8992\n",
      "Epoch 6936/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 1159.7347 - val_loss: 1022.8654\n",
      "Epoch 6937/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1159.7017 - val_loss: 1022.8314\n",
      "Epoch 6938/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 1159.6682 - val_loss: 1022.7974\n",
      "Epoch 6939/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 1159.6348 - val_loss: 1022.7632\n",
      "Epoch 6940/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 1159.6013 - val_loss: 1022.7291\n",
      "Epoch 6941/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 1159.5679 - val_loss: 1022.6949\n",
      "Epoch 6942/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 1159.5341 - val_loss: 1022.6605\n",
      "Epoch 6943/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1159.5001 - val_loss: 1022.6262\n",
      "Epoch 6944/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 1159.4661 - val_loss: 1022.5916\n",
      "Epoch 6945/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 1159.4321 - val_loss: 1022.5570\n",
      "Epoch 6946/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 1159.3978 - val_loss: 1022.5223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6947/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1159.3636 - val_loss: 1022.4874\n",
      "Epoch 6948/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 1159.3292 - val_loss: 1022.4524\n",
      "Epoch 6949/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 1159.2946 - val_loss: 1022.4172\n",
      "Epoch 6950/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 1159.2599 - val_loss: 1022.3819\n",
      "Epoch 6951/100000\n",
      "11/11 [==============================] - 0s 204us/step - loss: 1159.2250 - val_loss: 1022.3465\n",
      "Epoch 6952/100000\n",
      "11/11 [==============================] - 0s 623us/step - loss: 1159.1899 - val_loss: 1022.3111\n",
      "Epoch 6953/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 1159.1547 - val_loss: 1022.2752\n",
      "Epoch 6954/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 1159.1193 - val_loss: 1022.2393\n",
      "Epoch 6955/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 1159.0839 - val_loss: 1022.2033\n",
      "Epoch 6956/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 1159.0477 - val_loss: 1022.1670\n",
      "Epoch 6957/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 1159.0118 - val_loss: 1022.1305\n",
      "Epoch 6958/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 1158.9757 - val_loss: 1022.0940\n",
      "Epoch 6959/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 1158.9395 - val_loss: 1022.0572\n",
      "Epoch 6960/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 1158.9028 - val_loss: 1022.0201\n",
      "Epoch 6961/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 1158.8657 - val_loss: 1021.9828\n",
      "Epoch 6962/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1158.8286 - val_loss: 1021.9453\n",
      "Epoch 6963/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 1158.7911 - val_loss: 1021.9075\n",
      "Epoch 6964/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 1158.7535 - val_loss: 1021.8695\n",
      "Epoch 6965/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 1158.7157 - val_loss: 1021.8312\n",
      "Epoch 6966/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 1158.6774 - val_loss: 1021.7925\n",
      "Epoch 6967/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 1158.6388 - val_loss: 1021.7535\n",
      "Epoch 6968/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1158.5997 - val_loss: 1021.7144\n",
      "Epoch 6969/100000\n",
      "11/11 [==============================] - 0s 647us/step - loss: 1158.5604 - val_loss: 1021.6749\n",
      "Epoch 6970/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 1158.5209 - val_loss: 1021.6349\n",
      "Epoch 6971/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1158.4808 - val_loss: 1021.5947\n",
      "Epoch 6972/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1158.4404 - val_loss: 1021.5539\n",
      "Epoch 6973/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1158.3995 - val_loss: 1021.5129\n",
      "Epoch 6974/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 1158.3583 - val_loss: 1021.4714\n",
      "Epoch 6975/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1158.3165 - val_loss: 1021.4296\n",
      "Epoch 6976/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 1158.2742 - val_loss: 1021.3871\n",
      "Epoch 6977/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 1158.2314 - val_loss: 1021.3443\n",
      "Epoch 6978/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 1158.1882 - val_loss: 1021.3011\n",
      "Epoch 6979/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 1158.1444 - val_loss: 1021.2571\n",
      "Epoch 6980/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1158.1000 - val_loss: 1021.2127\n",
      "Epoch 6981/100000\n",
      "11/11 [==============================] - 0s 615us/step - loss: 1158.0548 - val_loss: 1021.1676\n",
      "Epoch 6982/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1158.0093 - val_loss: 1021.1220\n",
      "Epoch 6983/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 1157.9630 - val_loss: 1021.0756\n",
      "Epoch 6984/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 1157.9159 - val_loss: 1021.0287\n",
      "Epoch 6985/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 1157.8680 - val_loss: 1020.9810\n",
      "Epoch 6986/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 1157.8195 - val_loss: 1020.9324\n",
      "Epoch 6987/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1157.7700 - val_loss: 1020.8832\n",
      "Epoch 6988/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 1157.7198 - val_loss: 1020.8333\n",
      "Epoch 6989/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 1157.6688 - val_loss: 1020.7823\n",
      "Epoch 6990/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 1157.6166 - val_loss: 1020.7305\n",
      "Epoch 6991/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 1157.5634 - val_loss: 1020.6777\n",
      "Epoch 6992/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 1157.5095 - val_loss: 1020.6240\n",
      "Epoch 6993/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 1157.4540 - val_loss: 1020.5691\n",
      "Epoch 6994/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1157.3977 - val_loss: 1020.5131\n",
      "Epoch 6995/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 1157.3402 - val_loss: 1020.4560\n",
      "Epoch 6996/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 1157.2814 - val_loss: 1020.3977\n",
      "Epoch 6997/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 1157.2211 - val_loss: 1020.3380\n",
      "Epoch 6998/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 1157.1594 - val_loss: 1020.2769\n",
      "Epoch 6999/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 1157.0962 - val_loss: 1020.2145\n",
      "Epoch 7000/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1157.0316 - val_loss: 1020.1505\n",
      "Epoch 7001/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 1156.9652 - val_loss: 1020.0849\n",
      "Epoch 7002/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 1156.8972 - val_loss: 1020.0176\n",
      "Epoch 7003/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1156.8273 - val_loss: 1019.9487\n",
      "Epoch 7004/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 1156.7555 - val_loss: 1019.8779\n",
      "Epoch 7005/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1156.6816 - val_loss: 1019.8051\n",
      "Epoch 7006/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 1156.6057 - val_loss: 1019.7301\n",
      "Epoch 7007/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1156.5275 - val_loss: 1019.6533\n",
      "Epoch 7008/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 1156.4471 - val_loss: 1019.5739\n",
      "Epoch 7009/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 1156.3641 - val_loss: 1019.4920\n",
      "Epoch 7010/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 1156.2784 - val_loss: 1019.4078\n",
      "Epoch 7011/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 1156.1899 - val_loss: 1019.3209\n",
      "Epoch 7012/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 1156.0988 - val_loss: 1019.2310\n",
      "Epoch 7013/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 1156.0044 - val_loss: 1019.1384\n",
      "Epoch 7014/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 1155.9069 - val_loss: 1019.0424\n",
      "Epoch 7015/100000\n",
      "11/11 [==============================] - 0s 610us/step - loss: 1155.8059 - val_loss: 1018.9434\n",
      "Epoch 7016/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 1155.7015 - val_loss: 1018.8408\n",
      "Epoch 7017/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 1155.5930 - val_loss: 1018.7346\n",
      "Epoch 7018/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 1155.4810 - val_loss: 1018.6244\n",
      "Epoch 7019/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 1155.3645 - val_loss: 1018.5102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7020/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 1155.2438 - val_loss: 1018.3917\n",
      "Epoch 7021/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 1155.1184 - val_loss: 1018.2690\n",
      "Epoch 7022/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 1154.9882 - val_loss: 1018.1412\n",
      "Epoch 7023/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 1154.8527 - val_loss: 1018.0086\n",
      "Epoch 7024/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 1154.7120 - val_loss: 1017.8707\n",
      "Epoch 7025/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 1154.5656 - val_loss: 1017.7273\n",
      "Epoch 7026/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 1154.4133 - val_loss: 1017.5782\n",
      "Epoch 7027/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1154.2545 - val_loss: 1017.4229\n",
      "Epoch 7028/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1154.0894 - val_loss: 1017.2612\n",
      "Epoch 7029/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 1153.9171 - val_loss: 1017.0928\n",
      "Epoch 7030/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1153.7378 - val_loss: 1016.9172\n",
      "Epoch 7031/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 1153.5508 - val_loss: 1016.7343\n",
      "Epoch 7032/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1153.3556 - val_loss: 1016.5437\n",
      "Epoch 7033/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 1153.1522 - val_loss: 1016.3449\n",
      "Epoch 7034/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 1152.9398 - val_loss: 1016.1375\n",
      "Epoch 7035/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1152.7181 - val_loss: 1015.9210\n",
      "Epoch 7036/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 1152.4869 - val_loss: 1015.6953\n",
      "Epoch 7037/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 1152.2456 - val_loss: 1015.4599\n",
      "Epoch 7038/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 1151.9937 - val_loss: 1015.2141\n",
      "Epoch 7039/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 1151.7306 - val_loss: 1014.9576\n",
      "Epoch 7040/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 1151.4559 - val_loss: 1014.6897\n",
      "Epoch 7041/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 1151.1692 - val_loss: 1014.4103\n",
      "Epoch 7042/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 1150.8700 - val_loss: 1014.1186\n",
      "Epoch 7043/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 1150.5574 - val_loss: 1013.8141\n",
      "Epoch 7044/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 1150.2310 - val_loss: 1013.4963\n",
      "Epoch 7045/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 1149.8901 - val_loss: 1013.1646\n",
      "Epoch 7046/100000\n",
      "11/11 [==============================] - 0s 629us/step - loss: 1149.5344 - val_loss: 1012.8183\n",
      "Epoch 7047/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 1149.1626 - val_loss: 1012.4565\n",
      "Epoch 7048/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 1148.7745 - val_loss: 1012.0790\n",
      "Epoch 7049/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 1148.3691 - val_loss: 1011.6846\n",
      "Epoch 7050/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 1147.9457 - val_loss: 1011.2729\n",
      "Epoch 7051/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 1147.5035 - val_loss: 1010.8428\n",
      "Epoch 7052/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 1147.0414 - val_loss: 1010.3936\n",
      "Epoch 7053/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 1146.5587 - val_loss: 1009.9244\n",
      "Epoch 7054/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 1146.0542 - val_loss: 1009.4340\n",
      "Epoch 7055/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 1145.5272 - val_loss: 1008.9217\n",
      "Epoch 7056/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 1144.9764 - val_loss: 1008.3865\n",
      "Epoch 7057/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 1144.4008 - val_loss: 1007.8272\n",
      "Epoch 7058/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 1143.7990 - val_loss: 1007.2426\n",
      "Epoch 7059/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 1143.1700 - val_loss: 1006.6315\n",
      "Epoch 7060/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 1142.5126 - val_loss: 1005.9927\n",
      "Epoch 7061/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 1141.8251 - val_loss: 1005.3248\n",
      "Epoch 7062/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 1141.1060 - val_loss: 1004.6266\n",
      "Epoch 7063/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 1140.3541 - val_loss: 1003.8963\n",
      "Epoch 7064/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 1139.5676 - val_loss: 1003.1324\n",
      "Epoch 7065/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 1138.7450 - val_loss: 1002.3336\n",
      "Epoch 7066/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 1137.8845 - val_loss: 1001.4983\n",
      "Epoch 7067/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1136.9844 - val_loss: 1000.6250\n",
      "Epoch 7068/100000\n",
      "11/11 [==============================] - 0s 672us/step - loss: 1136.0431 - val_loss: 999.7120\n",
      "Epoch 7069/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 1135.0590 - val_loss: 998.7580\n",
      "Epoch 7070/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 1134.0302 - val_loss: 997.7613\n",
      "Epoch 7071/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 1132.9552 - val_loss: 996.7207\n",
      "Epoch 7072/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 1131.8328 - val_loss: 995.6348\n",
      "Epoch 7073/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 1130.6610 - val_loss: 994.5023\n",
      "Epoch 7074/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 1129.4387 - val_loss: 993.3223\n",
      "Epoch 7075/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 1128.1646 - val_loss: 992.0936\n",
      "Epoch 7076/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 1126.8379 - val_loss: 990.8154\n",
      "Epoch 7077/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 1125.4572 - val_loss: 989.4872\n",
      "Epoch 7078/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 1124.0219 - val_loss: 988.1080\n",
      "Epoch 7079/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 1122.5310 - val_loss: 986.6776\n",
      "Epoch 7080/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 1120.9845 - val_loss: 985.1953\n",
      "Epoch 7081/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 1119.3813 - val_loss: 983.6613\n",
      "Epoch 7082/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 1117.7216 - val_loss: 982.0754\n",
      "Epoch 7083/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1116.0052 - val_loss: 980.4379\n",
      "Epoch 7084/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 1114.2322 - val_loss: 978.7490\n",
      "Epoch 7085/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 1112.4031 - val_loss: 977.0092\n",
      "Epoch 7086/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 1110.5181 - val_loss: 975.2191\n",
      "Epoch 7087/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 1108.5781 - val_loss: 973.3797\n",
      "Epoch 7088/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 1106.5841 - val_loss: 971.4921\n",
      "Epoch 7089/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 1104.5370 - val_loss: 969.5576\n",
      "Epoch 7090/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 1102.4380 - val_loss: 967.5772\n",
      "Epoch 7091/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 1100.2892 - val_loss: 965.5529\n",
      "Epoch 7092/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 1098.0914 - val_loss: 963.4863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7093/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 1095.8472 - val_loss: 961.3793\n",
      "Epoch 7094/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 1093.5585 - val_loss: 959.2338\n",
      "Epoch 7095/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 1091.2271 - val_loss: 957.0520\n",
      "Epoch 7096/100000\n",
      "11/11 [==============================] - 0s 654us/step - loss: 1088.8558 - val_loss: 954.8361\n",
      "Epoch 7097/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 1086.4467 - val_loss: 952.5885\n",
      "Epoch 7098/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 1084.0022 - val_loss: 950.3113\n",
      "Epoch 7099/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 1081.5253 - val_loss: 948.0071\n",
      "Epoch 7100/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 1079.0182 - val_loss: 945.6786\n",
      "Epoch 7101/100000\n",
      "11/11 [==============================] - 0s 678us/step - loss: 1076.4840 - val_loss: 943.3278\n",
      "Epoch 7102/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1073.9253 - val_loss: 940.9576\n",
      "Epoch 7103/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1071.3447 - val_loss: 938.5703\n",
      "Epoch 7104/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 1068.7450 - val_loss: 936.1684\n",
      "Epoch 7105/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 1066.1290 - val_loss: 933.7543\n",
      "Epoch 7106/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 1063.4996 - val_loss: 931.3303\n",
      "Epoch 7107/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 1060.8589 - val_loss: 928.8985\n",
      "Epoch 7108/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 1058.2098 - val_loss: 926.4615\n",
      "Epoch 7109/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 1055.5546 - val_loss: 924.0208\n",
      "Epoch 7110/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 1052.8955 - val_loss: 921.5789\n",
      "Epoch 7111/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 1050.2349 - val_loss: 919.1373\n",
      "Epoch 7112/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 1047.5747 - val_loss: 916.6978\n",
      "Epoch 7113/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 1044.9170 - val_loss: 914.2618\n",
      "Epoch 7114/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 1042.2632 - val_loss: 911.8310\n",
      "Epoch 7115/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 1039.6152 - val_loss: 909.4062\n",
      "Epoch 7116/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 1036.9747 - val_loss: 906.9895\n",
      "Epoch 7117/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 1034.3429 - val_loss: 904.5811\n",
      "Epoch 7118/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 1031.7211 - val_loss: 902.1827\n",
      "Epoch 7119/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 1029.1105 - val_loss: 899.7951\n",
      "Epoch 7120/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 1026.5121 - val_loss: 897.4189\n",
      "Epoch 7121/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 1023.9271 - val_loss: 895.0553\n",
      "Epoch 7122/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 1021.3565 - val_loss: 892.7049\n",
      "Epoch 7123/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 1018.8010 - val_loss: 890.3683\n",
      "Epoch 7124/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 1016.2614 - val_loss: 888.0461\n",
      "Epoch 7125/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 1013.7382 - val_loss: 885.7392\n",
      "Epoch 7126/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 1011.2325 - val_loss: 883.4478\n",
      "Epoch 7127/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 1008.7444 - val_loss: 881.1722\n",
      "Epoch 7128/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 1006.2745 - val_loss: 878.9133\n",
      "Epoch 7129/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 1003.8235 - val_loss: 876.6711\n",
      "Epoch 7130/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 1001.3915 - val_loss: 874.4460\n",
      "Epoch 7131/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 998.9789 - val_loss: 872.2383\n",
      "Epoch 7132/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 996.5861 - val_loss: 870.0484\n",
      "Epoch 7133/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 994.2133 - val_loss: 867.8762\n",
      "Epoch 7134/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 991.8604 - val_loss: 865.7221\n",
      "Epoch 7135/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 989.5280 - val_loss: 863.5863\n",
      "Epoch 7136/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 987.2161 - val_loss: 861.4688\n",
      "Epoch 7137/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 984.9250 - val_loss: 859.3701\n",
      "Epoch 7138/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 982.6549 - val_loss: 857.2900\n",
      "Epoch 7139/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 980.4057 - val_loss: 855.2286\n",
      "Epoch 7140/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 978.1776 - val_loss: 853.1860\n",
      "Epoch 7141/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 975.9706 - val_loss: 851.1619\n",
      "Epoch 7142/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 973.7845 - val_loss: 849.1567\n",
      "Epoch 7143/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 971.6198 - val_loss: 847.1703\n",
      "Epoch 7144/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 969.4761 - val_loss: 845.2024\n",
      "Epoch 7145/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 967.3533 - val_loss: 843.2533\n",
      "Epoch 7146/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 965.2516 - val_loss: 841.3227\n",
      "Epoch 7147/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 963.1709 - val_loss: 839.4107\n",
      "Epoch 7148/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 961.1108 - val_loss: 837.5176\n",
      "Epoch 7149/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 959.0719 - val_loss: 835.6431\n",
      "Epoch 7150/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 957.0535 - val_loss: 833.7873\n",
      "Epoch 7151/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 955.0557 - val_loss: 831.9496\n",
      "Epoch 7152/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 953.0786 - val_loss: 830.1308\n",
      "Epoch 7153/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 951.1219 - val_loss: 828.3303\n",
      "Epoch 7154/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 949.1854 - val_loss: 826.5479\n",
      "Epoch 7155/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 947.2690 - val_loss: 824.7841\n",
      "Epoch 7156/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 945.3725 - val_loss: 823.0380\n",
      "Epoch 7157/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 943.4960 - val_loss: 821.3098\n",
      "Epoch 7158/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 941.6391 - val_loss: 819.5995\n",
      "Epoch 7159/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 939.8018 - val_loss: 817.9068\n",
      "Epoch 7160/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 937.9840 - val_loss: 816.2314\n",
      "Epoch 7161/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 936.1850 - val_loss: 814.5737\n",
      "Epoch 7162/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 934.4053 - val_loss: 812.9326\n",
      "Epoch 7163/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 932.6443 - val_loss: 811.3086\n",
      "Epoch 7164/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 930.9022 - val_loss: 809.7014\n",
      "Epoch 7165/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 929.1785 - val_loss: 808.1109\n",
      "Epoch 7166/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 927.4731 - val_loss: 806.5369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7167/100000\n",
      "11/11 [==============================] - 0s 658us/step - loss: 925.7856 - val_loss: 804.9791\n",
      "Epoch 7168/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 924.1164 - val_loss: 803.4379\n",
      "Epoch 7169/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 922.4647 - val_loss: 801.9125\n",
      "Epoch 7170/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 920.8305 - val_loss: 800.4033\n",
      "Epoch 7171/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 919.2138 - val_loss: 798.9097\n",
      "Epoch 7172/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 917.6142 - val_loss: 797.4316\n",
      "Epoch 7173/100000\n",
      "11/11 [==============================] - 0s 608us/step - loss: 916.0314 - val_loss: 795.9694\n",
      "Epoch 7174/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 914.4656 - val_loss: 794.5222\n",
      "Epoch 7175/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 912.9162 - val_loss: 793.0902\n",
      "Epoch 7176/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 911.3832 - val_loss: 791.6729\n",
      "Epoch 7177/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 909.8663 - val_loss: 790.2703\n",
      "Epoch 7178/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 908.3655 - val_loss: 788.8822\n",
      "Epoch 7179/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 906.8803 - val_loss: 787.5084\n",
      "Epoch 7180/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 905.4109 - val_loss: 786.1487\n",
      "Epoch 7181/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 903.9566 - val_loss: 784.8030\n",
      "Epoch 7182/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 902.5175 - val_loss: 783.4713\n",
      "Epoch 7183/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 901.0934 - val_loss: 782.1531\n",
      "Epoch 7184/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 899.6843 - val_loss: 780.8480\n",
      "Epoch 7185/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 898.2895 - val_loss: 779.5566\n",
      "Epoch 7186/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 896.9092 - val_loss: 778.2781\n",
      "Epoch 7187/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 895.5430 - val_loss: 777.0128\n",
      "Epoch 7188/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 894.1908 - val_loss: 775.7603\n",
      "Epoch 7189/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 892.8525 - val_loss: 774.5203\n",
      "Epoch 7190/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 891.5277 - val_loss: 773.2928\n",
      "Epoch 7191/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 890.2162 - val_loss: 772.0776\n",
      "Epoch 7192/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 888.9182 - val_loss: 770.8744\n",
      "Epoch 7193/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 887.6331 - val_loss: 769.6833\n",
      "Epoch 7194/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 886.3608 - val_loss: 768.5037\n",
      "Epoch 7195/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 885.1012 - val_loss: 767.3359\n",
      "Epoch 7196/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 883.8542 - val_loss: 766.1794\n",
      "Epoch 7197/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 882.6194 - val_loss: 765.0342\n",
      "Epoch 7198/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 881.3967 - val_loss: 763.9000\n",
      "Epoch 7199/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 880.1860 - val_loss: 762.7767\n",
      "Epoch 7200/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 878.9871 - val_loss: 761.6643\n",
      "Epoch 7201/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 877.7996 - val_loss: 760.5625\n",
      "Epoch 7202/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 876.6237 - val_loss: 759.4711\n",
      "Epoch 7203/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 875.4590 - val_loss: 758.3902\n",
      "Epoch 7204/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 874.3054 - val_loss: 757.3193\n",
      "Epoch 7205/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 873.1627 - val_loss: 756.2585\n",
      "Epoch 7206/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 872.0308 - val_loss: 755.2076\n",
      "Epoch 7207/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 870.9096 - val_loss: 754.1666\n",
      "Epoch 7208/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 869.7986 - val_loss: 753.1349\n",
      "Epoch 7209/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 868.6982 - val_loss: 752.1129\n",
      "Epoch 7210/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 867.6077 - val_loss: 751.0999\n",
      "Epoch 7211/100000\n",
      "11/11 [==============================] - 0s 639us/step - loss: 866.5272 - val_loss: 750.0963\n",
      "Epoch 7212/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 865.4564 - val_loss: 749.1016\n",
      "Epoch 7213/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 864.3954 - val_loss: 748.1157\n",
      "Epoch 7214/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 863.3439 - val_loss: 747.1386\n",
      "Epoch 7215/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 862.3017 - val_loss: 746.1700\n",
      "Epoch 7216/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 861.2688 - val_loss: 745.2101\n",
      "Epoch 7217/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 860.2451 - val_loss: 744.2585\n",
      "Epoch 7218/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 859.2304 - val_loss: 743.3151\n",
      "Epoch 7219/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 858.2242 - val_loss: 742.3798\n",
      "Epoch 7220/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 857.2269 - val_loss: 741.4524\n",
      "Epoch 7221/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 856.2381 - val_loss: 740.5331\n",
      "Epoch 7222/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 855.2578 - val_loss: 739.6215\n",
      "Epoch 7223/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 854.2858 - val_loss: 738.7173\n",
      "Epoch 7224/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 853.3218 - val_loss: 737.8209\n",
      "Epoch 7225/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 852.3660 - val_loss: 736.9317\n",
      "Epoch 7226/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 851.4180 - val_loss: 736.0499\n",
      "Epoch 7227/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 850.4779 - val_loss: 735.1752\n",
      "Epoch 7228/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 849.5453 - val_loss: 734.3075\n",
      "Epoch 7229/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 848.6204 - val_loss: 733.4468\n",
      "Epoch 7230/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 847.7029 - val_loss: 732.5930\n",
      "Epoch 7231/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 846.7927 - val_loss: 731.7460\n",
      "Epoch 7232/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 845.8898 - val_loss: 730.9055\n",
      "Epoch 7233/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 844.9940 - val_loss: 730.0717\n",
      "Epoch 7234/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 844.1051 - val_loss: 729.2443\n",
      "Epoch 7235/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 843.2233 - val_loss: 728.4232\n",
      "Epoch 7236/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 842.3482 - val_loss: 727.6084\n",
      "Epoch 7237/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 841.4797 - val_loss: 726.7997\n",
      "Epoch 7238/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 840.6179 - val_loss: 725.9972\n",
      "Epoch 7239/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 839.7625 - val_loss: 725.2006\n",
      "Epoch 7240/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 838.9135 - val_loss: 724.4099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7241/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 838.0709 - val_loss: 723.6251\n",
      "Epoch 7242/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 837.2344 - val_loss: 722.8460\n",
      "Epoch 7243/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 836.4039 - val_loss: 722.0724\n",
      "Epoch 7244/100000\n",
      "11/11 [==============================] - 0s 750us/step - loss: 835.5797 - val_loss: 721.3046\n",
      "Epoch 7245/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 834.7614 - val_loss: 720.5421\n",
      "Epoch 7246/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 833.9488 - val_loss: 719.7851\n",
      "Epoch 7247/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 833.1420 - val_loss: 719.0332\n",
      "Epoch 7248/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 832.3408 - val_loss: 718.2866\n",
      "Epoch 7249/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 831.5453 - val_loss: 717.5453\n",
      "Epoch 7250/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 830.7553 - val_loss: 716.8090\n",
      "Epoch 7251/100000\n",
      "11/11 [==============================] - 0s 623us/step - loss: 829.9705 - val_loss: 716.0778\n",
      "Epoch 7252/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 829.1915 - val_loss: 715.3513\n",
      "Epoch 7253/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 828.4174 - val_loss: 714.6299\n",
      "Epoch 7254/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 827.6486 - val_loss: 713.9132\n",
      "Epoch 7255/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 826.8849 - val_loss: 713.2012\n",
      "Epoch 7256/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 826.1265 - val_loss: 712.4940\n",
      "Epoch 7257/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 825.3727 - val_loss: 711.7912\n",
      "Epoch 7258/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 824.6240 - val_loss: 711.0930\n",
      "Epoch 7259/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 823.8801 - val_loss: 710.3994\n",
      "Epoch 7260/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 823.1410 - val_loss: 709.7099\n",
      "Epoch 7261/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 822.4065 - val_loss: 709.0249\n",
      "Epoch 7262/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 821.6767 - val_loss: 708.3441\n",
      "Epoch 7263/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 820.9514 - val_loss: 707.6677\n",
      "Epoch 7264/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 820.2307 - val_loss: 706.9954\n",
      "Epoch 7265/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 819.5142 - val_loss: 706.3271\n",
      "Epoch 7266/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 818.8023 - val_loss: 705.6630\n",
      "Epoch 7267/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 818.0948 - val_loss: 705.0027\n",
      "Epoch 7268/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 817.3914 - val_loss: 704.3464\n",
      "Epoch 7269/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 816.6922 - val_loss: 703.6941\n",
      "Epoch 7270/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 815.9971 - val_loss: 703.0455\n",
      "Epoch 7271/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 815.3062 - val_loss: 702.4006\n",
      "Epoch 7272/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 814.6191 - val_loss: 701.7597\n",
      "Epoch 7273/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 813.9363 - val_loss: 701.1221\n",
      "Epoch 7274/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 813.2573 - val_loss: 700.4885\n",
      "Epoch 7275/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 812.5820 - val_loss: 699.8583\n",
      "Epoch 7276/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 811.9107 - val_loss: 699.2316\n",
      "Epoch 7277/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 811.2430 - val_loss: 698.6083\n",
      "Epoch 7278/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 810.5791 - val_loss: 697.9888\n",
      "Epoch 7279/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 809.9190 - val_loss: 697.3723\n",
      "Epoch 7280/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 809.2623 - val_loss: 696.7592\n",
      "Epoch 7281/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 808.6093 - val_loss: 696.1495\n",
      "Epoch 7282/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 807.9596 - val_loss: 695.5431\n",
      "Epoch 7283/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 807.3137 - val_loss: 694.9398\n",
      "Epoch 7284/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 806.6709 - val_loss: 694.3398\n",
      "Epoch 7285/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 806.0319 - val_loss: 693.7427\n",
      "Epoch 7286/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 805.3959 - val_loss: 693.1490\n",
      "Epoch 7287/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 804.7631 - val_loss: 692.5582\n",
      "Epoch 7288/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 804.1338 - val_loss: 691.9705\n",
      "Epoch 7289/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 803.5078 - val_loss: 691.3855\n",
      "Epoch 7290/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 802.8846 - val_loss: 690.8037\n",
      "Epoch 7291/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 802.2649 - val_loss: 690.2247\n",
      "Epoch 7292/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 801.6481 - val_loss: 689.6486\n",
      "Epoch 7293/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 801.0342 - val_loss: 689.0754\n",
      "Epoch 7294/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 800.4236 - val_loss: 688.5048\n",
      "Epoch 7295/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 799.8160 - val_loss: 687.9371\n",
      "Epoch 7296/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 799.2112 - val_loss: 687.3721\n",
      "Epoch 7297/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 798.6092 - val_loss: 686.8099\n",
      "Epoch 7298/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 798.0103 - val_loss: 686.2500\n",
      "Epoch 7299/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 797.4140 - val_loss: 685.6931\n",
      "Epoch 7300/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 796.8207 - val_loss: 685.1387\n",
      "Epoch 7301/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 796.2301 - val_loss: 684.5869\n",
      "Epoch 7302/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 795.6422 - val_loss: 684.0374\n",
      "Epoch 7303/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 795.0570 - val_loss: 683.4907\n",
      "Epoch 7304/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 794.4745 - val_loss: 682.9463\n",
      "Epoch 7305/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 793.8947 - val_loss: 682.4043\n",
      "Epoch 7306/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 793.3173 - val_loss: 681.8648\n",
      "Epoch 7307/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 792.7424 - val_loss: 681.3277\n",
      "Epoch 7308/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 792.1703 - val_loss: 680.7929\n",
      "Epoch 7309/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 791.6006 - val_loss: 680.2604\n",
      "Epoch 7310/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 791.0334 - val_loss: 679.7303\n",
      "Epoch 7311/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 790.4688 - val_loss: 679.2025\n",
      "Epoch 7312/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 789.9062 - val_loss: 678.6769\n",
      "Epoch 7313/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 789.3465 - val_loss: 678.1534\n",
      "Epoch 7314/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 788.7888 - val_loss: 677.6323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7315/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 788.2336 - val_loss: 677.1132\n",
      "Epoch 7316/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 787.6807 - val_loss: 676.5964\n",
      "Epoch 7317/100000\n",
      "11/11 [==============================] - 0s 581us/step - loss: 787.1301 - val_loss: 676.0817\n",
      "Epoch 7318/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 786.5816 - val_loss: 675.5690\n",
      "Epoch 7319/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 786.0355 - val_loss: 675.0583\n",
      "Epoch 7320/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 785.4916 - val_loss: 674.5500\n",
      "Epoch 7321/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 784.9498 - val_loss: 674.0435\n",
      "Epoch 7322/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 784.4103 - val_loss: 673.5390\n",
      "Epoch 7323/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 783.8729 - val_loss: 673.0365\n",
      "Epoch 7324/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 783.3373 - val_loss: 672.5359\n",
      "Epoch 7325/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 782.8043 - val_loss: 672.0374\n",
      "Epoch 7326/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 782.2730 - val_loss: 671.5408\n",
      "Epoch 7327/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 781.7438 - val_loss: 671.0460\n",
      "Epoch 7328/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 781.2168 - val_loss: 670.5530\n",
      "Epoch 7329/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 780.6918 - val_loss: 670.0623\n",
      "Epoch 7330/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 780.1686 - val_loss: 669.5731\n",
      "Epoch 7331/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 779.6475 - val_loss: 669.0857\n",
      "Epoch 7332/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 779.1282 - val_loss: 668.6002\n",
      "Epoch 7333/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 778.6109 - val_loss: 668.1164\n",
      "Epoch 7334/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 778.0955 - val_loss: 667.6344\n",
      "Epoch 7335/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 777.5818 - val_loss: 667.1543\n",
      "Epoch 7336/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 777.0703 - val_loss: 666.6756\n",
      "Epoch 7337/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 776.5605 - val_loss: 666.1989\n",
      "Epoch 7338/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 776.0523 - val_loss: 665.7238\n",
      "Epoch 7339/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 775.5463 - val_loss: 665.2504\n",
      "Epoch 7340/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 775.0418 - val_loss: 664.7786\n",
      "Epoch 7341/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 774.5391 - val_loss: 664.3085\n",
      "Epoch 7342/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 774.0381 - val_loss: 663.8399\n",
      "Epoch 7343/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 773.5389 - val_loss: 663.3730\n",
      "Epoch 7344/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 773.0414 - val_loss: 662.9077\n",
      "Epoch 7345/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 772.5455 - val_loss: 662.4440\n",
      "Epoch 7346/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 772.0515 - val_loss: 661.9819\n",
      "Epoch 7347/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 771.5588 - val_loss: 661.5212\n",
      "Epoch 7348/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 771.0682 - val_loss: 661.0621\n",
      "Epoch 7349/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 770.5790 - val_loss: 660.6046\n",
      "Epoch 7350/100000\n",
      "11/11 [==============================] - 0s 201us/step - loss: 770.0914 - val_loss: 660.1486\n",
      "Epoch 7351/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 769.6053 - val_loss: 659.6940\n",
      "Epoch 7352/100000\n",
      "11/11 [==============================] - 0s 190us/step - loss: 769.1209 - val_loss: 659.2410\n",
      "Epoch 7353/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 768.6381 - val_loss: 658.7892\n",
      "Epoch 7354/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 768.1568 - val_loss: 658.3392\n",
      "Epoch 7355/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 767.6770 - val_loss: 657.8904\n",
      "Epoch 7356/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 767.1988 - val_loss: 657.4431\n",
      "Epoch 7357/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 766.7219 - val_loss: 656.9971\n",
      "Epoch 7358/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 766.2467 - val_loss: 656.5526\n",
      "Epoch 7359/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 765.7727 - val_loss: 656.1094\n",
      "Epoch 7360/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 765.3006 - val_loss: 655.6677\n",
      "Epoch 7361/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 764.8297 - val_loss: 655.2272\n",
      "Epoch 7362/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 764.3603 - val_loss: 654.7881\n",
      "Epoch 7363/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 763.8922 - val_loss: 654.3503\n",
      "Epoch 7364/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 763.4256 - val_loss: 653.9138\n",
      "Epoch 7365/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 762.9602 - val_loss: 653.4786\n",
      "Epoch 7366/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 762.4965 - val_loss: 653.0447\n",
      "Epoch 7367/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 762.0338 - val_loss: 652.6121\n",
      "Epoch 7368/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 761.5727 - val_loss: 652.1807\n",
      "Epoch 7369/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 761.1129 - val_loss: 651.7505\n",
      "Epoch 7370/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 760.6544 - val_loss: 651.3217\n",
      "Epoch 7371/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 760.1973 - val_loss: 650.8943\n",
      "Epoch 7372/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 759.7414 - val_loss: 650.4678\n",
      "Epoch 7373/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 759.2869 - val_loss: 650.0428\n",
      "Epoch 7374/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 758.8337 - val_loss: 649.6188\n",
      "Epoch 7375/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 758.3817 - val_loss: 649.1960\n",
      "Epoch 7376/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 757.9310 - val_loss: 648.7744\n",
      "Epoch 7377/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 757.4815 - val_loss: 648.3541\n",
      "Epoch 7378/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 757.0334 - val_loss: 647.9348\n",
      "Epoch 7379/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 756.5864 - val_loss: 647.5168\n",
      "Epoch 7380/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 756.1406 - val_loss: 647.0997\n",
      "Epoch 7381/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 755.6960 - val_loss: 646.6840\n",
      "Epoch 7382/100000\n",
      "11/11 [==============================] - 0s 633us/step - loss: 755.2526 - val_loss: 646.2693\n",
      "Epoch 7383/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 754.8105 - val_loss: 645.8557\n",
      "Epoch 7384/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 754.3695 - val_loss: 645.4433\n",
      "Epoch 7385/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 753.9297 - val_loss: 645.0320\n",
      "Epoch 7386/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 753.4910 - val_loss: 644.6215\n",
      "Epoch 7387/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 753.0535 - val_loss: 644.2124\n",
      "Epoch 7388/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 752.6170 - val_loss: 643.8043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7389/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 752.1818 - val_loss: 643.3972\n",
      "Epoch 7390/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 751.7475 - val_loss: 642.9911\n",
      "Epoch 7391/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 751.3146 - val_loss: 642.5860\n",
      "Epoch 7392/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 750.8826 - val_loss: 642.1821\n",
      "Epoch 7393/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 750.4517 - val_loss: 641.7792\n",
      "Epoch 7394/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 750.0220 - val_loss: 641.3772\n",
      "Epoch 7395/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 749.5934 - val_loss: 640.9764\n",
      "Epoch 7396/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 749.1658 - val_loss: 640.5764\n",
      "Epoch 7397/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 748.7393 - val_loss: 640.1775\n",
      "Epoch 7398/100000\n",
      "11/11 [==============================] - 0s 654us/step - loss: 748.3137 - val_loss: 639.7796\n",
      "Epoch 7399/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 747.8890 - val_loss: 639.3826\n",
      "Epoch 7400/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 747.4656 - val_loss: 638.9866\n",
      "Epoch 7401/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 747.0432 - val_loss: 638.5916\n",
      "Epoch 7402/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 746.6218 - val_loss: 638.1976\n",
      "Epoch 7403/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 746.2014 - val_loss: 637.8044\n",
      "Epoch 7404/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 745.7820 - val_loss: 637.4122\n",
      "Epoch 7405/100000\n",
      "11/11 [==============================] - 0s 588us/step - loss: 745.3636 - val_loss: 637.0209\n",
      "Epoch 7406/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 744.9461 - val_loss: 636.6306\n",
      "Epoch 7407/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 744.5297 - val_loss: 636.2412\n",
      "Epoch 7408/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 744.1142 - val_loss: 635.8528\n",
      "Epoch 7409/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 743.6998 - val_loss: 635.4652\n",
      "Epoch 7410/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 743.2861 - val_loss: 635.0785\n",
      "Epoch 7411/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 742.8735 - val_loss: 634.6926\n",
      "Epoch 7412/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 742.4619 - val_loss: 634.3077\n",
      "Epoch 7413/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 742.0510 - val_loss: 633.9238\n",
      "Epoch 7414/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 741.6412 - val_loss: 633.5406\n",
      "Epoch 7415/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 741.2324 - val_loss: 633.1583\n",
      "Epoch 7416/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 740.8244 - val_loss: 632.7769\n",
      "Epoch 7417/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 740.4173 - val_loss: 632.3964\n",
      "Epoch 7418/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 740.0112 - val_loss: 632.0165\n",
      "Epoch 7419/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 739.6058 - val_loss: 631.6376\n",
      "Epoch 7420/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 739.2014 - val_loss: 631.2596\n",
      "Epoch 7421/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 738.7978 - val_loss: 630.8823\n",
      "Epoch 7422/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 738.3952 - val_loss: 630.5060\n",
      "Epoch 7423/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 737.9934 - val_loss: 630.1304\n",
      "Epoch 7424/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 737.5924 - val_loss: 629.7556\n",
      "Epoch 7425/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 737.1925 - val_loss: 629.3816\n",
      "Epoch 7426/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 736.7930 - val_loss: 629.0085\n",
      "Epoch 7427/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 736.3946 - val_loss: 628.6360\n",
      "Epoch 7428/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 735.9970 - val_loss: 628.2645\n",
      "Epoch 7429/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 735.6003 - val_loss: 627.8936\n",
      "Epoch 7430/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 735.2045 - val_loss: 627.5236\n",
      "Epoch 7431/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 734.8095 - val_loss: 627.1545\n",
      "Epoch 7432/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 734.4150 - val_loss: 626.7859\n",
      "Epoch 7433/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 734.0217 - val_loss: 626.4182\n",
      "Epoch 7434/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 733.6290 - val_loss: 626.0512\n",
      "Epoch 7435/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 733.2371 - val_loss: 625.6851\n",
      "Epoch 7436/100000\n",
      "11/11 [==============================] - 0s 608us/step - loss: 732.8459 - val_loss: 625.3195\n",
      "Epoch 7437/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 732.4556 - val_loss: 624.9548\n",
      "Epoch 7438/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 732.0662 - val_loss: 624.5908\n",
      "Epoch 7439/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 731.6774 - val_loss: 624.2275\n",
      "Epoch 7440/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 731.2893 - val_loss: 623.8651\n",
      "Epoch 7441/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 730.9022 - val_loss: 623.5031\n",
      "Epoch 7442/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 730.5157 - val_loss: 623.1422\n",
      "Epoch 7443/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 730.1299 - val_loss: 622.7818\n",
      "Epoch 7444/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 729.7451 - val_loss: 622.4221\n",
      "Epoch 7445/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 729.3608 - val_loss: 622.0631\n",
      "Epoch 7446/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 728.9772 - val_loss: 621.7048\n",
      "Epoch 7447/100000\n",
      "11/11 [==============================] - 0s 591us/step - loss: 728.5944 - val_loss: 621.3473\n",
      "Epoch 7448/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 728.2124 - val_loss: 620.9904\n",
      "Epoch 7449/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 727.8311 - val_loss: 620.6342\n",
      "Epoch 7450/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 727.4506 - val_loss: 620.2787\n",
      "Epoch 7451/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 727.0707 - val_loss: 619.9239\n",
      "Epoch 7452/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 726.6914 - val_loss: 619.5698\n",
      "Epoch 7453/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 726.3131 - val_loss: 619.2162\n",
      "Epoch 7454/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 725.9352 - val_loss: 618.8635\n",
      "Epoch 7455/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 725.5583 - val_loss: 618.5112\n",
      "Epoch 7456/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 725.1817 - val_loss: 618.1598\n",
      "Epoch 7457/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 724.8061 - val_loss: 617.8088\n",
      "Epoch 7458/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 724.4311 - val_loss: 617.4587\n",
      "Epoch 7459/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 724.0568 - val_loss: 617.1091\n",
      "Epoch 7460/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 723.6832 - val_loss: 616.7601\n",
      "Epoch 7461/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 723.3101 - val_loss: 616.4119\n",
      "Epoch 7462/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 722.9377 - val_loss: 616.0642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7463/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 722.5660 - val_loss: 615.7172\n",
      "Epoch 7464/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 722.1949 - val_loss: 615.3708\n",
      "Epoch 7465/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 721.8248 - val_loss: 615.0250\n",
      "Epoch 7466/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 721.4550 - val_loss: 614.6799\n",
      "Epoch 7467/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 721.0859 - val_loss: 614.3353\n",
      "Epoch 7468/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 720.7173 - val_loss: 613.9915\n",
      "Epoch 7469/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 720.3497 - val_loss: 613.6480\n",
      "Epoch 7470/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 719.9825 - val_loss: 613.3052\n",
      "Epoch 7471/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 719.6160 - val_loss: 612.9631\n",
      "Epoch 7472/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 719.2499 - val_loss: 612.6215\n",
      "Epoch 7473/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 718.8847 - val_loss: 612.2808\n",
      "Epoch 7474/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 718.5201 - val_loss: 611.9404\n",
      "Epoch 7475/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 718.1560 - val_loss: 611.6006\n",
      "Epoch 7476/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 717.7924 - val_loss: 611.2614\n",
      "Epoch 7477/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 717.4296 - val_loss: 610.9229\n",
      "Epoch 7478/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 717.0674 - val_loss: 610.5848\n",
      "Epoch 7479/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 716.7057 - val_loss: 610.2473\n",
      "Epoch 7480/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 716.3447 - val_loss: 609.9105\n",
      "Epoch 7481/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 715.9843 - val_loss: 609.5741\n",
      "Epoch 7482/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 715.6244 - val_loss: 609.2382\n",
      "Epoch 7483/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 715.2651 - val_loss: 608.9031\n",
      "Epoch 7484/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 714.9064 - val_loss: 608.5685\n",
      "Epoch 7485/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 714.5483 - val_loss: 608.2344\n",
      "Epoch 7486/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 714.1907 - val_loss: 607.9009\n",
      "Epoch 7487/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 713.8337 - val_loss: 607.5679\n",
      "Epoch 7488/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 713.4772 - val_loss: 607.2355\n",
      "Epoch 7489/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 713.1215 - val_loss: 606.9034\n",
      "Epoch 7490/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 712.7662 - val_loss: 606.5723\n",
      "Epoch 7491/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 712.4115 - val_loss: 606.2413\n",
      "Epoch 7492/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 712.0573 - val_loss: 605.9112\n",
      "Epoch 7493/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 711.7037 - val_loss: 605.5812\n",
      "Epoch 7494/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 711.3506 - val_loss: 605.2522\n",
      "Epoch 7495/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 710.9981 - val_loss: 604.9233\n",
      "Epoch 7496/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 710.6462 - val_loss: 604.5953\n",
      "Epoch 7497/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 710.2946 - val_loss: 604.2675\n",
      "Epoch 7498/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 709.9436 - val_loss: 603.9404\n",
      "Epoch 7499/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 709.5933 - val_loss: 603.6137\n",
      "Epoch 7500/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 709.2434 - val_loss: 603.2874\n",
      "Epoch 7501/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 708.8940 - val_loss: 602.9620\n",
      "Epoch 7502/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 708.5454 - val_loss: 602.6368\n",
      "Epoch 7503/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 708.1972 - val_loss: 602.3121\n",
      "Epoch 7504/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 707.8493 - val_loss: 601.9879\n",
      "Epoch 7505/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 707.5021 - val_loss: 601.6644\n",
      "Epoch 7506/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 707.1553 - val_loss: 601.3412\n",
      "Epoch 7507/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 706.8091 - val_loss: 601.0186\n",
      "Epoch 7508/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 706.4634 - val_loss: 600.6965\n",
      "Epoch 7509/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 706.1183 - val_loss: 600.3749\n",
      "Epoch 7510/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 705.7735 - val_loss: 600.0536\n",
      "Epoch 7511/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 705.4293 - val_loss: 599.7330\n",
      "Epoch 7512/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 705.0856 - val_loss: 599.4128\n",
      "Epoch 7513/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 704.7425 - val_loss: 599.0930\n",
      "Epoch 7514/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 704.3998 - val_loss: 598.7738\n",
      "Epoch 7515/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 704.0575 - val_loss: 598.4550\n",
      "Epoch 7516/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 703.7158 - val_loss: 598.1367\n",
      "Epoch 7517/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 703.3746 - val_loss: 597.8188\n",
      "Epoch 7518/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 703.0336 - val_loss: 597.5015\n",
      "Epoch 7519/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 702.6933 - val_loss: 597.1845\n",
      "Epoch 7520/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 702.3536 - val_loss: 596.8683\n",
      "Epoch 7521/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 702.0142 - val_loss: 596.5519\n",
      "Epoch 7522/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 701.6752 - val_loss: 596.2369\n",
      "Epoch 7523/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 701.3369 - val_loss: 595.9213\n",
      "Epoch 7524/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 700.9990 - val_loss: 595.6072\n",
      "Epoch 7525/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 700.6614 - val_loss: 595.2922\n",
      "Epoch 7526/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 700.3245 - val_loss: 594.9794\n",
      "Epoch 7527/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 699.9879 - val_loss: 594.6653\n",
      "Epoch 7528/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 699.6518 - val_loss: 594.3533\n",
      "Epoch 7529/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 699.3160 - val_loss: 594.0399\n",
      "Epoch 7530/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 698.9809 - val_loss: 593.7291\n",
      "Epoch 7531/100000\n",
      "11/11 [==============================] - 0s 589us/step - loss: 698.6462 - val_loss: 593.4163\n",
      "Epoch 7532/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 698.3119 - val_loss: 593.1068\n",
      "Epoch 7533/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 697.9781 - val_loss: 592.7943\n",
      "Epoch 7534/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 697.6447 - val_loss: 592.4862\n",
      "Epoch 7535/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 697.3115 - val_loss: 592.1738\n",
      "Epoch 7536/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 696.9791 - val_loss: 591.8674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7537/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 696.6470 - val_loss: 591.5549\n",
      "Epoch 7538/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 696.3153 - val_loss: 591.2509\n",
      "Epoch 7539/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 695.9841 - val_loss: 590.9374\n",
      "Epoch 7540/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 695.6534 - val_loss: 590.6364\n",
      "Epoch 7541/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 695.3229 - val_loss: 590.3210\n",
      "Epoch 7542/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 694.9930 - val_loss: 590.0237\n",
      "Epoch 7543/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 694.6635 - val_loss: 589.7066\n",
      "Epoch 7544/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 694.3345 - val_loss: 589.4119\n",
      "Epoch 7545/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 694.0057 - val_loss: 589.0953\n",
      "Epoch 7546/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 693.6775 - val_loss: 588.7997\n",
      "Epoch 7547/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 693.3497 - val_loss: 588.4880\n",
      "Epoch 7548/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 693.0222 - val_loss: 588.1871\n",
      "Epoch 7549/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 692.6953 - val_loss: 587.8834\n",
      "Epoch 7550/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 692.3686 - val_loss: 587.5761\n",
      "Epoch 7551/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 692.0424 - val_loss: 587.2790\n",
      "Epoch 7552/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 691.7166 - val_loss: 586.9691\n",
      "Epoch 7553/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 691.3912 - val_loss: 586.6736\n",
      "Epoch 7554/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 691.0662 - val_loss: 586.3665\n",
      "Epoch 7555/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 690.7416 - val_loss: 586.0676\n",
      "Epoch 7556/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 690.4174 - val_loss: 585.7664\n",
      "Epoch 7557/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 690.0937 - val_loss: 585.4631\n",
      "Epoch 7558/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 689.7703 - val_loss: 585.1668\n",
      "Epoch 7559/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 689.4473 - val_loss: 584.8619\n",
      "Epoch 7560/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 689.1247 - val_loss: 584.5671\n",
      "Epoch 7561/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 688.8025 - val_loss: 584.2641\n",
      "Epoch 7562/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 688.4805 - val_loss: 583.9670\n",
      "Epoch 7563/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 688.1590 - val_loss: 583.6686\n",
      "Epoch 7564/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 687.8380 - val_loss: 583.3687\n",
      "Epoch 7565/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 687.5173 - val_loss: 583.0741\n",
      "Epoch 7566/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 687.1970 - val_loss: 582.7731\n",
      "Epoch 7567/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 686.8770 - val_loss: 582.4796\n",
      "Epoch 7568/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 686.5576 - val_loss: 582.1802\n",
      "Epoch 7569/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 686.2383 - val_loss: 581.8855\n",
      "Epoch 7570/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 685.9195 - val_loss: 581.5894\n",
      "Epoch 7571/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 685.6010 - val_loss: 581.2928\n",
      "Epoch 7572/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 685.2830 - val_loss: 580.9996\n",
      "Epoch 7573/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 684.9653 - val_loss: 580.7025\n",
      "Epoch 7574/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 684.6480 - val_loss: 580.4106\n",
      "Epoch 7575/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 684.3311 - val_loss: 580.1143\n",
      "Epoch 7576/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 684.0144 - val_loss: 579.8222\n",
      "Epoch 7577/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 683.6982 - val_loss: 579.5281\n",
      "Epoch 7578/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 683.3823 - val_loss: 579.2351\n",
      "Epoch 7579/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 683.0667 - val_loss: 578.9431\n",
      "Epoch 7580/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 682.7515 - val_loss: 578.6495\n",
      "Epoch 7581/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 682.4368 - val_loss: 578.3593\n",
      "Epoch 7582/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 682.1223 - val_loss: 578.0660\n",
      "Epoch 7583/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 681.8083 - val_loss: 577.7765\n",
      "Epoch 7584/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 681.4946 - val_loss: 577.4842\n",
      "Epoch 7585/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 681.1811 - val_loss: 577.1946\n",
      "Epoch 7586/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 680.8679 - val_loss: 576.9041\n",
      "Epoch 7587/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 680.5553 - val_loss: 576.6141\n",
      "Epoch 7588/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 680.2429 - val_loss: 576.3253\n",
      "Epoch 7589/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 679.9309 - val_loss: 576.0352\n",
      "Epoch 7590/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 679.6194 - val_loss: 575.7475\n",
      "Epoch 7591/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 679.3079 - val_loss: 575.4578\n",
      "Epoch 7592/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 678.9968 - val_loss: 575.1710\n",
      "Epoch 7593/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 678.6862 - val_loss: 574.8818\n",
      "Epoch 7594/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 678.3759 - val_loss: 574.5955\n",
      "Epoch 7595/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 678.0659 - val_loss: 574.3076\n",
      "Epoch 7596/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 677.7561 - val_loss: 574.0214\n",
      "Epoch 7597/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 677.4469 - val_loss: 573.7345\n",
      "Epoch 7598/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 677.1378 - val_loss: 573.4486\n",
      "Epoch 7599/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 676.8292 - val_loss: 573.1628\n",
      "Epoch 7600/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 676.5209 - val_loss: 572.8772\n",
      "Epoch 7601/100000\n",
      "11/11 [==============================] - 0s 642us/step - loss: 676.2129 - val_loss: 572.5925\n",
      "Epoch 7602/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 675.9052 - val_loss: 572.3072\n",
      "Epoch 7603/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 675.5978 - val_loss: 572.0233\n",
      "Epoch 7604/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 675.2908 - val_loss: 571.7385\n",
      "Epoch 7605/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 674.9841 - val_loss: 571.4554\n",
      "Epoch 7606/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 674.6777 - val_loss: 571.1710\n",
      "Epoch 7607/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 674.3716 - val_loss: 570.8888\n",
      "Epoch 7608/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 674.0658 - val_loss: 570.6048\n",
      "Epoch 7609/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 673.7603 - val_loss: 570.3235\n",
      "Epoch 7610/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 673.4552 - val_loss: 570.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7611/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 673.1505 - val_loss: 569.7595\n",
      "Epoch 7612/100000\n",
      "11/11 [==============================] - 0s 765us/step - loss: 672.8459 - val_loss: 569.4761\n",
      "Epoch 7613/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 672.5417 - val_loss: 569.1968\n",
      "Epoch 7614/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 672.2379 - val_loss: 568.9135\n",
      "Epoch 7615/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 671.9341 - val_loss: 568.6356\n",
      "Epoch 7616/100000\n",
      "11/11 [==============================] - 0s 205us/step - loss: 671.6309 - val_loss: 568.3519\n",
      "Epoch 7617/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 671.3281 - val_loss: 568.0759\n",
      "Epoch 7618/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 671.0255 - val_loss: 567.7913\n",
      "Epoch 7619/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 670.7230 - val_loss: 567.5175\n",
      "Epoch 7620/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 670.4208 - val_loss: 567.2317\n",
      "Epoch 7621/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 670.1192 - val_loss: 566.9608\n",
      "Epoch 7622/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 669.8176 - val_loss: 566.6728\n",
      "Epoch 7623/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 669.5165 - val_loss: 566.4052\n",
      "Epoch 7624/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 669.2156 - val_loss: 566.1156\n",
      "Epoch 7625/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 668.9150 - val_loss: 565.8500\n",
      "Epoch 7626/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 668.6148 - val_loss: 565.5612\n",
      "Epoch 7627/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 668.3148 - val_loss: 565.2940\n",
      "Epoch 7628/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 668.0152 - val_loss: 565.0103\n",
      "Epoch 7629/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 667.7159 - val_loss: 564.7375\n",
      "Epoch 7630/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 667.4168 - val_loss: 564.4615\n",
      "Epoch 7631/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 667.1180 - val_loss: 564.1822\n",
      "Epoch 7632/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 666.8194 - val_loss: 563.9125\n",
      "Epoch 7633/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 666.5213 - val_loss: 563.6299\n",
      "Epoch 7634/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 666.2234 - val_loss: 563.3625\n",
      "Epoch 7635/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 665.9257 - val_loss: 563.0812\n",
      "Epoch 7636/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 665.6284 - val_loss: 562.8116\n",
      "Epoch 7637/100000\n",
      "11/11 [==============================] - 0s 643us/step - loss: 665.3313 - val_loss: 562.5353\n",
      "Epoch 7638/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 665.0345 - val_loss: 562.2611\n",
      "Epoch 7639/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 664.7380 - val_loss: 561.9902\n",
      "Epoch 7640/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 664.4418 - val_loss: 561.7126\n",
      "Epoch 7641/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 664.1459 - val_loss: 561.4449\n",
      "Epoch 7642/100000\n",
      "11/11 [==============================] - 0s 648us/step - loss: 663.8502 - val_loss: 561.1670\n",
      "Epoch 7643/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 663.5549 - val_loss: 560.8990\n",
      "Epoch 7644/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 663.2597 - val_loss: 560.6238\n",
      "Epoch 7645/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 662.9648 - val_loss: 560.3533\n",
      "Epoch 7646/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 662.6703 - val_loss: 560.0822\n",
      "Epoch 7647/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 662.3761 - val_loss: 559.8090\n",
      "Epoch 7648/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 662.0820 - val_loss: 559.5410\n",
      "Epoch 7649/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 661.7883 - val_loss: 559.2668\n",
      "Epoch 7650/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 661.4949 - val_loss: 559.0000\n",
      "Epoch 7651/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 661.2017 - val_loss: 558.7264\n",
      "Epoch 7652/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 660.9086 - val_loss: 558.4592\n",
      "Epoch 7653/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 660.6160 - val_loss: 558.1878\n",
      "Epoch 7654/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 660.3237 - val_loss: 557.9193\n",
      "Epoch 7655/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 660.0315 - val_loss: 557.6503\n",
      "Epoch 7656/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 659.7397 - val_loss: 557.3805\n",
      "Epoch 7657/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 659.4482 - val_loss: 557.1136\n",
      "Epoch 7658/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 659.1568 - val_loss: 556.8431\n",
      "Epoch 7659/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 658.8657 - val_loss: 556.5775\n",
      "Epoch 7660/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 658.5748 - val_loss: 556.3076\n",
      "Epoch 7661/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 658.2844 - val_loss: 556.0421\n",
      "Epoch 7662/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 657.9940 - val_loss: 555.7730\n",
      "Epoch 7663/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 657.7040 - val_loss: 555.5076\n",
      "Epoch 7664/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 657.4143 - val_loss: 555.2397\n",
      "Epoch 7665/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 657.1248 - val_loss: 554.9741\n",
      "Epoch 7666/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 656.8355 - val_loss: 554.7076\n",
      "Epoch 7667/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 656.5466 - val_loss: 554.4418\n",
      "Epoch 7668/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 656.2579 - val_loss: 554.1765\n",
      "Epoch 7669/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 655.9694 - val_loss: 553.9103\n",
      "Epoch 7670/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 655.6811 - val_loss: 553.6463\n",
      "Epoch 7671/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 655.3932 - val_loss: 553.3802\n",
      "Epoch 7672/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 655.1055 - val_loss: 553.1169\n",
      "Epoch 7673/100000\n",
      "11/11 [==============================] - 0s 843us/step - loss: 654.8181 - val_loss: 552.8510\n",
      "Epoch 7674/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 654.5308 - val_loss: 552.5888\n",
      "Epoch 7675/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 654.2438 - val_loss: 552.3229\n",
      "Epoch 7676/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 653.9572 - val_loss: 552.0616\n",
      "Epoch 7677/100000\n",
      "11/11 [==============================] - 0s 604us/step - loss: 653.6707 - val_loss: 551.7957\n",
      "Epoch 7678/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 653.3844 - val_loss: 551.5356\n",
      "Epoch 7679/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 653.0984 - val_loss: 551.2693\n",
      "Epoch 7680/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 652.8127 - val_loss: 551.0106\n",
      "Epoch 7681/100000\n",
      "11/11 [==============================] - 0s 649us/step - loss: 652.5272 - val_loss: 550.7437\n",
      "Epoch 7682/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 652.2421 - val_loss: 550.4869\n",
      "Epoch 7683/100000\n",
      "11/11 [==============================] - 0s 813us/step - loss: 651.9570 - val_loss: 550.2189\n",
      "Epoch 7684/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 651.6723 - val_loss: 549.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7685/100000\n",
      "11/11 [==============================] - 0s 810us/step - loss: 651.3878 - val_loss: 549.6946\n",
      "Epoch 7686/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 651.1034 - val_loss: 549.4435\n",
      "Epoch 7687/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 650.8195 - val_loss: 549.1712\n",
      "Epoch 7688/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 650.5357 - val_loss: 548.9233\n",
      "Epoch 7689/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 650.2521 - val_loss: 548.6494\n",
      "Epoch 7690/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 649.9687 - val_loss: 548.4027\n",
      "Epoch 7691/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 649.6857 - val_loss: 548.1307\n",
      "Epoch 7692/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 649.4030 - val_loss: 547.8807\n",
      "Epoch 7693/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 649.1204 - val_loss: 547.6152\n",
      "Epoch 7694/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 648.8380 - val_loss: 547.3582\n",
      "Epoch 7695/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 648.5558 - val_loss: 547.1011\n",
      "Epoch 7696/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 648.2740 - val_loss: 546.8372\n",
      "Epoch 7697/100000\n",
      "11/11 [==============================] - 0s 594us/step - loss: 647.9924 - val_loss: 546.5862\n",
      "Epoch 7698/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 647.7109 - val_loss: 546.3193\n",
      "Epoch 7699/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 647.4296 - val_loss: 546.0699\n",
      "Epoch 7700/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 647.1487 - val_loss: 545.8051\n",
      "Epoch 7701/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 646.8680 - val_loss: 545.5524\n",
      "Epoch 7702/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 646.5875 - val_loss: 545.2930\n",
      "Epoch 7703/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 646.3072 - val_loss: 545.0353\n",
      "Epoch 7704/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 646.0272 - val_loss: 544.7817\n",
      "Epoch 7705/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 645.7475 - val_loss: 544.5202\n",
      "Epoch 7706/100000\n",
      "11/11 [==============================] - 0s 642us/step - loss: 645.4679 - val_loss: 544.2699\n",
      "Epoch 7707/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 645.1885 - val_loss: 544.0076\n",
      "Epoch 7708/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 644.9094 - val_loss: 543.7572\n",
      "Epoch 7709/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 644.6305 - val_loss: 543.4974\n",
      "Epoch 7710/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 644.3517 - val_loss: 543.2444\n",
      "Epoch 7711/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 644.0733 - val_loss: 542.9886\n",
      "Epoch 7712/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 643.7951 - val_loss: 542.7325\n",
      "Epoch 7713/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 643.5172 - val_loss: 542.4804\n",
      "Epoch 7714/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 643.2393 - val_loss: 542.2222\n",
      "Epoch 7715/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 642.9619 - val_loss: 541.9724\n",
      "Epoch 7716/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 642.6845 - val_loss: 541.7138\n",
      "Epoch 7717/100000\n",
      "11/11 [==============================] - 0s 648us/step - loss: 642.4073 - val_loss: 541.4640\n",
      "Epoch 7718/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 642.1304 - val_loss: 541.2071\n",
      "Epoch 7719/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 641.8538 - val_loss: 540.9561\n",
      "Epoch 7720/100000\n",
      "11/11 [==============================] - 0s 663us/step - loss: 641.5772 - val_loss: 540.7016\n",
      "Epoch 7721/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 641.3011 - val_loss: 540.4489\n",
      "Epoch 7722/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 641.0250 - val_loss: 540.1970\n",
      "Epoch 7723/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 640.7493 - val_loss: 539.9430\n",
      "Epoch 7724/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 640.4736 - val_loss: 539.6929\n",
      "Epoch 7725/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 640.1983 - val_loss: 539.4382\n",
      "Epoch 7726/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 639.9231 - val_loss: 539.1893\n",
      "Epoch 7727/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 639.6482 - val_loss: 538.9346\n",
      "Epoch 7728/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 639.3735 - val_loss: 538.6863\n",
      "Epoch 7729/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 639.0989 - val_loss: 538.4321\n",
      "Epoch 7730/100000\n",
      "11/11 [==============================] - 0s 690us/step - loss: 638.8246 - val_loss: 538.1841\n",
      "Epoch 7731/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 638.5505 - val_loss: 537.9305\n",
      "Epoch 7732/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 638.2766 - val_loss: 537.6827\n",
      "Epoch 7733/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 638.0030 - val_loss: 537.4297\n",
      "Epoch 7734/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 637.7295 - val_loss: 537.1822\n",
      "Epoch 7735/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 637.4563 - val_loss: 536.9299\n",
      "Epoch 7736/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 637.1832 - val_loss: 536.6827\n",
      "Epoch 7737/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 636.9104 - val_loss: 536.4307\n",
      "Epoch 7738/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 636.6379 - val_loss: 536.1841\n",
      "Epoch 7739/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 636.3654 - val_loss: 535.9323\n",
      "Epoch 7740/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 636.0932 - val_loss: 535.6865\n",
      "Epoch 7741/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 635.8212 - val_loss: 535.4346\n",
      "Epoch 7742/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 635.5494 - val_loss: 535.1899\n",
      "Epoch 7743/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 635.2778 - val_loss: 534.9374\n",
      "Epoch 7744/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 635.0065 - val_loss: 534.6946\n",
      "Epoch 7745/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 634.7353 - val_loss: 534.4407\n",
      "Epoch 7746/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 634.4642 - val_loss: 534.2006\n",
      "Epoch 7747/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 634.1935 - val_loss: 533.9441\n",
      "Epoch 7748/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 633.9229 - val_loss: 533.7081\n",
      "Epoch 7749/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 633.6526 - val_loss: 533.4478\n",
      "Epoch 7750/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 633.3823 - val_loss: 533.2167\n",
      "Epoch 7751/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 633.1123 - val_loss: 532.9525\n",
      "Epoch 7752/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 632.8427 - val_loss: 532.7247\n",
      "Epoch 7753/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 632.5732 - val_loss: 532.4612\n",
      "Epoch 7754/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 632.3037 - val_loss: 532.2294\n",
      "Epoch 7755/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 632.0346 - val_loss: 531.9749\n",
      "Epoch 7756/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 631.7654 - val_loss: 531.7319\n",
      "Epoch 7757/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 631.4968 - val_loss: 531.4905\n",
      "Epoch 7758/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 631.2283 - val_loss: 531.2365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7759/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 630.9599 - val_loss: 531.0034\n",
      "Epoch 7760/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 630.6917 - val_loss: 530.7466\n",
      "Epoch 7761/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 630.4238 - val_loss: 530.5120\n",
      "Epoch 7762/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 630.1558 - val_loss: 530.2620\n",
      "Epoch 7763/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 629.8883 - val_loss: 530.0187\n",
      "Epoch 7764/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 629.6208 - val_loss: 529.7786\n",
      "Epoch 7765/100000\n",
      "11/11 [==============================] - 0s 849us/step - loss: 629.3536 - val_loss: 529.5278\n",
      "Epoch 7766/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 629.0865 - val_loss: 529.2931\n",
      "Epoch 7767/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 628.8198 - val_loss: 529.0415\n",
      "Epoch 7768/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 628.5532 - val_loss: 528.8046\n",
      "Epoch 7769/100000\n",
      "11/11 [==============================] - 0s 851us/step - loss: 628.2867 - val_loss: 528.5588\n",
      "Epoch 7770/100000\n",
      "11/11 [==============================] - 0s 807us/step - loss: 628.0205 - val_loss: 528.3154\n",
      "Epoch 7771/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 627.7542 - val_loss: 528.0767\n",
      "Epoch 7772/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 627.4885 - val_loss: 527.8286\n",
      "Epoch 7773/100000\n",
      "11/11 [==============================] - 0s 643us/step - loss: 627.2227 - val_loss: 527.5931\n",
      "Epoch 7774/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 626.9571 - val_loss: 527.3453\n",
      "Epoch 7775/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 626.6919 - val_loss: 527.1078\n",
      "Epoch 7776/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 626.4268 - val_loss: 526.8643\n",
      "Epoch 7777/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 626.1617 - val_loss: 526.6226\n",
      "Epoch 7778/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 625.8969 - val_loss: 526.3840\n",
      "Epoch 7779/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 625.6323 - val_loss: 526.1390\n",
      "Epoch 7780/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 625.3679 - val_loss: 525.9031\n",
      "Epoch 7781/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 625.1037 - val_loss: 525.6578\n",
      "Epoch 7782/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 624.8396 - val_loss: 525.4214\n",
      "Epoch 7783/100000\n",
      "11/11 [==============================] - 0s 722us/step - loss: 624.5757 - val_loss: 525.1787\n",
      "Epoch 7784/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 624.3121 - val_loss: 524.9398\n",
      "Epoch 7785/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 624.0485 - val_loss: 524.7004\n",
      "Epoch 7786/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 623.7853 - val_loss: 524.4591\n",
      "Epoch 7787/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 623.5220 - val_loss: 524.2225\n",
      "Epoch 7788/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 623.2592 - val_loss: 523.9800\n",
      "Epoch 7789/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 622.9965 - val_loss: 523.7446\n",
      "Epoch 7790/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 622.7338 - val_loss: 523.5024\n",
      "Epoch 7791/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 622.4713 - val_loss: 523.2665\n",
      "Epoch 7792/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 622.2090 - val_loss: 523.0261\n",
      "Epoch 7793/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 621.9470 - val_loss: 522.7891\n",
      "Epoch 7794/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 621.6850 - val_loss: 522.5505\n",
      "Epoch 7795/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 621.4233 - val_loss: 522.3123\n",
      "Epoch 7796/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 621.1617 - val_loss: 522.0757\n",
      "Epoch 7797/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 620.9003 - val_loss: 521.8367\n",
      "Epoch 7798/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 620.6391 - val_loss: 521.6013\n",
      "Epoch 7799/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 620.3780 - val_loss: 521.3619\n",
      "Epoch 7800/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 620.1172 - val_loss: 521.1275\n",
      "Epoch 7801/100000\n",
      "11/11 [==============================] - 0s 790us/step - loss: 619.8564 - val_loss: 520.8881\n",
      "Epoch 7802/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 619.5959 - val_loss: 520.6542\n",
      "Epoch 7803/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 619.3355 - val_loss: 520.4151\n",
      "Epoch 7804/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 619.0753 - val_loss: 520.1817\n",
      "Epoch 7805/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 618.8152 - val_loss: 519.9429\n",
      "Epoch 7806/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 618.5554 - val_loss: 519.7100\n",
      "Epoch 7807/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 618.2957 - val_loss: 519.4713\n",
      "Epoch 7808/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 618.0361 - val_loss: 519.2390\n",
      "Epoch 7809/100000\n",
      "11/11 [==============================] - 0s 750us/step - loss: 617.7768 - val_loss: 519.0003\n",
      "Epoch 7810/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 617.5175 - val_loss: 518.7690\n",
      "Epoch 7811/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 617.2584 - val_loss: 518.5298\n",
      "Epoch 7812/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 616.9996 - val_loss: 518.3001\n",
      "Epoch 7813/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 616.7408 - val_loss: 518.0597\n",
      "Epoch 7814/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 616.4823 - val_loss: 517.8323\n",
      "Epoch 7815/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 616.2239 - val_loss: 517.5898\n",
      "Epoch 7816/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 615.9656 - val_loss: 517.3658\n",
      "Epoch 7817/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 615.7075 - val_loss: 517.1197\n",
      "Epoch 7818/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 615.4496 - val_loss: 516.9010\n",
      "Epoch 7819/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 615.1919 - val_loss: 516.6498\n",
      "Epoch 7820/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 614.9341 - val_loss: 516.4365\n",
      "Epoch 7821/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 614.6767 - val_loss: 516.1822\n",
      "Epoch 7822/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 614.4194 - val_loss: 515.9699\n",
      "Epoch 7823/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 614.1622 - val_loss: 515.7198\n",
      "Epoch 7824/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 613.9052 - val_loss: 515.4988\n",
      "Epoch 7825/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 613.6483 - val_loss: 515.2622\n",
      "Epoch 7826/100000\n",
      "11/11 [==============================] - 0s 589us/step - loss: 613.3918 - val_loss: 515.0269\n",
      "Epoch 7827/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 613.1352 - val_loss: 514.8040\n",
      "Epoch 7828/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 612.8787 - val_loss: 514.5592\n",
      "Epoch 7829/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 612.6226 - val_loss: 514.3416\n",
      "Epoch 7830/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 612.3665 - val_loss: 514.0979\n",
      "Epoch 7831/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 612.1105 - val_loss: 513.8745\n",
      "Epoch 7832/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 611.8547 - val_loss: 513.6411\n",
      "Epoch 7833/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 611.5991 - val_loss: 513.4069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7834/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 611.3435 - val_loss: 513.1836\n",
      "Epoch 7835/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 611.0883 - val_loss: 512.9430\n",
      "Epoch 7836/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 610.8329 - val_loss: 512.7227\n",
      "Epoch 7837/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 610.5779 - val_loss: 512.4842\n",
      "Epoch 7838/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 610.3230 - val_loss: 512.2590\n",
      "Epoch 7839/100000\n",
      "11/11 [==============================] - 0s 730us/step - loss: 610.0682 - val_loss: 512.0283\n",
      "Epoch 7840/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 609.8135 - val_loss: 511.7954\n",
      "Epoch 7841/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 609.5590 - val_loss: 511.5720\n",
      "Epoch 7842/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 609.3047 - val_loss: 511.3350\n",
      "Epoch 7843/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 609.0505 - val_loss: 511.1134\n",
      "Epoch 7844/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 608.7964 - val_loss: 510.8781\n",
      "Epoch 7845/100000\n",
      "11/11 [==============================] - 0s 201us/step - loss: 608.5425 - val_loss: 510.6532\n",
      "Epoch 7846/100000\n",
      "11/11 [==============================] - 0s 623us/step - loss: 608.2886 - val_loss: 510.4233\n",
      "Epoch 7847/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 608.0350 - val_loss: 510.1932\n",
      "Epoch 7848/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 607.7815 - val_loss: 509.9687\n",
      "Epoch 7849/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 607.5281 - val_loss: 509.7353\n",
      "Epoch 7850/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 607.2748 - val_loss: 509.5130\n",
      "Epoch 7851/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 607.0219 - val_loss: 509.2799\n",
      "Epoch 7852/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 606.7688 - val_loss: 509.0565\n",
      "Epoch 7853/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 606.5159 - val_loss: 508.8261\n",
      "Epoch 7854/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 606.2631 - val_loss: 508.6001\n",
      "Epoch 7855/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 606.0107 - val_loss: 508.3733\n",
      "Epoch 7856/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 605.7582 - val_loss: 508.1446\n",
      "Epoch 7857/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 605.5058 - val_loss: 507.9205\n",
      "Epoch 7858/100000\n",
      "11/11 [==============================] - 0s 716us/step - loss: 605.2537 - val_loss: 507.6905\n",
      "Epoch 7859/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 605.0015 - val_loss: 507.4678\n",
      "Epoch 7860/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 604.7496 - val_loss: 507.2378\n",
      "Epoch 7861/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 604.4979 - val_loss: 507.0151\n",
      "Epoch 7862/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 604.2462 - val_loss: 506.7863\n",
      "Epoch 7863/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 603.9947 - val_loss: 506.5628\n",
      "Epoch 7864/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 603.7432 - val_loss: 506.3355\n",
      "Epoch 7865/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 603.4919 - val_loss: 506.1109\n",
      "Epoch 7866/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 603.2407 - val_loss: 505.8855\n",
      "Epoch 7867/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 602.9896 - val_loss: 505.6600\n",
      "Epoch 7868/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 602.7387 - val_loss: 505.4359\n",
      "Epoch 7869/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 602.4879 - val_loss: 505.2099\n",
      "Epoch 7870/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 602.2372 - val_loss: 504.9868\n",
      "Epoch 7871/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 601.9866 - val_loss: 504.7605\n",
      "Epoch 7872/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 601.7362 - val_loss: 504.5385\n",
      "Epoch 7873/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 601.4858 - val_loss: 504.3118\n",
      "Epoch 7874/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 601.2358 - val_loss: 504.0909\n",
      "Epoch 7875/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 600.9856 - val_loss: 503.8636\n",
      "Epoch 7876/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 600.7357 - val_loss: 503.6441\n",
      "Epoch 7877/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 600.4857 - val_loss: 503.4157\n",
      "Epoch 7878/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 600.2361 - val_loss: 503.1985\n",
      "Epoch 7879/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 599.9866 - val_loss: 502.9680\n",
      "Epoch 7880/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 599.7369 - val_loss: 502.7541\n",
      "Epoch 7881/100000\n",
      "11/11 [==============================] - 0s 746us/step - loss: 599.4875 - val_loss: 502.5199\n",
      "Epoch 7882/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 599.2383 - val_loss: 502.3116\n",
      "Epoch 7883/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 598.9893 - val_loss: 502.0716\n",
      "Epoch 7884/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 598.7402 - val_loss: 501.8704\n",
      "Epoch 7885/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 598.4913 - val_loss: 501.6239\n",
      "Epoch 7886/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 598.2426 - val_loss: 501.4280\n",
      "Epoch 7887/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 597.9938 - val_loss: 501.1811\n",
      "Epoch 7888/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 597.7453 - val_loss: 500.9801\n",
      "Epoch 7889/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 597.4968 - val_loss: 500.7460\n",
      "Epoch 7890/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 597.2485 - val_loss: 500.5274\n",
      "Epoch 7891/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 597.0002 - val_loss: 500.3130\n",
      "Epoch 7892/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 596.7522 - val_loss: 500.0780\n",
      "Epoch 7893/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 596.5041 - val_loss: 499.8747\n",
      "Epoch 7894/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 596.2563 - val_loss: 499.6372\n",
      "Epoch 7895/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 596.0085 - val_loss: 499.4289\n",
      "Epoch 7896/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 595.7608 - val_loss: 499.2036\n",
      "Epoch 7897/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 595.5134 - val_loss: 498.9807\n",
      "Epoch 7898/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 595.2659 - val_loss: 498.7696\n",
      "Epoch 7899/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 595.0186 - val_loss: 498.5371\n",
      "Epoch 7900/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 594.7713 - val_loss: 498.3302\n",
      "Epoch 7901/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 594.5243 - val_loss: 498.1009\n",
      "Epoch 7902/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 594.2773 - val_loss: 497.8861\n",
      "Epoch 7903/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 594.0305 - val_loss: 497.6681\n",
      "Epoch 7904/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 593.7837 - val_loss: 497.4428\n",
      "Epoch 7905/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 593.5371 - val_loss: 497.2330\n",
      "Epoch 7906/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 593.2905 - val_loss: 497.0045\n",
      "Epoch 7907/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 593.0441 - val_loss: 496.7940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7908/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 592.7978 - val_loss: 496.5708\n",
      "Epoch 7909/100000\n",
      "11/11 [==============================] - 0s 680us/step - loss: 592.5517 - val_loss: 496.3531\n",
      "Epoch 7910/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 592.3054 - val_loss: 496.1382\n",
      "Epoch 7911/100000\n",
      "11/11 [==============================] - 0s 618us/step - loss: 592.0595 - val_loss: 495.9140\n",
      "Epoch 7912/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 591.8137 - val_loss: 495.7036\n",
      "Epoch 7913/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 591.5679 - val_loss: 495.4789\n",
      "Epoch 7914/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 591.3223 - val_loss: 495.2668\n",
      "Epoch 7915/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 591.0767 - val_loss: 495.0464\n",
      "Epoch 7916/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 590.8313 - val_loss: 494.8295\n",
      "Epoch 7917/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 590.5860 - val_loss: 494.6146\n",
      "Epoch 7918/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 590.3408 - val_loss: 494.3935\n",
      "Epoch 7919/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 590.0957 - val_loss: 494.1819\n",
      "Epoch 7920/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 589.8506 - val_loss: 493.9599\n",
      "Epoch 7921/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 589.6058 - val_loss: 493.7480\n",
      "Epoch 7922/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 589.3610 - val_loss: 493.5284\n",
      "Epoch 7923/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 589.1165 - val_loss: 493.3139\n",
      "Epoch 7924/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 588.8719 - val_loss: 493.0979\n",
      "Epoch 7925/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 588.6275 - val_loss: 492.8804\n",
      "Epoch 7926/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 588.3832 - val_loss: 492.6677\n",
      "Epoch 7927/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 588.1390 - val_loss: 492.4482\n",
      "Epoch 7928/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 587.8949 - val_loss: 492.2370\n",
      "Epoch 7929/100000\n",
      "11/11 [==============================] - 0s 674us/step - loss: 587.6509 - val_loss: 492.0174\n",
      "Epoch 7930/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 587.4070 - val_loss: 491.8063\n",
      "Epoch 7931/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 587.1633 - val_loss: 491.5878\n",
      "Epoch 7932/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 586.9197 - val_loss: 491.3757\n",
      "Epoch 7933/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 586.6761 - val_loss: 491.1591\n",
      "Epoch 7934/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 586.4328 - val_loss: 490.9456\n",
      "Epoch 7935/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 586.1894 - val_loss: 490.7310\n",
      "Epoch 7936/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 585.9462 - val_loss: 490.5161\n",
      "Epoch 7937/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 585.7033 - val_loss: 490.3033\n",
      "Epoch 7938/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 585.4603 - val_loss: 490.0874\n",
      "Epoch 7939/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 585.2175 - val_loss: 489.8759\n",
      "Epoch 7940/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 584.9747 - val_loss: 489.6594\n",
      "Epoch 7941/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 584.7320 - val_loss: 489.4490\n",
      "Epoch 7942/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 584.4896 - val_loss: 489.2320\n",
      "Epoch 7943/100000\n",
      "11/11 [==============================] - 0s 640us/step - loss: 584.2471 - val_loss: 489.0229\n",
      "Epoch 7944/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 584.0049 - val_loss: 488.8050\n",
      "Epoch 7945/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 583.7628 - val_loss: 488.5975\n",
      "Epoch 7946/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 583.5208 - val_loss: 488.3782\n",
      "Epoch 7947/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 583.2787 - val_loss: 488.1730\n",
      "Epoch 7948/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 583.0370 - val_loss: 487.9517\n",
      "Epoch 7949/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 582.7953 - val_loss: 487.7497\n",
      "Epoch 7950/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 582.5538 - val_loss: 487.5247\n",
      "Epoch 7951/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 582.3123 - val_loss: 487.3279\n",
      "Epoch 7952/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 582.0710 - val_loss: 487.0975\n",
      "Epoch 7953/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 581.8297 - val_loss: 486.9072\n",
      "Epoch 7954/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 581.5886 - val_loss: 486.6710\n",
      "Epoch 7955/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 581.3477 - val_loss: 486.4856\n",
      "Epoch 7956/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 581.1068 - val_loss: 486.2483\n",
      "Epoch 7957/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 580.8660 - val_loss: 486.0594\n",
      "Epoch 7958/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 580.6254 - val_loss: 485.8321\n",
      "Epoch 7959/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 580.3848 - val_loss: 485.6288\n",
      "Epoch 7960/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 580.1445 - val_loss: 485.4191\n",
      "Epoch 7961/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 579.9042 - val_loss: 485.1992\n",
      "Epoch 7962/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 579.6640 - val_loss: 485.0031\n",
      "Epoch 7963/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 579.4239 - val_loss: 484.7755\n",
      "Epoch 7964/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 579.1840 - val_loss: 484.5816\n",
      "Epoch 7965/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 578.9443 - val_loss: 484.3587\n",
      "Epoch 7966/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 578.7045 - val_loss: 484.1553\n",
      "Epoch 7967/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 578.4650 - val_loss: 483.9453\n",
      "Epoch 7968/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 578.2256 - val_loss: 483.7296\n",
      "Epoch 7969/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 577.9863 - val_loss: 483.5301\n",
      "Epoch 7970/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 577.7471 - val_loss: 483.3083\n",
      "Epoch 7971/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 577.5080 - val_loss: 483.1106\n",
      "Epoch 7972/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 577.2690 - val_loss: 482.8921\n",
      "Epoch 7973/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 577.0302 - val_loss: 482.6882\n",
      "Epoch 7974/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 576.7916 - val_loss: 482.4784\n",
      "Epoch 7975/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 576.5529 - val_loss: 482.2660\n",
      "Epoch 7976/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 576.3145 - val_loss: 482.0639\n",
      "Epoch 7977/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 576.0761 - val_loss: 481.8470\n",
      "Epoch 7978/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 575.8380 - val_loss: 481.6471\n",
      "Epoch 7979/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 575.5999 - val_loss: 481.4312\n",
      "Epoch 7980/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 575.3619 - val_loss: 481.2282\n",
      "Epoch 7981/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 575.1240 - val_loss: 481.0177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7982/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 574.8863 - val_loss: 480.8093\n",
      "Epoch 7983/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 574.6488 - val_loss: 480.6045\n",
      "Epoch 7984/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 574.4114 - val_loss: 480.3918\n",
      "Epoch 7985/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 574.1739 - val_loss: 480.1903\n",
      "Epoch 7986/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 573.9368 - val_loss: 479.9765\n",
      "Epoch 7987/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 573.6996 - val_loss: 479.7752\n",
      "Epoch 7988/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 573.4628 - val_loss: 479.5631\n",
      "Epoch 7989/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 573.2258 - val_loss: 479.3595\n",
      "Epoch 7990/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 572.9892 - val_loss: 479.1508\n",
      "Epoch 7991/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 572.7526 - val_loss: 478.9442\n",
      "Epoch 7992/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 572.5162 - val_loss: 478.7389\n",
      "Epoch 7993/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 572.2799 - val_loss: 478.5297\n",
      "Epoch 7994/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 572.0436 - val_loss: 478.3269\n",
      "Epoch 7995/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 571.8076 - val_loss: 478.1162\n",
      "Epoch 7996/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 571.5717 - val_loss: 477.9151\n",
      "Epoch 7997/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 571.3359 - val_loss: 477.7039\n",
      "Epoch 7998/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 571.1002 - val_loss: 477.5032\n",
      "Epoch 7999/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 570.8646 - val_loss: 477.2924\n",
      "Epoch 8000/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 570.6293 - val_loss: 477.0916\n",
      "Epoch 8001/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 570.3939 - val_loss: 476.8817\n",
      "Epoch 8002/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 570.1588 - val_loss: 476.6805\n",
      "Epoch 8003/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 569.9238 - val_loss: 476.4717\n",
      "Epoch 8004/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 569.6889 - val_loss: 476.2698\n",
      "Epoch 8005/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 569.4542 - val_loss: 476.0619\n",
      "Epoch 8006/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 569.2195 - val_loss: 475.8598\n",
      "Epoch 8007/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 568.9850 - val_loss: 475.6525\n",
      "Epoch 8008/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 568.7505 - val_loss: 475.4504\n",
      "Epoch 8009/100000\n",
      "11/11 [==============================] - 0s 651us/step - loss: 568.5164 - val_loss: 475.2435\n",
      "Epoch 8010/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 568.2822 - val_loss: 475.0418\n",
      "Epoch 8011/100000\n",
      "11/11 [==============================] - 0s 757us/step - loss: 568.0482 - val_loss: 474.8347\n",
      "Epoch 8012/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 567.8145 - val_loss: 474.6341\n",
      "Epoch 8013/100000\n",
      "11/11 [==============================] - 0s 683us/step - loss: 567.5807 - val_loss: 474.4262\n",
      "Epoch 8014/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 567.3472 - val_loss: 474.2271\n",
      "Epoch 8015/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 567.1136 - val_loss: 474.0178\n",
      "Epoch 8016/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 566.8804 - val_loss: 473.8213\n",
      "Epoch 8017/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 566.6471 - val_loss: 473.6089\n",
      "Epoch 8018/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 566.4140 - val_loss: 473.4171\n",
      "Epoch 8019/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 566.1812 - val_loss: 473.1992\n",
      "Epoch 8020/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 565.9485 - val_loss: 473.0150\n",
      "Epoch 8021/100000\n",
      "11/11 [==============================] - 0s 709us/step - loss: 565.7158 - val_loss: 472.7885\n",
      "Epoch 8022/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 565.4832 - val_loss: 472.6146\n",
      "Epoch 8023/100000\n",
      "11/11 [==============================] - 0s 639us/step - loss: 565.2507 - val_loss: 472.3782\n",
      "Epoch 8024/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 565.0186 - val_loss: 472.2118\n",
      "Epoch 8025/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 564.7864 - val_loss: 471.9754\n",
      "Epoch 8026/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 564.5544 - val_loss: 471.7993\n",
      "Epoch 8027/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 564.3226 - val_loss: 471.5839\n",
      "Epoch 8028/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 564.0909 - val_loss: 471.3805\n",
      "Epoch 8029/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 563.8593 - val_loss: 471.1930\n",
      "Epoch 8030/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 563.6277 - val_loss: 470.9687\n",
      "Epoch 8031/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 563.3965 - val_loss: 470.7913\n",
      "Epoch 8032/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 563.1653 - val_loss: 470.5707\n",
      "Epoch 8033/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 562.9343 - val_loss: 470.3782\n",
      "Epoch 8034/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 562.7033 - val_loss: 470.1798\n",
      "Epoch 8035/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 562.4725 - val_loss: 469.9660\n",
      "Epoch 8036/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 562.2418 - val_loss: 469.7827\n",
      "Epoch 8037/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 562.0113 - val_loss: 469.5649\n",
      "Epoch 8038/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 561.7809 - val_loss: 469.3753\n",
      "Epoch 8039/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 561.5507 - val_loss: 469.1722\n",
      "Epoch 8040/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 561.3206 - val_loss: 468.9655\n",
      "Epoch 8041/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 561.0905 - val_loss: 468.7773\n",
      "Epoch 8042/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 560.8607 - val_loss: 468.5632\n",
      "Epoch 8043/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 560.6309 - val_loss: 468.3742\n",
      "Epoch 8044/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 560.4013 - val_loss: 468.1687\n",
      "Epoch 8045/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 560.1718 - val_loss: 467.9675\n",
      "Epoch 8046/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 559.9424 - val_loss: 467.7750\n",
      "Epoch 8047/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 559.7134 - val_loss: 467.5649\n",
      "Epoch 8048/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 559.4843 - val_loss: 467.3758\n",
      "Epoch 8049/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 559.2553 - val_loss: 467.1692\n",
      "Epoch 8050/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 559.0267 - val_loss: 466.9722\n",
      "Epoch 8051/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 558.7979 - val_loss: 466.7757\n",
      "Epoch 8052/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 558.5693 - val_loss: 466.5702\n",
      "Epoch 8053/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 558.3409 - val_loss: 466.3796\n",
      "Epoch 8054/100000\n",
      "11/11 [==============================] - 0s 588us/step - loss: 558.1127 - val_loss: 466.1731\n",
      "Epoch 8055/100000\n",
      "11/11 [==============================] - 0s 710us/step - loss: 557.8845 - val_loss: 465.9798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8056/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 557.6566 - val_loss: 465.7793\n",
      "Epoch 8057/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 557.4286 - val_loss: 465.5792\n",
      "Epoch 8058/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 557.2009 - val_loss: 465.3855\n",
      "Epoch 8059/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 556.9733 - val_loss: 465.1813\n",
      "Epoch 8060/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 556.7458 - val_loss: 464.9891\n",
      "Epoch 8061/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 556.5184 - val_loss: 464.7867\n",
      "Epoch 8062/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 556.2913 - val_loss: 464.5911\n",
      "Epoch 8063/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 556.0642 - val_loss: 464.3937\n",
      "Epoch 8064/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 555.8372 - val_loss: 464.1937\n",
      "Epoch 8065/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 555.6104 - val_loss: 464.0002\n",
      "Epoch 8066/100000\n",
      "11/11 [==============================] - 0s 689us/step - loss: 555.3837 - val_loss: 463.7985\n",
      "Epoch 8067/100000\n",
      "11/11 [==============================] - 0s 666us/step - loss: 555.1572 - val_loss: 463.6052\n",
      "Epoch 8068/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 554.9307 - val_loss: 463.4053\n",
      "Epoch 8069/100000\n",
      "11/11 [==============================] - 0s 918us/step - loss: 554.7045 - val_loss: 463.2097\n",
      "Epoch 8070/100000\n",
      "11/11 [==============================] - 0s 881us/step - loss: 554.4783 - val_loss: 463.0131\n",
      "Epoch 8071/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 554.2522 - val_loss: 462.8145\n",
      "Epoch 8072/100000\n",
      "11/11 [==============================] - 0s 667us/step - loss: 554.0262 - val_loss: 462.6209\n",
      "Epoch 8073/100000\n",
      "11/11 [==============================] - 0s 607us/step - loss: 553.8005 - val_loss: 462.4209\n",
      "Epoch 8074/100000\n",
      "11/11 [==============================] - 0s 952us/step - loss: 553.5749 - val_loss: 462.2279\n",
      "Epoch 8075/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 553.3494 - val_loss: 462.0288\n",
      "Epoch 8076/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 553.1240 - val_loss: 461.8346\n",
      "Epoch 8077/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 552.8987 - val_loss: 461.6377\n",
      "Epoch 8078/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 552.6736 - val_loss: 461.4415\n",
      "Epoch 8079/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 552.4485 - val_loss: 461.2469\n",
      "Epoch 8080/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 552.2237 - val_loss: 461.0493\n",
      "Epoch 8081/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 551.9990 - val_loss: 460.8562\n",
      "Epoch 8082/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 551.7744 - val_loss: 460.6581\n",
      "Epoch 8083/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 551.5499 - val_loss: 460.4655\n",
      "Epoch 8084/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 551.3256 - val_loss: 460.2677\n",
      "Epoch 8085/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 551.1013 - val_loss: 460.0750\n",
      "Epoch 8086/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 550.8772 - val_loss: 459.8781\n",
      "Epoch 8087/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 550.6533 - val_loss: 459.6846\n",
      "Epoch 8088/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 550.4293 - val_loss: 459.4890\n",
      "Epoch 8089/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 550.2057 - val_loss: 459.2946\n",
      "Epoch 8090/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 549.9821 - val_loss: 459.1004\n",
      "Epoch 8091/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 549.7587 - val_loss: 458.9054\n",
      "Epoch 8092/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 549.5352 - val_loss: 458.7119\n",
      "Epoch 8093/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 549.3121 - val_loss: 458.5167\n",
      "Epoch 8094/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 549.0889 - val_loss: 458.3239\n",
      "Epoch 8095/100000\n",
      "11/11 [==============================] - 0s 196us/step - loss: 548.8660 - val_loss: 458.1286\n",
      "Epoch 8096/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 548.6432 - val_loss: 457.9364\n",
      "Epoch 8097/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 548.4205 - val_loss: 457.7410\n",
      "Epoch 8098/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 548.1980 - val_loss: 457.5492\n",
      "Epoch 8099/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 547.9756 - val_loss: 457.3537\n",
      "Epoch 8100/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 547.7532 - val_loss: 457.1627\n",
      "Epoch 8101/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 547.5310 - val_loss: 456.9668\n",
      "Epoch 8102/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 547.3090 - val_loss: 456.7768\n",
      "Epoch 8103/100000\n",
      "11/11 [==============================] - 0s 734us/step - loss: 547.0870 - val_loss: 456.5799\n",
      "Epoch 8104/100000\n",
      "11/11 [==============================] - 0s 964us/step - loss: 546.8651 - val_loss: 456.3917\n",
      "Epoch 8105/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 546.6435 - val_loss: 456.1932\n",
      "Epoch 8106/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 546.4219 - val_loss: 456.0076\n",
      "Epoch 8107/100000\n",
      "11/11 [==============================] - 0s 821us/step - loss: 546.2005 - val_loss: 455.8062\n",
      "Epoch 8108/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 545.9792 - val_loss: 455.6249\n",
      "Epoch 8109/100000\n",
      "11/11 [==============================] - 0s 737us/step - loss: 545.7579 - val_loss: 455.4184\n",
      "Epoch 8110/100000\n",
      "11/11 [==============================] - 0s 754us/step - loss: 545.5368 - val_loss: 455.2440\n",
      "Epoch 8111/100000\n",
      "11/11 [==============================] - 0s 632us/step - loss: 545.3159 - val_loss: 455.0294\n",
      "Epoch 8112/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 545.0952 - val_loss: 454.8654\n",
      "Epoch 8113/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 544.8744 - val_loss: 454.6399\n",
      "Epoch 8114/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 544.6539 - val_loss: 454.4861\n",
      "Epoch 8115/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 544.4334 - val_loss: 454.2552\n",
      "Epoch 8116/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 544.2130 - val_loss: 454.0989\n",
      "Epoch 8117/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 543.9927 - val_loss: 453.8822\n",
      "Epoch 8118/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 543.7727 - val_loss: 453.7018\n",
      "Epoch 8119/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 543.5527 - val_loss: 453.5150\n",
      "Epoch 8120/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 543.3328 - val_loss: 453.3065\n",
      "Epoch 8121/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 543.1132 - val_loss: 453.1405\n",
      "Epoch 8122/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 542.8936 - val_loss: 452.9239\n",
      "Epoch 8123/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 542.6741 - val_loss: 452.7530\n",
      "Epoch 8124/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 542.4548 - val_loss: 452.5532\n",
      "Epoch 8125/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 542.2355 - val_loss: 452.3595\n",
      "Epoch 8126/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 542.0164 - val_loss: 452.1824\n",
      "Epoch 8127/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 541.7974 - val_loss: 451.9733\n",
      "Epoch 8128/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 541.5786 - val_loss: 451.8016\n",
      "Epoch 8129/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 541.3598 - val_loss: 451.5984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8130/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 541.1412 - val_loss: 451.4128\n",
      "Epoch 8131/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 540.9227 - val_loss: 451.2277\n",
      "Epoch 8132/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 540.7043 - val_loss: 451.0263\n",
      "Epoch 8133/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 540.4860 - val_loss: 450.8511\n",
      "Epoch 8134/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 540.2678 - val_loss: 450.6484\n",
      "Epoch 8135/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 540.0499 - val_loss: 450.4672\n",
      "Epoch 8136/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 539.8319 - val_loss: 450.2763\n",
      "Epoch 8137/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 539.6141 - val_loss: 450.0822\n",
      "Epoch 8138/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 539.3965 - val_loss: 449.9025\n",
      "Epoch 8139/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 539.1789 - val_loss: 449.7024\n",
      "Epoch 8140/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 538.9615 - val_loss: 449.5232\n",
      "Epoch 8141/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 538.7442 - val_loss: 449.3285\n",
      "Epoch 8142/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 538.5269 - val_loss: 449.1408\n",
      "Epoch 8143/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 538.3099 - val_loss: 448.9559\n",
      "Epoch 8144/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 538.0930 - val_loss: 448.7605\n",
      "Epoch 8145/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 537.8760 - val_loss: 448.5804\n",
      "Epoch 8146/100000\n",
      "11/11 [==============================] - 0s 189us/step - loss: 537.6594 - val_loss: 448.3846\n",
      "Epoch 8147/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 537.4427 - val_loss: 448.2017\n",
      "Epoch 8148/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 537.2263 - val_loss: 448.0117\n",
      "Epoch 8149/100000\n",
      "11/11 [==============================] - 0s 198us/step - loss: 537.0099 - val_loss: 447.8224\n",
      "Epoch 8150/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 536.7936 - val_loss: 447.6386\n",
      "Epoch 8151/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 536.5775 - val_loss: 447.4453\n",
      "Epoch 8152/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 536.3615 - val_loss: 447.2636\n",
      "Epoch 8153/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 536.1456 - val_loss: 447.0712\n",
      "Epoch 8154/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 535.9298 - val_loss: 446.8869\n",
      "Epoch 8155/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 535.7141 - val_loss: 446.6986\n",
      "Epoch 8156/100000\n",
      "11/11 [==============================] - 0s 647us/step - loss: 535.4985 - val_loss: 446.5104\n",
      "Epoch 8157/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 535.2831 - val_loss: 446.3261\n",
      "Epoch 8158/100000\n",
      "11/11 [==============================] - 0s 813us/step - loss: 535.0678 - val_loss: 446.1353\n",
      "Epoch 8159/100000\n",
      "11/11 [==============================] - 0s 759us/step - loss: 534.8526 - val_loss: 445.9526\n",
      "Epoch 8160/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 534.6375 - val_loss: 445.7621\n",
      "Epoch 8161/100000\n",
      "11/11 [==============================] - 0s 203us/step - loss: 534.4226 - val_loss: 445.5784\n",
      "Epoch 8162/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 534.2078 - val_loss: 445.3901\n",
      "Epoch 8163/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 533.9929 - val_loss: 445.2041\n",
      "Epoch 8164/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 533.7784 - val_loss: 445.0186\n",
      "Epoch 8165/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 533.5637 - val_loss: 444.8306\n",
      "Epoch 8166/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 533.3494 - val_loss: 444.6470\n",
      "Epoch 8167/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 533.1351 - val_loss: 444.4582\n",
      "Epoch 8168/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 532.9210 - val_loss: 444.2750\n",
      "Epoch 8169/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 532.7068 - val_loss: 444.0869\n",
      "Epoch 8170/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 532.4929 - val_loss: 443.9029\n",
      "Epoch 8171/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 532.2791 - val_loss: 443.7163\n",
      "Epoch 8172/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 532.0654 - val_loss: 443.5312\n",
      "Epoch 8173/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 531.8519 - val_loss: 443.3462\n",
      "Epoch 8174/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 531.6383 - val_loss: 443.1601\n",
      "Epoch 8175/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 531.4250 - val_loss: 442.9763\n",
      "Epoch 8176/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 531.2117 - val_loss: 442.7895\n",
      "Epoch 8177/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 530.9985 - val_loss: 442.6064\n",
      "Epoch 8178/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 530.7854 - val_loss: 442.4196\n",
      "Epoch 8179/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 530.5726 - val_loss: 442.2370\n",
      "Epoch 8180/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 530.3597 - val_loss: 442.0503\n",
      "Epoch 8181/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 530.1470 - val_loss: 441.8678\n",
      "Epoch 8182/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 529.9344 - val_loss: 441.6813\n",
      "Epoch 8183/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 529.7220 - val_loss: 441.4990\n",
      "Epoch 8184/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 529.5097 - val_loss: 441.3129\n",
      "Epoch 8185/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 529.2974 - val_loss: 441.1306\n",
      "Epoch 8186/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 529.0853 - val_loss: 440.9449\n",
      "Epoch 8187/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 528.8732 - val_loss: 440.7627\n",
      "Epoch 8188/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 528.6613 - val_loss: 440.5771\n",
      "Epoch 8189/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 528.4495 - val_loss: 440.3953\n",
      "Epoch 8190/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 528.2377 - val_loss: 440.2097\n",
      "Epoch 8191/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 528.0262 - val_loss: 440.0285\n",
      "Epoch 8192/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 527.8146 - val_loss: 439.8425\n",
      "Epoch 8193/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 527.6033 - val_loss: 439.6624\n",
      "Epoch 8194/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 527.3922 - val_loss: 439.4755\n",
      "Epoch 8195/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 527.1810 - val_loss: 439.2969\n",
      "Epoch 8196/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 526.9698 - val_loss: 439.1084\n",
      "Epoch 8197/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 526.7590 - val_loss: 438.9324\n",
      "Epoch 8198/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 526.5482 - val_loss: 438.7410\n",
      "Epoch 8199/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 526.3375 - val_loss: 438.5695\n",
      "Epoch 8200/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 526.1269 - val_loss: 438.3726\n",
      "Epoch 8201/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 525.9164 - val_loss: 438.2087\n",
      "Epoch 8202/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 525.7061 - val_loss: 438.0025\n",
      "Epoch 8203/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 525.4958 - val_loss: 437.8507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8204/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 525.2857 - val_loss: 437.6310\n",
      "Epoch 8205/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 525.0756 - val_loss: 437.4928\n",
      "Epoch 8206/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 524.8657 - val_loss: 437.2638\n",
      "Epoch 8207/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 524.6558 - val_loss: 437.1258\n",
      "Epoch 8208/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 524.4460 - val_loss: 436.9113\n",
      "Epoch 8209/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 524.2364 - val_loss: 436.7451\n",
      "Epoch 8210/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 524.0269 - val_loss: 436.5677\n",
      "Epoch 8211/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 523.8174 - val_loss: 436.3654\n",
      "Epoch 8212/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 523.6081 - val_loss: 436.2145\n",
      "Epoch 8213/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 523.3990 - val_loss: 436.0027\n",
      "Epoch 8214/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 523.1899 - val_loss: 435.8434\n",
      "Epoch 8215/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 522.9809 - val_loss: 435.6552\n",
      "Epoch 8216/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 522.7720 - val_loss: 435.4661\n",
      "Epoch 8217/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 522.5632 - val_loss: 435.3048\n",
      "Epoch 8218/100000\n",
      "11/11 [==============================] - 0s 716us/step - loss: 522.3547 - val_loss: 435.1004\n",
      "Epoch 8219/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 522.1461 - val_loss: 434.9397\n",
      "Epoch 8220/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 521.9376 - val_loss: 434.7492\n",
      "Epoch 8221/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 521.7293 - val_loss: 434.5665\n",
      "Epoch 8222/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 521.5211 - val_loss: 434.3988\n",
      "Epoch 8223/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 521.3129 - val_loss: 434.2007\n",
      "Epoch 8224/100000\n",
      "11/11 [==============================] - 0s 564us/step - loss: 521.1049 - val_loss: 434.0374\n",
      "Epoch 8225/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 520.8970 - val_loss: 433.8471\n",
      "Epoch 8226/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 520.6892 - val_loss: 433.6683\n",
      "Epoch 8227/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 520.4814 - val_loss: 433.4960\n",
      "Epoch 8228/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 520.2738 - val_loss: 433.3034\n",
      "Epoch 8229/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 520.0664 - val_loss: 433.1374\n",
      "Epoch 8230/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 519.8589 - val_loss: 432.9479\n",
      "Epoch 8231/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 519.6516 - val_loss: 432.7722\n",
      "Epoch 8232/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 519.4445 - val_loss: 432.5960\n",
      "Epoch 8233/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 519.2374 - val_loss: 432.4084\n",
      "Epoch 8234/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 519.0305 - val_loss: 432.2399\n",
      "Epoch 8235/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 518.8237 - val_loss: 432.0515\n",
      "Epoch 8236/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 518.6168 - val_loss: 431.8781\n",
      "Epoch 8237/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 518.4102 - val_loss: 431.6989\n",
      "Epoch 8238/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 518.2037 - val_loss: 431.5159\n",
      "Epoch 8239/100000\n",
      "11/11 [==============================] - 0s 711us/step - loss: 517.9972 - val_loss: 431.3446\n",
      "Epoch 8240/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 517.7908 - val_loss: 431.1580\n",
      "Epoch 8241/100000\n",
      "11/11 [==============================] - 0s 586us/step - loss: 517.5845 - val_loss: 430.9861\n",
      "Epoch 8242/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 517.3784 - val_loss: 430.8044\n",
      "Epoch 8243/100000\n",
      "11/11 [==============================] - 0s 670us/step - loss: 517.1724 - val_loss: 430.6260\n",
      "Epoch 8244/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 516.9666 - val_loss: 430.4514\n",
      "Epoch 8245/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 516.7607 - val_loss: 430.2677\n",
      "Epoch 8246/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 516.5549 - val_loss: 430.0959\n",
      "Epoch 8247/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 516.3492 - val_loss: 429.9130\n",
      "Epoch 8248/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 516.1437 - val_loss: 429.7383\n",
      "Epoch 8249/100000\n",
      "11/11 [==============================] - 0s 203us/step - loss: 515.9384 - val_loss: 429.5602\n",
      "Epoch 8250/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 515.7330 - val_loss: 429.3806\n",
      "Epoch 8251/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 515.5278 - val_loss: 429.2070\n",
      "Epoch 8252/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 515.3228 - val_loss: 429.0251\n",
      "Epoch 8253/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 515.1176 - val_loss: 428.8521\n",
      "Epoch 8254/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 514.9127 - val_loss: 428.6719\n",
      "Epoch 8255/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 514.7080 - val_loss: 428.4964\n",
      "Epoch 8256/100000\n",
      "11/11 [==============================] - 0s 610us/step - loss: 514.5032 - val_loss: 428.3196\n",
      "Epoch 8257/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 514.2987 - val_loss: 428.1411\n",
      "Epoch 8258/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 514.0942 - val_loss: 427.9672\n",
      "Epoch 8259/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 513.8897 - val_loss: 427.7872\n",
      "Epoch 8260/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 513.6855 - val_loss: 427.6139\n",
      "Epoch 8261/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 513.4812 - val_loss: 427.4347\n",
      "Epoch 8262/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 513.2771 - val_loss: 427.2600\n",
      "Epoch 8263/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 513.0731 - val_loss: 427.0833\n",
      "Epoch 8264/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 512.8692 - val_loss: 426.9065\n",
      "Epoch 8265/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 512.6655 - val_loss: 426.7321\n",
      "Epoch 8266/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 512.4618 - val_loss: 426.5537\n",
      "Epoch 8267/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 512.2582 - val_loss: 426.3806\n",
      "Epoch 8268/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 512.0546 - val_loss: 426.2021\n",
      "Epoch 8269/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 511.8513 - val_loss: 426.0288\n",
      "Epoch 8270/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 511.6479 - val_loss: 425.8513\n",
      "Epoch 8271/100000\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 511.4447 - val_loss: 425.6771\n",
      "Epoch 8272/100000\n",
      "11/11 [==============================] - 0s 983us/step - loss: 511.2417 - val_loss: 425.5011\n",
      "Epoch 8273/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 511.0387 - val_loss: 425.3259\n",
      "Epoch 8274/100000\n",
      "11/11 [==============================] - 0s 912us/step - loss: 510.8358 - val_loss: 425.1511\n",
      "Epoch 8275/100000\n",
      "11/11 [==============================] - 0s 875us/step - loss: 510.6331 - val_loss: 424.9751\n",
      "Epoch 8276/100000\n",
      "11/11 [==============================] - 0s 687us/step - loss: 510.4303 - val_loss: 424.8013\n",
      "Epoch 8277/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 510.2277 - val_loss: 424.6249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8278/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 510.0252 - val_loss: 424.4517\n",
      "Epoch 8279/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 509.8227 - val_loss: 424.2752\n",
      "Epoch 8280/100000\n",
      "11/11 [==============================] - 0s 776us/step - loss: 509.6204 - val_loss: 424.1025\n",
      "Epoch 8281/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 509.4182 - val_loss: 423.9259\n",
      "Epoch 8282/100000\n",
      "11/11 [==============================] - 0s 622us/step - loss: 509.2161 - val_loss: 423.7535\n",
      "Epoch 8283/100000\n",
      "11/11 [==============================] - 0s 747us/step - loss: 509.0141 - val_loss: 423.5771\n",
      "Epoch 8284/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 508.8121 - val_loss: 423.4049\n",
      "Epoch 8285/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 508.6103 - val_loss: 423.2288\n",
      "Epoch 8286/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 508.4087 - val_loss: 423.0566\n",
      "Epoch 8287/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 508.2069 - val_loss: 422.8809\n",
      "Epoch 8288/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 508.0055 - val_loss: 422.7086\n",
      "Epoch 8289/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 507.8040 - val_loss: 422.5333\n",
      "Epoch 8290/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 507.6027 - val_loss: 422.3611\n",
      "Epoch 8291/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 507.4015 - val_loss: 422.1860\n",
      "Epoch 8292/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 507.2003 - val_loss: 422.0140\n",
      "Epoch 8293/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 506.9992 - val_loss: 421.8390\n",
      "Epoch 8294/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 506.7983 - val_loss: 421.6674\n",
      "Epoch 8295/100000\n",
      "11/11 [==============================] - 0s 205us/step - loss: 506.5975 - val_loss: 421.4924\n",
      "Epoch 8296/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 506.3968 - val_loss: 421.3213\n",
      "Epoch 8297/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 506.1960 - val_loss: 421.1459\n",
      "Epoch 8298/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 505.9955 - val_loss: 420.9759\n",
      "Epoch 8299/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 505.7951 - val_loss: 420.7994\n",
      "Epoch 8300/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 505.5947 - val_loss: 420.6312\n",
      "Epoch 8301/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 505.3945 - val_loss: 420.4529\n",
      "Epoch 8302/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 505.1943 - val_loss: 420.2873\n",
      "Epoch 8303/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 504.9941 - val_loss: 420.1058\n",
      "Epoch 8304/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 504.7942 - val_loss: 419.9452\n",
      "Epoch 8305/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 504.5943 - val_loss: 419.7575\n",
      "Epoch 8306/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 504.3945 - val_loss: 419.6057\n",
      "Epoch 8307/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 504.1949 - val_loss: 419.4068\n",
      "Epoch 8308/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 503.9952 - val_loss: 419.2696\n",
      "Epoch 8309/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 503.7958 - val_loss: 419.0536\n",
      "Epoch 8310/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 503.5963 - val_loss: 418.9344\n",
      "Epoch 8311/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 503.3971 - val_loss: 418.7057\n",
      "Epoch 8312/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 503.1978 - val_loss: 418.5870\n",
      "Epoch 8313/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 502.9987 - val_loss: 418.3772\n",
      "Epoch 8314/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 502.7996 - val_loss: 418.2210\n",
      "Epoch 8315/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 502.6008 - val_loss: 418.0594\n",
      "Epoch 8316/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 502.4019 - val_loss: 417.8586\n",
      "Epoch 8317/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 502.2031 - val_loss: 417.7259\n",
      "Epoch 8318/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 502.0045 - val_loss: 417.5206\n",
      "Epoch 8319/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 501.8058 - val_loss: 417.3682\n",
      "Epoch 8320/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 501.6074 - val_loss: 417.1993\n",
      "Epoch 8321/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 501.4090 - val_loss: 417.0087\n",
      "Epoch 8322/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 501.2108 - val_loss: 416.8667\n",
      "Epoch 8323/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 501.0126 - val_loss: 416.6700\n",
      "Epoch 8324/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 500.8145 - val_loss: 416.5133\n",
      "Epoch 8325/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 500.6165 - val_loss: 416.3453\n",
      "Epoch 8326/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 500.4187 - val_loss: 416.1587\n",
      "Epoch 8327/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 500.2207 - val_loss: 416.0109\n",
      "Epoch 8328/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 500.0230 - val_loss: 415.8212\n",
      "Epoch 8329/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 499.8254 - val_loss: 415.6603\n",
      "Epoch 8330/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 499.6279 - val_loss: 415.4940\n",
      "Epoch 8331/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 499.4305 - val_loss: 415.3102\n",
      "Epoch 8332/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 499.2331 - val_loss: 415.1581\n",
      "Epoch 8333/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 499.0358 - val_loss: 414.9740\n",
      "Epoch 8334/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 498.8387 - val_loss: 414.8103\n",
      "Epoch 8335/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 498.6416 - val_loss: 414.6447\n",
      "Epoch 8336/100000\n",
      "11/11 [==============================] - 0s 191us/step - loss: 498.4446 - val_loss: 414.4638\n",
      "Epoch 8337/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 498.2477 - val_loss: 414.3084\n",
      "Epoch 8338/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 498.0510 - val_loss: 414.1280\n",
      "Epoch 8339/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 497.8541 - val_loss: 413.9633\n",
      "Epoch 8340/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 497.6576 - val_loss: 413.7973\n",
      "Epoch 8341/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 497.4611 - val_loss: 413.6195\n",
      "Epoch 8342/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 497.2646 - val_loss: 413.4615\n",
      "Epoch 8343/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 497.0683 - val_loss: 413.2837\n",
      "Epoch 8344/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 496.8721 - val_loss: 413.1192\n",
      "Epoch 8345/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 496.6760 - val_loss: 412.9519\n",
      "Epoch 8346/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 496.4799 - val_loss: 412.7773\n",
      "Epoch 8347/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 496.2839 - val_loss: 412.6171\n",
      "Epoch 8348/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 496.0880 - val_loss: 412.4410\n",
      "Epoch 8349/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 495.8922 - val_loss: 412.2774\n",
      "Epoch 8350/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 495.6966 - val_loss: 412.1088\n",
      "Epoch 8351/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 495.5009 - val_loss: 411.9371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8352/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 495.3054 - val_loss: 411.7751\n",
      "Epoch 8353/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 495.1100 - val_loss: 411.6007\n",
      "Epoch 8354/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 494.9146 - val_loss: 411.4378\n",
      "Epoch 8355/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 494.7195 - val_loss: 411.2679\n",
      "Epoch 8356/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 494.5242 - val_loss: 411.0992\n",
      "Epoch 8357/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 494.3292 - val_loss: 410.9351\n",
      "Epoch 8358/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 494.1342 - val_loss: 410.7628\n",
      "Epoch 8359/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 493.9393 - val_loss: 410.6001\n",
      "Epoch 8360/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 493.7446 - val_loss: 410.4296\n",
      "Epoch 8361/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 493.5498 - val_loss: 410.2633\n",
      "Epoch 8362/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 493.3552 - val_loss: 410.0975\n",
      "Epoch 8363/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 493.1608 - val_loss: 409.9273\n",
      "Epoch 8364/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 492.9663 - val_loss: 409.7642\n",
      "Epoch 8365/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 492.7719 - val_loss: 409.5936\n",
      "Epoch 8366/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 492.5776 - val_loss: 409.4295\n",
      "Epoch 8367/100000\n",
      "11/11 [==============================] - 0s 194us/step - loss: 492.3834 - val_loss: 409.2616\n",
      "Epoch 8368/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 492.1894 - val_loss: 409.0945\n",
      "Epoch 8369/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 491.9954 - val_loss: 408.9298\n",
      "Epoch 8370/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 491.8015 - val_loss: 408.7605\n",
      "Epoch 8371/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 491.6076 - val_loss: 408.5973\n",
      "Epoch 8372/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 491.4140 - val_loss: 408.4283\n",
      "Epoch 8373/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 491.2202 - val_loss: 408.2638\n",
      "Epoch 8374/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 491.0268 - val_loss: 408.0972\n",
      "Epoch 8375/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 490.8334 - val_loss: 407.9306\n",
      "Epoch 8376/100000\n",
      "11/11 [==============================] - 0s 590us/step - loss: 490.6399 - val_loss: 407.7660\n",
      "Epoch 8377/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 490.4467 - val_loss: 407.5984\n",
      "Epoch 8378/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 490.2535 - val_loss: 407.4345\n",
      "Epoch 8379/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 490.0604 - val_loss: 407.2671\n",
      "Epoch 8380/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 489.8674 - val_loss: 407.1028\n",
      "Epoch 8381/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 489.6744 - val_loss: 406.9366\n",
      "Epoch 8382/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 489.4816 - val_loss: 406.7713\n",
      "Epoch 8383/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 489.2888 - val_loss: 406.6063\n",
      "Epoch 8384/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 489.0962 - val_loss: 406.4402\n",
      "Epoch 8385/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 488.9036 - val_loss: 406.2763\n",
      "Epoch 8386/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 488.7112 - val_loss: 406.1098\n",
      "Epoch 8387/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 488.5187 - val_loss: 405.9463\n",
      "Epoch 8388/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 488.3264 - val_loss: 405.7799\n",
      "Epoch 8389/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 488.1342 - val_loss: 405.6164\n",
      "Epoch 8390/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 487.9421 - val_loss: 405.4506\n",
      "Epoch 8391/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 487.7500 - val_loss: 405.2867\n",
      "Epoch 8392/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 487.5581 - val_loss: 405.1216\n",
      "Epoch 8393/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 487.3662 - val_loss: 404.9575\n",
      "Epoch 8394/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 487.1744 - val_loss: 404.7929\n",
      "Epoch 8395/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 486.9827 - val_loss: 404.6284\n",
      "Epoch 8396/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 486.7910 - val_loss: 404.4646\n",
      "Epoch 8397/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 486.5995 - val_loss: 404.2998\n",
      "Epoch 8398/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 486.4080 - val_loss: 404.1366\n",
      "Epoch 8399/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 486.2167 - val_loss: 403.9716\n",
      "Epoch 8400/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 486.0254 - val_loss: 403.8089\n",
      "Epoch 8401/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 485.8343 - val_loss: 403.6438\n",
      "Epoch 8402/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 485.6431 - val_loss: 403.4813\n",
      "Epoch 8403/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 485.4521 - val_loss: 403.3164\n",
      "Epoch 8404/100000\n",
      "11/11 [==============================] - 0s 591us/step - loss: 485.2612 - val_loss: 403.1543\n",
      "Epoch 8405/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 485.0704 - val_loss: 402.9893\n",
      "Epoch 8406/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 484.8796 - val_loss: 402.8273\n",
      "Epoch 8407/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 484.6888 - val_loss: 402.6624\n",
      "Epoch 8408/100000\n",
      "11/11 [==============================] - 0s 878us/step - loss: 484.4982 - val_loss: 402.5009\n",
      "Epoch 8409/100000\n",
      "11/11 [==============================] - 0s 712us/step - loss: 484.3078 - val_loss: 402.3359\n",
      "Epoch 8410/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 484.1174 - val_loss: 402.1750\n",
      "Epoch 8411/100000\n",
      "11/11 [==============================] - 0s 659us/step - loss: 483.9272 - val_loss: 402.0096\n",
      "Epoch 8412/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 483.7368 - val_loss: 401.8492\n",
      "Epoch 8413/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 483.5466 - val_loss: 401.6835\n",
      "Epoch 8414/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 483.3566 - val_loss: 401.5244\n",
      "Epoch 8415/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 483.1666 - val_loss: 401.3573\n",
      "Epoch 8416/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 482.9767 - val_loss: 401.2001\n",
      "Epoch 8417/100000\n",
      "11/11 [==============================] - 0s 640us/step - loss: 482.7869 - val_loss: 401.0310\n",
      "Epoch 8418/100000\n",
      "11/11 [==============================] - 0s 701us/step - loss: 482.5971 - val_loss: 400.8768\n",
      "Epoch 8419/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 482.4075 - val_loss: 400.7043\n",
      "Epoch 8420/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 482.2179 - val_loss: 400.5548\n",
      "Epoch 8421/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 482.0284 - val_loss: 400.3766\n",
      "Epoch 8422/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 481.8392 - val_loss: 400.2350\n",
      "Epoch 8423/100000\n",
      "11/11 [==============================] - 0s 608us/step - loss: 481.6497 - val_loss: 400.0469\n",
      "Epoch 8424/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 481.4605 - val_loss: 399.9178\n",
      "Epoch 8425/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 481.2715 - val_loss: 399.7158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8426/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 481.0824 - val_loss: 399.6015\n",
      "Epoch 8427/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 480.8934 - val_loss: 399.3872\n",
      "Epoch 8428/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 480.7046 - val_loss: 399.2784\n",
      "Epoch 8429/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 480.5158 - val_loss: 399.0714\n",
      "Epoch 8430/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 480.3270 - val_loss: 398.9404\n",
      "Epoch 8431/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 480.1383 - val_loss: 398.7686\n",
      "Epoch 8432/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 479.9498 - val_loss: 398.5975\n",
      "Epoch 8433/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 479.7614 - val_loss: 398.4622\n",
      "Epoch 8434/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 479.5729 - val_loss: 398.2667\n",
      "Epoch 8435/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 479.3847 - val_loss: 398.1394\n",
      "Epoch 8436/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 479.1965 - val_loss: 397.9542\n",
      "Epoch 8437/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 479.0083 - val_loss: 397.8025\n",
      "Epoch 8438/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 478.8202 - val_loss: 397.6487\n",
      "Epoch 8439/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 478.6322 - val_loss: 397.4684\n",
      "Epoch 8440/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 478.4444 - val_loss: 397.3334\n",
      "Epoch 8441/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 478.2566 - val_loss: 397.1490\n",
      "Epoch 8442/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 478.0689 - val_loss: 397.0040\n",
      "Epoch 8443/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 477.8813 - val_loss: 396.8401\n",
      "Epoch 8444/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 477.6937 - val_loss: 396.6715\n",
      "Epoch 8445/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 477.5062 - val_loss: 396.5278\n",
      "Epoch 8446/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 477.3187 - val_loss: 396.3484\n",
      "Epoch 8447/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 477.1314 - val_loss: 396.2047\n",
      "Epoch 8448/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 476.9443 - val_loss: 396.0358\n",
      "Epoch 8449/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 476.7572 - val_loss: 395.8758\n",
      "Epoch 8450/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 476.5701 - val_loss: 395.7242\n",
      "Epoch 8451/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 476.3831 - val_loss: 395.5510\n",
      "Epoch 8452/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 476.1962 - val_loss: 395.4060\n",
      "Epoch 8453/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 476.0095 - val_loss: 395.2346\n",
      "Epoch 8454/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 475.8227 - val_loss: 395.0812\n",
      "Epoch 8455/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 475.6360 - val_loss: 394.9225\n",
      "Epoch 8456/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 475.4495 - val_loss: 394.7567\n",
      "Epoch 8457/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 475.2630 - val_loss: 394.6074\n",
      "Epoch 8458/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 475.0766 - val_loss: 394.4374\n",
      "Epoch 8459/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 474.8902 - val_loss: 394.2873\n",
      "Epoch 8460/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 474.7040 - val_loss: 394.1231\n",
      "Epoch 8461/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 474.5179 - val_loss: 393.9647\n",
      "Epoch 8462/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 474.3318 - val_loss: 393.8097\n",
      "Epoch 8463/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 474.1460 - val_loss: 393.6440\n",
      "Epoch 8464/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 473.9600 - val_loss: 393.4935\n",
      "Epoch 8465/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 473.7743 - val_loss: 393.3273\n",
      "Epoch 8466/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 473.5884 - val_loss: 393.1740\n",
      "Epoch 8467/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 473.4027 - val_loss: 393.0134\n",
      "Epoch 8468/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 473.2172 - val_loss: 392.8539\n",
      "Epoch 8469/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 473.0316 - val_loss: 392.6994\n",
      "Epoch 8470/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 472.8462 - val_loss: 392.5357\n",
      "Epoch 8471/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 472.6609 - val_loss: 392.3836\n",
      "Epoch 8472/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 472.4756 - val_loss: 392.2199\n",
      "Epoch 8473/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 472.2905 - val_loss: 392.0660\n",
      "Epoch 8474/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 472.1054 - val_loss: 391.9060\n",
      "Epoch 8475/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 471.9203 - val_loss: 391.7481\n",
      "Epoch 8476/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 471.7355 - val_loss: 391.5925\n",
      "Epoch 8477/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 471.5506 - val_loss: 391.4312\n",
      "Epoch 8478/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 471.3657 - val_loss: 391.2779\n",
      "Epoch 8479/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 471.1811 - val_loss: 391.1158\n",
      "Epoch 8480/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 470.9964 - val_loss: 390.9624\n",
      "Epoch 8481/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 470.8119 - val_loss: 390.8020\n",
      "Epoch 8482/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 470.6275 - val_loss: 390.6464\n",
      "Epoch 8483/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 470.4430 - val_loss: 390.4887\n",
      "Epoch 8484/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 470.2587 - val_loss: 390.3309\n",
      "Epoch 8485/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 470.0746 - val_loss: 390.1756\n",
      "Epoch 8486/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 469.8904 - val_loss: 390.0160\n",
      "Epoch 8487/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 469.7063 - val_loss: 389.8621\n",
      "Epoch 8488/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 469.5224 - val_loss: 389.7021\n",
      "Epoch 8489/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 469.3385 - val_loss: 389.5482\n",
      "Epoch 8490/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 469.1546 - val_loss: 389.3889\n",
      "Epoch 8491/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 468.9708 - val_loss: 389.2343\n",
      "Epoch 8492/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 468.7872 - val_loss: 389.0764\n",
      "Epoch 8493/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 468.6035 - val_loss: 388.9208\n",
      "Epoch 8494/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 468.4202 - val_loss: 388.7643\n",
      "Epoch 8495/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 468.2368 - val_loss: 388.6076\n",
      "Epoch 8496/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 468.0534 - val_loss: 388.4521\n",
      "Epoch 8497/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 467.8701 - val_loss: 388.2947\n",
      "Epoch 8498/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 467.6869 - val_loss: 388.1402\n",
      "Epoch 8499/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 467.5039 - val_loss: 387.9823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8500/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 467.3207 - val_loss: 387.8285\n",
      "Epoch 8501/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 467.1379 - val_loss: 387.6704\n",
      "Epoch 8502/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 466.9550 - val_loss: 387.5171\n",
      "Epoch 8503/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 466.7723 - val_loss: 387.3587\n",
      "Epoch 8504/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 466.5895 - val_loss: 387.2059\n",
      "Epoch 8505/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 466.4069 - val_loss: 387.0473\n",
      "Epoch 8506/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 466.2242 - val_loss: 386.8948\n",
      "Epoch 8507/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 466.0417 - val_loss: 386.7363\n",
      "Epoch 8508/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 465.8595 - val_loss: 386.5844\n",
      "Epoch 8509/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 465.6771 - val_loss: 386.4255\n",
      "Epoch 8510/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 465.4949 - val_loss: 386.2744\n",
      "Epoch 8511/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 465.3127 - val_loss: 386.1148\n",
      "Epoch 8512/100000\n",
      "11/11 [==============================] - 0s 196us/step - loss: 465.1307 - val_loss: 385.9646\n",
      "Epoch 8513/100000\n",
      "11/11 [==============================] - 0s 721us/step - loss: 464.9486 - val_loss: 385.8042\n",
      "Epoch 8514/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 464.7667 - val_loss: 385.6556\n",
      "Epoch 8515/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 464.5848 - val_loss: 385.4933\n",
      "Epoch 8516/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 464.4030 - val_loss: 385.3476\n",
      "Epoch 8517/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 464.2214 - val_loss: 385.1822\n",
      "Epoch 8518/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 464.0398 - val_loss: 385.0406\n",
      "Epoch 8519/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 463.8582 - val_loss: 384.8700\n",
      "Epoch 8520/100000\n",
      "11/11 [==============================] - 0s 682us/step - loss: 463.6768 - val_loss: 384.7356\n",
      "Epoch 8521/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 463.4953 - val_loss: 384.5563\n",
      "Epoch 8522/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 463.3141 - val_loss: 384.4331\n",
      "Epoch 8523/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 463.1329 - val_loss: 384.2409\n",
      "Epoch 8524/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 462.9517 - val_loss: 384.1317\n",
      "Epoch 8525/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 462.7707 - val_loss: 383.9268\n",
      "Epoch 8526/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 462.5896 - val_loss: 383.8261\n",
      "Epoch 8527/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 462.4087 - val_loss: 383.6223\n",
      "Epoch 8528/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 462.2279 - val_loss: 383.5078\n",
      "Epoch 8529/100000\n",
      "11/11 [==============================] - 0s 614us/step - loss: 462.0471 - val_loss: 383.3314\n",
      "Epoch 8530/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 461.8664 - val_loss: 383.1810\n",
      "Epoch 8531/100000\n",
      "11/11 [==============================] - 0s 643us/step - loss: 461.6859 - val_loss: 383.0421\n",
      "Epoch 8532/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 461.5052 - val_loss: 382.8603\n",
      "Epoch 8533/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 461.3248 - val_loss: 382.7413\n",
      "Epoch 8534/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 461.1444 - val_loss: 382.5555\n",
      "Epoch 8535/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 460.9641 - val_loss: 382.4251\n",
      "Epoch 8536/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 460.7839 - val_loss: 382.2630\n",
      "Epoch 8537/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 460.6037 - val_loss: 382.1039\n",
      "Epoch 8538/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 460.4236 - val_loss: 381.9687\n",
      "Epoch 8539/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 460.2437 - val_loss: 381.7914\n",
      "Epoch 8540/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 460.0638 - val_loss: 381.6625\n",
      "Epoch 8541/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 459.8840 - val_loss: 381.4917\n",
      "Epoch 8542/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 459.7042 - val_loss: 381.3468\n",
      "Epoch 8543/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 459.5244 - val_loss: 381.1971\n",
      "Epoch 8544/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 459.3448 - val_loss: 381.0321\n",
      "Epoch 8545/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 459.1653 - val_loss: 380.8972\n",
      "Epoch 8546/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 458.9858 - val_loss: 380.7264\n",
      "Epoch 8547/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 458.8064 - val_loss: 380.5883\n",
      "Epoch 8548/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 458.6271 - val_loss: 380.4285\n",
      "Epoch 8549/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 458.4478 - val_loss: 380.2756\n",
      "Epoch 8550/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 458.2686 - val_loss: 380.1311\n",
      "Epoch 8551/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 458.0897 - val_loss: 379.9666\n",
      "Epoch 8552/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 457.9106 - val_loss: 379.8282\n",
      "Epoch 8553/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 457.7316 - val_loss: 379.6643\n",
      "Epoch 8554/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 457.5528 - val_loss: 379.5200\n",
      "Epoch 8555/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 457.3740 - val_loss: 379.3660\n",
      "Epoch 8556/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 457.1953 - val_loss: 379.2109\n",
      "Epoch 8557/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 457.0167 - val_loss: 379.0667\n",
      "Epoch 8558/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 456.8381 - val_loss: 378.9052\n",
      "Epoch 8559/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 456.6597 - val_loss: 378.7636\n",
      "Epoch 8560/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 456.4812 - val_loss: 378.6039\n",
      "Epoch 8561/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 456.3029 - val_loss: 378.4575\n",
      "Epoch 8562/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 456.1246 - val_loss: 378.3048\n",
      "Epoch 8563/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 455.9465 - val_loss: 378.1513\n",
      "Epoch 8564/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 455.7685 - val_loss: 378.0052\n",
      "Epoch 8565/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 455.5904 - val_loss: 377.8471\n",
      "Epoch 8566/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 455.4123 - val_loss: 377.7033\n",
      "Epoch 8567/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 455.2345 - val_loss: 377.5458\n",
      "Epoch 8568/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 455.0566 - val_loss: 377.3995\n",
      "Epoch 8569/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 454.8789 - val_loss: 377.2464\n",
      "Epoch 8570/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 454.7012 - val_loss: 377.0955\n",
      "Epoch 8571/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 454.5237 - val_loss: 376.9470\n",
      "Epoch 8572/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 454.3461 - val_loss: 376.7926\n",
      "Epoch 8573/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 454.1688 - val_loss: 376.6468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8574/100000\n",
      "11/11 [==============================] - 0s 609us/step - loss: 453.9915 - val_loss: 376.4912\n",
      "Epoch 8575/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 453.8141 - val_loss: 376.3454\n",
      "Epoch 8576/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 453.6369 - val_loss: 376.1913\n",
      "Epoch 8577/100000\n",
      "11/11 [==============================] - 0s 198us/step - loss: 453.4598 - val_loss: 376.0435\n",
      "Epoch 8578/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 453.2827 - val_loss: 375.8920\n",
      "Epoch 8579/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 453.1057 - val_loss: 375.7419\n",
      "Epoch 8580/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 452.9288 - val_loss: 375.5929\n",
      "Epoch 8581/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 452.7519 - val_loss: 375.4409\n",
      "Epoch 8582/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 452.5752 - val_loss: 375.2936\n",
      "Epoch 8583/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 452.3984 - val_loss: 375.1406\n",
      "Epoch 8584/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 452.2219 - val_loss: 374.9940\n",
      "Epoch 8585/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 452.0452 - val_loss: 374.8412\n",
      "Epoch 8586/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 451.8688 - val_loss: 374.6943\n",
      "Epoch 8587/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 451.6924 - val_loss: 374.5423\n",
      "Epoch 8588/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 451.5161 - val_loss: 374.3948\n",
      "Epoch 8589/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 451.3399 - val_loss: 374.2439\n",
      "Epoch 8590/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 451.1637 - val_loss: 374.0955\n",
      "Epoch 8591/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 450.9875 - val_loss: 373.9455\n",
      "Epoch 8592/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 450.8115 - val_loss: 373.7965\n",
      "Epoch 8593/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 450.6355 - val_loss: 373.6475\n",
      "Epoch 8594/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 450.4596 - val_loss: 373.4979\n",
      "Epoch 8595/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 450.2838 - val_loss: 373.3496\n",
      "Epoch 8596/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 450.1080 - val_loss: 373.1997\n",
      "Epoch 8597/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 449.9325 - val_loss: 373.0520\n",
      "Epoch 8598/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 449.7568 - val_loss: 372.9018\n",
      "Epoch 8599/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 449.5813 - val_loss: 372.7546\n",
      "Epoch 8600/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 449.4059 - val_loss: 372.6041\n",
      "Epoch 8601/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 449.2304 - val_loss: 372.4576\n",
      "Epoch 8602/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 449.0551 - val_loss: 372.3066\n",
      "Epoch 8603/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 448.8799 - val_loss: 372.1610\n",
      "Epoch 8604/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 448.7049 - val_loss: 372.0094\n",
      "Epoch 8605/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 448.5297 - val_loss: 371.8647\n",
      "Epoch 8606/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 448.3546 - val_loss: 371.7123\n",
      "Epoch 8607/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 448.1797 - val_loss: 371.5688\n",
      "Epoch 8608/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 448.0049 - val_loss: 371.4151\n",
      "Epoch 8609/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 447.8300 - val_loss: 371.2737\n",
      "Epoch 8610/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 447.6553 - val_loss: 371.1177\n",
      "Epoch 8611/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 447.4807 - val_loss: 370.9796\n",
      "Epoch 8612/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 447.3061 - val_loss: 370.8196\n",
      "Epoch 8613/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 447.1316 - val_loss: 370.6869\n",
      "Epoch 8614/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 446.9572 - val_loss: 370.5204\n",
      "Epoch 8615/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 446.7827 - val_loss: 370.3963\n",
      "Epoch 8616/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 446.6084 - val_loss: 370.2192\n",
      "Epoch 8617/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 446.4343 - val_loss: 370.1084\n",
      "Epoch 8618/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 446.2601 - val_loss: 369.9164\n",
      "Epoch 8619/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 446.0860 - val_loss: 369.8213\n",
      "Epoch 8620/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 445.9121 - val_loss: 369.6165\n",
      "Epoch 8621/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 445.7381 - val_loss: 369.5266\n",
      "Epoch 8622/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 445.5643 - val_loss: 369.3299\n",
      "Epoch 8623/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 445.3904 - val_loss: 369.2168\n",
      "Epoch 8624/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 445.2167 - val_loss: 369.0566\n",
      "Epoch 8625/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 445.0430 - val_loss: 368.9012\n",
      "Epoch 8626/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 444.8695 - val_loss: 368.7804\n",
      "Epoch 8627/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 444.6959 - val_loss: 368.5973\n",
      "Epoch 8628/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 444.5226 - val_loss: 368.4877\n",
      "Epoch 8629/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 444.3492 - val_loss: 368.3122\n",
      "Epoch 8630/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 444.1759 - val_loss: 368.1795\n",
      "Epoch 8631/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 444.0026 - val_loss: 368.0359\n",
      "Epoch 8632/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 443.8294 - val_loss: 367.8720\n",
      "Epoch 8633/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 443.6564 - val_loss: 367.7516\n",
      "Epoch 8634/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 443.4833 - val_loss: 367.5783\n",
      "Epoch 8635/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 443.3105 - val_loss: 367.4528\n",
      "Epoch 8636/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 443.1375 - val_loss: 367.2971\n",
      "Epoch 8637/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 442.9648 - val_loss: 367.1476\n",
      "Epoch 8638/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 442.7920 - val_loss: 367.0156\n",
      "Epoch 8639/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 442.6194 - val_loss: 366.8497\n",
      "Epoch 8640/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 442.4468 - val_loss: 366.7237\n",
      "Epoch 8641/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 442.2741 - val_loss: 366.5630\n",
      "Epoch 8642/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 442.1018 - val_loss: 366.4235\n",
      "Epoch 8643/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 441.9294 - val_loss: 366.2809\n",
      "Epoch 8644/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 441.7570 - val_loss: 366.1245\n",
      "Epoch 8645/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 441.5849 - val_loss: 365.9938\n",
      "Epoch 8646/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 441.4127 - val_loss: 365.8334\n",
      "Epoch 8647/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 441.2406 - val_loss: 365.6991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8648/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 441.0686 - val_loss: 365.5486\n",
      "Epoch 8649/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 440.8966 - val_loss: 365.4015\n",
      "Epoch 8650/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 440.7247 - val_loss: 365.2637\n",
      "Epoch 8651/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 440.5529 - val_loss: 365.1077\n",
      "Epoch 8652/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 440.3812 - val_loss: 364.9741\n",
      "Epoch 8653/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 440.2096 - val_loss: 364.8196\n",
      "Epoch 8654/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 440.0379 - val_loss: 364.6800\n",
      "Epoch 8655/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 439.8663 - val_loss: 364.5345\n",
      "Epoch 8656/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 439.6949 - val_loss: 364.3858\n",
      "Epoch 8657/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 439.5235 - val_loss: 364.2482\n",
      "Epoch 8658/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 439.3522 - val_loss: 364.0949\n",
      "Epoch 8659/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 439.1809 - val_loss: 363.9584\n",
      "Epoch 8660/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 439.0098 - val_loss: 363.8076\n",
      "Epoch 8661/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 438.8386 - val_loss: 363.6662\n",
      "Epoch 8662/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 438.6675 - val_loss: 363.5219\n",
      "Epoch 8663/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 438.4965 - val_loss: 363.3746\n",
      "Epoch 8664/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 438.3257 - val_loss: 363.2353\n",
      "Epoch 8665/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 438.1548 - val_loss: 363.0851\n",
      "Epoch 8666/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 437.9840 - val_loss: 362.9466\n",
      "Epoch 8667/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 437.8134 - val_loss: 362.7980\n",
      "Epoch 8668/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 437.6426 - val_loss: 362.6565\n",
      "Epoch 8669/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 437.4721 - val_loss: 362.5121\n",
      "Epoch 8670/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 437.3016 - val_loss: 362.3667\n",
      "Epoch 8671/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 437.1311 - val_loss: 362.2259\n",
      "Epoch 8672/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 436.9608 - val_loss: 362.0782\n",
      "Epoch 8673/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 436.7905 - val_loss: 361.9387\n",
      "Epoch 8674/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 436.6204 - val_loss: 361.7912\n",
      "Epoch 8675/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 436.4501 - val_loss: 361.6505\n",
      "Epoch 8676/100000\n",
      "11/11 [==============================] - 0s 195us/step - loss: 436.2800 - val_loss: 361.5053\n",
      "Epoch 8677/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 436.1101 - val_loss: 361.3623\n",
      "Epoch 8678/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 435.9401 - val_loss: 361.2196\n",
      "Epoch 8679/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 435.7701 - val_loss: 361.0746\n",
      "Epoch 8680/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 435.6004 - val_loss: 360.9338\n",
      "Epoch 8681/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 435.4306 - val_loss: 360.7878\n",
      "Epoch 8682/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 435.2610 - val_loss: 360.6476\n",
      "Epoch 8683/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 435.0913 - val_loss: 360.5017\n",
      "Epoch 8684/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 434.9217 - val_loss: 360.3611\n",
      "Epoch 8685/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 434.7523 - val_loss: 360.2165\n",
      "Epoch 8686/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 434.5829 - val_loss: 360.0747\n",
      "Epoch 8687/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 434.4136 - val_loss: 359.9315\n",
      "Epoch 8688/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 434.2443 - val_loss: 359.7886\n",
      "Epoch 8689/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 434.0752 - val_loss: 359.6467\n",
      "Epoch 8690/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 433.9059 - val_loss: 359.5028\n",
      "Epoch 8691/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 433.7368 - val_loss: 359.3621\n",
      "Epoch 8692/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 433.5680 - val_loss: 359.2177\n",
      "Epoch 8693/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 433.3990 - val_loss: 359.0774\n",
      "Epoch 8694/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 433.2302 - val_loss: 358.9328\n",
      "Epoch 8695/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 433.0613 - val_loss: 358.7928\n",
      "Epoch 8696/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 432.8926 - val_loss: 358.6484\n",
      "Epoch 8697/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 432.7240 - val_loss: 358.5085\n",
      "Epoch 8698/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 432.5554 - val_loss: 358.3642\n",
      "Epoch 8699/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 432.3868 - val_loss: 358.2244\n",
      "Epoch 8700/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 432.2184 - val_loss: 358.0803\n",
      "Epoch 8701/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 432.0499 - val_loss: 357.9406\n",
      "Epoch 8702/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 431.8817 - val_loss: 357.7967\n",
      "Epoch 8703/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 431.7134 - val_loss: 357.6571\n",
      "Epoch 8704/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 431.5451 - val_loss: 357.5131\n",
      "Epoch 8705/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 431.3770 - val_loss: 357.3741\n",
      "Epoch 8706/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 431.2090 - val_loss: 357.2297\n",
      "Epoch 8707/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 431.0410 - val_loss: 357.0913\n",
      "Epoch 8708/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 430.8730 - val_loss: 356.9465\n",
      "Epoch 8709/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 430.7052 - val_loss: 356.8090\n",
      "Epoch 8710/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 430.5373 - val_loss: 356.6633\n",
      "Epoch 8711/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 430.3696 - val_loss: 356.5273\n",
      "Epoch 8712/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 430.2021 - val_loss: 356.3801\n",
      "Epoch 8713/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 430.0345 - val_loss: 356.2463\n",
      "Epoch 8714/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 429.8670 - val_loss: 356.0963\n",
      "Epoch 8715/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 429.6995 - val_loss: 355.9665\n",
      "Epoch 8716/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 429.5320 - val_loss: 355.8117\n",
      "Epoch 8717/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 429.3647 - val_loss: 355.6883\n",
      "Epoch 8718/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 429.1974 - val_loss: 355.5257\n",
      "Epoch 8719/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 429.0303 - val_loss: 355.4123\n",
      "Epoch 8720/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 428.8632 - val_loss: 355.2378\n",
      "Epoch 8721/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 428.6962 - val_loss: 355.1389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8722/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 428.5291 - val_loss: 354.9487\n",
      "Epoch 8723/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 428.3623 - val_loss: 354.8650\n",
      "Epoch 8724/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 428.1954 - val_loss: 354.6644\n",
      "Epoch 8725/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 428.0286 - val_loss: 354.5813\n",
      "Epoch 8726/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 427.8618 - val_loss: 354.3948\n",
      "Epoch 8727/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 427.6951 - val_loss: 354.2827\n",
      "Epoch 8728/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 427.5286 - val_loss: 354.1367\n",
      "Epoch 8729/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 427.3620 - val_loss: 353.9814\n",
      "Epoch 8730/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 427.1955 - val_loss: 353.8725\n",
      "Epoch 8731/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 427.0291 - val_loss: 353.6939\n",
      "Epoch 8732/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 426.8628 - val_loss: 353.5909\n",
      "Epoch 8733/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 426.6965 - val_loss: 353.4248\n",
      "Epoch 8734/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 426.5303 - val_loss: 353.2953\n",
      "Epoch 8735/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 426.3641 - val_loss: 353.1624\n",
      "Epoch 8736/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 426.1981 - val_loss: 353.0024\n",
      "Epoch 8737/100000\n",
      "11/11 [==============================] - 0s 699us/step - loss: 426.0320 - val_loss: 352.8904\n",
      "Epoch 8738/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 425.8661 - val_loss: 352.7241\n",
      "Epoch 8739/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 425.7003 - val_loss: 352.6041\n",
      "Epoch 8740/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 425.5345 - val_loss: 352.4571\n",
      "Epoch 8741/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 425.3686 - val_loss: 352.3127\n",
      "Epoch 8742/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 425.2029 - val_loss: 352.1888\n",
      "Epoch 8743/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 425.0373 - val_loss: 352.0292\n",
      "Epoch 8744/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 424.8718 - val_loss: 351.9100\n",
      "Epoch 8745/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 424.7062 - val_loss: 351.7567\n",
      "Epoch 8746/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 424.5408 - val_loss: 351.6233\n",
      "Epoch 8747/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 424.3755 - val_loss: 351.4883\n",
      "Epoch 8748/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 424.2103 - val_loss: 351.3381\n",
      "Epoch 8749/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 424.0450 - val_loss: 351.2146\n",
      "Epoch 8750/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 423.8798 - val_loss: 351.0608\n",
      "Epoch 8751/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 423.7147 - val_loss: 350.9335\n",
      "Epoch 8752/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 423.5497 - val_loss: 350.7898\n",
      "Epoch 8753/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 423.3846 - val_loss: 350.6496\n",
      "Epoch 8754/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 423.2198 - val_loss: 350.5185\n",
      "Epoch 8755/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 423.0548 - val_loss: 350.3693\n",
      "Epoch 8756/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 422.8900 - val_loss: 350.2426\n",
      "Epoch 8757/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 422.7255 - val_loss: 350.0948\n",
      "Epoch 8758/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 422.5607 - val_loss: 349.9622\n",
      "Epoch 8759/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 422.3962 - val_loss: 349.8232\n",
      "Epoch 8760/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 422.2316 - val_loss: 349.6816\n",
      "Epoch 8761/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 422.0672 - val_loss: 349.5504\n",
      "Epoch 8762/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 421.9028 - val_loss: 349.4041\n",
      "Epoch 8763/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 421.7385 - val_loss: 349.2743\n",
      "Epoch 8764/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 421.5741 - val_loss: 349.1303\n",
      "Epoch 8765/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 421.4100 - val_loss: 348.9959\n",
      "Epoch 8766/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 421.2458 - val_loss: 348.8581\n",
      "Epoch 8767/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 421.0817 - val_loss: 348.7177\n",
      "Epoch 8768/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 420.9177 - val_loss: 348.5850\n",
      "Epoch 8769/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 420.7537 - val_loss: 348.4416\n",
      "Epoch 8770/100000\n",
      "11/11 [==============================] - 0s 201us/step - loss: 420.5899 - val_loss: 348.3101\n",
      "Epoch 8771/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 420.4261 - val_loss: 348.1678\n",
      "Epoch 8772/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 420.2623 - val_loss: 348.0338\n",
      "Epoch 8773/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 420.0985 - val_loss: 347.8952\n",
      "Epoch 8774/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 419.9350 - val_loss: 347.7574\n",
      "Epoch 8775/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 419.7714 - val_loss: 347.6226\n",
      "Epoch 8776/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 419.6078 - val_loss: 347.4821\n",
      "Epoch 8777/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 419.4445 - val_loss: 347.3493\n",
      "Epoch 8778/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 419.2811 - val_loss: 347.2081\n",
      "Epoch 8779/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 419.1176 - val_loss: 347.0749\n",
      "Epoch 8780/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 418.9545 - val_loss: 346.9354\n",
      "Epoch 8781/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 418.7912 - val_loss: 346.8003\n",
      "Epoch 8782/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 418.6281 - val_loss: 346.6632\n",
      "Epoch 8783/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 418.4651 - val_loss: 346.5259\n",
      "Epoch 8784/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 418.3021 - val_loss: 346.3911\n",
      "Epoch 8785/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 418.1392 - val_loss: 346.2522\n",
      "Epoch 8786/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 417.9763 - val_loss: 346.1185\n",
      "Epoch 8787/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 417.8135 - val_loss: 345.9792\n",
      "Epoch 8788/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 417.6507 - val_loss: 345.8458\n",
      "Epoch 8789/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 417.4880 - val_loss: 345.7070\n",
      "Epoch 8790/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 417.3254 - val_loss: 345.5731\n",
      "Epoch 8791/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 417.1629 - val_loss: 345.4353\n",
      "Epoch 8792/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 417.0004 - val_loss: 345.3003\n",
      "Epoch 8793/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 416.8379 - val_loss: 345.1638\n",
      "Epoch 8794/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 416.6755 - val_loss: 345.0278\n",
      "Epoch 8795/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 416.5131 - val_loss: 344.8925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8796/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 416.3510 - val_loss: 344.7558\n",
      "Epoch 8797/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 416.1888 - val_loss: 344.6213\n",
      "Epoch 8798/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 416.0266 - val_loss: 344.4841\n",
      "Epoch 8799/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 415.8645 - val_loss: 344.3502\n",
      "Epoch 8800/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 415.7025 - val_loss: 344.2128\n",
      "Epoch 8801/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 415.5405 - val_loss: 344.0793\n",
      "Epoch 8802/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 415.3787 - val_loss: 343.9420\n",
      "Epoch 8803/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 415.2169 - val_loss: 343.8084\n",
      "Epoch 8804/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 415.0550 - val_loss: 343.6715\n",
      "Epoch 8805/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 414.8935 - val_loss: 343.5379\n",
      "Epoch 8806/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 414.7318 - val_loss: 343.4012\n",
      "Epoch 8807/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 414.5703 - val_loss: 343.2674\n",
      "Epoch 8808/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 414.4088 - val_loss: 343.1311\n",
      "Epoch 8809/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 414.2473 - val_loss: 342.9973\n",
      "Epoch 8810/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 414.0859 - val_loss: 342.8613\n",
      "Epoch 8811/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 413.9246 - val_loss: 342.7276\n",
      "Epoch 8812/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 413.7633 - val_loss: 342.5916\n",
      "Epoch 8813/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 413.6021 - val_loss: 342.4581\n",
      "Epoch 8814/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 413.4410 - val_loss: 342.3221\n",
      "Epoch 8815/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 413.2798 - val_loss: 342.1888\n",
      "Epoch 8816/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 413.1188 - val_loss: 342.0528\n",
      "Epoch 8817/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 412.9578 - val_loss: 341.9200\n",
      "Epoch 8818/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 412.7971 - val_loss: 341.7835\n",
      "Epoch 8819/100000\n",
      "11/11 [==============================] - 0s 719us/step - loss: 412.6361 - val_loss: 341.6517\n",
      "Epoch 8820/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 412.4754 - val_loss: 341.5144\n",
      "Epoch 8821/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 412.3148 - val_loss: 341.3839\n",
      "Epoch 8822/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 412.1541 - val_loss: 341.2451\n",
      "Epoch 8823/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 411.9935 - val_loss: 341.1167\n",
      "Epoch 8824/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 411.8330 - val_loss: 340.9754\n",
      "Epoch 8825/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 411.6725 - val_loss: 340.8506\n",
      "Epoch 8826/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 411.5121 - val_loss: 340.7050\n",
      "Epoch 8827/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 411.3517 - val_loss: 340.5862\n",
      "Epoch 8828/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 411.1915 - val_loss: 340.4330\n",
      "Epoch 8829/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 411.0312 - val_loss: 340.3242\n",
      "Epoch 8830/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 410.8711 - val_loss: 340.1585\n",
      "Epoch 8831/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 410.7111 - val_loss: 340.0657\n",
      "Epoch 8832/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 410.5510 - val_loss: 339.8811\n",
      "Epoch 8833/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 410.3909 - val_loss: 339.8088\n",
      "Epoch 8834/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 410.2311 - val_loss: 339.6067\n",
      "Epoch 8835/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 410.0713 - val_loss: 339.5430\n",
      "Epoch 8836/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 409.9115 - val_loss: 339.3493\n",
      "Epoch 8837/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 409.7518 - val_loss: 339.2561\n",
      "Epoch 8838/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 409.5919 - val_loss: 339.1101\n",
      "Epoch 8839/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 409.4323 - val_loss: 338.9622\n",
      "Epoch 8840/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 409.2728 - val_loss: 338.8652\n",
      "Epoch 8841/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 409.1132 - val_loss: 338.6861\n",
      "Epoch 8842/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 408.9538 - val_loss: 338.5959\n",
      "Epoch 8843/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 408.7945 - val_loss: 338.4355\n",
      "Epoch 8844/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 408.6351 - val_loss: 338.3082\n",
      "Epoch 8845/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 408.4759 - val_loss: 338.1913\n",
      "Epoch 8846/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 408.3166 - val_loss: 338.0282\n",
      "Epoch 8847/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 408.1575 - val_loss: 337.9297\n",
      "Epoch 8848/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 407.9985 - val_loss: 337.7703\n",
      "Epoch 8849/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 407.8394 - val_loss: 337.6494\n",
      "Epoch 8850/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 407.6805 - val_loss: 337.5227\n",
      "Epoch 8851/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 407.5215 - val_loss: 337.3708\n",
      "Epoch 8852/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 407.3628 - val_loss: 337.2642\n",
      "Epoch 8853/100000\n",
      "11/11 [==============================] - 0s 625us/step - loss: 407.2040 - val_loss: 337.1089\n",
      "Epoch 8854/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 407.0452 - val_loss: 336.9897\n",
      "Epoch 8855/100000\n",
      "11/11 [==============================] - 0s 604us/step - loss: 406.8865 - val_loss: 336.8577\n",
      "Epoch 8856/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 406.7279 - val_loss: 336.7136\n",
      "Epoch 8857/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 406.5694 - val_loss: 336.6005\n",
      "Epoch 8858/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 406.4109 - val_loss: 336.4493\n",
      "Epoch 8859/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 406.2524 - val_loss: 336.3306\n",
      "Epoch 8860/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 406.0940 - val_loss: 336.1950\n",
      "Epoch 8861/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 405.9358 - val_loss: 336.0573\n",
      "Epoch 8862/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 405.7775 - val_loss: 335.9384\n",
      "Epoch 8863/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 405.6193 - val_loss: 335.7917\n",
      "Epoch 8864/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 405.4612 - val_loss: 335.6724\n",
      "Epoch 8865/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 405.3031 - val_loss: 335.5347\n",
      "Epoch 8866/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 405.1451 - val_loss: 335.4019\n",
      "Epoch 8867/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 404.9872 - val_loss: 335.2782\n",
      "Epoch 8868/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 404.8293 - val_loss: 335.1355\n",
      "Epoch 8869/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 404.6714 - val_loss: 335.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8870/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 404.5136 - val_loss: 334.8763\n",
      "Epoch 8871/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 404.3559 - val_loss: 334.7477\n",
      "Epoch 8872/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 404.1982 - val_loss: 334.6194\n",
      "Epoch 8873/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 404.0406 - val_loss: 334.4815\n",
      "Epoch 8874/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 403.8832 - val_loss: 334.3592\n",
      "Epoch 8875/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 403.7257 - val_loss: 334.2202\n",
      "Epoch 8876/100000\n",
      "11/11 [==============================] - 0s 615us/step - loss: 403.5681 - val_loss: 334.0945\n",
      "Epoch 8877/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 403.4108 - val_loss: 333.9624\n",
      "Epoch 8878/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 403.2535 - val_loss: 333.8291\n",
      "Epoch 8879/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 403.0962 - val_loss: 333.7038\n",
      "Epoch 8880/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 402.9391 - val_loss: 333.5665\n",
      "Epoch 8881/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 402.7820 - val_loss: 333.4418\n",
      "Epoch 8882/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 402.6248 - val_loss: 333.3075\n",
      "Epoch 8883/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 402.4679 - val_loss: 333.1781\n",
      "Epoch 8884/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 402.3109 - val_loss: 333.0493\n",
      "Epoch 8885/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 402.1540 - val_loss: 332.9152\n",
      "Epoch 8886/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 401.9971 - val_loss: 332.7896\n",
      "Epoch 8887/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 401.8403 - val_loss: 332.6549\n",
      "Epoch 8888/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 401.6836 - val_loss: 332.5281\n",
      "Epoch 8889/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 401.5269 - val_loss: 332.3965\n",
      "Epoch 8890/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 401.3704 - val_loss: 332.2660\n",
      "Epoch 8891/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 401.2138 - val_loss: 332.1381\n",
      "Epoch 8892/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 401.0573 - val_loss: 332.0051\n",
      "Epoch 8893/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 400.9009 - val_loss: 331.8786\n",
      "Epoch 8894/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 400.7445 - val_loss: 331.7457\n",
      "Epoch 8895/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 400.5883 - val_loss: 331.6181\n",
      "Epoch 8896/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 400.4319 - val_loss: 331.4876\n",
      "Epoch 8897/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 400.2758 - val_loss: 331.3574\n",
      "Epoch 8898/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 400.1195 - val_loss: 331.2296\n",
      "Epoch 8899/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 399.9635 - val_loss: 331.0975\n",
      "Epoch 8900/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 399.8074 - val_loss: 330.9709\n",
      "Epoch 8901/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 399.6514 - val_loss: 330.8388\n",
      "Epoch 8902/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 399.4955 - val_loss: 330.7115\n",
      "Epoch 8903/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 399.3396 - val_loss: 330.5812\n",
      "Epoch 8904/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 399.1839 - val_loss: 330.4521\n",
      "Epoch 8905/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 399.0281 - val_loss: 330.3237\n",
      "Epoch 8906/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 398.8724 - val_loss: 330.1932\n",
      "Epoch 8907/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 398.7167 - val_loss: 330.0658\n",
      "Epoch 8908/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 398.5612 - val_loss: 329.9352\n",
      "Epoch 8909/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 398.4057 - val_loss: 329.8077\n",
      "Epoch 8910/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 398.2502 - val_loss: 329.6778\n",
      "Epoch 8911/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 398.0949 - val_loss: 329.5496\n",
      "Epoch 8912/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 397.9395 - val_loss: 329.4208\n",
      "Epoch 8913/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 397.7843 - val_loss: 329.2917\n",
      "Epoch 8914/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 397.6290 - val_loss: 329.1638\n",
      "Epoch 8915/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 397.4737 - val_loss: 329.0343\n",
      "Epoch 8916/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 397.3187 - val_loss: 328.9070\n",
      "Epoch 8917/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 397.1636 - val_loss: 328.7771\n",
      "Epoch 8918/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 397.0086 - val_loss: 328.6502\n",
      "Epoch 8919/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 396.8536 - val_loss: 328.5207\n",
      "Epoch 8920/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 396.6989 - val_loss: 328.3933\n",
      "Epoch 8921/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 396.5440 - val_loss: 328.2645\n",
      "Epoch 8922/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 396.3892 - val_loss: 328.1366\n",
      "Epoch 8923/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 396.2344 - val_loss: 328.0086\n",
      "Epoch 8924/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 396.0797 - val_loss: 327.8802\n",
      "Epoch 8925/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 395.9251 - val_loss: 327.7529\n",
      "Epoch 8926/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 395.7706 - val_loss: 327.6241\n",
      "Epoch 8927/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 395.6161 - val_loss: 327.4972\n",
      "Epoch 8928/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 395.4616 - val_loss: 327.3683\n",
      "Epoch 8929/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 395.3072 - val_loss: 327.2417\n",
      "Epoch 8930/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 395.1530 - val_loss: 327.1131\n",
      "Epoch 8931/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 394.9987 - val_loss: 326.9864\n",
      "Epoch 8932/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 394.8445 - val_loss: 326.8580\n",
      "Epoch 8933/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 394.6903 - val_loss: 326.7311\n",
      "Epoch 8934/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 394.5362 - val_loss: 326.6033\n",
      "Epoch 8935/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 394.3822 - val_loss: 326.4761\n",
      "Epoch 8936/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 394.2281 - val_loss: 326.3487\n",
      "Epoch 8937/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 394.0742 - val_loss: 326.2215\n",
      "Epoch 8938/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 393.9204 - val_loss: 326.0942\n",
      "Epoch 8939/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 393.7666 - val_loss: 325.9671\n",
      "Epoch 8940/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 393.6128 - val_loss: 325.8400\n",
      "Epoch 8941/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 393.4590 - val_loss: 325.7130\n",
      "Epoch 8942/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 393.3054 - val_loss: 325.5859\n",
      "Epoch 8943/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 393.1517 - val_loss: 325.4592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8944/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 392.9983 - val_loss: 325.3322\n",
      "Epoch 8945/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 392.8448 - val_loss: 325.2055\n",
      "Epoch 8946/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 392.6913 - val_loss: 325.0785\n",
      "Epoch 8947/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 392.5379 - val_loss: 324.9523\n",
      "Epoch 8948/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 392.3846 - val_loss: 324.8251\n",
      "Epoch 8949/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 392.2314 - val_loss: 324.6992\n",
      "Epoch 8950/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 392.0782 - val_loss: 324.5720\n",
      "Epoch 8951/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 391.9250 - val_loss: 324.4465\n",
      "Epoch 8952/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 391.7719 - val_loss: 324.3189\n",
      "Epoch 8953/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 391.6189 - val_loss: 324.1939\n",
      "Epoch 8954/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 391.4658 - val_loss: 324.0660\n",
      "Epoch 8955/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 391.3129 - val_loss: 323.9417\n",
      "Epoch 8956/100000\n",
      "11/11 [==============================] - 0s 690us/step - loss: 391.1601 - val_loss: 323.8134\n",
      "Epoch 8957/100000\n",
      "11/11 [==============================] - 0s 200us/step - loss: 391.0072 - val_loss: 323.6899\n",
      "Epoch 8958/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 390.8545 - val_loss: 323.5609\n",
      "Epoch 8959/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 390.7018 - val_loss: 323.4384\n",
      "Epoch 8960/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 390.5491 - val_loss: 323.3081\n",
      "Epoch 8961/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 390.3965 - val_loss: 323.1877\n",
      "Epoch 8962/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 390.2439 - val_loss: 323.0551\n",
      "Epoch 8963/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 390.0914 - val_loss: 322.9380\n",
      "Epoch 8964/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 389.9390 - val_loss: 322.8013\n",
      "Epoch 8965/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 389.7867 - val_loss: 322.6898\n",
      "Epoch 8966/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 389.6343 - val_loss: 322.5460\n",
      "Epoch 8967/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 389.4821 - val_loss: 322.4442\n",
      "Epoch 8968/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 389.3299 - val_loss: 322.2881\n",
      "Epoch 8969/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 389.1777 - val_loss: 322.2021\n",
      "Epoch 8970/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 389.0257 - val_loss: 322.0271\n",
      "Epoch 8971/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 388.8736 - val_loss: 321.9624\n",
      "Epoch 8972/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 388.7216 - val_loss: 321.7672\n",
      "Epoch 8973/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 388.5696 - val_loss: 321.7160\n",
      "Epoch 8974/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 388.4178 - val_loss: 321.5227\n",
      "Epoch 8975/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 388.2659 - val_loss: 321.4483\n",
      "Epoch 8976/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 388.1141 - val_loss: 321.2995\n",
      "Epoch 8977/100000\n",
      "11/11 [==============================] - 0s 204us/step - loss: 387.9624 - val_loss: 321.1682\n",
      "Epoch 8978/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 387.8107 - val_loss: 321.0753\n",
      "Epoch 8979/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 387.6591 - val_loss: 320.9037\n",
      "Epoch 8980/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 387.5075 - val_loss: 320.8265\n",
      "Epoch 8981/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 387.3560 - val_loss: 320.6671\n",
      "Epoch 8982/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 387.2046 - val_loss: 320.5551\n",
      "Epoch 8983/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 387.0531 - val_loss: 320.4416\n",
      "Epoch 8984/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 386.9017 - val_loss: 320.2879\n",
      "Epoch 8985/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 386.7504 - val_loss: 320.1999\n",
      "Epoch 8986/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 386.5993 - val_loss: 320.0442\n",
      "Epoch 8987/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 386.4481 - val_loss: 319.9363\n",
      "Epoch 8988/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 386.2970 - val_loss: 319.8142\n",
      "Epoch 8989/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 386.1458 - val_loss: 319.6716\n",
      "Epoch 8990/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 385.9948 - val_loss: 319.5742\n",
      "Epoch 8991/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 385.8438 - val_loss: 319.4246\n",
      "Epoch 8992/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 385.6929 - val_loss: 319.3163\n",
      "Epoch 8993/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 385.5420 - val_loss: 319.1906\n",
      "Epoch 8994/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 385.3911 - val_loss: 319.0551\n",
      "Epoch 8995/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 385.2406 - val_loss: 318.9509\n",
      "Epoch 8996/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 385.0898 - val_loss: 318.8065\n",
      "Epoch 8997/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 384.9392 - val_loss: 318.6971\n",
      "Epoch 8998/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 384.7885 - val_loss: 318.5693\n",
      "Epoch 8999/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 384.6380 - val_loss: 318.4391\n",
      "Epoch 9000/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 384.4875 - val_loss: 318.3295\n",
      "Epoch 9001/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 384.3372 - val_loss: 318.1898\n",
      "Epoch 9002/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 384.1867 - val_loss: 318.0792\n",
      "Epoch 9003/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 384.0364 - val_loss: 317.9499\n",
      "Epoch 9004/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 383.8861 - val_loss: 317.8242\n",
      "Epoch 9005/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 383.7359 - val_loss: 317.7098\n",
      "Epoch 9006/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 383.5858 - val_loss: 317.5744\n",
      "Epoch 9007/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 383.4356 - val_loss: 317.4624\n",
      "Epoch 9008/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 383.2856 - val_loss: 317.3323\n",
      "Epoch 9009/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 383.1356 - val_loss: 317.2101\n",
      "Epoch 9010/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 382.9856 - val_loss: 317.0919\n",
      "Epoch 9011/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 382.8358 - val_loss: 316.9604\n",
      "Epoch 9012/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 382.6859 - val_loss: 316.8467\n",
      "Epoch 9013/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 382.5361 - val_loss: 316.7167\n",
      "Epoch 9014/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 382.3863 - val_loss: 316.5972\n",
      "Epoch 9015/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 382.2367 - val_loss: 316.4756\n",
      "Epoch 9016/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 382.0871 - val_loss: 316.3481\n",
      "Epoch 9017/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 381.9375 - val_loss: 316.2322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9018/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 381.7880 - val_loss: 316.1029\n",
      "Epoch 9019/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 381.6385 - val_loss: 315.9853\n",
      "Epoch 9020/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 381.4892 - val_loss: 315.8610\n",
      "Epoch 9021/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 381.3398 - val_loss: 315.7371\n",
      "Epoch 9022/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 381.1904 - val_loss: 315.6186\n",
      "Epoch 9023/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 381.0411 - val_loss: 315.4912\n",
      "Epoch 9024/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 380.8919 - val_loss: 315.3739\n",
      "Epoch 9025/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 380.7428 - val_loss: 315.2483\n",
      "Epoch 9026/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 380.5938 - val_loss: 315.1274\n",
      "Epoch 9027/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 380.4446 - val_loss: 315.0064\n",
      "Epoch 9028/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 380.2957 - val_loss: 314.8815\n",
      "Epoch 9029/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 380.1467 - val_loss: 314.7633\n",
      "Epoch 9030/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 379.9978 - val_loss: 314.6378\n",
      "Epoch 9031/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 379.8490 - val_loss: 314.5186\n",
      "Epoch 9032/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 379.7002 - val_loss: 314.3956\n",
      "Epoch 9033/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 379.5515 - val_loss: 314.2735\n",
      "Epoch 9034/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 379.4028 - val_loss: 314.1535\n",
      "Epoch 9035/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 379.2542 - val_loss: 314.0293\n",
      "Epoch 9036/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 379.1055 - val_loss: 313.9106\n",
      "Epoch 9037/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 378.9572 - val_loss: 313.7868\n",
      "Epoch 9038/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 378.8088 - val_loss: 313.6668\n",
      "Epoch 9039/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 378.6603 - val_loss: 313.5449\n",
      "Epoch 9040/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 378.5118 - val_loss: 313.4231\n",
      "Epoch 9041/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 378.3636 - val_loss: 313.3031\n",
      "Epoch 9042/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 378.2153 - val_loss: 313.1801\n",
      "Epoch 9043/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 378.0671 - val_loss: 313.0608\n",
      "Epoch 9044/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 377.9190 - val_loss: 312.9380\n",
      "Epoch 9045/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 377.7708 - val_loss: 312.8181\n",
      "Epoch 9046/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 377.6228 - val_loss: 312.6967\n",
      "Epoch 9047/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 377.4749 - val_loss: 312.5755\n",
      "Epoch 9048/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 377.3269 - val_loss: 312.4555\n",
      "Epoch 9049/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 377.1790 - val_loss: 312.3334\n",
      "Epoch 9050/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 377.0312 - val_loss: 312.2140\n",
      "Epoch 9051/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 376.8833 - val_loss: 312.0919\n",
      "Epoch 9052/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 376.7356 - val_loss: 311.9723\n",
      "Epoch 9053/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 376.5879 - val_loss: 311.8511\n",
      "Epoch 9054/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 376.4403 - val_loss: 311.7308\n",
      "Epoch 9055/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 376.2927 - val_loss: 311.6103\n",
      "Epoch 9056/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 376.1451 - val_loss: 311.4896\n",
      "Epoch 9057/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 375.9978 - val_loss: 311.3698\n",
      "Epoch 9058/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 375.8503 - val_loss: 311.2488\n",
      "Epoch 9059/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 375.7030 - val_loss: 311.1294\n",
      "Epoch 9060/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 375.5557 - val_loss: 311.0083\n",
      "Epoch 9061/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 375.4084 - val_loss: 310.8889\n",
      "Epoch 9062/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 375.2612 - val_loss: 310.7683\n",
      "Epoch 9063/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 375.1141 - val_loss: 310.6484\n",
      "Epoch 9064/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 374.9668 - val_loss: 310.5285\n",
      "Epoch 9065/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 374.8198 - val_loss: 310.4082\n",
      "Epoch 9066/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 374.6728 - val_loss: 310.2889\n",
      "Epoch 9067/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 374.5258 - val_loss: 310.1682\n",
      "Epoch 9068/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 374.3789 - val_loss: 310.0495\n",
      "Epoch 9069/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 374.2321 - val_loss: 309.9288\n",
      "Epoch 9070/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 374.0854 - val_loss: 309.8101\n",
      "Epoch 9071/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 373.9385 - val_loss: 309.6896\n",
      "Epoch 9072/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 373.7919 - val_loss: 309.5708\n",
      "Epoch 9073/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 373.6452 - val_loss: 309.4508\n",
      "Epoch 9074/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 373.4986 - val_loss: 309.3315\n",
      "Epoch 9075/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 373.3521 - val_loss: 309.2124\n",
      "Epoch 9076/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 373.2056 - val_loss: 309.0925\n",
      "Epoch 9077/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 373.0591 - val_loss: 308.9741\n",
      "Epoch 9078/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 372.9128 - val_loss: 308.8539\n",
      "Epoch 9079/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 372.7664 - val_loss: 308.7358\n",
      "Epoch 9080/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 372.6201 - val_loss: 308.6157\n",
      "Epoch 9081/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 372.4739 - val_loss: 308.4975\n",
      "Epoch 9082/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 372.3277 - val_loss: 308.3778\n",
      "Epoch 9083/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 372.1815 - val_loss: 308.2594\n",
      "Epoch 9084/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 372.0355 - val_loss: 308.1402\n",
      "Epoch 9085/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 371.8894 - val_loss: 308.0214\n",
      "Epoch 9086/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 371.7434 - val_loss: 307.9029\n",
      "Epoch 9087/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 371.5975 - val_loss: 307.7837\n",
      "Epoch 9088/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 371.4517 - val_loss: 307.6657\n",
      "Epoch 9089/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 371.3058 - val_loss: 307.5464\n",
      "Epoch 9090/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 371.1600 - val_loss: 307.4287\n",
      "Epoch 9091/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 371.0144 - val_loss: 307.3092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9092/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 370.8687 - val_loss: 307.1919\n",
      "Epoch 9093/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 370.7231 - val_loss: 307.0723\n",
      "Epoch 9094/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 370.5775 - val_loss: 306.9552\n",
      "Epoch 9095/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 370.4320 - val_loss: 306.8357\n",
      "Epoch 9096/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 370.2865 - val_loss: 306.7189\n",
      "Epoch 9097/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 370.1411 - val_loss: 306.5992\n",
      "Epoch 9098/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 369.9957 - val_loss: 306.4827\n",
      "Epoch 9099/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 369.8504 - val_loss: 306.3630\n",
      "Epoch 9100/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 369.7052 - val_loss: 306.2467\n",
      "Epoch 9101/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 369.5599 - val_loss: 306.1270\n",
      "Epoch 9102/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 369.4147 - val_loss: 306.0110\n",
      "Epoch 9103/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 369.2697 - val_loss: 305.8912\n",
      "Epoch 9104/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 369.1246 - val_loss: 305.7756\n",
      "Epoch 9105/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 368.9796 - val_loss: 305.6553\n",
      "Epoch 9106/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 368.8346 - val_loss: 305.5406\n",
      "Epoch 9107/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 368.6897 - val_loss: 305.4197\n",
      "Epoch 9108/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 368.5450 - val_loss: 305.3060\n",
      "Epoch 9109/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 368.4001 - val_loss: 305.1841\n",
      "Epoch 9110/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 368.2553 - val_loss: 305.0718\n",
      "Epoch 9111/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 368.1107 - val_loss: 304.9483\n",
      "Epoch 9112/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 367.9660 - val_loss: 304.8382\n",
      "Epoch 9113/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 367.8214 - val_loss: 304.7123\n",
      "Epoch 9114/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 367.6769 - val_loss: 304.6055\n",
      "Epoch 9115/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 367.5323 - val_loss: 304.4756\n",
      "Epoch 9116/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 367.3878 - val_loss: 304.3740\n",
      "Epoch 9117/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 367.2434 - val_loss: 304.2379\n",
      "Epoch 9118/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 367.0991 - val_loss: 304.1444\n",
      "Epoch 9119/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 366.9549 - val_loss: 303.9987\n",
      "Epoch 9120/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 366.8105 - val_loss: 303.9167\n",
      "Epoch 9121/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 366.6664 - val_loss: 303.7582\n",
      "Epoch 9122/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 366.5223 - val_loss: 303.6899\n",
      "Epoch 9123/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 366.3782 - val_loss: 303.5190\n",
      "Epoch 9124/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 366.2343 - val_loss: 303.4597\n",
      "Epoch 9125/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 366.0902 - val_loss: 303.2870\n",
      "Epoch 9126/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 365.9462 - val_loss: 303.2194\n",
      "Epoch 9127/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 365.8024 - val_loss: 303.0669\n",
      "Epoch 9128/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 365.6584 - val_loss: 302.9689\n",
      "Epoch 9129/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 365.5146 - val_loss: 302.8527\n",
      "Epoch 9130/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 365.3708 - val_loss: 302.7193\n",
      "Epoch 9131/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 365.2272 - val_loss: 302.6326\n",
      "Epoch 9132/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 365.0836 - val_loss: 302.4806\n",
      "Epoch 9133/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 364.9400 - val_loss: 302.3993\n",
      "Epoch 9134/100000\n",
      "11/11 [==============================] - 0s 702us/step - loss: 364.7964 - val_loss: 302.2556\n",
      "Epoch 9135/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 364.6530 - val_loss: 302.1552\n",
      "Epoch 9136/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 364.5095 - val_loss: 302.0373\n",
      "Epoch 9137/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 364.3661 - val_loss: 301.9103\n",
      "Epoch 9138/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 364.2227 - val_loss: 301.8149\n",
      "Epoch 9139/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 364.0795 - val_loss: 301.6740\n",
      "Epoch 9140/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 363.9362 - val_loss: 301.5822\n",
      "Epoch 9141/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 363.7930 - val_loss: 301.4483\n",
      "Epoch 9142/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 363.6499 - val_loss: 301.3417\n",
      "Epoch 9143/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 363.5067 - val_loss: 301.2269\n",
      "Epoch 9144/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 363.3638 - val_loss: 301.1018\n",
      "Epoch 9145/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 363.2208 - val_loss: 301.0019\n",
      "Epoch 9146/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 363.0779 - val_loss: 300.8684\n",
      "Epoch 9147/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 362.9350 - val_loss: 300.7697\n",
      "Epoch 9148/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 362.7922 - val_loss: 300.6420\n",
      "Epoch 9149/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 362.6494 - val_loss: 300.5325\n",
      "Epoch 9150/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 362.5066 - val_loss: 300.4182\n",
      "Epoch 9151/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 362.3638 - val_loss: 300.2959\n",
      "Epoch 9152/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 362.2212 - val_loss: 300.1920\n",
      "Epoch 9153/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 362.0787 - val_loss: 300.0641\n",
      "Epoch 9154/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 361.9362 - val_loss: 299.9608\n",
      "Epoch 9155/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 361.7936 - val_loss: 299.8371\n",
      "Epoch 9156/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 361.6512 - val_loss: 299.7265\n",
      "Epoch 9157/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 361.5087 - val_loss: 299.6120\n",
      "Epoch 9158/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 361.3664 - val_loss: 299.4926\n",
      "Epoch 9159/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 361.2242 - val_loss: 299.3854\n",
      "Epoch 9160/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 361.0819 - val_loss: 299.2617\n",
      "Epoch 9161/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 360.9397 - val_loss: 299.1558\n",
      "Epoch 9162/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 360.7976 - val_loss: 299.0340\n",
      "Epoch 9163/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 360.6554 - val_loss: 298.9240\n",
      "Epoch 9164/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 360.5135 - val_loss: 298.8080\n",
      "Epoch 9165/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 360.3714 - val_loss: 298.6920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9166/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 360.2295 - val_loss: 298.5816\n",
      "Epoch 9167/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 360.0876 - val_loss: 298.4617\n",
      "Epoch 9168/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 359.9458 - val_loss: 298.3535\n",
      "Epoch 9169/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 359.8040 - val_loss: 298.2335\n",
      "Epoch 9170/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 359.6623 - val_loss: 298.1240\n",
      "Epoch 9171/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 359.5206 - val_loss: 298.0067\n",
      "Epoch 9172/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 359.3789 - val_loss: 297.8938\n",
      "Epoch 9173/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 359.2372 - val_loss: 297.7805\n",
      "Epoch 9174/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 359.0957 - val_loss: 297.6642\n",
      "Epoch 9175/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 358.9542 - val_loss: 297.5538\n",
      "Epoch 9176/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 358.8128 - val_loss: 297.4358\n",
      "Epoch 9177/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 358.6714 - val_loss: 297.3261\n",
      "Epoch 9178/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 358.5301 - val_loss: 297.2087\n",
      "Epoch 9179/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 358.3888 - val_loss: 297.0977\n",
      "Epoch 9180/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 358.2476 - val_loss: 296.9825\n",
      "Epoch 9181/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 358.1064 - val_loss: 296.8694\n",
      "Epoch 9182/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 357.9653 - val_loss: 296.7563\n",
      "Epoch 9183/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 357.8240 - val_loss: 296.6413\n",
      "Epoch 9184/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 357.6830 - val_loss: 296.5299\n",
      "Epoch 9185/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 357.5420 - val_loss: 296.4142\n",
      "Epoch 9186/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 357.4010 - val_loss: 296.3032\n",
      "Epoch 9187/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 357.2601 - val_loss: 296.1877\n",
      "Epoch 9188/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 357.1193 - val_loss: 296.0763\n",
      "Epoch 9189/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 356.9785 - val_loss: 295.9618\n",
      "Epoch 9190/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 356.8378 - val_loss: 295.8494\n",
      "Epoch 9191/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 356.6971 - val_loss: 295.7363\n",
      "Epoch 9192/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 356.5565 - val_loss: 295.6228\n",
      "Epoch 9193/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 356.4158 - val_loss: 295.5107\n",
      "Epoch 9194/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 356.2753 - val_loss: 295.3965\n",
      "Epoch 9195/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 356.1348 - val_loss: 295.2852\n",
      "Epoch 9196/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 355.9943 - val_loss: 295.1707\n",
      "Epoch 9197/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 355.8539 - val_loss: 295.0594\n",
      "Epoch 9198/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 355.7135 - val_loss: 294.9453\n",
      "Epoch 9199/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 355.5732 - val_loss: 294.8340\n",
      "Epoch 9200/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 355.4330 - val_loss: 294.7201\n",
      "Epoch 9201/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 355.2927 - val_loss: 294.6087\n",
      "Epoch 9202/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 355.1526 - val_loss: 294.4953\n",
      "Epoch 9203/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 355.0125 - val_loss: 294.3836\n",
      "Epoch 9204/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 354.8724 - val_loss: 294.2707\n",
      "Epoch 9205/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 354.7325 - val_loss: 294.1586\n",
      "Epoch 9206/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 354.5925 - val_loss: 294.0462\n",
      "Epoch 9207/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 354.4525 - val_loss: 293.9338\n",
      "Epoch 9208/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 354.3126 - val_loss: 293.8220\n",
      "Epoch 9209/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 354.1728 - val_loss: 293.7093\n",
      "Epoch 9210/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 354.0331 - val_loss: 293.5979\n",
      "Epoch 9211/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 353.8933 - val_loss: 293.4850\n",
      "Epoch 9212/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 353.7536 - val_loss: 293.3740\n",
      "Epoch 9213/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 353.6141 - val_loss: 293.2611\n",
      "Epoch 9214/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 353.4745 - val_loss: 293.1503\n",
      "Epoch 9215/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 353.3351 - val_loss: 293.0374\n",
      "Epoch 9216/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 353.1956 - val_loss: 292.9266\n",
      "Epoch 9217/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 353.0560 - val_loss: 292.8139\n",
      "Epoch 9218/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 352.9167 - val_loss: 292.7033\n",
      "Epoch 9219/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 352.7775 - val_loss: 292.5906\n",
      "Epoch 9220/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 352.6381 - val_loss: 292.4802\n",
      "Epoch 9221/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 352.4989 - val_loss: 292.3673\n",
      "Epoch 9222/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 352.3597 - val_loss: 292.2573\n",
      "Epoch 9223/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 352.2205 - val_loss: 292.1443\n",
      "Epoch 9224/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 352.0815 - val_loss: 292.0347\n",
      "Epoch 9225/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 351.9425 - val_loss: 291.9215\n",
      "Epoch 9226/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 351.8034 - val_loss: 291.8124\n",
      "Epoch 9227/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 351.6646 - val_loss: 291.6988\n",
      "Epoch 9228/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 351.5257 - val_loss: 291.5904\n",
      "Epoch 9229/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 351.3868 - val_loss: 291.4761\n",
      "Epoch 9230/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 351.2481 - val_loss: 291.3687\n",
      "Epoch 9231/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 351.1093 - val_loss: 291.2534\n",
      "Epoch 9232/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 350.9706 - val_loss: 291.1475\n",
      "Epoch 9233/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 350.8320 - val_loss: 291.0306\n",
      "Epoch 9234/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 350.6933 - val_loss: 290.9269\n",
      "Epoch 9235/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 350.5548 - val_loss: 290.8077\n",
      "Epoch 9236/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 350.4164 - val_loss: 290.7071\n",
      "Epoch 9237/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 350.2779 - val_loss: 290.5841\n",
      "Epoch 9238/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 350.1395 - val_loss: 290.4884\n",
      "Epoch 9239/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 350.0012 - val_loss: 290.3597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9240/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 349.8630 - val_loss: 290.2713\n",
      "Epoch 9241/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 349.7247 - val_loss: 290.1339\n",
      "Epoch 9242/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 349.5865 - val_loss: 290.0561\n",
      "Epoch 9243/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 349.4483 - val_loss: 289.9065\n",
      "Epoch 9244/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 349.3102 - val_loss: 289.8423\n",
      "Epoch 9245/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 349.1721 - val_loss: 289.6794\n",
      "Epoch 9246/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 349.0341 - val_loss: 289.6263\n",
      "Epoch 9247/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 348.8963 - val_loss: 289.4584\n",
      "Epoch 9248/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 348.7584 - val_loss: 289.4011\n",
      "Epoch 9249/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 348.6205 - val_loss: 289.2491\n",
      "Epoch 9250/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 348.4826 - val_loss: 289.1648\n",
      "Epoch 9251/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 348.3448 - val_loss: 289.0478\n",
      "Epoch 9252/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 348.2072 - val_loss: 288.9271\n",
      "Epoch 9253/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 348.0696 - val_loss: 288.8424\n",
      "Epoch 9254/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 347.9320 - val_loss: 288.6988\n",
      "Epoch 9255/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 347.7944 - val_loss: 288.6246\n",
      "Epoch 9256/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 347.6568 - val_loss: 288.4840\n",
      "Epoch 9257/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 347.5193 - val_loss: 288.3950\n",
      "Epoch 9258/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 347.3819 - val_loss: 288.2780\n",
      "Epoch 9259/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 347.2444 - val_loss: 288.1621\n",
      "Epoch 9260/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 347.1071 - val_loss: 288.0700\n",
      "Epoch 9261/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 346.9699 - val_loss: 287.9366\n",
      "Epoch 9262/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 346.8327 - val_loss: 287.8523\n",
      "Epoch 9263/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 346.6956 - val_loss: 287.7219\n",
      "Epoch 9264/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 346.5585 - val_loss: 287.6258\n",
      "Epoch 9265/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 346.4214 - val_loss: 287.5130\n",
      "Epoch 9266/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 346.2843 - val_loss: 287.3979\n",
      "Epoch 9267/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 346.1474 - val_loss: 287.3019\n",
      "Epoch 9268/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 346.0104 - val_loss: 287.1756\n",
      "Epoch 9269/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 345.8735 - val_loss: 287.0838\n",
      "Epoch 9270/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 345.7367 - val_loss: 286.9610\n",
      "Epoch 9271/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 345.5999 - val_loss: 286.8600\n",
      "Epoch 9272/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 345.4632 - val_loss: 286.7498\n",
      "Epoch 9273/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 345.3264 - val_loss: 286.6357\n",
      "Epoch 9274/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 345.1897 - val_loss: 286.5370\n",
      "Epoch 9275/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 345.0533 - val_loss: 286.4160\n",
      "Epoch 9276/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 344.9168 - val_loss: 286.3194\n",
      "Epoch 9277/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 344.7803 - val_loss: 286.2010\n",
      "Epoch 9278/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 344.6438 - val_loss: 286.0980\n",
      "Epoch 9279/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 344.5074 - val_loss: 285.9885\n",
      "Epoch 9280/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 344.3711 - val_loss: 285.8765\n",
      "Epoch 9281/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 344.2347 - val_loss: 285.7749\n",
      "Epoch 9282/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 344.0985 - val_loss: 285.6577\n",
      "Epoch 9283/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 343.9622 - val_loss: 285.5582\n",
      "Epoch 9284/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 343.8262 - val_loss: 285.4425\n",
      "Epoch 9285/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 343.6900 - val_loss: 285.3390\n",
      "Epoch 9286/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 343.5539 - val_loss: 285.2291\n",
      "Epoch 9287/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 343.4179 - val_loss: 285.1196\n",
      "Epoch 9288/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 343.2820 - val_loss: 285.0154\n",
      "Epoch 9289/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 343.1461 - val_loss: 284.9018\n",
      "Epoch 9290/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 343.0102 - val_loss: 284.7999\n",
      "Epoch 9291/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 342.8744 - val_loss: 284.6862\n",
      "Epoch 9292/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 342.7386 - val_loss: 284.5828\n",
      "Epoch 9293/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 342.6028 - val_loss: 284.4721\n",
      "Epoch 9294/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 342.4672 - val_loss: 284.3650\n",
      "Epoch 9295/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 342.3315 - val_loss: 284.2586\n",
      "Epoch 9296/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 342.1960 - val_loss: 284.1479\n",
      "Epoch 9297/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 342.0604 - val_loss: 284.0443\n",
      "Epoch 9298/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 341.9250 - val_loss: 283.9322\n",
      "Epoch 9299/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 341.7895 - val_loss: 283.8288\n",
      "Epoch 9300/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 341.6542 - val_loss: 283.7178\n",
      "Epoch 9301/100000\n",
      "11/11 [==============================] - 0s 608us/step - loss: 341.5189 - val_loss: 283.6128\n",
      "Epoch 9302/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 341.3835 - val_loss: 283.5042\n",
      "Epoch 9303/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 341.2484 - val_loss: 283.3967\n",
      "Epoch 9304/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 341.1132 - val_loss: 283.2906\n",
      "Epoch 9305/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 340.9781 - val_loss: 283.1814\n",
      "Epoch 9306/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 340.8430 - val_loss: 283.0765\n",
      "Epoch 9307/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 340.7079 - val_loss: 282.9667\n",
      "Epoch 9308/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 340.5729 - val_loss: 282.8620\n",
      "Epoch 9309/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 340.4379 - val_loss: 282.7529\n",
      "Epoch 9310/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 340.3030 - val_loss: 282.6473\n",
      "Epoch 9311/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 340.1682 - val_loss: 282.5395\n",
      "Epoch 9312/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 340.0334 - val_loss: 282.4327\n",
      "Epoch 9313/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 339.8987 - val_loss: 282.3264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9314/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 339.7640 - val_loss: 282.2185\n",
      "Epoch 9315/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 339.6293 - val_loss: 282.1131\n",
      "Epoch 9316/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 339.4948 - val_loss: 282.0048\n",
      "Epoch 9317/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 339.3602 - val_loss: 281.8997\n",
      "Epoch 9318/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 339.2257 - val_loss: 281.7915\n",
      "Epoch 9319/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 339.0912 - val_loss: 281.6861\n",
      "Epoch 9320/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 338.9568 - val_loss: 281.5787\n",
      "Epoch 9321/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 338.8224 - val_loss: 281.4727\n",
      "Epoch 9322/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 338.6881 - val_loss: 281.3661\n",
      "Epoch 9323/100000\n",
      "11/11 [==============================] - 0s 590us/step - loss: 338.5539 - val_loss: 281.2595\n",
      "Epoch 9324/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 338.4196 - val_loss: 281.1537\n",
      "Epoch 9325/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 338.2855 - val_loss: 281.0467\n",
      "Epoch 9326/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 338.1514 - val_loss: 280.9413\n",
      "Epoch 9327/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 338.0173 - val_loss: 280.8341\n",
      "Epoch 9328/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 337.8832 - val_loss: 280.7289\n",
      "Epoch 9329/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 337.7493 - val_loss: 280.6219\n",
      "Epoch 9330/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 337.6153 - val_loss: 280.5165\n",
      "Epoch 9331/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 337.4813 - val_loss: 280.4099\n",
      "Epoch 9332/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 337.3476 - val_loss: 280.3044\n",
      "Epoch 9333/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 337.2138 - val_loss: 280.1981\n",
      "Epoch 9334/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 337.0800 - val_loss: 280.0925\n",
      "Epoch 9335/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 336.9464 - val_loss: 279.9865\n",
      "Epoch 9336/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 336.8127 - val_loss: 279.8806\n",
      "Epoch 9337/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 336.6791 - val_loss: 279.7752\n",
      "Epoch 9338/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 336.5456 - val_loss: 279.6693\n",
      "Epoch 9339/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 336.4121 - val_loss: 279.5639\n",
      "Epoch 9340/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 336.2788 - val_loss: 279.4579\n",
      "Epoch 9341/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 336.1452 - val_loss: 279.3529\n",
      "Epoch 9342/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 336.0120 - val_loss: 279.2469\n",
      "Epoch 9343/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 335.8786 - val_loss: 279.1419\n",
      "Epoch 9344/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 335.7453 - val_loss: 279.0359\n",
      "Epoch 9345/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 335.6122 - val_loss: 278.9311\n",
      "Epoch 9346/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 335.4789 - val_loss: 278.8252\n",
      "Epoch 9347/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 335.3459 - val_loss: 278.7205\n",
      "Epoch 9348/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 335.2127 - val_loss: 278.6148\n",
      "Epoch 9349/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 335.0797 - val_loss: 278.5101\n",
      "Epoch 9350/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 334.9467 - val_loss: 278.4047\n",
      "Epoch 9351/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 334.8138 - val_loss: 278.2998\n",
      "Epoch 9352/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 334.6810 - val_loss: 278.1947\n",
      "Epoch 9353/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 334.5481 - val_loss: 278.0897\n",
      "Epoch 9354/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 334.4154 - val_loss: 277.9850\n",
      "Epoch 9355/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 334.2827 - val_loss: 277.8796\n",
      "Epoch 9356/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 334.1500 - val_loss: 277.7754\n",
      "Epoch 9357/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 334.0173 - val_loss: 277.6697\n",
      "Epoch 9358/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 333.8847 - val_loss: 277.5660\n",
      "Epoch 9359/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 333.7522 - val_loss: 277.4600\n",
      "Epoch 9360/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 333.6196 - val_loss: 277.3570\n",
      "Epoch 9361/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 333.4873 - val_loss: 277.2505\n",
      "Epoch 9362/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 333.3549 - val_loss: 277.1482\n",
      "Epoch 9363/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 333.2225 - val_loss: 277.0411\n",
      "Epoch 9364/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 333.0903 - val_loss: 276.9397\n",
      "Epoch 9365/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 332.9580 - val_loss: 276.8317\n",
      "Epoch 9366/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 332.8259 - val_loss: 276.7316\n",
      "Epoch 9367/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 332.6937 - val_loss: 276.6221\n",
      "Epoch 9368/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 332.5616 - val_loss: 276.5239\n",
      "Epoch 9369/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 332.4295 - val_loss: 276.4125\n",
      "Epoch 9370/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 332.2975 - val_loss: 276.3168\n",
      "Epoch 9371/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 332.1654 - val_loss: 276.2023\n",
      "Epoch 9372/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 332.0336 - val_loss: 276.1110\n",
      "Epoch 9373/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 331.9017 - val_loss: 275.9914\n",
      "Epoch 9374/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 331.7699 - val_loss: 275.9065\n",
      "Epoch 9375/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 331.6381 - val_loss: 275.7790\n",
      "Epoch 9376/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 331.5065 - val_loss: 275.7041\n",
      "Epoch 9377/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 331.3747 - val_loss: 275.5648\n",
      "Epoch 9378/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 331.2431 - val_loss: 275.5036\n",
      "Epoch 9379/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 331.1116 - val_loss: 275.3499\n",
      "Epoch 9380/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 330.9801 - val_loss: 275.3026\n",
      "Epoch 9381/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 330.8486 - val_loss: 275.1388\n",
      "Epoch 9382/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 330.7172 - val_loss: 275.0940\n",
      "Epoch 9383/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 330.5859 - val_loss: 274.9393\n",
      "Epoch 9384/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 330.4543 - val_loss: 274.8723\n",
      "Epoch 9385/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 330.3230 - val_loss: 274.7510\n",
      "Epoch 9386/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 330.1917 - val_loss: 274.6453\n",
      "Epoch 9387/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 330.0605 - val_loss: 274.5619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9388/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 329.9294 - val_loss: 274.4263\n",
      "Epoch 9389/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 329.7984 - val_loss: 274.3605\n",
      "Epoch 9390/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 329.6673 - val_loss: 274.2220\n",
      "Epoch 9391/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 329.5362 - val_loss: 274.1447\n",
      "Epoch 9392/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 329.4052 - val_loss: 274.0294\n",
      "Epoch 9393/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 329.2744 - val_loss: 273.9233\n",
      "Epoch 9394/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 329.1434 - val_loss: 273.8360\n",
      "Epoch 9395/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 329.0127 - val_loss: 273.7090\n",
      "Epoch 9396/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 328.8819 - val_loss: 273.6324\n",
      "Epoch 9397/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 328.7512 - val_loss: 273.5067\n",
      "Epoch 9398/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 328.6205 - val_loss: 273.4182\n",
      "Epoch 9399/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 328.4899 - val_loss: 273.3114\n",
      "Epoch 9400/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 328.3593 - val_loss: 273.2021\n",
      "Epoch 9401/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 328.2287 - val_loss: 273.1139\n",
      "Epoch 9402/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 328.0983 - val_loss: 272.9926\n",
      "Epoch 9403/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 327.9679 - val_loss: 272.9081\n",
      "Epoch 9404/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 327.8374 - val_loss: 272.7916\n",
      "Epoch 9405/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 327.7072 - val_loss: 272.6959\n",
      "Epoch 9406/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 327.5768 - val_loss: 272.5941\n",
      "Epoch 9407/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 327.4466 - val_loss: 272.4842\n",
      "Epoch 9408/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 327.3164 - val_loss: 272.3935\n",
      "Epoch 9409/100000\n",
      "11/11 [==============================] - 0s 698us/step - loss: 327.1862 - val_loss: 272.2779\n",
      "Epoch 9410/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 327.0562 - val_loss: 272.1872\n",
      "Epoch 9411/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 326.9261 - val_loss: 272.0769\n",
      "Epoch 9412/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 326.7960 - val_loss: 271.9774\n",
      "Epoch 9413/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 326.6660 - val_loss: 271.8775\n",
      "Epoch 9414/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 326.5361 - val_loss: 271.7688\n",
      "Epoch 9415/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 326.4062 - val_loss: 271.6756\n",
      "Epoch 9416/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 326.2765 - val_loss: 271.5642\n",
      "Epoch 9417/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 326.1466 - val_loss: 271.4698\n",
      "Epoch 9418/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 326.0170 - val_loss: 271.3633\n",
      "Epoch 9419/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 325.8874 - val_loss: 271.2622\n",
      "Epoch 9420/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 325.7577 - val_loss: 271.1628\n",
      "Epoch 9421/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 325.6281 - val_loss: 271.0557\n",
      "Epoch 9422/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 325.4985 - val_loss: 270.9604\n",
      "Epoch 9423/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 325.3690 - val_loss: 270.8520\n",
      "Epoch 9424/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 325.2396 - val_loss: 270.7559\n",
      "Epoch 9425/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 325.1103 - val_loss: 270.6505\n",
      "Epoch 9426/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 324.9809 - val_loss: 270.5500\n",
      "Epoch 9427/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 324.8515 - val_loss: 270.4496\n",
      "Epoch 9428/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 324.7222 - val_loss: 270.3447\n",
      "Epoch 9429/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 324.5930 - val_loss: 270.2478\n",
      "Epoch 9430/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 324.4640 - val_loss: 270.1414\n",
      "Epoch 9431/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 324.3348 - val_loss: 270.0443\n",
      "Epoch 9432/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 324.2057 - val_loss: 269.9397\n",
      "Epoch 9433/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 324.0767 - val_loss: 269.8401\n",
      "Epoch 9434/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 323.9479 - val_loss: 269.7388\n",
      "Epoch 9435/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 323.8189 - val_loss: 269.6358\n",
      "Epoch 9436/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 323.6899 - val_loss: 269.5374\n",
      "Epoch 9437/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 323.5612 - val_loss: 269.4329\n",
      "Epoch 9438/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 323.4324 - val_loss: 269.3350\n",
      "Epoch 9439/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 323.3036 - val_loss: 269.2309\n",
      "Epoch 9440/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 323.1748 - val_loss: 269.1321\n",
      "Epoch 9441/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 323.0462 - val_loss: 269.0298\n",
      "Epoch 9442/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 322.9177 - val_loss: 268.9290\n",
      "Epoch 9443/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 322.7891 - val_loss: 268.8290\n",
      "Epoch 9444/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 322.6607 - val_loss: 268.7264\n",
      "Epoch 9445/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 322.5321 - val_loss: 268.6277\n",
      "Epoch 9446/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 322.4038 - val_loss: 268.5248\n",
      "Epoch 9447/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 322.2755 - val_loss: 268.4260\n",
      "Epoch 9448/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 322.1471 - val_loss: 268.3237\n",
      "Epoch 9449/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 322.0189 - val_loss: 268.2240\n",
      "Epoch 9450/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 321.8907 - val_loss: 268.1230\n",
      "Epoch 9451/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 321.7625 - val_loss: 268.0221\n",
      "Epoch 9452/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 321.6344 - val_loss: 267.9224\n",
      "Epoch 9453/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 321.5063 - val_loss: 267.8206\n",
      "Epoch 9454/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 321.3782 - val_loss: 267.7215\n",
      "Epoch 9455/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 321.2502 - val_loss: 267.6199\n",
      "Epoch 9456/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 321.1223 - val_loss: 267.5205\n",
      "Epoch 9457/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 320.9944 - val_loss: 267.4194\n",
      "Epoch 9458/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 320.8665 - val_loss: 267.3195\n",
      "Epoch 9459/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 320.7388 - val_loss: 267.2192\n",
      "Epoch 9460/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 320.6110 - val_loss: 267.1188\n",
      "Epoch 9461/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 320.4834 - val_loss: 267.0192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9462/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 320.3557 - val_loss: 266.9183\n",
      "Epoch 9463/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 320.2282 - val_loss: 266.8191\n",
      "Epoch 9464/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 320.1005 - val_loss: 266.7181\n",
      "Epoch 9465/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 319.9731 - val_loss: 266.6190\n",
      "Epoch 9466/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 319.8456 - val_loss: 266.5182\n",
      "Epoch 9467/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 319.7181 - val_loss: 266.4191\n",
      "Epoch 9468/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 319.5907 - val_loss: 266.3185\n",
      "Epoch 9469/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 319.4634 - val_loss: 266.2192\n",
      "Epoch 9470/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 319.3362 - val_loss: 266.1190\n",
      "Epoch 9471/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 319.2089 - val_loss: 266.0194\n",
      "Epoch 9472/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 319.0817 - val_loss: 265.9198\n",
      "Epoch 9473/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 318.9545 - val_loss: 265.8199\n",
      "Epoch 9474/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 318.8275 - val_loss: 265.7207\n",
      "Epoch 9475/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 318.7004 - val_loss: 265.6206\n",
      "Epoch 9476/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 318.5735 - val_loss: 265.5218\n",
      "Epoch 9477/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 318.4466 - val_loss: 265.4215\n",
      "Epoch 9478/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 318.3196 - val_loss: 265.3228\n",
      "Epoch 9479/100000\n",
      "11/11 [==============================] - 0s 199us/step - loss: 318.1928 - val_loss: 265.2227\n",
      "Epoch 9480/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 318.0660 - val_loss: 265.1240\n",
      "Epoch 9481/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 317.9391 - val_loss: 265.0239\n",
      "Epoch 9482/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 317.8124 - val_loss: 264.9254\n",
      "Epoch 9483/100000\n",
      "11/11 [==============================] - 0s 660us/step - loss: 317.6859 - val_loss: 264.8254\n",
      "Epoch 9484/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 317.5591 - val_loss: 264.7268\n",
      "Epoch 9485/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 317.4326 - val_loss: 264.6272\n",
      "Epoch 9486/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 317.3061 - val_loss: 264.5284\n",
      "Epoch 9487/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 317.1796 - val_loss: 264.4290\n",
      "Epoch 9488/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 317.0531 - val_loss: 264.3303\n",
      "Epoch 9489/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 316.9268 - val_loss: 264.2310\n",
      "Epoch 9490/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 316.8005 - val_loss: 264.1323\n",
      "Epoch 9491/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 316.6741 - val_loss: 264.0332\n",
      "Epoch 9492/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 316.5479 - val_loss: 263.9344\n",
      "Epoch 9493/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 316.4217 - val_loss: 263.8355\n",
      "Epoch 9494/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 316.2955 - val_loss: 263.7366\n",
      "Epoch 9495/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 316.1693 - val_loss: 263.6380\n",
      "Epoch 9496/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 316.0432 - val_loss: 263.5391\n",
      "Epoch 9497/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 315.9173 - val_loss: 263.4406\n",
      "Epoch 9498/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 315.7913 - val_loss: 263.3417\n",
      "Epoch 9499/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 315.6653 - val_loss: 263.2435\n",
      "Epoch 9500/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 315.5395 - val_loss: 263.1445\n",
      "Epoch 9501/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 315.4136 - val_loss: 263.0465\n",
      "Epoch 9502/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 315.2878 - val_loss: 262.9474\n",
      "Epoch 9503/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 315.1621 - val_loss: 262.8497\n",
      "Epoch 9504/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 315.0363 - val_loss: 262.7503\n",
      "Epoch 9505/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 314.9107 - val_loss: 262.6531\n",
      "Epoch 9506/100000\n",
      "11/11 [==============================] - 0s 648us/step - loss: 314.7851 - val_loss: 262.5535\n",
      "Epoch 9507/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 314.6596 - val_loss: 262.4567\n",
      "Epoch 9508/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 314.5341 - val_loss: 262.3569\n",
      "Epoch 9509/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 314.4086 - val_loss: 262.2604\n",
      "Epoch 9510/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 314.2832 - val_loss: 262.1604\n",
      "Epoch 9511/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 314.1578 - val_loss: 262.0642\n",
      "Epoch 9512/100000\n",
      "11/11 [==============================] - 0s 187us/step - loss: 314.0324 - val_loss: 261.9639\n",
      "Epoch 9513/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 313.9072 - val_loss: 261.8685\n",
      "Epoch 9514/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 313.7819 - val_loss: 261.7674\n",
      "Epoch 9515/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 313.6567 - val_loss: 261.6732\n",
      "Epoch 9516/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 313.5316 - val_loss: 261.5706\n",
      "Epoch 9517/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 313.4064 - val_loss: 261.4785\n",
      "Epoch 9518/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 313.2816 - val_loss: 261.3738\n",
      "Epoch 9519/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 313.1566 - val_loss: 261.2842\n",
      "Epoch 9520/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 313.0315 - val_loss: 261.1765\n",
      "Epoch 9521/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 312.9066 - val_loss: 261.0910\n",
      "Epoch 9522/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 312.7817 - val_loss: 260.9782\n",
      "Epoch 9523/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 312.6569 - val_loss: 260.8992\n",
      "Epoch 9524/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 312.5323 - val_loss: 260.7787\n",
      "Epoch 9525/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 312.4074 - val_loss: 260.7093\n",
      "Epoch 9526/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 312.2828 - val_loss: 260.5773\n",
      "Epoch 9527/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 312.1581 - val_loss: 260.5214\n",
      "Epoch 9528/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 312.0336 - val_loss: 260.3750\n",
      "Epoch 9529/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 311.9091 - val_loss: 260.3333\n",
      "Epoch 9530/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 311.7846 - val_loss: 260.1762\n",
      "Epoch 9531/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 311.6601 - val_loss: 260.1379\n",
      "Epoch 9532/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 311.5357 - val_loss: 259.9886\n",
      "Epoch 9533/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 311.4113 - val_loss: 259.9296\n",
      "Epoch 9534/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 311.2870 - val_loss: 259.8126\n",
      "Epoch 9535/100000\n",
      "11/11 [==============================] - 0s 713us/step - loss: 311.1627 - val_loss: 259.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9536/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 311.0384 - val_loss: 259.6364\n",
      "Epoch 9537/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 310.9143 - val_loss: 259.5079\n",
      "Epoch 9538/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 310.7901 - val_loss: 259.4481\n",
      "Epoch 9539/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 310.6661 - val_loss: 259.3156\n",
      "Epoch 9540/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 310.5420 - val_loss: 259.2451\n",
      "Epoch 9541/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 310.4179 - val_loss: 259.1352\n",
      "Epoch 9542/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 310.2940 - val_loss: 259.0363\n",
      "Epoch 9543/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 310.1700 - val_loss: 258.9545\n",
      "Epoch 9544/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 310.0462 - val_loss: 258.8342\n",
      "Epoch 9545/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 309.9225 - val_loss: 258.7635\n",
      "Epoch 9546/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 309.7987 - val_loss: 258.6439\n",
      "Epoch 9547/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 309.6749 - val_loss: 258.5619\n",
      "Epoch 9548/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 309.5512 - val_loss: 258.4612\n",
      "Epoch 9549/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 309.4277 - val_loss: 258.3582\n",
      "Epoch 9550/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 309.3042 - val_loss: 258.2760\n",
      "Epoch 9551/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 309.1807 - val_loss: 258.1610\n",
      "Epoch 9552/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 309.0571 - val_loss: 258.0823\n",
      "Epoch 9553/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 308.9335 - val_loss: 257.9722\n",
      "Epoch 9554/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 308.8102 - val_loss: 257.8825\n",
      "Epoch 9555/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 308.6868 - val_loss: 257.7871\n",
      "Epoch 9556/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 308.5634 - val_loss: 257.6830\n",
      "Epoch 9557/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 308.4402 - val_loss: 257.5988\n",
      "Epoch 9558/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 308.3170 - val_loss: 257.4890\n",
      "Epoch 9559/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 308.1938 - val_loss: 257.4045\n",
      "Epoch 9560/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 308.0707 - val_loss: 257.3006\n",
      "Epoch 9561/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 307.9475 - val_loss: 257.2069\n",
      "Epoch 9562/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 307.8247 - val_loss: 257.1136\n",
      "Epoch 9563/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 307.7015 - val_loss: 257.0104\n",
      "Epoch 9564/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 307.5786 - val_loss: 256.9236\n",
      "Epoch 9565/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 307.4557 - val_loss: 256.8182\n",
      "Epoch 9566/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 307.3329 - val_loss: 256.7299\n",
      "Epoch 9567/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 307.2101 - val_loss: 256.6292\n",
      "Epoch 9568/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 307.0871 - val_loss: 256.5343\n",
      "Epoch 9569/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 306.9646 - val_loss: 256.4409\n",
      "Epoch 9570/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 306.8418 - val_loss: 256.3398\n",
      "Epoch 9571/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 306.7192 - val_loss: 256.2509\n",
      "Epoch 9572/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 306.5967 - val_loss: 256.1483\n",
      "Epoch 9573/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 306.4741 - val_loss: 256.0580\n",
      "Epoch 9574/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 306.3516 - val_loss: 255.9590\n",
      "Epoch 9575/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 306.2291 - val_loss: 255.8640\n",
      "Epoch 9576/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 306.1067 - val_loss: 255.7702\n",
      "Epoch 9577/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 305.9844 - val_loss: 255.6709\n",
      "Epoch 9578/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 305.8620 - val_loss: 255.5801\n",
      "Epoch 9579/100000\n",
      "11/11 [==============================] - 0s 201us/step - loss: 305.7398 - val_loss: 255.4797\n",
      "Epoch 9580/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 305.6175 - val_loss: 255.3884\n",
      "Epoch 9581/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 305.4954 - val_loss: 255.2902\n",
      "Epoch 9582/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 305.3732 - val_loss: 255.1958\n",
      "Epoch 9583/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 305.2510 - val_loss: 255.1011\n",
      "Epoch 9584/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 305.1290 - val_loss: 255.0037\n",
      "Epoch 9585/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 305.0070 - val_loss: 254.9113\n",
      "Epoch 9586/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 304.8851 - val_loss: 254.8128\n",
      "Epoch 9587/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 304.7631 - val_loss: 254.7208\n",
      "Epoch 9588/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 304.6413 - val_loss: 254.6229\n",
      "Epoch 9589/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 304.5195 - val_loss: 254.5296\n",
      "Epoch 9590/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 304.3977 - val_loss: 254.4337\n",
      "Epoch 9591/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 304.2760 - val_loss: 254.3382\n",
      "Epoch 9592/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 304.1543 - val_loss: 254.2445\n",
      "Epoch 9593/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 304.0326 - val_loss: 254.1476\n",
      "Epoch 9594/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 303.9111 - val_loss: 254.0548\n",
      "Epoch 9595/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 303.7895 - val_loss: 253.9577\n",
      "Epoch 9596/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 303.6679 - val_loss: 253.8647\n",
      "Epoch 9597/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 303.5465 - val_loss: 253.7684\n",
      "Epoch 9598/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 303.4250 - val_loss: 253.6745\n",
      "Epoch 9599/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 303.3037 - val_loss: 253.5793\n",
      "Epoch 9600/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 303.1823 - val_loss: 253.4844\n",
      "Epoch 9601/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 303.0611 - val_loss: 253.3904\n",
      "Epoch 9602/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 302.9398 - val_loss: 253.2946\n",
      "Epoch 9603/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 302.8186 - val_loss: 253.2014\n",
      "Epoch 9604/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 302.6975 - val_loss: 253.1052\n",
      "Epoch 9605/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 302.5763 - val_loss: 253.0121\n",
      "Epoch 9606/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 302.4553 - val_loss: 252.9163\n",
      "Epoch 9607/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 302.3342 - val_loss: 252.8227\n",
      "Epoch 9608/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 302.2133 - val_loss: 252.7277\n",
      "Epoch 9609/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 302.0923 - val_loss: 252.6334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9610/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 301.9715 - val_loss: 252.5394\n",
      "Epoch 9611/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 301.8507 - val_loss: 252.4444\n",
      "Epoch 9612/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 301.7299 - val_loss: 252.3507\n",
      "Epoch 9613/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 301.6089 - val_loss: 252.2555\n",
      "Epoch 9614/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 301.4883 - val_loss: 252.1622\n",
      "Epoch 9615/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 301.3676 - val_loss: 252.0672\n",
      "Epoch 9616/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 301.2471 - val_loss: 251.9737\n",
      "Epoch 9617/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 301.1264 - val_loss: 251.8789\n",
      "Epoch 9618/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 301.0059 - val_loss: 251.7854\n",
      "Epoch 9619/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 300.8855 - val_loss: 251.6908\n",
      "Epoch 9620/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 300.7649 - val_loss: 251.5972\n",
      "Epoch 9621/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 300.6447 - val_loss: 251.5030\n",
      "Epoch 9622/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 300.5242 - val_loss: 251.4090\n",
      "Epoch 9623/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 300.4040 - val_loss: 251.3152\n",
      "Epoch 9624/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 300.2836 - val_loss: 251.2210\n",
      "Epoch 9625/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 300.1634 - val_loss: 251.1275\n",
      "Epoch 9626/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 300.0432 - val_loss: 251.0333\n",
      "Epoch 9627/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 299.9231 - val_loss: 250.9397\n",
      "Epoch 9628/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 299.8029 - val_loss: 250.8458\n",
      "Epoch 9629/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 299.6829 - val_loss: 250.7523\n",
      "Epoch 9630/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 299.5629 - val_loss: 250.6584\n",
      "Epoch 9631/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 299.4430 - val_loss: 250.5649\n",
      "Epoch 9632/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 299.3231 - val_loss: 250.4711\n",
      "Epoch 9633/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 299.2031 - val_loss: 250.3775\n",
      "Epoch 9634/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 299.0833 - val_loss: 250.2841\n",
      "Epoch 9635/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 298.9636 - val_loss: 250.1905\n",
      "Epoch 9636/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 298.8439 - val_loss: 250.0971\n",
      "Epoch 9637/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 298.7242 - val_loss: 250.0036\n",
      "Epoch 9638/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 298.6045 - val_loss: 249.9100\n",
      "Epoch 9639/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 298.4847 - val_loss: 249.8168\n",
      "Epoch 9640/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 298.3652 - val_loss: 249.7232\n",
      "Epoch 9641/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 298.2457 - val_loss: 249.6301\n",
      "Epoch 9642/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 298.1262 - val_loss: 249.5366\n",
      "Epoch 9643/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 298.0068 - val_loss: 249.4437\n",
      "Epoch 9644/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 297.8874 - val_loss: 249.3502\n",
      "Epoch 9645/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 297.7680 - val_loss: 249.2572\n",
      "Epoch 9646/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 297.6487 - val_loss: 249.1639\n",
      "Epoch 9647/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 297.5295 - val_loss: 249.0710\n",
      "Epoch 9648/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 297.4103 - val_loss: 248.9777\n",
      "Epoch 9649/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 297.2911 - val_loss: 248.8848\n",
      "Epoch 9650/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 297.1720 - val_loss: 248.7916\n",
      "Epoch 9651/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 297.0528 - val_loss: 248.6988\n",
      "Epoch 9652/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 296.9338 - val_loss: 248.6057\n",
      "Epoch 9653/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 296.8148 - val_loss: 248.5130\n",
      "Epoch 9654/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 296.6959 - val_loss: 248.4198\n",
      "Epoch 9655/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 296.5768 - val_loss: 248.3273\n",
      "Epoch 9656/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 296.4581 - val_loss: 248.2342\n",
      "Epoch 9657/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 296.3392 - val_loss: 248.1416\n",
      "Epoch 9658/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 296.2203 - val_loss: 248.0486\n",
      "Epoch 9659/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 296.1017 - val_loss: 247.9563\n",
      "Epoch 9660/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 295.9829 - val_loss: 247.8631\n",
      "Epoch 9661/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 295.8642 - val_loss: 247.7711\n",
      "Epoch 9662/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 295.7456 - val_loss: 247.6776\n",
      "Epoch 9663/100000\n",
      "11/11 [==============================] - 0s 580us/step - loss: 295.6270 - val_loss: 247.5860\n",
      "Epoch 9664/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 295.5085 - val_loss: 247.4923\n",
      "Epoch 9665/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 295.3901 - val_loss: 247.4013\n",
      "Epoch 9666/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 295.2717 - val_loss: 247.3071\n",
      "Epoch 9667/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 295.1533 - val_loss: 247.2169\n",
      "Epoch 9668/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 295.0350 - val_loss: 247.1217\n",
      "Epoch 9669/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 294.9167 - val_loss: 247.0328\n",
      "Epoch 9670/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 294.7983 - val_loss: 246.9360\n",
      "Epoch 9671/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 294.6801 - val_loss: 246.8492\n",
      "Epoch 9672/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 294.5619 - val_loss: 246.7500\n",
      "Epoch 9673/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 294.4437 - val_loss: 246.6665\n",
      "Epoch 9674/100000\n",
      "11/11 [==============================] - 0s 628us/step - loss: 294.3257 - val_loss: 246.5633\n",
      "Epoch 9675/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 294.2076 - val_loss: 246.4849\n",
      "Epoch 9676/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 294.0895 - val_loss: 246.3753\n",
      "Epoch 9677/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 293.9716 - val_loss: 246.3054\n",
      "Epoch 9678/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 293.8538 - val_loss: 246.1853\n",
      "Epoch 9679/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 293.7359 - val_loss: 246.1282\n",
      "Epoch 9680/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 293.6180 - val_loss: 245.9932\n",
      "Epoch 9681/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 293.5003 - val_loss: 245.9530\n",
      "Epoch 9682/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 293.3826 - val_loss: 245.8014\n",
      "Epoch 9683/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 293.2650 - val_loss: 245.7743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9684/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 293.1473 - val_loss: 245.6185\n",
      "Epoch 9685/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 293.0296 - val_loss: 245.5813\n",
      "Epoch 9686/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 292.9119 - val_loss: 245.4520\n",
      "Epoch 9687/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 292.7944 - val_loss: 245.3749\n",
      "Epoch 9688/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 292.6768 - val_loss: 245.2918\n",
      "Epoch 9689/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 292.5594 - val_loss: 245.1721\n",
      "Epoch 9690/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 292.4419 - val_loss: 245.1199\n",
      "Epoch 9691/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 292.3246 - val_loss: 244.9872\n",
      "Epoch 9692/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 292.2073 - val_loss: 244.9287\n",
      "Epoch 9693/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 292.0901 - val_loss: 244.8190\n",
      "Epoch 9694/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 291.9727 - val_loss: 244.7272\n",
      "Epoch 9695/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 291.8554 - val_loss: 244.6523\n",
      "Epoch 9696/100000\n",
      "11/11 [==============================] - 0s 817us/step - loss: 291.7384 - val_loss: 244.5337\n",
      "Epoch 9697/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 291.6213 - val_loss: 244.4720\n",
      "Epoch 9698/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 291.5042 - val_loss: 244.3561\n",
      "Epoch 9699/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 291.3871 - val_loss: 244.2779\n",
      "Epoch 9700/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 291.2702 - val_loss: 244.1871\n",
      "Epoch 9701/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 291.1532 - val_loss: 244.0830\n",
      "Epoch 9702/100000\n",
      "11/11 [==============================] - 0s 992us/step - loss: 291.0363 - val_loss: 244.0120\n",
      "Epoch 9703/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 290.9195 - val_loss: 243.8991\n",
      "Epoch 9704/100000\n",
      "11/11 [==============================] - 0s 875us/step - loss: 290.8026 - val_loss: 243.8247\n",
      "Epoch 9705/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 290.6858 - val_loss: 243.7253\n",
      "Epoch 9706/100000\n",
      "11/11 [==============================] - 0s 657us/step - loss: 290.5691 - val_loss: 243.6322\n",
      "Epoch 9707/100000\n",
      "11/11 [==============================] - 0s 753us/step - loss: 290.4524 - val_loss: 243.5515\n",
      "Epoch 9708/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 290.3356 - val_loss: 243.4451\n",
      "Epoch 9709/100000\n",
      "11/11 [==============================] - 0s 835us/step - loss: 290.2191 - val_loss: 243.3697\n",
      "Epoch 9710/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 290.1025 - val_loss: 243.2667\n",
      "Epoch 9711/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 289.9859 - val_loss: 243.1810\n",
      "Epoch 9712/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 289.8695 - val_loss: 243.0921\n",
      "Epoch 9713/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 289.7531 - val_loss: 242.9929\n",
      "Epoch 9714/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 289.6367 - val_loss: 242.9137\n",
      "Epoch 9715/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 289.5203 - val_loss: 242.8109\n",
      "Epoch 9716/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 289.4039 - val_loss: 242.7291\n",
      "Epoch 9717/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 289.2878 - val_loss: 242.6342\n",
      "Epoch 9718/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 289.1715 - val_loss: 242.5420\n",
      "Epoch 9719/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 289.0554 - val_loss: 242.4572\n",
      "Epoch 9720/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 288.9391 - val_loss: 242.3578\n",
      "Epoch 9721/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 288.8230 - val_loss: 242.2760\n",
      "Epoch 9722/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 288.7070 - val_loss: 242.1783\n",
      "Epoch 9723/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 288.5909 - val_loss: 242.0913\n",
      "Epoch 9724/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 288.4749 - val_loss: 242.0009\n",
      "Epoch 9725/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 288.3589 - val_loss: 241.9067\n",
      "Epoch 9726/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 288.2431 - val_loss: 241.8218\n",
      "Epoch 9727/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 288.1272 - val_loss: 241.7251\n",
      "Epoch 9728/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 288.0115 - val_loss: 241.6400\n",
      "Epoch 9729/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 287.8956 - val_loss: 241.5462\n",
      "Epoch 9730/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 287.7799 - val_loss: 241.4565\n",
      "Epoch 9731/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 287.6643 - val_loss: 241.3679\n",
      "Epoch 9732/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 287.5486 - val_loss: 241.2738\n",
      "Epoch 9733/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 287.4329 - val_loss: 241.1882\n",
      "Epoch 9734/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 287.3175 - val_loss: 241.0933\n",
      "Epoch 9735/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 287.2018 - val_loss: 241.0065\n",
      "Epoch 9736/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 287.0864 - val_loss: 240.9144\n",
      "Epoch 9737/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 286.9708 - val_loss: 240.8242\n",
      "Epoch 9738/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 286.8555 - val_loss: 240.7357\n",
      "Epoch 9739/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 286.7402 - val_loss: 240.6427\n",
      "Epoch 9740/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 286.6248 - val_loss: 240.5559\n",
      "Epoch 9741/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 286.5096 - val_loss: 240.4628\n",
      "Epoch 9742/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 286.3944 - val_loss: 240.3748\n",
      "Epoch 9743/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 286.2791 - val_loss: 240.2839\n",
      "Epoch 9744/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 286.1640 - val_loss: 240.1936\n",
      "Epoch 9745/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 286.0489 - val_loss: 240.1050\n",
      "Epoch 9746/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 285.9339 - val_loss: 240.0130\n",
      "Epoch 9747/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 285.8188 - val_loss: 239.9254\n",
      "Epoch 9748/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 285.7038 - val_loss: 239.8333\n",
      "Epoch 9749/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 285.5888 - val_loss: 239.7451\n",
      "Epoch 9750/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 285.4739 - val_loss: 239.6545\n",
      "Epoch 9751/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 285.3591 - val_loss: 239.5647\n",
      "Epoch 9752/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 285.2441 - val_loss: 239.4756\n",
      "Epoch 9753/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 285.1294 - val_loss: 239.3847\n",
      "Epoch 9754/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 285.0147 - val_loss: 239.2964\n",
      "Epoch 9755/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 284.8998 - val_loss: 239.2053\n",
      "Epoch 9756/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 284.7854 - val_loss: 239.1170\n",
      "Epoch 9757/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 284.6707 - val_loss: 239.0264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9758/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 284.5560 - val_loss: 238.9373\n",
      "Epoch 9759/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 284.4416 - val_loss: 238.8480\n",
      "Epoch 9760/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 284.3271 - val_loss: 238.7578\n",
      "Epoch 9761/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 284.2127 - val_loss: 238.6692\n",
      "Epoch 9762/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 284.0982 - val_loss: 238.5788\n",
      "Epoch 9763/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 283.9839 - val_loss: 238.4904\n",
      "Epoch 9764/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 283.8696 - val_loss: 238.4001\n",
      "Epoch 9765/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 283.7552 - val_loss: 238.3113\n",
      "Epoch 9766/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 283.6409 - val_loss: 238.2216\n",
      "Epoch 9767/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 283.5267 - val_loss: 238.1324\n",
      "Epoch 9768/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 283.4126 - val_loss: 238.0434\n",
      "Epoch 9769/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 283.2984 - val_loss: 237.9536\n",
      "Epoch 9770/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 283.1843 - val_loss: 237.8651\n",
      "Epoch 9771/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 283.0703 - val_loss: 237.7752\n",
      "Epoch 9772/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 282.9563 - val_loss: 237.6868\n",
      "Epoch 9773/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 282.8423 - val_loss: 237.5969\n",
      "Epoch 9774/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 282.7283 - val_loss: 237.5084\n",
      "Epoch 9775/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 282.6145 - val_loss: 237.4190\n",
      "Epoch 9776/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 282.5007 - val_loss: 237.3301\n",
      "Epoch 9777/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 282.3868 - val_loss: 237.2413\n",
      "Epoch 9778/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 282.2732 - val_loss: 237.1517\n",
      "Epoch 9779/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 282.1592 - val_loss: 237.0635\n",
      "Epoch 9780/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 282.0457 - val_loss: 236.9738\n",
      "Epoch 9781/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 281.9320 - val_loss: 236.8858\n",
      "Epoch 9782/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 281.8184 - val_loss: 236.7961\n",
      "Epoch 9783/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 281.7049 - val_loss: 236.7080\n",
      "Epoch 9784/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 281.5913 - val_loss: 236.6185\n",
      "Epoch 9785/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 281.4778 - val_loss: 236.5303\n",
      "Epoch 9786/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 281.3644 - val_loss: 236.4411\n",
      "Epoch 9787/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 281.2509 - val_loss: 236.3526\n",
      "Epoch 9788/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 281.1376 - val_loss: 236.2639\n",
      "Epoch 9789/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 281.0242 - val_loss: 236.1752\n",
      "Epoch 9790/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 280.9110 - val_loss: 236.0868\n",
      "Epoch 9791/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 280.7978 - val_loss: 235.9979\n",
      "Epoch 9792/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 280.6845 - val_loss: 235.9097\n",
      "Epoch 9793/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 280.5714 - val_loss: 235.8207\n",
      "Epoch 9794/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 280.4583 - val_loss: 235.7327\n",
      "Epoch 9795/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 280.3452 - val_loss: 235.6438\n",
      "Epoch 9796/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 280.2321 - val_loss: 235.5557\n",
      "Epoch 9797/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 280.1192 - val_loss: 235.4669\n",
      "Epoch 9798/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 280.0062 - val_loss: 235.3788\n",
      "Epoch 9799/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 279.8932 - val_loss: 235.2901\n",
      "Epoch 9800/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 279.7803 - val_loss: 235.2020\n",
      "Epoch 9801/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 279.6674 - val_loss: 235.1136\n",
      "Epoch 9802/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 279.5547 - val_loss: 235.0253\n",
      "Epoch 9803/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 279.4418 - val_loss: 234.9371\n",
      "Epoch 9804/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 279.3292 - val_loss: 234.8489\n",
      "Epoch 9805/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 279.2165 - val_loss: 234.7607\n",
      "Epoch 9806/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 279.1038 - val_loss: 234.6725\n",
      "Epoch 9807/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 278.9912 - val_loss: 234.5844\n",
      "Epoch 9808/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 278.8786 - val_loss: 234.4963\n",
      "Epoch 9809/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 278.7662 - val_loss: 234.4082\n",
      "Epoch 9810/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 278.6537 - val_loss: 234.3202\n",
      "Epoch 9811/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 278.5412 - val_loss: 234.2321\n",
      "Epoch 9812/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 278.4288 - val_loss: 234.1443\n",
      "Epoch 9813/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 278.3165 - val_loss: 234.0560\n",
      "Epoch 9814/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 278.2041 - val_loss: 233.9684\n",
      "Epoch 9815/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 278.0918 - val_loss: 233.8802\n",
      "Epoch 9816/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 277.9795 - val_loss: 233.7926\n",
      "Epoch 9817/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 277.8672 - val_loss: 233.7044\n",
      "Epoch 9818/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 277.7551 - val_loss: 233.6169\n",
      "Epoch 9819/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 277.6429 - val_loss: 233.5288\n",
      "Epoch 9820/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 277.5309 - val_loss: 233.4414\n",
      "Epoch 9821/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 277.4189 - val_loss: 233.3534\n",
      "Epoch 9822/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 277.3069 - val_loss: 233.2659\n",
      "Epoch 9823/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 277.1948 - val_loss: 233.1780\n",
      "Epoch 9824/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 277.0829 - val_loss: 233.0905\n",
      "Epoch 9825/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 276.9710 - val_loss: 233.0027\n",
      "Epoch 9826/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 276.8591 - val_loss: 232.9152\n",
      "Epoch 9827/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 276.7473 - val_loss: 232.8276\n",
      "Epoch 9828/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 276.6355 - val_loss: 232.7400\n",
      "Epoch 9829/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 276.5238 - val_loss: 232.6526\n",
      "Epoch 9830/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 276.4121 - val_loss: 232.5650\n",
      "Epoch 9831/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 276.3004 - val_loss: 232.4778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9832/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 276.1888 - val_loss: 232.3900\n",
      "Epoch 9833/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 276.0772 - val_loss: 232.3031\n",
      "Epoch 9834/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 275.9657 - val_loss: 232.2150\n",
      "Epoch 9835/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 275.8541 - val_loss: 232.1284\n",
      "Epoch 9836/100000\n",
      "11/11 [==============================] - 0s 205us/step - loss: 275.7426 - val_loss: 232.0402\n",
      "Epoch 9837/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 275.6312 - val_loss: 231.9540\n",
      "Epoch 9838/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 275.5198 - val_loss: 231.8654\n",
      "Epoch 9839/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 275.4084 - val_loss: 231.7798\n",
      "Epoch 9840/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 275.2971 - val_loss: 231.6906\n",
      "Epoch 9841/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 275.1859 - val_loss: 231.6060\n",
      "Epoch 9842/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 275.0746 - val_loss: 231.5155\n",
      "Epoch 9843/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 274.9634 - val_loss: 231.4327\n",
      "Epoch 9844/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 274.8522 - val_loss: 231.3400\n",
      "Epoch 9845/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 274.7411 - val_loss: 231.2602\n",
      "Epoch 9846/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 274.6300 - val_loss: 231.1638\n",
      "Epoch 9847/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 274.5190 - val_loss: 231.0890\n",
      "Epoch 9848/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 274.4079 - val_loss: 230.9859\n",
      "Epoch 9849/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 274.2970 - val_loss: 230.9201\n",
      "Epoch 9850/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 274.1862 - val_loss: 230.8055\n",
      "Epoch 9851/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 274.0752 - val_loss: 230.7545\n",
      "Epoch 9852/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 273.9644 - val_loss: 230.6218\n",
      "Epoch 9853/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 273.8536 - val_loss: 230.5919\n",
      "Epoch 9854/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 273.7429 - val_loss: 230.4378\n",
      "Epoch 9855/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 273.6322 - val_loss: 230.4245\n",
      "Epoch 9856/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 273.5215 - val_loss: 230.2670\n",
      "Epoch 9857/100000\n",
      "11/11 [==============================] - 0s 588us/step - loss: 273.4109 - val_loss: 230.2361\n",
      "Epoch 9858/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 273.3000 - val_loss: 230.1187\n",
      "Epoch 9859/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 273.1894 - val_loss: 230.0325\n",
      "Epoch 9860/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 273.0789 - val_loss: 229.9728\n",
      "Epoch 9861/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 272.9684 - val_loss: 229.8417\n",
      "Epoch 9862/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 272.8581 - val_loss: 229.8031\n",
      "Epoch 9863/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 272.7475 - val_loss: 229.6792\n",
      "Epoch 9864/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 272.6370 - val_loss: 229.6086\n",
      "Epoch 9865/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 272.5267 - val_loss: 229.5304\n",
      "Epoch 9866/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 272.4164 - val_loss: 229.4165\n",
      "Epoch 9867/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 272.3062 - val_loss: 229.3657\n",
      "Epoch 9868/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 272.1958 - val_loss: 229.2478\n",
      "Epoch 9869/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 272.0855 - val_loss: 229.1781\n",
      "Epoch 9870/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 271.9753 - val_loss: 229.0939\n",
      "Epoch 9871/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 271.8651 - val_loss: 228.9891\n",
      "Epoch 9872/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 271.7551 - val_loss: 228.9295\n",
      "Epoch 9873/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 271.6451 - val_loss: 228.8185\n",
      "Epoch 9874/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 271.5352 - val_loss: 228.7464\n",
      "Epoch 9875/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 271.4252 - val_loss: 228.6605\n",
      "Epoch 9876/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 271.3152 - val_loss: 228.5609\n",
      "Epoch 9877/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 271.2054 - val_loss: 228.4951\n",
      "Epoch 9878/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 271.0955 - val_loss: 228.3895\n",
      "Epoch 9879/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 270.9856 - val_loss: 228.3149\n",
      "Epoch 9880/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 270.8759 - val_loss: 228.2282\n",
      "Epoch 9881/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 270.7660 - val_loss: 228.1325\n",
      "Epoch 9882/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 270.6563 - val_loss: 228.0618\n",
      "Epoch 9883/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 270.5466 - val_loss: 227.9607\n",
      "Epoch 9884/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 270.4370 - val_loss: 227.8841\n",
      "Epoch 9885/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 270.3274 - val_loss: 227.7969\n",
      "Epoch 9886/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 270.2178 - val_loss: 227.7043\n",
      "Epoch 9887/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 270.1083 - val_loss: 227.6299\n",
      "Epoch 9888/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 269.9989 - val_loss: 227.5321\n",
      "Epoch 9889/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 269.8894 - val_loss: 227.4543\n",
      "Epoch 9890/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 269.7800 - val_loss: 227.3664\n",
      "Epoch 9891/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 269.6705 - val_loss: 227.2765\n",
      "Epoch 9892/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 269.5612 - val_loss: 227.1990\n",
      "Epoch 9893/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 269.4519 - val_loss: 227.1039\n",
      "Epoch 9894/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 269.3426 - val_loss: 227.0252\n",
      "Epoch 9895/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 269.2334 - val_loss: 226.9367\n",
      "Epoch 9896/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 269.1241 - val_loss: 226.8490\n",
      "Epoch 9897/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 269.0150 - val_loss: 226.7690\n",
      "Epoch 9898/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 268.9060 - val_loss: 226.6762\n",
      "Epoch 9899/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 268.7968 - val_loss: 226.5967\n",
      "Epoch 9900/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 268.6877 - val_loss: 226.5078\n",
      "Epoch 9901/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 268.5788 - val_loss: 226.4219\n",
      "Epoch 9902/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 268.4698 - val_loss: 226.3399\n",
      "Epoch 9903/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 268.3609 - val_loss: 226.2490\n",
      "Epoch 9904/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 268.2519 - val_loss: 226.1689\n",
      "Epoch 9905/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 268.1431 - val_loss: 226.0798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9906/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 268.0344 - val_loss: 225.9954\n",
      "Epoch 9907/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 267.9255 - val_loss: 225.9115\n",
      "Epoch 9908/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 267.8168 - val_loss: 225.8227\n",
      "Epoch 9909/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 267.7080 - val_loss: 225.7415\n",
      "Epoch 9910/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 267.5994 - val_loss: 225.6526\n",
      "Epoch 9911/100000\n",
      "11/11 [==============================] - 0s 186us/step - loss: 267.4908 - val_loss: 225.5692\n",
      "Epoch 9912/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 267.3822 - val_loss: 225.4840\n",
      "Epoch 9913/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 267.2736 - val_loss: 225.3967\n",
      "Epoch 9914/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 267.1649 - val_loss: 225.3146\n",
      "Epoch 9915/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 267.0565 - val_loss: 225.2263\n",
      "Epoch 9916/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 266.9481 - val_loss: 225.1434\n",
      "Epoch 9917/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 266.8396 - val_loss: 225.0571\n",
      "Epoch 9918/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 266.7312 - val_loss: 224.9717\n",
      "Epoch 9919/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 266.6229 - val_loss: 224.8881\n",
      "Epoch 9920/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 266.5146 - val_loss: 224.8008\n",
      "Epoch 9921/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 266.4063 - val_loss: 224.7180\n",
      "Epoch 9922/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 266.2980 - val_loss: 224.6311\n",
      "Epoch 9923/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 266.1898 - val_loss: 224.5471\n",
      "Epoch 9924/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 266.0817 - val_loss: 224.4622\n",
      "Epoch 9925/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 265.9736 - val_loss: 224.3764\n",
      "Epoch 9926/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 265.8655 - val_loss: 224.2928\n",
      "Epoch 9927/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 265.7574 - val_loss: 224.2065\n",
      "Epoch 9928/100000\n",
      "11/11 [==============================] - 0s 770us/step - loss: 265.6494 - val_loss: 224.1227\n",
      "Epoch 9929/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 265.5415 - val_loss: 224.0373\n",
      "Epoch 9930/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 265.4335 - val_loss: 223.9523\n",
      "Epoch 9931/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 265.3255 - val_loss: 223.8682\n",
      "Epoch 9932/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 265.2177 - val_loss: 223.7824\n",
      "Epoch 9933/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 265.1098 - val_loss: 223.6987\n",
      "Epoch 9934/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 265.0020 - val_loss: 223.6131\n",
      "Epoch 9935/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 264.8943 - val_loss: 223.5289\n",
      "Epoch 9936/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 264.7865 - val_loss: 223.4441\n",
      "Epoch 9937/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 264.6787 - val_loss: 223.3591\n",
      "Epoch 9938/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 264.5711 - val_loss: 223.2751\n",
      "Epoch 9939/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 264.4635 - val_loss: 223.1897\n",
      "Epoch 9940/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 264.3559 - val_loss: 223.1059\n",
      "Epoch 9941/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 264.2483 - val_loss: 223.0207\n",
      "Epoch 9942/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 264.1407 - val_loss: 222.9365\n",
      "Epoch 9943/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 264.0334 - val_loss: 222.8521\n",
      "Epoch 9944/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 263.9260 - val_loss: 222.7673\n",
      "Epoch 9945/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 263.8185 - val_loss: 222.6833\n",
      "Epoch 9946/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 263.7111 - val_loss: 222.5983\n",
      "Epoch 9947/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 263.6038 - val_loss: 222.5144\n",
      "Epoch 9948/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 263.4965 - val_loss: 222.4296\n",
      "Epoch 9949/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 263.3892 - val_loss: 222.3455\n",
      "Epoch 9950/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 263.2820 - val_loss: 222.2612\n",
      "Epoch 9951/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 263.1748 - val_loss: 222.1765\n",
      "Epoch 9952/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 263.0676 - val_loss: 222.0927\n",
      "Epoch 9953/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 262.9604 - val_loss: 222.0079\n",
      "Epoch 9954/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 262.8534 - val_loss: 221.9242\n",
      "Epoch 9955/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 262.7463 - val_loss: 221.8396\n",
      "Epoch 9956/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 262.6393 - val_loss: 221.7556\n",
      "Epoch 9957/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 262.5323 - val_loss: 221.6714\n",
      "Epoch 9958/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 262.4254 - val_loss: 221.5873\n",
      "Epoch 9959/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 262.3186 - val_loss: 221.5032\n",
      "Epoch 9960/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 262.2116 - val_loss: 221.4190\n",
      "Epoch 9961/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 262.1048 - val_loss: 221.3351\n",
      "Epoch 9962/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 261.9980 - val_loss: 221.2509\n",
      "Epoch 9963/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 261.8912 - val_loss: 221.1670\n",
      "Epoch 9964/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 261.7845 - val_loss: 221.0830\n",
      "Epoch 9965/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 261.6778 - val_loss: 220.9990\n",
      "Epoch 9966/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 261.5711 - val_loss: 220.9150\n",
      "Epoch 9967/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 261.4645 - val_loss: 220.8311\n",
      "Epoch 9968/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 261.3579 - val_loss: 220.7472\n",
      "Epoch 9969/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 261.2513 - val_loss: 220.6633\n",
      "Epoch 9970/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 261.1447 - val_loss: 220.5795\n",
      "Epoch 9971/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 261.0383 - val_loss: 220.4958\n",
      "Epoch 9972/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 260.9319 - val_loss: 220.4118\n",
      "Epoch 9973/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 260.8254 - val_loss: 220.3281\n",
      "Epoch 9974/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 260.7190 - val_loss: 220.2443\n",
      "Epoch 9975/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 260.6128 - val_loss: 220.1607\n",
      "Epoch 9976/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 260.5064 - val_loss: 220.0768\n",
      "Epoch 9977/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 260.4000 - val_loss: 219.9933\n",
      "Epoch 9978/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 260.2939 - val_loss: 219.9094\n",
      "Epoch 9979/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 260.1876 - val_loss: 219.8261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9980/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 260.0815 - val_loss: 219.7422\n",
      "Epoch 9981/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 259.9754 - val_loss: 219.6588\n",
      "Epoch 9982/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 259.8692 - val_loss: 219.5751\n",
      "Epoch 9983/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 259.7632 - val_loss: 219.4916\n",
      "Epoch 9984/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 259.6570 - val_loss: 219.4080\n",
      "Epoch 9985/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 259.5510 - val_loss: 219.3247\n",
      "Epoch 9986/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 259.4452 - val_loss: 219.2412\n",
      "Epoch 9987/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 259.3392 - val_loss: 219.1577\n",
      "Epoch 9988/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 259.2333 - val_loss: 219.0742\n",
      "Epoch 9989/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 259.1273 - val_loss: 218.9909\n",
      "Epoch 9990/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 259.0215 - val_loss: 218.9074\n",
      "Epoch 9991/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 258.9157 - val_loss: 218.8242\n",
      "Epoch 9992/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 258.8100 - val_loss: 218.7408\n",
      "Epoch 9993/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 258.7043 - val_loss: 218.6576\n",
      "Epoch 9994/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 258.5986 - val_loss: 218.5741\n",
      "Epoch 9995/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 258.4929 - val_loss: 218.4911\n",
      "Epoch 9996/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 258.3874 - val_loss: 218.4078\n",
      "Epoch 9997/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 258.2818 - val_loss: 218.3245\n",
      "Epoch 9998/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 258.1762 - val_loss: 218.2414\n",
      "Epoch 9999/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 258.0706 - val_loss: 218.1581\n",
      "Epoch 10000/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 257.9652 - val_loss: 218.0751\n",
      "Epoch 10001/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 257.8597 - val_loss: 217.9918\n",
      "Epoch 10002/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 257.7543 - val_loss: 217.9089\n",
      "Epoch 10003/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 257.6489 - val_loss: 217.8256\n",
      "Epoch 10004/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 257.5435 - val_loss: 217.7428\n",
      "Epoch 10005/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 257.4382 - val_loss: 217.6594\n",
      "Epoch 10006/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 257.3329 - val_loss: 217.5769\n",
      "Epoch 10007/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 257.2277 - val_loss: 217.4935\n",
      "Epoch 10008/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 257.1225 - val_loss: 217.4109\n",
      "Epoch 10009/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 257.0173 - val_loss: 217.3276\n",
      "Epoch 10010/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 256.9122 - val_loss: 217.2451\n",
      "Epoch 10011/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 256.8070 - val_loss: 217.1617\n",
      "Epoch 10012/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 256.7019 - val_loss: 217.0793\n",
      "Epoch 10013/100000\n",
      "11/11 [==============================] - 0s 200us/step - loss: 256.5970 - val_loss: 216.9961\n",
      "Epoch 10014/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 256.4919 - val_loss: 216.9136\n",
      "Epoch 10015/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 256.3869 - val_loss: 216.8306\n",
      "Epoch 10016/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 256.2821 - val_loss: 216.7481\n",
      "Epoch 10017/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 256.1771 - val_loss: 216.6649\n",
      "Epoch 10018/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 256.0721 - val_loss: 216.5826\n",
      "Epoch 10019/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 255.9673 - val_loss: 216.4995\n",
      "Epoch 10020/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 255.8625 - val_loss: 216.4173\n",
      "Epoch 10021/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 255.7578 - val_loss: 216.3340\n",
      "Epoch 10022/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 255.6531 - val_loss: 216.2519\n",
      "Epoch 10023/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 255.5482 - val_loss: 216.1687\n",
      "Epoch 10024/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 255.4436 - val_loss: 216.0869\n",
      "Epoch 10025/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 255.3390 - val_loss: 216.0035\n",
      "Epoch 10026/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 255.2344 - val_loss: 215.9218\n",
      "Epoch 10027/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 255.1298 - val_loss: 215.8383\n",
      "Epoch 10028/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 255.0253 - val_loss: 215.7569\n",
      "Epoch 10029/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 254.9208 - val_loss: 215.6732\n",
      "Epoch 10030/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 254.8163 - val_loss: 215.5921\n",
      "Epoch 10031/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 254.7119 - val_loss: 215.5081\n",
      "Epoch 10032/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 254.6074 - val_loss: 215.4275\n",
      "Epoch 10033/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 254.5030 - val_loss: 215.3429\n",
      "Epoch 10034/100000\n",
      "11/11 [==============================] - 0s 658us/step - loss: 254.3987 - val_loss: 215.2632\n",
      "Epoch 10035/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 254.2944 - val_loss: 215.1776\n",
      "Epoch 10036/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 254.1901 - val_loss: 215.0993\n",
      "Epoch 10037/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 254.0859 - val_loss: 215.0118\n",
      "Epoch 10038/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 253.9816 - val_loss: 214.9361\n",
      "Epoch 10039/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 253.8775 - val_loss: 214.8455\n",
      "Epoch 10040/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 253.7733 - val_loss: 214.7738\n",
      "Epoch 10041/100000\n",
      "11/11 [==============================] - 0s 876us/step - loss: 253.6693 - val_loss: 214.6782\n",
      "Epoch 10042/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 253.5651 - val_loss: 214.6131\n",
      "Epoch 10043/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 253.4611 - val_loss: 214.5091\n",
      "Epoch 10044/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 253.3571 - val_loss: 214.4548\n",
      "Epoch 10045/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 253.2532 - val_loss: 214.3376\n",
      "Epoch 10046/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 253.1494 - val_loss: 214.2991\n",
      "Epoch 10047/100000\n",
      "11/11 [==============================] - 0s 978us/step - loss: 253.0455 - val_loss: 214.1647\n",
      "Epoch 10048/100000\n",
      "11/11 [==============================] - 0s 762us/step - loss: 252.9416 - val_loss: 214.1422\n",
      "Epoch 10049/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 252.8378 - val_loss: 213.9976\n",
      "Epoch 10050/100000\n",
      "11/11 [==============================] - 0s 891us/step - loss: 252.7339 - val_loss: 213.9734\n",
      "Epoch 10051/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 252.6300 - val_loss: 213.8470\n",
      "Epoch 10052/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 252.5262 - val_loss: 213.7883\n",
      "Epoch 10053/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 252.4225 - val_loss: 213.7069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10054/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 252.3188 - val_loss: 213.6031\n",
      "Epoch 10055/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 252.2152 - val_loss: 213.5573\n",
      "Epoch 10056/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 252.1116 - val_loss: 213.4350\n",
      "Epoch 10057/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 252.0079 - val_loss: 213.3870\n",
      "Epoch 10058/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 251.9044 - val_loss: 213.2859\n",
      "Epoch 10059/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 251.8007 - val_loss: 213.2048\n",
      "Epoch 10060/100000\n",
      "11/11 [==============================] - 0s 765us/step - loss: 251.6973 - val_loss: 213.1392\n",
      "Epoch 10061/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 251.5939 - val_loss: 213.0305\n",
      "Epoch 10062/100000\n",
      "11/11 [==============================] - 0s 675us/step - loss: 251.4904 - val_loss: 212.9777\n",
      "Epoch 10063/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 251.3871 - val_loss: 212.8735\n",
      "Epoch 10064/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 251.2837 - val_loss: 212.8017\n",
      "Epoch 10065/100000\n",
      "11/11 [==============================] - 0s 824us/step - loss: 251.1803 - val_loss: 212.7242\n",
      "Epoch 10066/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 251.0770 - val_loss: 212.6268\n",
      "Epoch 10067/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 250.9738 - val_loss: 212.5665\n",
      "Epoch 10068/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 250.8705 - val_loss: 212.4647\n",
      "Epoch 10069/100000\n",
      "11/11 [==============================] - 0s 609us/step - loss: 250.7674 - val_loss: 212.3962\n",
      "Epoch 10070/100000\n",
      "11/11 [==============================] - 0s 624us/step - loss: 250.6642 - val_loss: 212.3117\n",
      "Epoch 10071/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 250.5610 - val_loss: 212.2229\n",
      "Epoch 10072/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 250.4579 - val_loss: 212.1555\n",
      "Epoch 10073/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 250.3549 - val_loss: 212.0577\n",
      "Epoch 10074/100000\n",
      "11/11 [==============================] - 0s 707us/step - loss: 250.2518 - val_loss: 211.9893\n",
      "Epoch 10075/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 250.1487 - val_loss: 211.9013\n",
      "Epoch 10076/100000\n",
      "11/11 [==============================] - 0s 684us/step - loss: 250.0458 - val_loss: 211.8185\n",
      "Epoch 10077/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 249.9428 - val_loss: 211.7451\n",
      "Epoch 10078/100000\n",
      "11/11 [==============================] - 0s 761us/step - loss: 249.8400 - val_loss: 211.6517\n",
      "Epoch 10079/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 249.7369 - val_loss: 211.5821\n",
      "Epoch 10080/100000\n",
      "11/11 [==============================] - 0s 956us/step - loss: 249.6341 - val_loss: 211.4924\n",
      "Epoch 10081/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 249.5314 - val_loss: 211.4139\n",
      "Epoch 10082/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 249.4286 - val_loss: 211.3355\n",
      "Epoch 10083/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 249.3259 - val_loss: 211.2470\n",
      "Epoch 10084/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 249.2231 - val_loss: 211.1746\n",
      "Epoch 10085/100000\n",
      "11/11 [==============================] - 0s 728us/step - loss: 249.1205 - val_loss: 211.0852\n",
      "Epoch 10086/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 249.0178 - val_loss: 211.0091\n",
      "Epoch 10087/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 248.9152 - val_loss: 210.9268\n",
      "Epoch 10088/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 248.8126 - val_loss: 210.8425\n",
      "Epoch 10089/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 248.7099 - val_loss: 210.7671\n",
      "Epoch 10090/100000\n",
      "11/11 [==============================] - 0s 871us/step - loss: 248.6075 - val_loss: 210.6792\n",
      "Epoch 10091/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 248.5049 - val_loss: 210.6039\n",
      "Epoch 10092/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 248.4025 - val_loss: 210.5192\n",
      "Epoch 10093/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 248.3001 - val_loss: 210.4384\n",
      "Epoch 10094/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 248.1976 - val_loss: 210.3598\n",
      "Epoch 10095/100000\n",
      "11/11 [==============================] - 0s 773us/step - loss: 248.0953 - val_loss: 210.2742\n",
      "Epoch 10096/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 247.9929 - val_loss: 210.1982\n",
      "Epoch 10097/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 247.8905 - val_loss: 210.1127\n",
      "Epoch 10098/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 247.7883 - val_loss: 210.0346\n",
      "Epoch 10099/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 247.6860 - val_loss: 209.9529\n",
      "Epoch 10100/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 247.5838 - val_loss: 209.8704\n",
      "Epoch 10101/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 247.4817 - val_loss: 209.7926\n",
      "Epoch 10102/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 247.3796 - val_loss: 209.7079\n",
      "Epoch 10103/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 247.2774 - val_loss: 209.6304\n",
      "Epoch 10104/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 247.1753 - val_loss: 209.5469\n",
      "Epoch 10105/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 247.0731 - val_loss: 209.4669\n",
      "Epoch 10106/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 246.9711 - val_loss: 209.3867\n",
      "Epoch 10107/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 246.8691 - val_loss: 209.3039\n",
      "Epoch 10108/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 246.7672 - val_loss: 209.2258\n",
      "Epoch 10109/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 246.6653 - val_loss: 209.1422\n",
      "Epoch 10110/100000\n",
      "11/11 [==============================] - 0s 981us/step - loss: 246.5633 - val_loss: 209.0637\n",
      "Epoch 10111/100000\n",
      "11/11 [==============================] - 0s 655us/step - loss: 246.4614 - val_loss: 208.9816\n",
      "Epoch 10112/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 246.3596 - val_loss: 208.9009\n",
      "Epoch 10113/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 246.2577 - val_loss: 208.8211\n",
      "Epoch 10114/100000\n",
      "11/11 [==============================] - 0s 954us/step - loss: 246.1559 - val_loss: 208.7386\n",
      "Epoch 10115/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 246.0542 - val_loss: 208.6600\n",
      "Epoch 10116/100000\n",
      "11/11 [==============================] - 0s 656us/step - loss: 245.9524 - val_loss: 208.5773\n",
      "Epoch 10117/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 245.8507 - val_loss: 208.4982\n",
      "Epoch 10118/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 245.7491 - val_loss: 208.4167\n",
      "Epoch 10119/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 245.6474 - val_loss: 208.3362\n",
      "Epoch 10120/100000\n",
      "11/11 [==============================] - 0s 764us/step - loss: 245.5459 - val_loss: 208.2561\n",
      "Epoch 10121/100000\n",
      "11/11 [==============================] - 0s 814us/step - loss: 245.4442 - val_loss: 208.1744\n",
      "Epoch 10122/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 245.3428 - val_loss: 208.0953\n",
      "Epoch 10123/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 245.2412 - val_loss: 208.0132\n",
      "Epoch 10124/100000\n",
      "11/11 [==============================] - 0s 876us/step - loss: 245.1397 - val_loss: 207.9339\n",
      "Epoch 10125/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 245.0383 - val_loss: 207.8526\n",
      "Epoch 10126/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 244.9368 - val_loss: 207.7724\n",
      "Epoch 10127/100000\n",
      "11/11 [==============================] - 0s 624us/step - loss: 244.8355 - val_loss: 207.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10128/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 244.7342 - val_loss: 207.6109\n",
      "Epoch 10129/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 244.6328 - val_loss: 207.5316\n",
      "Epoch 10130/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 244.5315 - val_loss: 207.4500\n",
      "Epoch 10131/100000\n",
      "11/11 [==============================] - 0s 610us/step - loss: 244.4302 - val_loss: 207.3705\n",
      "Epoch 10132/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 244.3289 - val_loss: 207.2893\n",
      "Epoch 10133/100000\n",
      "11/11 [==============================] - 0s 774us/step - loss: 244.2276 - val_loss: 207.2096\n",
      "Epoch 10134/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 244.1266 - val_loss: 207.1291\n",
      "Epoch 10135/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 244.0255 - val_loss: 207.0485\n",
      "Epoch 10136/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 243.9243 - val_loss: 206.9686\n",
      "Epoch 10137/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 243.8232 - val_loss: 206.8878\n",
      "Epoch 10138/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 243.7222 - val_loss: 206.8081\n",
      "Epoch 10139/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 243.6212 - val_loss: 206.7272\n",
      "Epoch 10140/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 243.5201 - val_loss: 206.6475\n",
      "Epoch 10141/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 243.4191 - val_loss: 206.5668\n",
      "Epoch 10142/100000\n",
      "11/11 [==============================] - 0s 820us/step - loss: 243.3181 - val_loss: 206.4869\n",
      "Epoch 10143/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 243.2173 - val_loss: 206.4066\n",
      "Epoch 10144/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 243.1164 - val_loss: 206.3264\n",
      "Epoch 10145/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 243.0156 - val_loss: 206.2464\n",
      "Epoch 10146/100000\n",
      "11/11 [==============================] - 0s 760us/step - loss: 242.9147 - val_loss: 206.1659\n",
      "Epoch 10147/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 242.8139 - val_loss: 206.0863\n",
      "Epoch 10148/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 242.7132 - val_loss: 206.0057\n",
      "Epoch 10149/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 242.6124 - val_loss: 205.9260\n",
      "Epoch 10150/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 242.5117 - val_loss: 205.8457\n",
      "Epoch 10151/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 242.4111 - val_loss: 205.7658\n",
      "Epoch 10152/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 242.3104 - val_loss: 205.6856\n",
      "Epoch 10153/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 242.2099 - val_loss: 205.6057\n",
      "Epoch 10154/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 242.1092 - val_loss: 205.5257\n",
      "Epoch 10155/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 242.0087 - val_loss: 205.4456\n",
      "Epoch 10156/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 241.9082 - val_loss: 205.3659\n",
      "Epoch 10157/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 241.8077 - val_loss: 205.2856\n",
      "Epoch 10158/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 241.7073 - val_loss: 205.2061\n",
      "Epoch 10159/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 241.6068 - val_loss: 205.1257\n",
      "Epoch 10160/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 241.5064 - val_loss: 205.0463\n",
      "Epoch 10161/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 241.4060 - val_loss: 204.9658\n",
      "Epoch 10162/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 241.3056 - val_loss: 204.8865\n",
      "Epoch 10163/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 241.2053 - val_loss: 204.8063\n",
      "Epoch 10164/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 241.1050 - val_loss: 204.7267\n",
      "Epoch 10165/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 241.0048 - val_loss: 204.6468\n",
      "Epoch 10166/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 240.9045 - val_loss: 204.5670\n",
      "Epoch 10167/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 240.8043 - val_loss: 204.4873\n",
      "Epoch 10168/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 240.7040 - val_loss: 204.4073\n",
      "Epoch 10169/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 240.6039 - val_loss: 204.3279\n",
      "Epoch 10170/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 240.5038 - val_loss: 204.2478\n",
      "Epoch 10171/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 240.4038 - val_loss: 204.1686\n",
      "Epoch 10172/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 240.3038 - val_loss: 204.0883\n",
      "Epoch 10173/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 240.2037 - val_loss: 204.0093\n",
      "Epoch 10174/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 240.1037 - val_loss: 203.9289\n",
      "Epoch 10175/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 240.0038 - val_loss: 203.8500\n",
      "Epoch 10176/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 239.9038 - val_loss: 203.7697\n",
      "Epoch 10177/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 239.8040 - val_loss: 203.6908\n",
      "Epoch 10178/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 239.7040 - val_loss: 203.6104\n",
      "Epoch 10179/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 239.6041 - val_loss: 203.5316\n",
      "Epoch 10180/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 239.5042 - val_loss: 203.4512\n",
      "Epoch 10181/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 239.4044 - val_loss: 203.3726\n",
      "Epoch 10182/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 239.3047 - val_loss: 203.2920\n",
      "Epoch 10183/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 239.2049 - val_loss: 203.2136\n",
      "Epoch 10184/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 239.1052 - val_loss: 203.1329\n",
      "Epoch 10185/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 239.0055 - val_loss: 203.0546\n",
      "Epoch 10186/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 238.9058 - val_loss: 202.9739\n",
      "Epoch 10187/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 238.8062 - val_loss: 202.8959\n",
      "Epoch 10188/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 238.7066 - val_loss: 202.8150\n",
      "Epoch 10189/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 238.6071 - val_loss: 202.7372\n",
      "Epoch 10190/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 238.5076 - val_loss: 202.6561\n",
      "Epoch 10191/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 238.4081 - val_loss: 202.5785\n",
      "Epoch 10192/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 238.3085 - val_loss: 202.4972\n",
      "Epoch 10193/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 238.2092 - val_loss: 202.4200\n",
      "Epoch 10194/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 238.1096 - val_loss: 202.3381\n",
      "Epoch 10195/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 238.0102 - val_loss: 202.2618\n",
      "Epoch 10196/100000\n",
      "11/11 [==============================] - 0s 742us/step - loss: 237.9110 - val_loss: 202.1791\n",
      "Epoch 10197/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 237.8116 - val_loss: 202.1037\n",
      "Epoch 10198/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 237.7123 - val_loss: 202.0197\n",
      "Epoch 10199/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 237.6129 - val_loss: 201.9461\n",
      "Epoch 10200/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 237.5137 - val_loss: 201.8599\n",
      "Epoch 10201/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 237.4144 - val_loss: 201.7892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10202/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 237.3153 - val_loss: 201.6996\n",
      "Epoch 10203/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 237.2160 - val_loss: 201.6331\n",
      "Epoch 10204/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 237.1169 - val_loss: 201.5382\n",
      "Epoch 10205/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 237.0177 - val_loss: 201.4783\n",
      "Epoch 10206/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 236.9186 - val_loss: 201.3757\n",
      "Epoch 10207/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 236.8196 - val_loss: 201.3251\n",
      "Epoch 10208/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 236.7206 - val_loss: 201.2119\n",
      "Epoch 10209/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 236.6216 - val_loss: 201.1727\n",
      "Epoch 10210/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 236.5228 - val_loss: 201.0489\n",
      "Epoch 10211/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 236.4238 - val_loss: 201.0170\n",
      "Epoch 10212/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 236.3249 - val_loss: 200.8921\n",
      "Epoch 10213/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 236.2259 - val_loss: 200.8522\n",
      "Epoch 10214/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 236.1270 - val_loss: 200.7455\n",
      "Epoch 10215/100000\n",
      "11/11 [==============================] - 0s 726us/step - loss: 236.0282 - val_loss: 200.6792\n",
      "Epoch 10216/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 235.9292 - val_loss: 200.6027\n",
      "Epoch 10217/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 235.8305 - val_loss: 200.5078\n",
      "Epoch 10218/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 235.7318 - val_loss: 200.4542\n",
      "Epoch 10219/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 235.6330 - val_loss: 200.3459\n",
      "Epoch 10220/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 235.5343 - val_loss: 200.2943\n",
      "Epoch 10221/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 235.4357 - val_loss: 200.1951\n",
      "Epoch 10222/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 235.3368 - val_loss: 200.1258\n",
      "Epoch 10223/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 235.2383 - val_loss: 200.0488\n",
      "Epoch 10224/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 235.1397 - val_loss: 199.9581\n",
      "Epoch 10225/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 235.0412 - val_loss: 199.8976\n",
      "Epoch 10226/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 234.9426 - val_loss: 199.7983\n",
      "Epoch 10227/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 234.8441 - val_loss: 199.7374\n",
      "Epoch 10228/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 234.7456 - val_loss: 199.6466\n",
      "Epoch 10229/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 234.6472 - val_loss: 199.5718\n",
      "Epoch 10230/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 234.5487 - val_loss: 199.4971\n",
      "Epoch 10231/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 234.4504 - val_loss: 199.4080\n",
      "Epoch 10232/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 234.3521 - val_loss: 199.3430\n",
      "Epoch 10233/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 234.2536 - val_loss: 199.2501\n",
      "Epoch 10234/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 234.1553 - val_loss: 199.1827\n",
      "Epoch 10235/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 234.0570 - val_loss: 199.0974\n",
      "Epoch 10236/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 233.9587 - val_loss: 199.0196\n",
      "Epoch 10237/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 233.8605 - val_loss: 198.9453\n",
      "Epoch 10238/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 233.7622 - val_loss: 198.8582\n",
      "Epoch 10239/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 233.6640 - val_loss: 198.7897\n",
      "Epoch 10240/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 233.5659 - val_loss: 198.7013\n",
      "Epoch 10241/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 233.4678 - val_loss: 198.6299\n",
      "Epoch 10242/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 233.3695 - val_loss: 198.5477\n",
      "Epoch 10243/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 233.2715 - val_loss: 198.4687\n",
      "Epoch 10244/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 233.1734 - val_loss: 198.3940\n",
      "Epoch 10245/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 233.0754 - val_loss: 198.3091\n",
      "Epoch 10246/100000\n",
      "11/11 [==============================] - 0s 591us/step - loss: 232.9775 - val_loss: 198.2380\n",
      "Epoch 10247/100000\n",
      "11/11 [==============================] - 0s 657us/step - loss: 232.8795 - val_loss: 198.1525\n",
      "Epoch 10248/100000\n",
      "11/11 [==============================] - 0s 618us/step - loss: 232.7816 - val_loss: 198.0792\n",
      "Epoch 10249/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 232.6837 - val_loss: 197.9980\n",
      "Epoch 10250/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 232.5858 - val_loss: 197.9194\n",
      "Epoch 10251/100000\n",
      "11/11 [==============================] - 0s 868us/step - loss: 232.4879 - val_loss: 197.8433\n",
      "Epoch 10252/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 232.3900 - val_loss: 197.7606\n",
      "Epoch 10253/100000\n",
      "11/11 [==============================] - 0s 670us/step - loss: 232.2923 - val_loss: 197.6873\n",
      "Epoch 10254/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 232.1945 - val_loss: 197.6037\n",
      "Epoch 10255/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 232.0967 - val_loss: 197.5295\n",
      "Epoch 10256/100000\n",
      "11/11 [==============================] - 0s 688us/step - loss: 231.9991 - val_loss: 197.4482\n",
      "Epoch 10257/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 231.9013 - val_loss: 197.3709\n",
      "Epoch 10258/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 231.8036 - val_loss: 197.2931\n",
      "Epoch 10259/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 231.7059 - val_loss: 197.2124\n",
      "Epoch 10260/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 231.6082 - val_loss: 197.1373\n",
      "Epoch 10261/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 231.5106 - val_loss: 197.0553\n",
      "Epoch 10262/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 231.4131 - val_loss: 196.9805\n",
      "Epoch 10263/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 231.3155 - val_loss: 196.8993\n",
      "Epoch 10264/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 231.2181 - val_loss: 196.8228\n",
      "Epoch 10265/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 231.1206 - val_loss: 196.7439\n",
      "Epoch 10266/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 231.0231 - val_loss: 196.6650\n",
      "Epoch 10267/100000\n",
      "11/11 [==============================] - 0s 628us/step - loss: 230.9257 - val_loss: 196.5883\n",
      "Epoch 10268/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 230.8283 - val_loss: 196.5076\n",
      "Epoch 10269/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 230.7309 - val_loss: 196.4322\n",
      "Epoch 10270/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 230.6335 - val_loss: 196.3511\n",
      "Epoch 10271/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 230.5362 - val_loss: 196.2754\n",
      "Epoch 10272/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 230.4389 - val_loss: 196.1952\n",
      "Epoch 10273/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 230.3416 - val_loss: 196.1182\n",
      "Epoch 10274/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 230.2444 - val_loss: 196.0397\n",
      "Epoch 10275/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 230.1472 - val_loss: 195.9610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10276/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 230.0500 - val_loss: 195.8839\n",
      "Epoch 10277/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 229.9527 - val_loss: 195.8041\n",
      "Epoch 10278/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 229.8556 - val_loss: 195.7278\n",
      "Epoch 10279/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 229.7584 - val_loss: 195.6479\n",
      "Epoch 10280/100000\n",
      "11/11 [==============================] - 0s 660us/step - loss: 229.6614 - val_loss: 195.5715\n",
      "Epoch 10281/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 229.5643 - val_loss: 195.4919\n",
      "Epoch 10282/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 229.4672 - val_loss: 195.4149\n",
      "Epoch 10283/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 229.3703 - val_loss: 195.3362\n",
      "Epoch 10284/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 229.2733 - val_loss: 195.2583\n",
      "Epoch 10285/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 229.1763 - val_loss: 195.1804\n",
      "Epoch 10286/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 229.0794 - val_loss: 195.1019\n",
      "Epoch 10287/100000\n",
      "11/11 [==============================] - 0s 642us/step - loss: 228.9825 - val_loss: 195.0248\n",
      "Epoch 10288/100000\n",
      "11/11 [==============================] - 0s 589us/step - loss: 228.8857 - val_loss: 194.9456\n",
      "Epoch 10289/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 228.7888 - val_loss: 194.8689\n",
      "Epoch 10290/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 228.6919 - val_loss: 194.7894\n",
      "Epoch 10291/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 228.5951 - val_loss: 194.7129\n",
      "Epoch 10292/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 228.4984 - val_loss: 194.6336\n",
      "Epoch 10293/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 228.4016 - val_loss: 194.5566\n",
      "Epoch 10294/100000\n",
      "11/11 [==============================] - 0s 898us/step - loss: 228.3047 - val_loss: 194.4780\n",
      "Epoch 10295/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 228.2081 - val_loss: 194.4005\n",
      "Epoch 10296/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 228.1114 - val_loss: 194.3224\n",
      "Epoch 10297/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 228.0147 - val_loss: 194.2443\n",
      "Epoch 10298/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 227.9181 - val_loss: 194.1668\n",
      "Epoch 10299/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 227.8215 - val_loss: 194.0884\n",
      "Epoch 10300/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 227.7249 - val_loss: 194.0113\n",
      "Epoch 10301/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 227.6284 - val_loss: 193.9325\n",
      "Epoch 10302/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 227.5319 - val_loss: 193.8557\n",
      "Epoch 10303/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 227.4353 - val_loss: 193.7768\n",
      "Epoch 10304/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 227.3390 - val_loss: 193.7001\n",
      "Epoch 10305/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 227.2425 - val_loss: 193.6212\n",
      "Epoch 10306/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 227.1461 - val_loss: 193.5444\n",
      "Epoch 10307/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 227.0496 - val_loss: 193.4656\n",
      "Epoch 10308/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 226.9533 - val_loss: 193.3889\n",
      "Epoch 10309/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 226.8570 - val_loss: 193.3102\n",
      "Epoch 10310/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 226.7607 - val_loss: 193.2332\n",
      "Epoch 10311/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 226.6644 - val_loss: 193.1548\n",
      "Epoch 10312/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 226.5681 - val_loss: 193.0778\n",
      "Epoch 10313/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 226.4719 - val_loss: 192.9994\n",
      "Epoch 10314/100000\n",
      "11/11 [==============================] - 0s 718us/step - loss: 226.3756 - val_loss: 192.9222\n",
      "Epoch 10315/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 226.2794 - val_loss: 192.8439\n",
      "Epoch 10316/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 226.1832 - val_loss: 192.7669\n",
      "Epoch 10317/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 226.0871 - val_loss: 192.6887\n",
      "Epoch 10318/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 225.9910 - val_loss: 192.6116\n",
      "Epoch 10319/100000\n",
      "11/11 [==============================] - 0s 201us/step - loss: 225.8949 - val_loss: 192.5334\n",
      "Epoch 10320/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 225.7988 - val_loss: 192.4563\n",
      "Epoch 10321/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 225.7027 - val_loss: 192.3782\n",
      "Epoch 10322/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 225.6068 - val_loss: 192.3012\n",
      "Epoch 10323/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 225.5108 - val_loss: 192.2229\n",
      "Epoch 10324/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 225.4148 - val_loss: 192.1461\n",
      "Epoch 10325/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 225.3189 - val_loss: 192.0678\n",
      "Epoch 10326/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 225.2230 - val_loss: 191.9911\n",
      "Epoch 10327/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 225.1273 - val_loss: 191.9127\n",
      "Epoch 10328/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 225.0313 - val_loss: 191.8361\n",
      "Epoch 10329/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 224.9354 - val_loss: 191.7576\n",
      "Epoch 10330/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 224.8397 - val_loss: 191.6814\n",
      "Epoch 10331/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 224.7439 - val_loss: 191.6021\n",
      "Epoch 10332/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 224.6481 - val_loss: 191.5268\n",
      "Epoch 10333/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 224.5524 - val_loss: 191.4467\n",
      "Epoch 10334/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 224.4565 - val_loss: 191.3725\n",
      "Epoch 10335/100000\n",
      "11/11 [==============================] - 0s 854us/step - loss: 224.3610 - val_loss: 191.2909\n",
      "Epoch 10336/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 224.2652 - val_loss: 191.2187\n",
      "Epoch 10337/100000\n",
      "11/11 [==============================] - 0s 830us/step - loss: 224.1697 - val_loss: 191.1348\n",
      "Epoch 10338/100000\n",
      "11/11 [==============================] - 0s 803us/step - loss: 224.0740 - val_loss: 191.0657\n",
      "Epoch 10339/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 223.9785 - val_loss: 190.9777\n",
      "Epoch 10340/100000\n",
      "11/11 [==============================] - 0s 665us/step - loss: 223.8829 - val_loss: 190.9140\n",
      "Epoch 10341/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 223.7875 - val_loss: 190.8192\n",
      "Epoch 10342/100000\n",
      "11/11 [==============================] - 0s 631us/step - loss: 223.6920 - val_loss: 190.7641\n",
      "Epoch 10343/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 223.5966 - val_loss: 190.6588\n",
      "Epoch 10344/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 223.5011 - val_loss: 190.6163\n",
      "Epoch 10345/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 223.4058 - val_loss: 190.4970\n",
      "Epoch 10346/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 223.3105 - val_loss: 190.4680\n",
      "Epoch 10347/100000\n",
      "11/11 [==============================] - 0s 819us/step - loss: 223.2151 - val_loss: 190.3395\n",
      "Epoch 10348/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 223.1198 - val_loss: 190.3104\n",
      "Epoch 10349/100000\n",
      "11/11 [==============================] - 0s 693us/step - loss: 223.0245 - val_loss: 190.1951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10350/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 222.9290 - val_loss: 190.1389\n",
      "Epoch 10351/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 222.8336 - val_loss: 190.0599\n",
      "Epoch 10352/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 222.7383 - val_loss: 189.9664\n",
      "Epoch 10353/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 222.6432 - val_loss: 189.9180\n",
      "Epoch 10354/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 222.5480 - val_loss: 189.8076\n",
      "Epoch 10355/100000\n",
      "11/11 [==============================] - 0s 856us/step - loss: 222.4529 - val_loss: 189.7591\n",
      "Epoch 10356/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 222.3577 - val_loss: 189.6649\n",
      "Epoch 10357/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 222.2625 - val_loss: 189.5894\n",
      "Epoch 10358/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 222.1673 - val_loss: 189.5248\n",
      "Epoch 10359/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 222.0724 - val_loss: 189.4260\n",
      "Epoch 10360/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 221.9773 - val_loss: 189.3728\n",
      "Epoch 10361/100000\n",
      "11/11 [==============================] - 0s 593us/step - loss: 221.8825 - val_loss: 189.2767\n",
      "Epoch 10362/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 221.7873 - val_loss: 189.2085\n",
      "Epoch 10363/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 221.6924 - val_loss: 189.1343\n",
      "Epoch 10364/100000\n",
      "11/11 [==============================] - 0s 667us/step - loss: 221.5975 - val_loss: 189.0448\n",
      "Epoch 10365/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 221.5025 - val_loss: 188.9851\n",
      "Epoch 10366/100000\n",
      "11/11 [==============================] - 0s 620us/step - loss: 221.4077 - val_loss: 188.8915\n",
      "Epoch 10367/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 221.3128 - val_loss: 188.8253\n",
      "Epoch 10368/100000\n",
      "11/11 [==============================] - 0s 202us/step - loss: 221.2180 - val_loss: 188.7458\n",
      "Epoch 10369/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 221.1231 - val_loss: 188.6629\n",
      "Epoch 10370/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 221.0283 - val_loss: 188.5975\n",
      "Epoch 10371/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 220.9336 - val_loss: 188.5073\n",
      "Epoch 10372/100000\n",
      "11/11 [==============================] - 0s 965us/step - loss: 220.8389 - val_loss: 188.4412\n",
      "Epoch 10373/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 220.7442 - val_loss: 188.3588\n",
      "Epoch 10374/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 220.6494 - val_loss: 188.2808\n",
      "Epoch 10375/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 220.5547 - val_loss: 188.2104\n",
      "Epoch 10376/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 220.4601 - val_loss: 188.1240\n",
      "Epoch 10377/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 220.3655 - val_loss: 188.0565\n",
      "Epoch 10378/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 220.2709 - val_loss: 187.9732\n",
      "Epoch 10379/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 220.1764 - val_loss: 187.8984\n",
      "Epoch 10380/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 220.0819 - val_loss: 187.8242\n",
      "Epoch 10381/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 219.9874 - val_loss: 187.7414\n",
      "Epoch 10382/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 219.8929 - val_loss: 187.6720\n",
      "Epoch 10383/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 219.7985 - val_loss: 187.5887\n",
      "Epoch 10384/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 219.7041 - val_loss: 187.5159\n",
      "Epoch 10385/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 219.6096 - val_loss: 187.4387\n",
      "Epoch 10386/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 219.5153 - val_loss: 187.3591\n",
      "Epoch 10387/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 219.4209 - val_loss: 187.2873\n",
      "Epoch 10388/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 219.3266 - val_loss: 187.2051\n",
      "Epoch 10389/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 219.2322 - val_loss: 187.1329\n",
      "Epoch 10390/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 219.1379 - val_loss: 187.0537\n",
      "Epoch 10391/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 219.0436 - val_loss: 186.9770\n",
      "Epoch 10392/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 218.9494 - val_loss: 186.9027\n",
      "Epoch 10393/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 218.8553 - val_loss: 186.8224\n",
      "Epoch 10394/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 218.7611 - val_loss: 186.7498\n",
      "Epoch 10395/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 218.6670 - val_loss: 186.6698\n",
      "Epoch 10396/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 218.5728 - val_loss: 186.5951\n",
      "Epoch 10397/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 218.4787 - val_loss: 186.5184\n",
      "Epoch 10398/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 218.3846 - val_loss: 186.4403\n",
      "Epoch 10399/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 218.2905 - val_loss: 186.3664\n",
      "Epoch 10400/100000\n",
      "11/11 [==============================] - 0s 665us/step - loss: 218.1965 - val_loss: 186.2869\n",
      "Epoch 10401/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 218.1026 - val_loss: 186.2131\n",
      "Epoch 10402/100000\n",
      "11/11 [==============================] - 0s 795us/step - loss: 218.0087 - val_loss: 186.1349\n",
      "Epoch 10403/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 217.9147 - val_loss: 186.0589\n",
      "Epoch 10404/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 217.8209 - val_loss: 185.9831\n",
      "Epoch 10405/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 217.7269 - val_loss: 185.9051\n",
      "Epoch 10406/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 217.6331 - val_loss: 185.8306\n",
      "Epoch 10407/100000\n",
      "11/11 [==============================] - 0s 672us/step - loss: 217.5392 - val_loss: 185.7522\n",
      "Epoch 10408/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 217.4453 - val_loss: 185.6772\n",
      "Epoch 10409/100000\n",
      "11/11 [==============================] - 0s 737us/step - loss: 217.3515 - val_loss: 185.6002\n",
      "Epoch 10410/100000\n",
      "11/11 [==============================] - 0s 776us/step - loss: 217.2578 - val_loss: 185.5236\n",
      "Epoch 10411/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 217.1640 - val_loss: 185.4482\n",
      "Epoch 10412/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 217.0703 - val_loss: 185.3705\n",
      "Epoch 10413/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 216.9766 - val_loss: 185.2956\n",
      "Epoch 10414/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 216.8829 - val_loss: 185.2180\n",
      "Epoch 10415/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 216.7893 - val_loss: 185.1426\n",
      "Epoch 10416/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 216.6957 - val_loss: 185.0660\n",
      "Epoch 10417/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 216.6021 - val_loss: 184.9895\n",
      "Epoch 10418/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 216.5086 - val_loss: 184.9140\n",
      "Epoch 10419/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 216.4151 - val_loss: 184.8368\n",
      "Epoch 10420/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 216.3216 - val_loss: 184.7617\n",
      "Epoch 10421/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 216.2282 - val_loss: 184.6845\n",
      "Epoch 10422/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 216.1347 - val_loss: 184.6090\n",
      "Epoch 10423/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 216.0413 - val_loss: 184.5325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10424/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 215.9478 - val_loss: 184.4563\n",
      "Epoch 10425/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 215.8545 - val_loss: 184.3806\n",
      "Epoch 10426/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 215.7611 - val_loss: 184.3039\n",
      "Epoch 10427/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 215.6678 - val_loss: 184.2285\n",
      "Epoch 10428/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 215.5745 - val_loss: 184.1518\n",
      "Epoch 10429/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 215.4813 - val_loss: 184.0762\n",
      "Epoch 10430/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 215.3879 - val_loss: 183.9998\n",
      "Epoch 10431/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 215.2947 - val_loss: 183.9238\n",
      "Epoch 10432/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 215.2015 - val_loss: 183.8480\n",
      "Epoch 10433/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 215.1084 - val_loss: 183.7717\n",
      "Epoch 10434/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 215.0152 - val_loss: 183.6962\n",
      "Epoch 10435/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 214.9221 - val_loss: 183.6198\n",
      "Epoch 10436/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 214.8291 - val_loss: 183.5443\n",
      "Epoch 10437/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 214.7360 - val_loss: 183.4681\n",
      "Epoch 10438/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 214.6429 - val_loss: 183.3923\n",
      "Epoch 10439/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 214.5499 - val_loss: 183.3165\n",
      "Epoch 10440/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 214.4570 - val_loss: 183.2404\n",
      "Epoch 10441/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 214.3640 - val_loss: 183.1649\n",
      "Epoch 10442/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 214.2711 - val_loss: 183.0888\n",
      "Epoch 10443/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 214.1782 - val_loss: 183.0132\n",
      "Epoch 10444/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 214.0853 - val_loss: 182.9372\n",
      "Epoch 10445/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 213.9924 - val_loss: 182.8616\n",
      "Epoch 10446/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 213.8996 - val_loss: 182.7859\n",
      "Epoch 10447/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 213.8068 - val_loss: 182.7100\n",
      "Epoch 10448/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 213.7140 - val_loss: 182.6345\n",
      "Epoch 10449/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 213.6212 - val_loss: 182.5586\n",
      "Epoch 10450/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 213.5286 - val_loss: 182.4832\n",
      "Epoch 10451/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 213.4359 - val_loss: 182.4072\n",
      "Epoch 10452/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 213.3432 - val_loss: 182.3318\n",
      "Epoch 10453/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 213.2504 - val_loss: 182.2560\n",
      "Epoch 10454/100000\n",
      "11/11 [==============================] - 0s 698us/step - loss: 213.1579 - val_loss: 182.1806\n",
      "Epoch 10455/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 213.0653 - val_loss: 182.1049\n",
      "Epoch 10456/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 212.9727 - val_loss: 182.0294\n",
      "Epoch 10457/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 212.8801 - val_loss: 181.9540\n",
      "Epoch 10458/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 212.7878 - val_loss: 181.8784\n",
      "Epoch 10459/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 212.6953 - val_loss: 181.8031\n",
      "Epoch 10460/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 212.6028 - val_loss: 181.7274\n",
      "Epoch 10461/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 212.5104 - val_loss: 181.6522\n",
      "Epoch 10462/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 212.4180 - val_loss: 181.5765\n",
      "Epoch 10463/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 212.3256 - val_loss: 181.5015\n",
      "Epoch 10464/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 212.2334 - val_loss: 181.4257\n",
      "Epoch 10465/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 212.1410 - val_loss: 181.3506\n",
      "Epoch 10466/100000\n",
      "11/11 [==============================] - 0s 851us/step - loss: 212.0486 - val_loss: 181.2750\n",
      "Epoch 10467/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 211.9564 - val_loss: 181.1999\n",
      "Epoch 10468/100000\n",
      "11/11 [==============================] - 0s 968us/step - loss: 211.8641 - val_loss: 181.1243\n",
      "Epoch 10469/100000\n",
      "11/11 [==============================] - 0s 824us/step - loss: 211.7719 - val_loss: 181.0493\n",
      "Epoch 10470/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 211.6797 - val_loss: 180.9739\n",
      "Epoch 10471/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 211.5875 - val_loss: 180.8987\n",
      "Epoch 10472/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 211.4954 - val_loss: 180.8234\n",
      "Epoch 10473/100000\n",
      "11/11 [==============================] - 0s 586us/step - loss: 211.4032 - val_loss: 180.7482\n",
      "Epoch 10474/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 211.3111 - val_loss: 180.6731\n",
      "Epoch 10475/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 211.2191 - val_loss: 180.5978\n",
      "Epoch 10476/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 211.1270 - val_loss: 180.5229\n",
      "Epoch 10477/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 211.0351 - val_loss: 180.4476\n",
      "Epoch 10478/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 210.9431 - val_loss: 180.3727\n",
      "Epoch 10479/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 210.8512 - val_loss: 180.2975\n",
      "Epoch 10480/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 210.7593 - val_loss: 180.2227\n",
      "Epoch 10481/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 210.6674 - val_loss: 180.1475\n",
      "Epoch 10482/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 210.5756 - val_loss: 180.0726\n",
      "Epoch 10483/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 210.4837 - val_loss: 179.9976\n",
      "Epoch 10484/100000\n",
      "11/11 [==============================] - 0s 640us/step - loss: 210.3919 - val_loss: 179.9227\n",
      "Epoch 10485/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 210.3002 - val_loss: 179.8478\n",
      "Epoch 10486/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 210.2084 - val_loss: 179.7727\n",
      "Epoch 10487/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 210.1166 - val_loss: 179.6979\n",
      "Epoch 10488/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 210.0249 - val_loss: 179.6230\n",
      "Epoch 10489/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 209.9333 - val_loss: 179.5482\n",
      "Epoch 10490/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 209.8416 - val_loss: 179.4733\n",
      "Epoch 10491/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 209.7498 - val_loss: 179.3986\n",
      "Epoch 10492/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 209.6582 - val_loss: 179.3237\n",
      "Epoch 10493/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 209.5667 - val_loss: 179.2490\n",
      "Epoch 10494/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 209.4751 - val_loss: 179.1743\n",
      "Epoch 10495/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 209.3837 - val_loss: 179.0995\n",
      "Epoch 10496/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 209.2921 - val_loss: 179.0251\n",
      "Epoch 10497/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 209.2008 - val_loss: 178.9503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10498/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 209.1094 - val_loss: 178.8759\n",
      "Epoch 10499/100000\n",
      "11/11 [==============================] - 0s 758us/step - loss: 209.0180 - val_loss: 178.8010\n",
      "Epoch 10500/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 208.9266 - val_loss: 178.7269\n",
      "Epoch 10501/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 208.8353 - val_loss: 178.6517\n",
      "Epoch 10502/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 208.7440 - val_loss: 178.5780\n",
      "Epoch 10503/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 208.6527 - val_loss: 178.5024\n",
      "Epoch 10504/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 208.5613 - val_loss: 178.4292\n",
      "Epoch 10505/100000\n",
      "11/11 [==============================] - 0s 666us/step - loss: 208.4701 - val_loss: 178.3532\n",
      "Epoch 10506/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 208.3789 - val_loss: 178.2806\n",
      "Epoch 10507/100000\n",
      "11/11 [==============================] - 0s 661us/step - loss: 208.2877 - val_loss: 178.2039\n",
      "Epoch 10508/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 208.1965 - val_loss: 178.1324\n",
      "Epoch 10509/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 208.1053 - val_loss: 178.0543\n",
      "Epoch 10510/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 208.0142 - val_loss: 177.9847\n",
      "Epoch 10511/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 207.9232 - val_loss: 177.9043\n",
      "Epoch 10512/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 207.8321 - val_loss: 177.8379\n",
      "Epoch 10513/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 207.7411 - val_loss: 177.7535\n",
      "Epoch 10514/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 207.6501 - val_loss: 177.6925\n",
      "Epoch 10515/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 207.5592 - val_loss: 177.6013\n",
      "Epoch 10516/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 207.4683 - val_loss: 177.5489\n",
      "Epoch 10517/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 207.3774 - val_loss: 177.4473\n",
      "Epoch 10518/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 207.2866 - val_loss: 177.4070\n",
      "Epoch 10519/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 207.1959 - val_loss: 177.2933\n",
      "Epoch 10520/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 207.1051 - val_loss: 177.2624\n",
      "Epoch 10521/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 207.0143 - val_loss: 177.1462\n",
      "Epoch 10522/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 206.9236 - val_loss: 177.1064\n",
      "Epoch 10523/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 206.8327 - val_loss: 177.0115\n",
      "Epoch 10524/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 206.7418 - val_loss: 176.9412\n",
      "Epoch 10525/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 206.6511 - val_loss: 176.8796\n",
      "Epoch 10526/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 206.5605 - val_loss: 176.7818\n",
      "Epoch 10527/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 206.4699 - val_loss: 176.7362\n",
      "Epoch 10528/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 206.3793 - val_loss: 176.6375\n",
      "Epoch 10529/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 206.2885 - val_loss: 176.5779\n",
      "Epoch 10530/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 206.1979 - val_loss: 176.5031\n",
      "Epoch 10531/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 206.1074 - val_loss: 176.4181\n",
      "Epoch 10532/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 206.0170 - val_loss: 176.3634\n",
      "Epoch 10533/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 205.9267 - val_loss: 176.2696\n",
      "Epoch 10534/100000\n",
      "11/11 [==============================] - 0s 672us/step - loss: 205.8362 - val_loss: 176.2106\n",
      "Epoch 10535/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 205.7458 - val_loss: 176.1315\n",
      "Epoch 10536/100000\n",
      "11/11 [==============================] - 0s 662us/step - loss: 205.6554 - val_loss: 176.0531\n",
      "Epoch 10537/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 205.5651 - val_loss: 175.9918\n",
      "Epoch 10538/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 205.4747 - val_loss: 175.9031\n",
      "Epoch 10539/100000\n",
      "11/11 [==============================] - 0s 588us/step - loss: 205.3845 - val_loss: 175.8423\n",
      "Epoch 10540/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 205.2942 - val_loss: 175.7621\n",
      "Epoch 10541/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 205.2039 - val_loss: 175.6874\n",
      "Epoch 10542/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 205.1138 - val_loss: 175.6217\n",
      "Epoch 10543/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 205.0236 - val_loss: 175.5370\n",
      "Epoch 10544/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 204.9335 - val_loss: 175.4741\n",
      "Epoch 10545/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 204.8433 - val_loss: 175.3941\n",
      "Epoch 10546/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 204.7532 - val_loss: 175.3216\n",
      "Epoch 10547/100000\n",
      "11/11 [==============================] - 0s 698us/step - loss: 204.6631 - val_loss: 175.2528\n",
      "Epoch 10548/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 204.5731 - val_loss: 175.1714\n",
      "Epoch 10549/100000\n",
      "11/11 [==============================] - 0s 621us/step - loss: 204.4830 - val_loss: 175.1066\n",
      "Epoch 10550/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 204.3931 - val_loss: 175.0272\n",
      "Epoch 10551/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 204.3031 - val_loss: 174.9561\n",
      "Epoch 10552/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 204.2132 - val_loss: 174.8850\n",
      "Epoch 10553/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 204.1233 - val_loss: 174.8065\n",
      "Epoch 10554/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 204.0335 - val_loss: 174.7399\n",
      "Epoch 10555/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 203.9436 - val_loss: 174.6612\n",
      "Epoch 10556/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 203.8539 - val_loss: 174.5912\n",
      "Epoch 10557/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 203.7641 - val_loss: 174.5183\n",
      "Epoch 10558/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 203.6743 - val_loss: 174.4422\n",
      "Epoch 10559/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 203.5846 - val_loss: 174.3739\n",
      "Epoch 10560/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 203.4949 - val_loss: 174.2961\n",
      "Epoch 10561/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 203.4052 - val_loss: 174.2265\n",
      "Epoch 10562/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 203.3155 - val_loss: 174.1524\n",
      "Epoch 10563/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 203.2259 - val_loss: 174.0783\n",
      "Epoch 10564/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 203.1363 - val_loss: 174.0084\n",
      "Epoch 10565/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 203.0467 - val_loss: 173.9318\n",
      "Epoch 10566/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 202.9572 - val_loss: 173.8622\n",
      "Epoch 10567/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 202.8676 - val_loss: 173.7874\n",
      "Epoch 10568/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 202.7781 - val_loss: 173.7151\n",
      "Epoch 10569/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 202.6888 - val_loss: 173.6435\n",
      "Epoch 10570/100000\n",
      "11/11 [==============================] - 0s 629us/step - loss: 202.5993 - val_loss: 173.5685\n",
      "Epoch 10571/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 317us/step - loss: 202.5100 - val_loss: 173.4985\n",
      "Epoch 10572/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 202.4206 - val_loss: 173.4236\n",
      "Epoch 10573/100000\n",
      "11/11 [==============================] - 0s 671us/step - loss: 202.3313 - val_loss: 173.3522\n",
      "Epoch 10574/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 202.2420 - val_loss: 173.2796\n",
      "Epoch 10575/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 202.1528 - val_loss: 173.2059\n",
      "Epoch 10576/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 202.0636 - val_loss: 173.1353\n",
      "Epoch 10577/100000\n",
      "11/11 [==============================] - 0s 781us/step - loss: 201.9744 - val_loss: 173.0607\n",
      "Epoch 10578/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 201.8852 - val_loss: 172.9899\n",
      "Epoch 10579/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 201.7960 - val_loss: 172.9165\n",
      "Epoch 10580/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 201.7069 - val_loss: 172.8442\n",
      "Epoch 10581/100000\n",
      "11/11 [==============================] - 0s 608us/step - loss: 201.6178 - val_loss: 172.7724\n",
      "Epoch 10582/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 201.5287 - val_loss: 172.6988\n",
      "Epoch 10583/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 201.4396 - val_loss: 172.6279\n",
      "Epoch 10584/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 201.3507 - val_loss: 172.5543\n",
      "Epoch 10585/100000\n",
      "11/11 [==============================] - 0s 894us/step - loss: 201.2616 - val_loss: 172.4828\n",
      "Epoch 10586/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 201.1727 - val_loss: 172.4103\n",
      "Epoch 10587/100000\n",
      "11/11 [==============================] - 0s 677us/step - loss: 201.0837 - val_loss: 172.3377\n",
      "Epoch 10588/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 200.9948 - val_loss: 172.2663\n",
      "Epoch 10589/100000\n",
      "11/11 [==============================] - 0s 833us/step - loss: 200.9060 - val_loss: 172.1931\n",
      "Epoch 10590/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 200.8171 - val_loss: 172.1219\n",
      "Epoch 10591/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 200.7283 - val_loss: 172.0491\n",
      "Epoch 10592/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 200.6396 - val_loss: 171.9774\n",
      "Epoch 10593/100000\n",
      "11/11 [==============================] - 0s 631us/step - loss: 200.5508 - val_loss: 171.9053\n",
      "Epoch 10594/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 200.4621 - val_loss: 171.8330\n",
      "Epoch 10595/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 200.3735 - val_loss: 171.7616\n",
      "Epoch 10596/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 200.2848 - val_loss: 171.6889\n",
      "Epoch 10597/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 200.1962 - val_loss: 171.6176\n",
      "Epoch 10598/100000\n",
      "11/11 [==============================] - 0s 789us/step - loss: 200.1076 - val_loss: 171.5452\n",
      "Epoch 10599/100000\n",
      "11/11 [==============================] - 0s 761us/step - loss: 200.0190 - val_loss: 171.4736\n",
      "Epoch 10600/100000\n",
      "11/11 [==============================] - 0s 862us/step - loss: 199.9306 - val_loss: 171.4018\n",
      "Epoch 10601/100000\n",
      "11/11 [==============================] - 0s 869us/step - loss: 199.8420 - val_loss: 171.3296\n",
      "Epoch 10602/100000\n",
      "11/11 [==============================] - 0s 891us/step - loss: 199.7535 - val_loss: 171.2583\n",
      "Epoch 10603/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 199.6650 - val_loss: 171.1859\n",
      "Epoch 10604/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 199.5766 - val_loss: 171.1148\n",
      "Epoch 10605/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 199.4882 - val_loss: 171.0425\n",
      "Epoch 10606/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 199.3997 - val_loss: 170.9711\n",
      "Epoch 10607/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 199.3114 - val_loss: 170.8994\n",
      "Epoch 10608/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 199.2231 - val_loss: 170.8277\n",
      "Epoch 10609/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 199.1348 - val_loss: 170.7564\n",
      "Epoch 10610/100000\n",
      "11/11 [==============================] - 0s 704us/step - loss: 199.0466 - val_loss: 170.6844\n",
      "Epoch 10611/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 198.9583 - val_loss: 170.6134\n",
      "Epoch 10612/100000\n",
      "11/11 [==============================] - 0s 840us/step - loss: 198.8703 - val_loss: 170.5414\n",
      "Epoch 10613/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 198.7820 - val_loss: 170.4704\n",
      "Epoch 10614/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 198.6940 - val_loss: 170.3986\n",
      "Epoch 10615/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 198.6058 - val_loss: 170.3273\n",
      "Epoch 10616/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 198.5178 - val_loss: 170.2560\n",
      "Epoch 10617/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 198.4297 - val_loss: 170.1844\n",
      "Epoch 10618/100000\n",
      "11/11 [==============================] - 0s 776us/step - loss: 198.3417 - val_loss: 170.1133\n",
      "Epoch 10619/100000\n",
      "11/11 [==============================] - 0s 814us/step - loss: 198.2537 - val_loss: 170.0417\n",
      "Epoch 10620/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 198.1657 - val_loss: 169.9706\n",
      "Epoch 10621/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 198.0778 - val_loss: 169.8993\n",
      "Epoch 10622/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 197.9899 - val_loss: 169.8280\n",
      "Epoch 10623/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 197.9019 - val_loss: 169.7568\n",
      "Epoch 10624/100000\n",
      "11/11 [==============================] - 0s 899us/step - loss: 197.8141 - val_loss: 169.6855\n",
      "Epoch 10625/100000\n",
      "11/11 [==============================] - 0s 809us/step - loss: 197.7261 - val_loss: 169.6146\n",
      "Epoch 10626/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 197.6385 - val_loss: 169.5433\n",
      "Epoch 10627/100000\n",
      "11/11 [==============================] - 0s 824us/step - loss: 197.5506 - val_loss: 169.4724\n",
      "Epoch 10628/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 197.4630 - val_loss: 169.4013\n",
      "Epoch 10629/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 197.3754 - val_loss: 169.3304\n",
      "Epoch 10630/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 197.2877 - val_loss: 169.2593\n",
      "Epoch 10631/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 197.2001 - val_loss: 169.1884\n",
      "Epoch 10632/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 197.1125 - val_loss: 169.1174\n",
      "Epoch 10633/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 197.0249 - val_loss: 169.0466\n",
      "Epoch 10634/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 196.9375 - val_loss: 168.9757\n",
      "Epoch 10635/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 196.8499 - val_loss: 168.9048\n",
      "Epoch 10636/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 196.7623 - val_loss: 168.8340\n",
      "Epoch 10637/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 196.6749 - val_loss: 168.7632\n",
      "Epoch 10638/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 196.5874 - val_loss: 168.6924\n",
      "Epoch 10639/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 196.5000 - val_loss: 168.6217\n",
      "Epoch 10640/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 196.4126 - val_loss: 168.5508\n",
      "Epoch 10641/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 196.3252 - val_loss: 168.4803\n",
      "Epoch 10642/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 196.2379 - val_loss: 168.4095\n",
      "Epoch 10643/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 196.1507 - val_loss: 168.3391\n",
      "Epoch 10644/100000\n",
      "11/11 [==============================] - 0s 951us/step - loss: 196.0634 - val_loss: 168.2682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10645/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 195.9761 - val_loss: 168.1979\n",
      "Epoch 10646/100000\n",
      "11/11 [==============================] - 0s 765us/step - loss: 195.8889 - val_loss: 168.1272\n",
      "Epoch 10647/100000\n",
      "11/11 [==============================] - 0s 671us/step - loss: 195.8018 - val_loss: 168.0569\n",
      "Epoch 10648/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 195.7147 - val_loss: 167.9862\n",
      "Epoch 10649/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 195.6275 - val_loss: 167.9159\n",
      "Epoch 10650/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 195.5405 - val_loss: 167.8454\n",
      "Epoch 10651/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 195.4535 - val_loss: 167.7751\n",
      "Epoch 10652/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 195.3665 - val_loss: 167.7047\n",
      "Epoch 10653/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 195.2794 - val_loss: 167.6343\n",
      "Epoch 10654/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 195.1925 - val_loss: 167.5642\n",
      "Epoch 10655/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 195.1056 - val_loss: 167.4937\n",
      "Epoch 10656/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 195.0187 - val_loss: 167.4237\n",
      "Epoch 10657/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 194.9318 - val_loss: 167.3532\n",
      "Epoch 10658/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 194.8449 - val_loss: 167.2832\n",
      "Epoch 10659/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 194.7581 - val_loss: 167.2127\n",
      "Epoch 10660/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 194.6713 - val_loss: 167.1429\n",
      "Epoch 10661/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 194.5845 - val_loss: 167.0724\n",
      "Epoch 10662/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 194.4977 - val_loss: 167.0027\n",
      "Epoch 10663/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 194.4111 - val_loss: 166.9323\n",
      "Epoch 10664/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 194.3244 - val_loss: 166.8626\n",
      "Epoch 10665/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 194.2377 - val_loss: 166.7922\n",
      "Epoch 10666/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 194.1511 - val_loss: 166.7227\n",
      "Epoch 10667/100000\n",
      "11/11 [==============================] - 0s 204us/step - loss: 194.0646 - val_loss: 166.6524\n",
      "Epoch 10668/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 193.9781 - val_loss: 166.5828\n",
      "Epoch 10669/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 193.8916 - val_loss: 166.5126\n",
      "Epoch 10670/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 193.8051 - val_loss: 166.4432\n",
      "Epoch 10671/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 193.7187 - val_loss: 166.3729\n",
      "Epoch 10672/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 193.6323 - val_loss: 166.3036\n",
      "Epoch 10673/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 193.5459 - val_loss: 166.2334\n",
      "Epoch 10674/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 193.4595 - val_loss: 166.1640\n",
      "Epoch 10675/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 193.3732 - val_loss: 166.0939\n",
      "Epoch 10676/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 193.2869 - val_loss: 166.0247\n",
      "Epoch 10677/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 193.2006 - val_loss: 165.9544\n",
      "Epoch 10678/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 193.1143 - val_loss: 165.8854\n",
      "Epoch 10679/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 193.0281 - val_loss: 165.8150\n",
      "Epoch 10680/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 192.9419 - val_loss: 165.7464\n",
      "Epoch 10681/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 192.8557 - val_loss: 165.6757\n",
      "Epoch 10682/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 192.7695 - val_loss: 165.6075\n",
      "Epoch 10683/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 192.6834 - val_loss: 165.5364\n",
      "Epoch 10684/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 192.5974 - val_loss: 165.4689\n",
      "Epoch 10685/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 192.5113 - val_loss: 165.3971\n",
      "Epoch 10686/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 192.4253 - val_loss: 165.3305\n",
      "Epoch 10687/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 192.3393 - val_loss: 165.2577\n",
      "Epoch 10688/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 192.2534 - val_loss: 165.1925\n",
      "Epoch 10689/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 192.1675 - val_loss: 165.1180\n",
      "Epoch 10690/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 192.0816 - val_loss: 165.0551\n",
      "Epoch 10691/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 191.9957 - val_loss: 164.9780\n",
      "Epoch 10692/100000\n",
      "11/11 [==============================] - 0s 855us/step - loss: 191.9099 - val_loss: 164.9185\n",
      "Epoch 10693/100000\n",
      "11/11 [==============================] - 0s 973us/step - loss: 191.8241 - val_loss: 164.8372\n",
      "Epoch 10694/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 191.7383 - val_loss: 164.7828\n",
      "Epoch 10695/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 191.6526 - val_loss: 164.6957\n",
      "Epoch 10696/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 191.5670 - val_loss: 164.6479\n",
      "Epoch 10697/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 191.4813 - val_loss: 164.5543\n",
      "Epoch 10698/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 191.3956 - val_loss: 164.5118\n",
      "Epoch 10699/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 191.3101 - val_loss: 164.4159\n",
      "Epoch 10700/100000\n",
      "11/11 [==============================] - 0s 639us/step - loss: 191.2243 - val_loss: 164.3707\n",
      "Epoch 10701/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 191.1387 - val_loss: 164.2835\n",
      "Epoch 10702/100000\n",
      "11/11 [==============================] - 0s 609us/step - loss: 191.0530 - val_loss: 164.2242\n",
      "Epoch 10703/100000\n",
      "11/11 [==============================] - 0s 992us/step - loss: 190.9675 - val_loss: 164.1547\n",
      "Epoch 10704/100000\n",
      "11/11 [==============================] - 0s 913us/step - loss: 190.8821 - val_loss: 164.0780\n",
      "Epoch 10705/100000\n",
      "11/11 [==============================] - 0s 791us/step - loss: 190.7967 - val_loss: 164.0230\n",
      "Epoch 10706/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 190.7113 - val_loss: 163.9374\n",
      "Epoch 10707/100000\n",
      "11/11 [==============================] - 0s 778us/step - loss: 190.6259 - val_loss: 163.8845\n",
      "Epoch 10708/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 190.5407 - val_loss: 163.8038\n",
      "Epoch 10709/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 190.4552 - val_loss: 163.7406\n",
      "Epoch 10710/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 190.3699 - val_loss: 163.6730\n",
      "Epoch 10711/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 190.2846 - val_loss: 163.5972\n",
      "Epoch 10712/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 190.1995 - val_loss: 163.5393\n",
      "Epoch 10713/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 190.1143 - val_loss: 163.4589\n",
      "Epoch 10714/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 190.0290 - val_loss: 163.3999\n",
      "Epoch 10715/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 189.9438 - val_loss: 163.3255\n",
      "Epoch 10716/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 189.8587 - val_loss: 163.2577\n",
      "Epoch 10717/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 189.7735 - val_loss: 163.1928\n",
      "Epoch 10718/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 189.6885 - val_loss: 163.1172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10719/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 189.6034 - val_loss: 163.0571\n",
      "Epoch 10720/100000\n",
      "11/11 [==============================] - 0s 850us/step - loss: 189.5185 - val_loss: 162.9810\n",
      "Epoch 10721/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 189.4335 - val_loss: 162.9177\n",
      "Epoch 10722/100000\n",
      "11/11 [==============================] - 0s 634us/step - loss: 189.3485 - val_loss: 162.8475\n",
      "Epoch 10723/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 189.2637 - val_loss: 162.7774\n",
      "Epoch 10724/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 189.1788 - val_loss: 162.7134\n",
      "Epoch 10725/100000\n",
      "11/11 [==============================] - 0s 756us/step - loss: 189.0940 - val_loss: 162.6392\n",
      "Epoch 10726/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 189.0091 - val_loss: 162.5766\n",
      "Epoch 10727/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 188.9243 - val_loss: 162.5039\n",
      "Epoch 10728/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 188.8397 - val_loss: 162.4379\n",
      "Epoch 10729/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 188.7549 - val_loss: 162.3698\n",
      "Epoch 10730/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 188.6702 - val_loss: 162.2992\n",
      "Epoch 10731/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 188.5855 - val_loss: 162.2348\n",
      "Epoch 10732/100000\n",
      "11/11 [==============================] - 0s 985us/step - loss: 188.5008 - val_loss: 162.1624\n",
      "Epoch 10733/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 188.4162 - val_loss: 162.0980\n",
      "Epoch 10734/100000\n",
      "11/11 [==============================] - 0s 693us/step - loss: 188.3316 - val_loss: 162.0272\n",
      "Epoch 10735/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 188.2470 - val_loss: 161.9600\n",
      "Epoch 10736/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 188.1625 - val_loss: 161.8927\n",
      "Epoch 10737/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 188.0779 - val_loss: 161.8226\n",
      "Epoch 10738/100000\n",
      "11/11 [==============================] - 0s 753us/step - loss: 187.9935 - val_loss: 161.7574\n",
      "Epoch 10739/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 187.9091 - val_loss: 161.6864\n",
      "Epoch 10740/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 187.8247 - val_loss: 161.6210\n",
      "Epoch 10741/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 187.7403 - val_loss: 161.5515\n",
      "Epoch 10742/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 187.6560 - val_loss: 161.4840\n",
      "Epoch 10743/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 187.5716 - val_loss: 161.4168\n",
      "Epoch 10744/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 187.4874 - val_loss: 161.3474\n",
      "Epoch 10745/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 187.4032 - val_loss: 161.2816\n",
      "Epoch 10746/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 187.3190 - val_loss: 161.2116\n",
      "Epoch 10747/100000\n",
      "11/11 [==============================] - 0s 896us/step - loss: 187.2347 - val_loss: 161.1457\n",
      "Epoch 10748/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 187.1506 - val_loss: 161.0767\n",
      "Epoch 10749/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 187.0665 - val_loss: 161.0094\n",
      "Epoch 10750/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 186.9824 - val_loss: 160.9418\n",
      "Epoch 10751/100000\n",
      "11/11 [==============================] - 0s 949us/step - loss: 186.8982 - val_loss: 160.8733\n",
      "Epoch 10752/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 186.8142 - val_loss: 160.8069\n",
      "Epoch 10753/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 186.7301 - val_loss: 160.7378\n",
      "Epoch 10754/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 186.6461 - val_loss: 160.6716\n",
      "Epoch 10755/100000\n",
      "11/11 [==============================] - 0s 662us/step - loss: 186.5622 - val_loss: 160.6029\n",
      "Epoch 10756/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 186.4782 - val_loss: 160.5359\n",
      "Epoch 10757/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 186.3943 - val_loss: 160.4683\n",
      "Epoch 10758/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 186.3105 - val_loss: 160.4004\n",
      "Epoch 10759/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 186.2266 - val_loss: 160.3336\n",
      "Epoch 10760/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 186.1429 - val_loss: 160.2653\n",
      "Epoch 10761/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 186.0591 - val_loss: 160.1989\n",
      "Epoch 10762/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 185.9754 - val_loss: 160.1305\n",
      "Epoch 10763/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 185.8917 - val_loss: 160.0639\n",
      "Epoch 10764/100000\n",
      "11/11 [==============================] - 0s 629us/step - loss: 185.8080 - val_loss: 159.9960\n",
      "Epoch 10765/100000\n",
      "11/11 [==============================] - 0s 633us/step - loss: 185.7243 - val_loss: 159.9289\n",
      "Epoch 10766/100000\n",
      "11/11 [==============================] - 0s 939us/step - loss: 185.6407 - val_loss: 159.8616\n",
      "Epoch 10767/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 185.5571 - val_loss: 159.7941\n",
      "Epoch 10768/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 185.4736 - val_loss: 159.7272\n",
      "Epoch 10769/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 185.3900 - val_loss: 159.6595\n",
      "Epoch 10770/100000\n",
      "11/11 [==============================] - 0s 741us/step - loss: 185.3065 - val_loss: 159.5928\n",
      "Epoch 10771/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 185.2229 - val_loss: 159.5250\n",
      "Epoch 10772/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 185.1395 - val_loss: 159.4583\n",
      "Epoch 10773/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 185.0561 - val_loss: 159.3909\n",
      "Epoch 10774/100000\n",
      "11/11 [==============================] - 0s 940us/step - loss: 184.9728 - val_loss: 159.3239\n",
      "Epoch 10775/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 184.8893 - val_loss: 159.2568\n",
      "Epoch 10776/100000\n",
      "11/11 [==============================] - 0s 662us/step - loss: 184.8060 - val_loss: 159.1897\n",
      "Epoch 10777/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 184.7227 - val_loss: 159.1229\n",
      "Epoch 10778/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 184.6395 - val_loss: 159.0555\n",
      "Epoch 10779/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 184.5563 - val_loss: 158.9890\n",
      "Epoch 10780/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 184.4731 - val_loss: 158.9216\n",
      "Epoch 10781/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 184.3900 - val_loss: 158.8551\n",
      "Epoch 10782/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 184.3068 - val_loss: 158.7878\n",
      "Epoch 10783/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 184.2236 - val_loss: 158.7211\n",
      "Epoch 10784/100000\n",
      "11/11 [==============================] - 0s 777us/step - loss: 184.1405 - val_loss: 158.6542\n",
      "Epoch 10785/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 184.0576 - val_loss: 158.5874\n",
      "Epoch 10786/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 183.9745 - val_loss: 158.5206\n",
      "Epoch 10787/100000\n",
      "11/11 [==============================] - 0s 856us/step - loss: 183.8915 - val_loss: 158.4537\n",
      "Epoch 10788/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 183.8085 - val_loss: 158.3871\n",
      "Epoch 10789/100000\n",
      "11/11 [==============================] - 0s 825us/step - loss: 183.7256 - val_loss: 158.3201\n",
      "Epoch 10790/100000\n",
      "11/11 [==============================] - 0s 888us/step - loss: 183.6426 - val_loss: 158.2537\n",
      "Epoch 10791/100000\n",
      "11/11 [==============================] - 0s 622us/step - loss: 183.5597 - val_loss: 158.1866\n",
      "Epoch 10792/100000\n",
      "11/11 [==============================] - 0s 634us/step - loss: 183.4769 - val_loss: 158.1203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10793/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 183.3941 - val_loss: 158.0533\n",
      "Epoch 10794/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 183.3113 - val_loss: 157.9871\n",
      "Epoch 10795/100000\n",
      "11/11 [==============================] - 0s 652us/step - loss: 183.2286 - val_loss: 157.9203\n",
      "Epoch 10796/100000\n",
      "11/11 [==============================] - 0s 679us/step - loss: 183.1459 - val_loss: 157.8539\n",
      "Epoch 10797/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 183.0632 - val_loss: 157.7872\n",
      "Epoch 10798/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 182.9806 - val_loss: 157.7208\n",
      "Epoch 10799/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 182.8979 - val_loss: 157.6543\n",
      "Epoch 10800/100000\n",
      "11/11 [==============================] - 0s 204us/step - loss: 182.8153 - val_loss: 157.5879\n",
      "Epoch 10801/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 182.7328 - val_loss: 157.5215\n",
      "Epoch 10802/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 182.6502 - val_loss: 157.4550\n",
      "Epoch 10803/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 182.5677 - val_loss: 157.3887\n",
      "Epoch 10804/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 182.4852 - val_loss: 157.3223\n",
      "Epoch 10805/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 182.4027 - val_loss: 157.2560\n",
      "Epoch 10806/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 182.3203 - val_loss: 157.1895\n",
      "Epoch 10807/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 182.2378 - val_loss: 157.1233\n",
      "Epoch 10808/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 182.1555 - val_loss: 157.0570\n",
      "Epoch 10809/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 182.0732 - val_loss: 156.9907\n",
      "Epoch 10810/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 181.9908 - val_loss: 156.9246\n",
      "Epoch 10811/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 181.9086 - val_loss: 156.8583\n",
      "Epoch 10812/100000\n",
      "11/11 [==============================] - 0s 954us/step - loss: 181.8263 - val_loss: 156.7923\n",
      "Epoch 10813/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 181.7442 - val_loss: 156.7261\n",
      "Epoch 10814/100000\n",
      "11/11 [==============================] - 0s 958us/step - loss: 181.6620 - val_loss: 156.6601\n",
      "Epoch 10815/100000\n",
      "11/11 [==============================] - 0s 754us/step - loss: 181.5799 - val_loss: 156.5939\n",
      "Epoch 10816/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 181.4978 - val_loss: 156.5281\n",
      "Epoch 10817/100000\n",
      "11/11 [==============================] - 0s 901us/step - loss: 181.4158 - val_loss: 156.4618\n",
      "Epoch 10818/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 181.3336 - val_loss: 156.3960\n",
      "Epoch 10819/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 181.2516 - val_loss: 156.3298\n",
      "Epoch 10820/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 181.1696 - val_loss: 156.2641\n",
      "Epoch 10821/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 181.0876 - val_loss: 156.1978\n",
      "Epoch 10822/100000\n",
      "11/11 [==============================] - 0s 754us/step - loss: 181.0057 - val_loss: 156.1322\n",
      "Epoch 10823/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 180.9238 - val_loss: 156.0661\n",
      "Epoch 10824/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 180.8419 - val_loss: 156.0005\n",
      "Epoch 10825/100000\n",
      "11/11 [==============================] - 0s 870us/step - loss: 180.7601 - val_loss: 155.9343\n",
      "Epoch 10826/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 180.6782 - val_loss: 155.8689\n",
      "Epoch 10827/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 180.5964 - val_loss: 155.8026\n",
      "Epoch 10828/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 180.5146 - val_loss: 155.7374\n",
      "Epoch 10829/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 180.4329 - val_loss: 155.6710\n",
      "Epoch 10830/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 180.3512 - val_loss: 155.6062\n",
      "Epoch 10831/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 180.2697 - val_loss: 155.5395\n",
      "Epoch 10832/100000\n",
      "11/11 [==============================] - 0s 706us/step - loss: 180.1880 - val_loss: 155.4750\n",
      "Epoch 10833/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 180.1064 - val_loss: 155.4080\n",
      "Epoch 10834/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 180.0248 - val_loss: 155.3441\n",
      "Epoch 10835/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 179.9434 - val_loss: 155.2765\n",
      "Epoch 10836/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 179.8619 - val_loss: 155.2134\n",
      "Epoch 10837/100000\n",
      "11/11 [==============================] - 0s 673us/step - loss: 179.7803 - val_loss: 155.1448\n",
      "Epoch 10838/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 179.6988 - val_loss: 155.0831\n",
      "Epoch 10839/100000\n",
      "11/11 [==============================] - 0s 751us/step - loss: 179.6175 - val_loss: 155.0129\n",
      "Epoch 10840/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 179.5361 - val_loss: 154.9532\n",
      "Epoch 10841/100000\n",
      "11/11 [==============================] - 0s 964us/step - loss: 179.4547 - val_loss: 154.8806\n",
      "Epoch 10842/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 179.3733 - val_loss: 154.8241\n",
      "Epoch 10843/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 179.2921 - val_loss: 154.7479\n",
      "Epoch 10844/100000\n",
      "11/11 [==============================] - 0s 609us/step - loss: 179.2108 - val_loss: 154.6956\n",
      "Epoch 10845/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 179.1296 - val_loss: 154.6149\n",
      "Epoch 10846/100000\n",
      "11/11 [==============================] - 0s 887us/step - loss: 179.0484 - val_loss: 154.5673\n",
      "Epoch 10847/100000\n",
      "11/11 [==============================] - 0s 639us/step - loss: 178.9674 - val_loss: 154.4828\n",
      "Epoch 10848/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 178.8862 - val_loss: 154.4369\n",
      "Epoch 10849/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 178.8051 - val_loss: 154.3540\n",
      "Epoch 10850/100000\n",
      "11/11 [==============================] - 0s 732us/step - loss: 178.7239 - val_loss: 154.3021\n",
      "Epoch 10851/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 178.6428 - val_loss: 154.2293\n",
      "Epoch 10852/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 178.5618 - val_loss: 154.1652\n",
      "Epoch 10853/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 178.4808 - val_loss: 154.1050\n",
      "Epoch 10854/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 178.3999 - val_loss: 154.0304\n",
      "Epoch 10855/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 178.3190 - val_loss: 153.9772\n",
      "Epoch 10856/100000\n",
      "11/11 [==============================] - 0s 686us/step - loss: 178.2381 - val_loss: 153.9005\n",
      "Epoch 10857/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 178.1572 - val_loss: 153.8444\n",
      "Epoch 10858/100000\n",
      "11/11 [==============================] - 0s 837us/step - loss: 178.0763 - val_loss: 153.7745\n",
      "Epoch 10859/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 177.9953 - val_loss: 153.7095\n",
      "Epoch 10860/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 177.9147 - val_loss: 153.6489\n",
      "Epoch 10861/100000\n",
      "11/11 [==============================] - 0s 739us/step - loss: 177.8339 - val_loss: 153.5767\n",
      "Epoch 10862/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 177.7533 - val_loss: 153.5202\n",
      "Epoch 10863/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 177.6725 - val_loss: 153.4478\n",
      "Epoch 10864/100000\n",
      "11/11 [==============================] - 0s 752us/step - loss: 177.5918 - val_loss: 153.3879\n",
      "Epoch 10865/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 177.5112 - val_loss: 153.3215\n",
      "Epoch 10866/100000\n",
      "11/11 [==============================] - 0s 970us/step - loss: 177.4306 - val_loss: 153.2549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10867/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 177.3501 - val_loss: 153.1946\n",
      "Epoch 10868/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 177.2695 - val_loss: 153.1241\n",
      "Epoch 10869/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 177.1891 - val_loss: 153.0650\n",
      "Epoch 10870/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 177.1087 - val_loss: 152.9960\n",
      "Epoch 10871/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 177.0282 - val_loss: 152.9334\n",
      "Epoch 10872/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 176.9478 - val_loss: 152.8691\n",
      "Epoch 10873/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 176.8674 - val_loss: 152.8021\n",
      "Epoch 10874/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 176.7871 - val_loss: 152.7412\n",
      "Epoch 10875/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 176.7067 - val_loss: 152.6725\n",
      "Epoch 10876/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 176.6264 - val_loss: 152.6115\n",
      "Epoch 10877/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 176.5461 - val_loss: 152.5448\n",
      "Epoch 10878/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 176.4660 - val_loss: 152.4808\n",
      "Epoch 10879/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 176.3857 - val_loss: 152.4175\n",
      "Epoch 10880/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 176.3056 - val_loss: 152.3507\n",
      "Epoch 10881/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 176.2254 - val_loss: 152.2892\n",
      "Epoch 10882/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 176.1454 - val_loss: 152.2220\n",
      "Epoch 10883/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 176.0653 - val_loss: 152.1598\n",
      "Epoch 10884/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 175.9853 - val_loss: 152.0944\n",
      "Epoch 10885/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 175.9053 - val_loss: 152.0300\n",
      "Epoch 10886/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 175.8254 - val_loss: 151.9668\n",
      "Epoch 10887/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 175.7453 - val_loss: 151.9008\n",
      "Epoch 10888/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 175.6655 - val_loss: 151.8386\n",
      "Epoch 10889/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 175.5856 - val_loss: 151.7725\n",
      "Epoch 10890/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 175.5057 - val_loss: 151.7097\n",
      "Epoch 10891/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 175.4259 - val_loss: 151.6448\n",
      "Epoch 10892/100000\n",
      "11/11 [==============================] - 0s 205us/step - loss: 175.3461 - val_loss: 151.5806\n",
      "Epoch 10893/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 175.2663 - val_loss: 151.5173\n",
      "Epoch 10894/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 175.1866 - val_loss: 151.4519\n",
      "Epoch 10895/100000\n",
      "11/11 [==============================] - 0s 203us/step - loss: 175.1069 - val_loss: 151.3893\n",
      "Epoch 10896/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 175.0272 - val_loss: 151.3239\n",
      "Epoch 10897/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 174.9475 - val_loss: 151.2610\n",
      "Epoch 10898/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 174.8680 - val_loss: 151.1964\n",
      "Epoch 10899/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 174.7884 - val_loss: 151.1325\n",
      "Epoch 10900/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 174.7089 - val_loss: 151.0690\n",
      "Epoch 10901/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 174.6293 - val_loss: 151.0044\n",
      "Epoch 10902/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 174.5499 - val_loss: 150.9415\n",
      "Epoch 10903/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 174.4705 - val_loss: 150.8766\n",
      "Epoch 10904/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 174.3910 - val_loss: 150.8136\n",
      "Epoch 10905/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 174.3116 - val_loss: 150.7493\n",
      "Epoch 10906/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 174.2323 - val_loss: 150.6858\n",
      "Epoch 10907/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 174.1530 - val_loss: 150.6221\n",
      "Epoch 10908/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 174.0737 - val_loss: 150.5580\n",
      "Epoch 10909/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 173.9944 - val_loss: 150.4948\n",
      "Epoch 10910/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 173.9151 - val_loss: 150.4305\n",
      "Epoch 10911/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 173.8359 - val_loss: 150.3675\n",
      "Epoch 10912/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 173.7568 - val_loss: 150.3033\n",
      "Epoch 10913/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 173.6776 - val_loss: 150.2402\n",
      "Epoch 10914/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 173.5985 - val_loss: 150.1764\n",
      "Epoch 10915/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 173.5194 - val_loss: 150.1129\n",
      "Epoch 10916/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 173.4404 - val_loss: 150.0495\n",
      "Epoch 10917/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 173.3613 - val_loss: 149.9857\n",
      "Epoch 10918/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 173.2824 - val_loss: 149.9227\n",
      "Epoch 10919/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 173.2034 - val_loss: 149.8588\n",
      "Epoch 10920/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 173.1246 - val_loss: 149.7958\n",
      "Epoch 10921/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 173.0456 - val_loss: 149.7321\n",
      "Epoch 10922/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 172.9668 - val_loss: 149.6690\n",
      "Epoch 10923/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 172.8880 - val_loss: 149.6056\n",
      "Epoch 10924/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 172.8092 - val_loss: 149.5422\n",
      "Epoch 10925/100000\n",
      "11/11 [==============================] - 0s 623us/step - loss: 172.7304 - val_loss: 149.4791\n",
      "Epoch 10926/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 172.6517 - val_loss: 149.4155\n",
      "Epoch 10927/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 172.5729 - val_loss: 149.3526\n",
      "Epoch 10928/100000\n",
      "11/11 [==============================] - 0s 672us/step - loss: 172.4943 - val_loss: 149.2891\n",
      "Epoch 10929/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 172.4156 - val_loss: 149.2262\n",
      "Epoch 10930/100000\n",
      "11/11 [==============================] - 0s 716us/step - loss: 172.3370 - val_loss: 149.1629\n",
      "Epoch 10931/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 172.2584 - val_loss: 149.0999\n",
      "Epoch 10932/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 172.1799 - val_loss: 149.0367\n",
      "Epoch 10933/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 172.1013 - val_loss: 148.9737\n",
      "Epoch 10934/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 172.0229 - val_loss: 148.9107\n",
      "Epoch 10935/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 171.9444 - val_loss: 148.8476\n",
      "Epoch 10936/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 171.8660 - val_loss: 148.7848\n",
      "Epoch 10937/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 171.7876 - val_loss: 148.7216\n",
      "Epoch 10938/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 171.7093 - val_loss: 148.6588\n",
      "Epoch 10939/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 171.6309 - val_loss: 148.5958\n",
      "Epoch 10940/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 171.5526 - val_loss: 148.5330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10941/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 171.4743 - val_loss: 148.4701\n",
      "Epoch 10942/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 171.3961 - val_loss: 148.4073\n",
      "Epoch 10943/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 171.3179 - val_loss: 148.3445\n",
      "Epoch 10944/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 171.2397 - val_loss: 148.2817\n",
      "Epoch 10945/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 171.1616 - val_loss: 148.2190\n",
      "Epoch 10946/100000\n",
      "11/11 [==============================] - 0s 695us/step - loss: 171.0835 - val_loss: 148.1562\n",
      "Epoch 10947/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 171.0054 - val_loss: 148.0936\n",
      "Epoch 10948/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 170.9273 - val_loss: 148.0308\n",
      "Epoch 10949/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 170.8493 - val_loss: 147.9683\n",
      "Epoch 10950/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 170.7713 - val_loss: 147.9056\n",
      "Epoch 10951/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 170.6935 - val_loss: 147.8431\n",
      "Epoch 10952/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 170.6155 - val_loss: 147.7805\n",
      "Epoch 10953/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 170.5376 - val_loss: 147.7180\n",
      "Epoch 10954/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 170.4598 - val_loss: 147.6555\n",
      "Epoch 10955/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 170.3820 - val_loss: 147.5930\n",
      "Epoch 10956/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 170.3042 - val_loss: 147.5305\n",
      "Epoch 10957/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 170.2264 - val_loss: 147.4681\n",
      "Epoch 10958/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 170.1486 - val_loss: 147.4057\n",
      "Epoch 10959/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 170.0710 - val_loss: 147.3434\n",
      "Epoch 10960/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 169.9933 - val_loss: 147.2809\n",
      "Epoch 10961/100000\n",
      "11/11 [==============================] - 0s 691us/step - loss: 169.9156 - val_loss: 147.2186\n",
      "Epoch 10962/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 169.8380 - val_loss: 147.1564\n",
      "Epoch 10963/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 169.7605 - val_loss: 147.0940\n",
      "Epoch 10964/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 169.6828 - val_loss: 147.0318\n",
      "Epoch 10965/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 169.6054 - val_loss: 146.9696\n",
      "Epoch 10966/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 169.5279 - val_loss: 146.9075\n",
      "Epoch 10967/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 169.4505 - val_loss: 146.8453\n",
      "Epoch 10968/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 169.3731 - val_loss: 146.7832\n",
      "Epoch 10969/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 169.2957 - val_loss: 146.7211\n",
      "Epoch 10970/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 169.2184 - val_loss: 146.6590\n",
      "Epoch 10971/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 169.1410 - val_loss: 146.5970\n",
      "Epoch 10972/100000\n",
      "11/11 [==============================] - 0s 665us/step - loss: 169.0638 - val_loss: 146.5349\n",
      "Epoch 10973/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 168.9864 - val_loss: 146.4729\n",
      "Epoch 10974/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 168.9092 - val_loss: 146.4110\n",
      "Epoch 10975/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 168.8320 - val_loss: 146.3491\n",
      "Epoch 10976/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 168.7548 - val_loss: 146.2871\n",
      "Epoch 10977/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 168.6777 - val_loss: 146.2253\n",
      "Epoch 10978/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 168.6006 - val_loss: 146.1632\n",
      "Epoch 10979/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 168.5234 - val_loss: 146.1017\n",
      "Epoch 10980/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 168.4465 - val_loss: 146.0396\n",
      "Epoch 10981/100000\n",
      "11/11 [==============================] - 0s 996us/step - loss: 168.3694 - val_loss: 145.9781\n",
      "Epoch 10982/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 168.2925 - val_loss: 145.9160\n",
      "Epoch 10983/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 168.2155 - val_loss: 145.8547\n",
      "Epoch 10984/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 168.1387 - val_loss: 145.7925\n",
      "Epoch 10985/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 168.0618 - val_loss: 145.7315\n",
      "Epoch 10986/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 167.9850 - val_loss: 145.6691\n",
      "Epoch 10987/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 167.9081 - val_loss: 145.6083\n",
      "Epoch 10988/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 167.8314 - val_loss: 145.5457\n",
      "Epoch 10989/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 167.7545 - val_loss: 145.4853\n",
      "Epoch 10990/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 167.6779 - val_loss: 145.4224\n",
      "Epoch 10991/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 167.6011 - val_loss: 145.3625\n",
      "Epoch 10992/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 167.5245 - val_loss: 145.2992\n",
      "Epoch 10993/100000\n",
      "11/11 [==============================] - 0s 644us/step - loss: 167.4479 - val_loss: 145.2400\n",
      "Epoch 10994/100000\n",
      "11/11 [==============================] - 0s 682us/step - loss: 167.3713 - val_loss: 145.1758\n",
      "Epoch 10995/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 167.2947 - val_loss: 145.1178\n",
      "Epoch 10996/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 167.2182 - val_loss: 145.0523\n",
      "Epoch 10997/100000\n",
      "11/11 [==============================] - 0s 954us/step - loss: 167.1417 - val_loss: 144.9960\n",
      "Epoch 10998/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 167.0653 - val_loss: 144.9287\n",
      "Epoch 10999/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 166.9888 - val_loss: 144.8746\n",
      "Epoch 11000/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 166.9124 - val_loss: 144.8049\n",
      "Epoch 11001/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 166.8361 - val_loss: 144.7536\n",
      "Epoch 11002/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 166.7599 - val_loss: 144.6813\n",
      "Epoch 11003/100000\n",
      "11/11 [==============================] - 0s 828us/step - loss: 166.6835 - val_loss: 144.6319\n",
      "Epoch 11004/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 166.6073 - val_loss: 144.5591\n",
      "Epoch 11005/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 166.5311 - val_loss: 144.5084\n",
      "Epoch 11006/100000\n",
      "11/11 [==============================] - 0s 836us/step - loss: 166.4548 - val_loss: 144.4390\n",
      "Epoch 11007/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 166.3785 - val_loss: 144.3829\n",
      "Epoch 11008/100000\n",
      "11/11 [==============================] - 0s 894us/step - loss: 166.3022 - val_loss: 144.3203\n",
      "Epoch 11009/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 166.2261 - val_loss: 144.2574\n",
      "Epoch 11010/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 166.1501 - val_loss: 144.2011\n",
      "Epoch 11011/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 166.0740 - val_loss: 144.1337\n",
      "Epoch 11012/100000\n",
      "11/11 [==============================] - 0s 783us/step - loss: 165.9980 - val_loss: 144.0798\n",
      "Epoch 11013/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 165.9221 - val_loss: 144.0126\n",
      "Epoch 11014/100000\n",
      "11/11 [==============================] - 0s 815us/step - loss: 165.8461 - val_loss: 143.9563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11015/100000\n",
      "11/11 [==============================] - 0s 757us/step - loss: 165.7701 - val_loss: 143.8932\n",
      "Epoch 11016/100000\n",
      "11/11 [==============================] - 0s 755us/step - loss: 165.6942 - val_loss: 143.8320\n",
      "Epoch 11017/100000\n",
      "11/11 [==============================] - 0s 948us/step - loss: 165.6183 - val_loss: 143.7739\n",
      "Epoch 11018/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 165.5426 - val_loss: 143.7090\n",
      "Epoch 11019/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 165.4668 - val_loss: 143.6529\n",
      "Epoch 11020/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 165.3910 - val_loss: 143.5879\n",
      "Epoch 11021/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 165.3153 - val_loss: 143.5305\n",
      "Epoch 11022/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 165.2395 - val_loss: 143.4682\n",
      "Epoch 11023/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 165.1639 - val_loss: 143.4075\n",
      "Epoch 11024/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 165.0883 - val_loss: 143.3484\n",
      "Epoch 11025/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 165.0125 - val_loss: 143.2851\n",
      "Epoch 11026/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 164.9370 - val_loss: 143.2278\n",
      "Epoch 11027/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 164.8614 - val_loss: 143.1644\n",
      "Epoch 11028/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 164.7860 - val_loss: 143.1062\n",
      "Epoch 11029/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 164.7106 - val_loss: 143.0445\n",
      "Epoch 11030/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 164.6351 - val_loss: 142.9841\n",
      "Epoch 11031/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 164.5597 - val_loss: 142.9249\n",
      "Epoch 11032/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 164.4843 - val_loss: 142.8626\n",
      "Epoch 11033/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 164.4089 - val_loss: 142.8044\n",
      "Epoch 11034/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 164.3335 - val_loss: 142.7420\n",
      "Epoch 11035/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 164.2583 - val_loss: 142.6834\n",
      "Epoch 11036/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 164.1830 - val_loss: 142.6221\n",
      "Epoch 11037/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 164.1078 - val_loss: 142.5622\n",
      "Epoch 11038/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 164.0326 - val_loss: 142.5025\n",
      "Epoch 11039/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 163.9575 - val_loss: 142.4412\n",
      "Epoch 11040/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 163.8823 - val_loss: 142.3825\n",
      "Epoch 11041/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 163.8072 - val_loss: 142.3210\n",
      "Epoch 11042/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 163.7322 - val_loss: 142.2622\n",
      "Epoch 11043/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 163.6571 - val_loss: 142.2012\n",
      "Epoch 11044/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 163.5822 - val_loss: 142.1416\n",
      "Epoch 11045/100000\n",
      "11/11 [==============================] - 0s 727us/step - loss: 163.5071 - val_loss: 142.0817\n",
      "Epoch 11046/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 163.4322 - val_loss: 142.0212\n",
      "Epoch 11047/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 163.3574 - val_loss: 141.9621\n",
      "Epoch 11048/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 163.2825 - val_loss: 141.9012\n",
      "Epoch 11049/100000\n",
      "11/11 [==============================] - 0s 730us/step - loss: 163.2076 - val_loss: 141.8423\n",
      "Epoch 11050/100000\n",
      "11/11 [==============================] - 0s 689us/step - loss: 163.1328 - val_loss: 141.7816\n",
      "Epoch 11051/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 163.0580 - val_loss: 141.7223\n",
      "Epoch 11052/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 162.9832 - val_loss: 141.6624\n",
      "Epoch 11053/100000\n",
      "11/11 [==============================] - 0s 684us/step - loss: 162.9086 - val_loss: 141.6025\n",
      "Epoch 11054/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 162.8339 - val_loss: 141.5432\n",
      "Epoch 11055/100000\n",
      "11/11 [==============================] - 0s 637us/step - loss: 162.7593 - val_loss: 141.4828\n",
      "Epoch 11056/100000\n",
      "11/11 [==============================] - 0s 899us/step - loss: 162.6846 - val_loss: 141.4238\n",
      "Epoch 11057/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 162.6100 - val_loss: 141.3635\n",
      "Epoch 11058/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 162.5355 - val_loss: 141.3044\n",
      "Epoch 11059/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 162.4610 - val_loss: 141.2444\n",
      "Epoch 11060/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 162.3865 - val_loss: 141.1851\n",
      "Epoch 11061/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 162.3121 - val_loss: 141.1255\n",
      "Epoch 11062/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 162.2376 - val_loss: 141.0659\n",
      "Epoch 11063/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 162.1632 - val_loss: 141.0067\n",
      "Epoch 11064/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 162.0889 - val_loss: 140.9468\n",
      "Epoch 11065/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 162.0145 - val_loss: 140.8879\n",
      "Epoch 11066/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 161.9403 - val_loss: 140.8280\n",
      "Epoch 11067/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 161.8660 - val_loss: 140.7690\n",
      "Epoch 11068/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 161.7917 - val_loss: 140.7093\n",
      "Epoch 11069/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 161.7175 - val_loss: 140.6502\n",
      "Epoch 11070/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 161.6434 - val_loss: 140.5909\n",
      "Epoch 11071/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 161.5692 - val_loss: 140.5316\n",
      "Epoch 11072/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 161.4951 - val_loss: 140.4725\n",
      "Epoch 11073/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 161.4211 - val_loss: 140.4131\n",
      "Epoch 11074/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 161.3471 - val_loss: 140.3542\n",
      "Epoch 11075/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 161.2731 - val_loss: 140.2948\n",
      "Epoch 11076/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 161.1991 - val_loss: 140.2360\n",
      "Epoch 11077/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 161.1252 - val_loss: 140.1766\n",
      "Epoch 11078/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 161.0512 - val_loss: 140.1178\n",
      "Epoch 11079/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 160.9774 - val_loss: 140.0586\n",
      "Epoch 11080/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 160.9035 - val_loss: 139.9996\n",
      "Epoch 11081/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 160.8297 - val_loss: 139.9407\n",
      "Epoch 11082/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 160.7559 - val_loss: 139.8817\n",
      "Epoch 11083/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 160.6822 - val_loss: 139.8229\n",
      "Epoch 11084/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 160.6084 - val_loss: 139.7638\n",
      "Epoch 11085/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 160.5347 - val_loss: 139.7052\n",
      "Epoch 11086/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 160.4611 - val_loss: 139.6461\n",
      "Epoch 11087/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 160.3874 - val_loss: 139.5876\n",
      "Epoch 11088/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 397us/step - loss: 160.3139 - val_loss: 139.5286\n",
      "Epoch 11089/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 160.2403 - val_loss: 139.4701\n",
      "Epoch 11090/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 160.1668 - val_loss: 139.4112\n",
      "Epoch 11091/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 160.0933 - val_loss: 139.3527\n",
      "Epoch 11092/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 160.0200 - val_loss: 139.2939\n",
      "Epoch 11093/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 159.9465 - val_loss: 139.2353\n",
      "Epoch 11094/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 159.8731 - val_loss: 139.1767\n",
      "Epoch 11095/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 159.7997 - val_loss: 139.1181\n",
      "Epoch 11096/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 159.7264 - val_loss: 139.0597\n",
      "Epoch 11097/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 159.6531 - val_loss: 139.0010\n",
      "Epoch 11098/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 159.5798 - val_loss: 138.9427\n",
      "Epoch 11099/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 159.5066 - val_loss: 138.8841\n",
      "Epoch 11100/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 159.4334 - val_loss: 138.8258\n",
      "Epoch 11101/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 159.3602 - val_loss: 138.7672\n",
      "Epoch 11102/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 159.2870 - val_loss: 138.7091\n",
      "Epoch 11103/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 159.2140 - val_loss: 138.6506\n",
      "Epoch 11104/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 159.1409 - val_loss: 138.5924\n",
      "Epoch 11105/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 159.0678 - val_loss: 138.5340\n",
      "Epoch 11106/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 158.9948 - val_loss: 138.4759\n",
      "Epoch 11107/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 158.9219 - val_loss: 138.4177\n",
      "Epoch 11108/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 158.8490 - val_loss: 138.3594\n",
      "Epoch 11109/100000\n",
      "11/11 [==============================] - 0s 609us/step - loss: 158.7760 - val_loss: 138.3014\n",
      "Epoch 11110/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 158.7033 - val_loss: 138.2432\n",
      "Epoch 11111/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 158.6304 - val_loss: 138.1852\n",
      "Epoch 11112/100000\n",
      "11/11 [==============================] - 0s 922us/step - loss: 158.5575 - val_loss: 138.1269\n",
      "Epoch 11113/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 158.4847 - val_loss: 138.0690\n",
      "Epoch 11114/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 158.4120 - val_loss: 138.0109\n",
      "Epoch 11115/100000\n",
      "11/11 [==============================] - 0s 993us/step - loss: 158.3393 - val_loss: 137.9530\n",
      "Epoch 11116/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 158.2666 - val_loss: 137.8949\n",
      "Epoch 11117/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 158.1939 - val_loss: 137.8372\n",
      "Epoch 11118/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 158.1214 - val_loss: 137.7791\n",
      "Epoch 11119/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 158.0488 - val_loss: 137.7215\n",
      "Epoch 11120/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 157.9762 - val_loss: 137.6634\n",
      "Epoch 11121/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 157.9037 - val_loss: 137.6058\n",
      "Epoch 11122/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 157.8312 - val_loss: 137.5478\n",
      "Epoch 11123/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 157.7588 - val_loss: 137.4903\n",
      "Epoch 11124/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 157.6863 - val_loss: 137.4323\n",
      "Epoch 11125/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 157.6140 - val_loss: 137.3749\n",
      "Epoch 11126/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 157.5416 - val_loss: 137.3170\n",
      "Epoch 11127/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 157.4693 - val_loss: 137.2596\n",
      "Epoch 11128/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 157.3970 - val_loss: 137.2017\n",
      "Epoch 11129/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 157.3247 - val_loss: 137.1444\n",
      "Epoch 11130/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 157.2524 - val_loss: 137.0866\n",
      "Epoch 11131/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 157.1803 - val_loss: 137.0293\n",
      "Epoch 11132/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 157.1080 - val_loss: 136.9716\n",
      "Epoch 11133/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 157.0360 - val_loss: 136.9145\n",
      "Epoch 11134/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 156.9639 - val_loss: 136.8567\n",
      "Epoch 11135/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 156.8919 - val_loss: 136.7997\n",
      "Epoch 11136/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 156.8198 - val_loss: 136.7418\n",
      "Epoch 11137/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 156.7478 - val_loss: 136.6851\n",
      "Epoch 11138/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 156.6758 - val_loss: 136.6270\n",
      "Epoch 11139/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 156.6039 - val_loss: 136.5706\n",
      "Epoch 11140/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 156.5320 - val_loss: 136.5124\n",
      "Epoch 11141/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 156.4601 - val_loss: 136.4563\n",
      "Epoch 11142/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 156.3883 - val_loss: 136.3978\n",
      "Epoch 11143/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 156.3165 - val_loss: 136.3423\n",
      "Epoch 11144/100000\n",
      "11/11 [==============================] - 0s 580us/step - loss: 156.2447 - val_loss: 136.2831\n",
      "Epoch 11145/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 156.1730 - val_loss: 136.2284\n",
      "Epoch 11146/100000\n",
      "11/11 [==============================] - 0s 710us/step - loss: 156.1012 - val_loss: 136.1685\n",
      "Epoch 11147/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 156.0296 - val_loss: 136.1149\n",
      "Epoch 11148/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 155.9580 - val_loss: 136.0538\n",
      "Epoch 11149/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 155.8864 - val_loss: 136.0016\n",
      "Epoch 11150/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 155.8148 - val_loss: 135.9392\n",
      "Epoch 11151/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 155.7433 - val_loss: 135.8884\n",
      "Epoch 11152/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 155.6719 - val_loss: 135.8249\n",
      "Epoch 11153/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 155.6003 - val_loss: 135.7748\n",
      "Epoch 11154/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 155.5289 - val_loss: 135.7115\n",
      "Epoch 11155/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 155.4574 - val_loss: 135.6601\n",
      "Epoch 11156/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 155.3860 - val_loss: 135.5992\n",
      "Epoch 11157/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 155.3146 - val_loss: 135.5447\n",
      "Epoch 11158/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 155.2433 - val_loss: 135.4876\n",
      "Epoch 11159/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 155.1720 - val_loss: 135.4296\n",
      "Epoch 11160/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 155.1008 - val_loss: 135.3757\n",
      "Epoch 11161/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 155.0295 - val_loss: 135.3154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11162/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 154.9584 - val_loss: 135.2627\n",
      "Epoch 11163/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 154.8872 - val_loss: 135.2025\n",
      "Epoch 11164/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 154.8160 - val_loss: 135.1487\n",
      "Epoch 11165/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 154.7450 - val_loss: 135.0907\n",
      "Epoch 11166/100000\n",
      "11/11 [==============================] - 0s 632us/step - loss: 154.6739 - val_loss: 135.0343\n",
      "Epoch 11167/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 154.6029 - val_loss: 134.9789\n",
      "Epoch 11168/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 154.5319 - val_loss: 134.9206\n",
      "Epoch 11169/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 154.4610 - val_loss: 134.8667\n",
      "Epoch 11170/100000\n",
      "11/11 [==============================] - 0s 648us/step - loss: 154.3900 - val_loss: 134.8078\n",
      "Epoch 11171/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 154.3192 - val_loss: 134.7534\n",
      "Epoch 11172/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 154.2482 - val_loss: 134.6958\n",
      "Epoch 11173/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 154.1774 - val_loss: 134.6401\n",
      "Epoch 11174/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 154.1066 - val_loss: 134.5841\n",
      "Epoch 11175/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 154.0358 - val_loss: 134.5269\n",
      "Epoch 11176/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 153.9651 - val_loss: 134.4723\n",
      "Epoch 11177/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 153.8945 - val_loss: 134.4144\n",
      "Epoch 11178/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 153.8238 - val_loss: 134.3598\n",
      "Epoch 11179/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 153.7531 - val_loss: 134.3026\n",
      "Epoch 11180/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 153.6825 - val_loss: 134.2472\n",
      "Epoch 11181/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 153.6120 - val_loss: 134.1910\n",
      "Epoch 11182/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 153.5414 - val_loss: 134.1346\n",
      "Epoch 11183/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 153.4709 - val_loss: 134.0795\n",
      "Epoch 11184/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 153.4004 - val_loss: 134.0224\n",
      "Epoch 11185/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 153.3300 - val_loss: 133.9677\n",
      "Epoch 11186/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 153.2596 - val_loss: 133.9107\n",
      "Epoch 11187/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 153.1891 - val_loss: 133.8556\n",
      "Epoch 11188/100000\n",
      "11/11 [==============================] - 0s 643us/step - loss: 153.1189 - val_loss: 133.7994\n",
      "Epoch 11189/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 153.0485 - val_loss: 133.7437\n",
      "Epoch 11190/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 152.9783 - val_loss: 133.6882\n",
      "Epoch 11191/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 152.9080 - val_loss: 133.6319\n",
      "Epoch 11192/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 152.8378 - val_loss: 133.5768\n",
      "Epoch 11193/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 152.7676 - val_loss: 133.5205\n",
      "Epoch 11194/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 152.6976 - val_loss: 133.4655\n",
      "Epoch 11195/100000\n",
      "11/11 [==============================] - 0s 836us/step - loss: 152.6274 - val_loss: 133.4094\n",
      "Epoch 11196/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 152.5573 - val_loss: 133.3541\n",
      "Epoch 11197/100000\n",
      "11/11 [==============================] - 0s 589us/step - loss: 152.4873 - val_loss: 133.2985\n",
      "Epoch 11198/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 152.4173 - val_loss: 133.2427\n",
      "Epoch 11199/100000\n",
      "11/11 [==============================] - 0s 635us/step - loss: 152.3472 - val_loss: 133.1876\n",
      "Epoch 11200/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 152.2774 - val_loss: 133.1317\n",
      "Epoch 11201/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 152.2074 - val_loss: 133.0767\n",
      "Epoch 11202/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 152.1375 - val_loss: 133.0208\n",
      "Epoch 11203/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 152.0676 - val_loss: 132.9658\n",
      "Epoch 11204/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 151.9978 - val_loss: 132.9102\n",
      "Epoch 11205/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 151.9280 - val_loss: 132.8550\n",
      "Epoch 11206/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 151.8583 - val_loss: 132.7998\n",
      "Epoch 11207/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 151.7886 - val_loss: 132.7444\n",
      "Epoch 11208/100000\n",
      "11/11 [==============================] - 0s 729us/step - loss: 151.7189 - val_loss: 132.6893\n",
      "Epoch 11209/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 151.6492 - val_loss: 132.6339\n",
      "Epoch 11210/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 151.5796 - val_loss: 132.5790\n",
      "Epoch 11211/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 151.5099 - val_loss: 132.5236\n",
      "Epoch 11212/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 151.4404 - val_loss: 132.4687\n",
      "Epoch 11213/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 151.3709 - val_loss: 132.4134\n",
      "Epoch 11214/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 151.3014 - val_loss: 132.3585\n",
      "Epoch 11215/100000\n",
      "11/11 [==============================] - 0s 773us/step - loss: 151.2319 - val_loss: 132.3035\n",
      "Epoch 11216/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 151.1625 - val_loss: 132.2484\n",
      "Epoch 11217/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 151.0931 - val_loss: 132.1935\n",
      "Epoch 11218/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 151.0237 - val_loss: 132.1385\n",
      "Epoch 11219/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 150.9544 - val_loss: 132.0838\n",
      "Epoch 11220/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 150.8851 - val_loss: 132.0288\n",
      "Epoch 11221/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 150.8159 - val_loss: 131.9741\n",
      "Epoch 11222/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 150.7466 - val_loss: 131.9191\n",
      "Epoch 11223/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 150.6774 - val_loss: 131.8645\n",
      "Epoch 11224/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 150.6083 - val_loss: 131.8097\n",
      "Epoch 11225/100000\n",
      "11/11 [==============================] - 0s 708us/step - loss: 150.5392 - val_loss: 131.7550\n",
      "Epoch 11226/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 150.4700 - val_loss: 131.7002\n",
      "Epoch 11227/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 150.4009 - val_loss: 131.6455\n",
      "Epoch 11228/100000\n",
      "11/11 [==============================] - 0s 721us/step - loss: 150.3319 - val_loss: 131.5910\n",
      "Epoch 11229/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 150.2629 - val_loss: 131.5363\n",
      "Epoch 11230/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 150.1939 - val_loss: 131.4818\n",
      "Epoch 11231/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 150.1249 - val_loss: 131.4272\n",
      "Epoch 11232/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 150.0560 - val_loss: 131.3728\n",
      "Epoch 11233/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 149.9872 - val_loss: 131.3183\n",
      "Epoch 11234/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 149.9184 - val_loss: 131.2638\n",
      "Epoch 11235/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 422us/step - loss: 149.8495 - val_loss: 131.2094\n",
      "Epoch 11236/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 149.7807 - val_loss: 131.1550\n",
      "Epoch 11237/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 149.7120 - val_loss: 131.1006\n",
      "Epoch 11238/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 149.6433 - val_loss: 131.0463\n",
      "Epoch 11239/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 149.5746 - val_loss: 130.9921\n",
      "Epoch 11240/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 149.5060 - val_loss: 130.9377\n",
      "Epoch 11241/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 149.4373 - val_loss: 130.8835\n",
      "Epoch 11242/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 149.3687 - val_loss: 130.8293\n",
      "Epoch 11243/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 149.3002 - val_loss: 130.7752\n",
      "Epoch 11244/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 149.2317 - val_loss: 130.7210\n",
      "Epoch 11245/100000\n",
      "11/11 [==============================] - 0s 637us/step - loss: 149.1632 - val_loss: 130.6669\n",
      "Epoch 11246/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 149.0947 - val_loss: 130.6127\n",
      "Epoch 11247/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 149.0263 - val_loss: 130.5587\n",
      "Epoch 11248/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 148.9579 - val_loss: 130.5046\n",
      "Epoch 11249/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 148.8895 - val_loss: 130.4507\n",
      "Epoch 11250/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 148.8213 - val_loss: 130.3967\n",
      "Epoch 11251/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 148.7529 - val_loss: 130.3429\n",
      "Epoch 11252/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 148.6848 - val_loss: 130.2890\n",
      "Epoch 11253/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 148.6166 - val_loss: 130.2350\n",
      "Epoch 11254/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 148.5483 - val_loss: 130.1812\n",
      "Epoch 11255/100000\n",
      "11/11 [==============================] - 0s 775us/step - loss: 148.4802 - val_loss: 130.1274\n",
      "Epoch 11256/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 148.4120 - val_loss: 130.0736\n",
      "Epoch 11257/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 148.3439 - val_loss: 130.0198\n",
      "Epoch 11258/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 148.2759 - val_loss: 129.9661\n",
      "Epoch 11259/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 148.2078 - val_loss: 129.9124\n",
      "Epoch 11260/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 148.1399 - val_loss: 129.8588\n",
      "Epoch 11261/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 148.0719 - val_loss: 129.8051\n",
      "Epoch 11262/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 148.0039 - val_loss: 129.7516\n",
      "Epoch 11263/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 147.9361 - val_loss: 129.6980\n",
      "Epoch 11264/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 147.8683 - val_loss: 129.6445\n",
      "Epoch 11265/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 147.8004 - val_loss: 129.5909\n",
      "Epoch 11266/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 147.7326 - val_loss: 129.5374\n",
      "Epoch 11267/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 147.6648 - val_loss: 129.4840\n",
      "Epoch 11268/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 147.5971 - val_loss: 129.4306\n",
      "Epoch 11269/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 147.5294 - val_loss: 129.3771\n",
      "Epoch 11270/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 147.4616 - val_loss: 129.3238\n",
      "Epoch 11271/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 147.3940 - val_loss: 129.2705\n",
      "Epoch 11272/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 147.3265 - val_loss: 129.2172\n",
      "Epoch 11273/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 147.2589 - val_loss: 129.1640\n",
      "Epoch 11274/100000\n",
      "11/11 [==============================] - 0s 643us/step - loss: 147.1914 - val_loss: 129.1107\n",
      "Epoch 11275/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 147.1238 - val_loss: 129.0575\n",
      "Epoch 11276/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 147.0563 - val_loss: 129.0043\n",
      "Epoch 11277/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 146.9890 - val_loss: 128.9512\n",
      "Epoch 11278/100000\n",
      "11/11 [==============================] - 0s 710us/step - loss: 146.9215 - val_loss: 128.8980\n",
      "Epoch 11279/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 146.8541 - val_loss: 128.8450\n",
      "Epoch 11280/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 146.7868 - val_loss: 128.7918\n",
      "Epoch 11281/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 146.7194 - val_loss: 128.7389\n",
      "Epoch 11282/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 146.6522 - val_loss: 128.6858\n",
      "Epoch 11283/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 146.5849 - val_loss: 128.6329\n",
      "Epoch 11284/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 146.5177 - val_loss: 128.5799\n",
      "Epoch 11285/100000\n",
      "11/11 [==============================] - 0s 628us/step - loss: 146.4505 - val_loss: 128.5271\n",
      "Epoch 11286/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 146.3834 - val_loss: 128.4742\n",
      "Epoch 11287/100000\n",
      "11/11 [==============================] - 0s 959us/step - loss: 146.3163 - val_loss: 128.4213\n",
      "Epoch 11288/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 146.2492 - val_loss: 128.3685\n",
      "Epoch 11289/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 146.1822 - val_loss: 128.3157\n",
      "Epoch 11290/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 146.1151 - val_loss: 128.2630\n",
      "Epoch 11291/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 146.0481 - val_loss: 128.2103\n",
      "Epoch 11292/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 145.9812 - val_loss: 128.1576\n",
      "Epoch 11293/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 145.9143 - val_loss: 128.1050\n",
      "Epoch 11294/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 145.8474 - val_loss: 128.0522\n",
      "Epoch 11295/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 145.7805 - val_loss: 127.9998\n",
      "Epoch 11296/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 145.7137 - val_loss: 127.9470\n",
      "Epoch 11297/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 145.6468 - val_loss: 127.8947\n",
      "Epoch 11298/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 145.5801 - val_loss: 127.8419\n",
      "Epoch 11299/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 145.5134 - val_loss: 127.7897\n",
      "Epoch 11300/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 145.4467 - val_loss: 127.7369\n",
      "Epoch 11301/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 145.3801 - val_loss: 127.6850\n",
      "Epoch 11302/100000\n",
      "11/11 [==============================] - 0s 628us/step - loss: 145.3134 - val_loss: 127.6320\n",
      "Epoch 11303/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 145.2468 - val_loss: 127.5804\n",
      "Epoch 11304/100000\n",
      "11/11 [==============================] - 0s 607us/step - loss: 145.1802 - val_loss: 127.5272\n",
      "Epoch 11305/100000\n",
      "11/11 [==============================] - 0s 911us/step - loss: 145.1138 - val_loss: 127.4760\n",
      "Epoch 11306/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 145.0472 - val_loss: 127.4224\n",
      "Epoch 11307/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 144.9808 - val_loss: 127.3720\n",
      "Epoch 11308/100000\n",
      "11/11 [==============================] - 0s 839us/step - loss: 144.9144 - val_loss: 127.3175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11309/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 144.8480 - val_loss: 127.2681\n",
      "Epoch 11310/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 144.7817 - val_loss: 127.2128\n",
      "Epoch 11311/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 144.7154 - val_loss: 127.1644\n",
      "Epoch 11312/100000\n",
      "11/11 [==============================] - 0s 631us/step - loss: 144.6491 - val_loss: 127.1084\n",
      "Epoch 11313/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 144.5829 - val_loss: 127.0603\n",
      "Epoch 11314/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 144.5166 - val_loss: 127.0045\n",
      "Epoch 11315/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 144.4504 - val_loss: 126.9553\n",
      "Epoch 11316/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 144.3842 - val_loss: 126.9017\n",
      "Epoch 11317/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 144.3179 - val_loss: 126.8499\n",
      "Epoch 11318/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 144.2518 - val_loss: 126.7991\n",
      "Epoch 11319/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 144.1858 - val_loss: 126.7453\n",
      "Epoch 11320/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 144.1198 - val_loss: 126.6959\n",
      "Epoch 11321/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 144.0538 - val_loss: 126.6417\n",
      "Epoch 11322/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 143.9878 - val_loss: 126.5916\n",
      "Epoch 11323/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 143.9217 - val_loss: 126.5390\n",
      "Epoch 11324/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 143.8558 - val_loss: 126.4872\n",
      "Epoch 11325/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 143.7900 - val_loss: 126.4366\n",
      "Epoch 11326/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 143.7242 - val_loss: 126.3834\n",
      "Epoch 11327/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 143.6584 - val_loss: 126.3334\n",
      "Epoch 11328/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 143.5925 - val_loss: 126.2804\n",
      "Epoch 11329/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 143.5268 - val_loss: 126.2297\n",
      "Epoch 11330/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 143.4611 - val_loss: 126.1780\n",
      "Epoch 11331/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 143.3954 - val_loss: 126.1259\n",
      "Epoch 11332/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 143.3297 - val_loss: 126.0756\n",
      "Epoch 11333/100000\n",
      "11/11 [==============================] - 0s 610us/step - loss: 143.2641 - val_loss: 126.0229\n",
      "Epoch 11334/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 143.1985 - val_loss: 125.9724\n",
      "Epoch 11335/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 143.1329 - val_loss: 125.9205\n",
      "Epoch 11336/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 143.0675 - val_loss: 125.8692\n",
      "Epoch 11337/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 143.0019 - val_loss: 125.8183\n",
      "Epoch 11338/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 142.9365 - val_loss: 125.7663\n",
      "Epoch 11339/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 142.8711 - val_loss: 125.7159\n",
      "Epoch 11340/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 142.8056 - val_loss: 125.6639\n",
      "Epoch 11341/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 142.7403 - val_loss: 125.6132\n",
      "Epoch 11342/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 142.6749 - val_loss: 125.5619\n",
      "Epoch 11343/100000\n",
      "11/11 [==============================] - 0s 614us/step - loss: 142.6096 - val_loss: 125.5105\n",
      "Epoch 11344/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 142.5443 - val_loss: 125.4600\n",
      "Epoch 11345/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 142.4792 - val_loss: 125.4083\n",
      "Epoch 11346/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 142.4140 - val_loss: 125.3578\n",
      "Epoch 11347/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 142.3488 - val_loss: 125.3064\n",
      "Epoch 11348/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 142.2837 - val_loss: 125.2555\n",
      "Epoch 11349/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 142.2185 - val_loss: 125.2047\n",
      "Epoch 11350/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 142.1535 - val_loss: 125.1535\n",
      "Epoch 11351/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 142.0884 - val_loss: 125.1030\n",
      "Epoch 11352/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 142.0235 - val_loss: 125.0518\n",
      "Epoch 11353/100000\n",
      "11/11 [==============================] - 0s 799us/step - loss: 141.9585 - val_loss: 125.0012\n",
      "Epoch 11354/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 141.8935 - val_loss: 124.9502\n",
      "Epoch 11355/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 141.8286 - val_loss: 124.8995\n",
      "Epoch 11356/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 141.7638 - val_loss: 124.8489\n",
      "Epoch 11357/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 141.6989 - val_loss: 124.7980\n",
      "Epoch 11358/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 141.6341 - val_loss: 124.7475\n",
      "Epoch 11359/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 141.5693 - val_loss: 124.6966\n",
      "Epoch 11360/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 141.5045 - val_loss: 124.6462\n",
      "Epoch 11361/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 141.4398 - val_loss: 124.5956\n",
      "Epoch 11362/100000\n",
      "11/11 [==============================] - 0s 720us/step - loss: 141.3752 - val_loss: 124.5449\n",
      "Epoch 11363/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 141.3105 - val_loss: 124.4946\n",
      "Epoch 11364/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 141.2459 - val_loss: 124.4439\n",
      "Epoch 11365/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 141.1814 - val_loss: 124.3936\n",
      "Epoch 11366/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 141.1168 - val_loss: 124.3430\n",
      "Epoch 11367/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 141.0523 - val_loss: 124.2927\n",
      "Epoch 11368/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 140.9878 - val_loss: 124.2423\n",
      "Epoch 11369/100000\n",
      "11/11 [==============================] - 0s 586us/step - loss: 140.9233 - val_loss: 124.1919\n",
      "Epoch 11370/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 140.8589 - val_loss: 124.1418\n",
      "Epoch 11371/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 140.7945 - val_loss: 124.0913\n",
      "Epoch 11372/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 140.7301 - val_loss: 124.0412\n",
      "Epoch 11373/100000\n",
      "11/11 [==============================] - 0s 719us/step - loss: 140.6658 - val_loss: 123.9909\n",
      "Epoch 11374/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 140.6015 - val_loss: 123.9408\n",
      "Epoch 11375/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 140.5373 - val_loss: 123.8906\n",
      "Epoch 11376/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 140.4730 - val_loss: 123.8405\n",
      "Epoch 11377/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 140.4089 - val_loss: 123.7905\n",
      "Epoch 11378/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 140.3447 - val_loss: 123.7403\n",
      "Epoch 11379/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 140.2807 - val_loss: 123.6903\n",
      "Epoch 11380/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 140.2164 - val_loss: 123.6403\n",
      "Epoch 11381/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 140.1525 - val_loss: 123.5903\n",
      "Epoch 11382/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 652us/step - loss: 140.0883 - val_loss: 123.5405\n",
      "Epoch 11383/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 140.0244 - val_loss: 123.4905\n",
      "Epoch 11384/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 139.9604 - val_loss: 123.4407\n",
      "Epoch 11385/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 139.8965 - val_loss: 123.3908\n",
      "Epoch 11386/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 139.8327 - val_loss: 123.3410\n",
      "Epoch 11387/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 139.7687 - val_loss: 123.2912\n",
      "Epoch 11388/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 139.7049 - val_loss: 123.2414\n",
      "Epoch 11389/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 139.6410 - val_loss: 123.1917\n",
      "Epoch 11390/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 139.5773 - val_loss: 123.1421\n",
      "Epoch 11391/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 139.5136 - val_loss: 123.0924\n",
      "Epoch 11392/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 139.4498 - val_loss: 123.0427\n",
      "Epoch 11393/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 139.3861 - val_loss: 122.9931\n",
      "Epoch 11394/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 139.3225 - val_loss: 122.9436\n",
      "Epoch 11395/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 139.2589 - val_loss: 122.8940\n",
      "Epoch 11396/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 139.1953 - val_loss: 122.8446\n",
      "Epoch 11397/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 139.1318 - val_loss: 122.7951\n",
      "Epoch 11398/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 139.0683 - val_loss: 122.7456\n",
      "Epoch 11399/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 139.0048 - val_loss: 122.6962\n",
      "Epoch 11400/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 138.9413 - val_loss: 122.6468\n",
      "Epoch 11401/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 138.8779 - val_loss: 122.5974\n",
      "Epoch 11402/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 138.8144 - val_loss: 122.5481\n",
      "Epoch 11403/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 138.7511 - val_loss: 122.4988\n",
      "Epoch 11404/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 138.6878 - val_loss: 122.4496\n",
      "Epoch 11405/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 138.6246 - val_loss: 122.4004\n",
      "Epoch 11406/100000\n",
      "11/11 [==============================] - 0s 693us/step - loss: 138.5613 - val_loss: 122.3511\n",
      "Epoch 11407/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 138.4980 - val_loss: 122.3020\n",
      "Epoch 11408/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 138.4349 - val_loss: 122.2529\n",
      "Epoch 11409/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 138.3717 - val_loss: 122.2037\n",
      "Epoch 11410/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 138.3086 - val_loss: 122.1546\n",
      "Epoch 11411/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 138.2454 - val_loss: 122.1056\n",
      "Epoch 11412/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 138.1824 - val_loss: 122.0566\n",
      "Epoch 11413/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 138.1194 - val_loss: 122.0076\n",
      "Epoch 11414/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 138.0564 - val_loss: 121.9587\n",
      "Epoch 11415/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 137.9934 - val_loss: 121.9097\n",
      "Epoch 11416/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 137.9305 - val_loss: 121.8609\n",
      "Epoch 11417/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 137.8676 - val_loss: 121.8120\n",
      "Epoch 11418/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 137.8047 - val_loss: 121.7632\n",
      "Epoch 11419/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 137.7419 - val_loss: 121.7144\n",
      "Epoch 11420/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 137.6791 - val_loss: 121.6656\n",
      "Epoch 11421/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 137.6163 - val_loss: 121.6169\n",
      "Epoch 11422/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 137.5536 - val_loss: 121.5682\n",
      "Epoch 11423/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 137.4909 - val_loss: 121.5195\n",
      "Epoch 11424/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 137.4282 - val_loss: 121.4708\n",
      "Epoch 11425/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 137.3655 - val_loss: 121.4223\n",
      "Epoch 11426/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 137.3029 - val_loss: 121.3736\n",
      "Epoch 11427/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 137.2402 - val_loss: 121.3250\n",
      "Epoch 11428/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 137.1777 - val_loss: 121.2766\n",
      "Epoch 11429/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 137.1152 - val_loss: 121.2281\n",
      "Epoch 11430/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 137.0527 - val_loss: 121.1796\n",
      "Epoch 11431/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 136.9903 - val_loss: 121.1311\n",
      "Epoch 11432/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 136.9278 - val_loss: 121.0828\n",
      "Epoch 11433/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 136.8655 - val_loss: 121.0344\n",
      "Epoch 11434/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 136.8031 - val_loss: 120.9861\n",
      "Epoch 11435/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 136.7408 - val_loss: 120.9378\n",
      "Epoch 11436/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 136.6785 - val_loss: 120.8894\n",
      "Epoch 11437/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 136.6162 - val_loss: 120.8412\n",
      "Epoch 11438/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 136.5540 - val_loss: 120.7930\n",
      "Epoch 11439/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 136.4918 - val_loss: 120.7448\n",
      "Epoch 11440/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 136.4296 - val_loss: 120.6966\n",
      "Epoch 11441/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 136.3675 - val_loss: 120.6485\n",
      "Epoch 11442/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 136.3054 - val_loss: 120.6004\n",
      "Epoch 11443/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 136.2432 - val_loss: 120.5523\n",
      "Epoch 11444/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 136.1812 - val_loss: 120.5043\n",
      "Epoch 11445/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 136.1192 - val_loss: 120.4563\n",
      "Epoch 11446/100000\n",
      "11/11 [==============================] - 0s 604us/step - loss: 136.0573 - val_loss: 120.4084\n",
      "Epoch 11447/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 135.9954 - val_loss: 120.3605\n",
      "Epoch 11448/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 135.9334 - val_loss: 120.3125\n",
      "Epoch 11449/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 135.8715 - val_loss: 120.2647\n",
      "Epoch 11450/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 135.8098 - val_loss: 120.2168\n",
      "Epoch 11451/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 135.7479 - val_loss: 120.1690\n",
      "Epoch 11452/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 135.6861 - val_loss: 120.1212\n",
      "Epoch 11453/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 135.6243 - val_loss: 120.0735\n",
      "Epoch 11454/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 135.5627 - val_loss: 120.0258\n",
      "Epoch 11455/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 135.5010 - val_loss: 119.9780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11456/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 135.4393 - val_loss: 119.9304\n",
      "Epoch 11457/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 135.3777 - val_loss: 119.8827\n",
      "Epoch 11458/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 135.3161 - val_loss: 119.8352\n",
      "Epoch 11459/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 135.2545 - val_loss: 119.7876\n",
      "Epoch 11460/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 135.1931 - val_loss: 119.7400\n",
      "Epoch 11461/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 135.1315 - val_loss: 119.6926\n",
      "Epoch 11462/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 135.0701 - val_loss: 119.6451\n",
      "Epoch 11463/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 135.0086 - val_loss: 119.5976\n",
      "Epoch 11464/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 134.9473 - val_loss: 119.5502\n",
      "Epoch 11465/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 134.8858 - val_loss: 119.5028\n",
      "Epoch 11466/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 134.8245 - val_loss: 119.4554\n",
      "Epoch 11467/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 134.7632 - val_loss: 119.4081\n",
      "Epoch 11468/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 134.7019 - val_loss: 119.3608\n",
      "Epoch 11469/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 134.6407 - val_loss: 119.3136\n",
      "Epoch 11470/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 134.5795 - val_loss: 119.2663\n",
      "Epoch 11471/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 134.5183 - val_loss: 119.2192\n",
      "Epoch 11472/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 134.4572 - val_loss: 119.1720\n",
      "Epoch 11473/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 134.3960 - val_loss: 119.1248\n",
      "Epoch 11474/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 134.3350 - val_loss: 119.0777\n",
      "Epoch 11475/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 134.2739 - val_loss: 119.0307\n",
      "Epoch 11476/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 134.2130 - val_loss: 118.9836\n",
      "Epoch 11477/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 134.1519 - val_loss: 118.9365\n",
      "Epoch 11478/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 134.0909 - val_loss: 118.8896\n",
      "Epoch 11479/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 134.0300 - val_loss: 118.8426\n",
      "Epoch 11480/100000\n",
      "11/11 [==============================] - 0s 776us/step - loss: 133.9692 - val_loss: 118.7957\n",
      "Epoch 11481/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 133.9083 - val_loss: 118.7488\n",
      "Epoch 11482/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 133.8475 - val_loss: 118.7020\n",
      "Epoch 11483/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 133.7867 - val_loss: 118.6551\n",
      "Epoch 11484/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 133.7259 - val_loss: 118.6083\n",
      "Epoch 11485/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 133.6652 - val_loss: 118.5615\n",
      "Epoch 11486/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 133.6045 - val_loss: 118.5148\n",
      "Epoch 11487/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 133.5439 - val_loss: 118.4681\n",
      "Epoch 11488/100000\n",
      "11/11 [==============================] - 0s 668us/step - loss: 133.4833 - val_loss: 118.4213\n",
      "Epoch 11489/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 133.4225 - val_loss: 118.3747\n",
      "Epoch 11490/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 133.3620 - val_loss: 118.3281\n",
      "Epoch 11491/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 133.3015 - val_loss: 118.2816\n",
      "Epoch 11492/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 133.2410 - val_loss: 118.2350\n",
      "Epoch 11493/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 133.1805 - val_loss: 118.1885\n",
      "Epoch 11494/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 133.1201 - val_loss: 118.1420\n",
      "Epoch 11495/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 133.0597 - val_loss: 118.0956\n",
      "Epoch 11496/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 132.9993 - val_loss: 118.0491\n",
      "Epoch 11497/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 132.9389 - val_loss: 118.0028\n",
      "Epoch 11498/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 132.8786 - val_loss: 117.9563\n",
      "Epoch 11499/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 132.8183 - val_loss: 117.9100\n",
      "Epoch 11500/100000\n",
      "11/11 [==============================] - 0s 625us/step - loss: 132.7581 - val_loss: 117.8637\n",
      "Epoch 11501/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 132.6978 - val_loss: 117.8174\n",
      "Epoch 11502/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 132.6376 - val_loss: 117.7712\n",
      "Epoch 11503/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 132.5775 - val_loss: 117.7249\n",
      "Epoch 11504/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 132.5173 - val_loss: 117.6787\n",
      "Epoch 11505/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 132.4572 - val_loss: 117.6326\n",
      "Epoch 11506/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 132.3972 - val_loss: 117.5865\n",
      "Epoch 11507/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 132.3372 - val_loss: 117.5404\n",
      "Epoch 11508/100000\n",
      "11/11 [==============================] - 0s 658us/step - loss: 132.2772 - val_loss: 117.4943\n",
      "Epoch 11509/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 132.2172 - val_loss: 117.4483\n",
      "Epoch 11510/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 132.1573 - val_loss: 117.4022\n",
      "Epoch 11511/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 132.0973 - val_loss: 117.3563\n",
      "Epoch 11512/100000\n",
      "11/11 [==============================] - 0s 780us/step - loss: 132.0375 - val_loss: 117.3103\n",
      "Epoch 11513/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 131.9776 - val_loss: 117.2644\n",
      "Epoch 11514/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 131.9178 - val_loss: 117.2185\n",
      "Epoch 11515/100000\n",
      "11/11 [==============================] - 0s 871us/step - loss: 131.8580 - val_loss: 117.1728\n",
      "Epoch 11516/100000\n",
      "11/11 [==============================] - 0s 793us/step - loss: 131.7984 - val_loss: 117.1269\n",
      "Epoch 11517/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 131.7386 - val_loss: 117.0811\n",
      "Epoch 11518/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 131.6789 - val_loss: 117.0353\n",
      "Epoch 11519/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 131.6193 - val_loss: 116.9896\n",
      "Epoch 11520/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 131.5597 - val_loss: 116.9439\n",
      "Epoch 11521/100000\n",
      "11/11 [==============================] - 0s 981us/step - loss: 131.5001 - val_loss: 116.8983\n",
      "Epoch 11522/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 131.4405 - val_loss: 116.8526\n",
      "Epoch 11523/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 131.3810 - val_loss: 116.8071\n",
      "Epoch 11524/100000\n",
      "11/11 [==============================] - 0s 857us/step - loss: 131.3215 - val_loss: 116.7615\n",
      "Epoch 11525/100000\n",
      "11/11 [==============================] - 0s 657us/step - loss: 131.2620 - val_loss: 116.7160\n",
      "Epoch 11526/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 131.2026 - val_loss: 116.6704\n",
      "Epoch 11527/100000\n",
      "11/11 [==============================] - 0s 745us/step - loss: 131.1432 - val_loss: 116.6250\n",
      "Epoch 11528/100000\n",
      "11/11 [==============================] - 0s 978us/step - loss: 131.0839 - val_loss: 116.5795\n",
      "Epoch 11529/100000\n",
      "11/11 [==============================] - 0s 691us/step - loss: 131.0245 - val_loss: 116.5342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11530/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 130.9653 - val_loss: 116.4887\n",
      "Epoch 11531/100000\n",
      "11/11 [==============================] - 0s 851us/step - loss: 130.9060 - val_loss: 116.4434\n",
      "Epoch 11532/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 130.8467 - val_loss: 116.3981\n",
      "Epoch 11533/100000\n",
      "11/11 [==============================] - 0s 662us/step - loss: 130.7876 - val_loss: 116.3528\n",
      "Epoch 11534/100000\n",
      "11/11 [==============================] - 0s 610us/step - loss: 130.7284 - val_loss: 116.3074\n",
      "Epoch 11535/100000\n",
      "11/11 [==============================] - 0s 713us/step - loss: 130.6691 - val_loss: 116.2621\n",
      "Epoch 11536/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 130.6100 - val_loss: 116.2169\n",
      "Epoch 11537/100000\n",
      "11/11 [==============================] - 0s 696us/step - loss: 130.5509 - val_loss: 116.1718\n",
      "Epoch 11538/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 130.4918 - val_loss: 116.1266\n",
      "Epoch 11539/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 130.4328 - val_loss: 116.0816\n",
      "Epoch 11540/100000\n",
      "11/11 [==============================] - 0s 805us/step - loss: 130.3738 - val_loss: 116.0365\n",
      "Epoch 11541/100000\n",
      "11/11 [==============================] - 0s 763us/step - loss: 130.3150 - val_loss: 115.9915\n",
      "Epoch 11542/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 130.2560 - val_loss: 115.9465\n",
      "Epoch 11543/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 130.1971 - val_loss: 115.9014\n",
      "Epoch 11544/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 130.1382 - val_loss: 115.8565\n",
      "Epoch 11545/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 130.0794 - val_loss: 115.8116\n",
      "Epoch 11546/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 130.0206 - val_loss: 115.7667\n",
      "Epoch 11547/100000\n",
      "11/11 [==============================] - 0s 983us/step - loss: 129.9618 - val_loss: 115.7217\n",
      "Epoch 11548/100000\n",
      "11/11 [==============================] - 0s 960us/step - loss: 129.9030 - val_loss: 115.6770\n",
      "Epoch 11549/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 129.8444 - val_loss: 115.6321\n",
      "Epoch 11550/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 129.7857 - val_loss: 115.5874\n",
      "Epoch 11551/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 129.7271 - val_loss: 115.5426\n",
      "Epoch 11552/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 129.6684 - val_loss: 115.4979\n",
      "Epoch 11553/100000\n",
      "11/11 [==============================] - 0s 1000us/step - loss: 129.6098 - val_loss: 115.4533\n",
      "Epoch 11554/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 129.5513 - val_loss: 115.4085\n",
      "Epoch 11555/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 129.4927 - val_loss: 115.3639\n",
      "Epoch 11556/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 129.4342 - val_loss: 115.3193\n",
      "Epoch 11557/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 129.3758 - val_loss: 115.2748\n",
      "Epoch 11558/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 129.3174 - val_loss: 115.2302\n",
      "Epoch 11559/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 129.2590 - val_loss: 115.1857\n",
      "Epoch 11560/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 129.2005 - val_loss: 115.1411\n",
      "Epoch 11561/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 129.1422 - val_loss: 115.0968\n",
      "Epoch 11562/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 129.0840 - val_loss: 115.0524\n",
      "Epoch 11563/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 129.0258 - val_loss: 115.0079\n",
      "Epoch 11564/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 128.9674 - val_loss: 114.9637\n",
      "Epoch 11565/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 128.9093 - val_loss: 114.9193\n",
      "Epoch 11566/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 128.8511 - val_loss: 114.8751\n",
      "Epoch 11567/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 128.7930 - val_loss: 114.8307\n",
      "Epoch 11568/100000\n",
      "11/11 [==============================] - 0s 685us/step - loss: 128.7348 - val_loss: 114.7866\n",
      "Epoch 11569/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 128.6768 - val_loss: 114.7423\n",
      "Epoch 11570/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 128.6187 - val_loss: 114.6981\n",
      "Epoch 11571/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 128.5606 - val_loss: 114.6540\n",
      "Epoch 11572/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 128.5027 - val_loss: 114.6099\n",
      "Epoch 11573/100000\n",
      "11/11 [==============================] - 0s 654us/step - loss: 128.4447 - val_loss: 114.5658\n",
      "Epoch 11574/100000\n",
      "11/11 [==============================] - 0s 850us/step - loss: 128.3868 - val_loss: 114.5217\n",
      "Epoch 11575/100000\n",
      "11/11 [==============================] - 0s 680us/step - loss: 128.3289 - val_loss: 114.4778\n",
      "Epoch 11576/100000\n",
      "11/11 [==============================] - 0s 795us/step - loss: 128.2711 - val_loss: 114.4338\n",
      "Epoch 11577/100000\n",
      "11/11 [==============================] - 0s 730us/step - loss: 128.2133 - val_loss: 114.3898\n",
      "Epoch 11578/100000\n",
      "11/11 [==============================] - 0s 843us/step - loss: 128.1555 - val_loss: 114.3459\n",
      "Epoch 11579/100000\n",
      "11/11 [==============================] - 0s 704us/step - loss: 128.0977 - val_loss: 114.3020\n",
      "Epoch 11580/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 128.0400 - val_loss: 114.2581\n",
      "Epoch 11581/100000\n",
      "11/11 [==============================] - 0s 763us/step - loss: 127.9822 - val_loss: 114.2143\n",
      "Epoch 11582/100000\n",
      "11/11 [==============================] - 0s 763us/step - loss: 127.9245 - val_loss: 114.1705\n",
      "Epoch 11583/100000\n",
      "11/11 [==============================] - 0s 844us/step - loss: 127.8669 - val_loss: 114.1267\n",
      "Epoch 11584/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 127.8092 - val_loss: 114.0829\n",
      "Epoch 11585/100000\n",
      "11/11 [==============================] - 0s 892us/step - loss: 127.7516 - val_loss: 114.0392\n",
      "Epoch 11586/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 127.6941 - val_loss: 113.9956\n",
      "Epoch 11587/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 127.6366 - val_loss: 113.9518\n",
      "Epoch 11588/100000\n",
      "11/11 [==============================] - 0s 618us/step - loss: 127.5791 - val_loss: 113.9083\n",
      "Epoch 11589/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 127.5217 - val_loss: 113.8646\n",
      "Epoch 11590/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 127.4642 - val_loss: 113.8211\n",
      "Epoch 11591/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 127.4068 - val_loss: 113.7775\n",
      "Epoch 11592/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 127.3494 - val_loss: 113.7340\n",
      "Epoch 11593/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 127.2921 - val_loss: 113.6906\n",
      "Epoch 11594/100000\n",
      "11/11 [==============================] - 0s 715us/step - loss: 127.2349 - val_loss: 113.6472\n",
      "Epoch 11595/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 127.1776 - val_loss: 113.6037\n",
      "Epoch 11596/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 127.1203 - val_loss: 113.5604\n",
      "Epoch 11597/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 127.0631 - val_loss: 113.5170\n",
      "Epoch 11598/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 127.0059 - val_loss: 113.4737\n",
      "Epoch 11599/100000\n",
      "11/11 [==============================] - 0s 844us/step - loss: 126.9487 - val_loss: 113.4304\n",
      "Epoch 11600/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 126.8916 - val_loss: 113.3871\n",
      "Epoch 11601/100000\n",
      "11/11 [==============================] - 0s 900us/step - loss: 126.8346 - val_loss: 113.3439\n",
      "Epoch 11602/100000\n",
      "11/11 [==============================] - 0s 945us/step - loss: 126.7775 - val_loss: 113.3007\n",
      "Epoch 11603/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 126.7205 - val_loss: 113.2575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11604/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 126.6634 - val_loss: 113.2144\n",
      "Epoch 11605/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 126.6065 - val_loss: 113.1713\n",
      "Epoch 11606/100000\n",
      "11/11 [==============================] - 0s 976us/step - loss: 126.5496 - val_loss: 113.1283\n",
      "Epoch 11607/100000\n",
      "11/11 [==============================] - 0s 835us/step - loss: 126.4927 - val_loss: 113.0852\n",
      "Epoch 11608/100000\n",
      "11/11 [==============================] - 0s 941us/step - loss: 126.4358 - val_loss: 113.0422\n",
      "Epoch 11609/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 126.3790 - val_loss: 112.9992\n",
      "Epoch 11610/100000\n",
      "11/11 [==============================] - 0s 588us/step - loss: 126.3222 - val_loss: 112.9563\n",
      "Epoch 11611/100000\n",
      "11/11 [==============================] - 0s 746us/step - loss: 126.2654 - val_loss: 112.9133\n",
      "Epoch 11612/100000\n",
      "11/11 [==============================] - 0s 659us/step - loss: 126.2086 - val_loss: 112.8704\n",
      "Epoch 11613/100000\n",
      "11/11 [==============================] - 0s 963us/step - loss: 126.1519 - val_loss: 112.8275\n",
      "Epoch 11614/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 126.0952 - val_loss: 112.7847\n",
      "Epoch 11615/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 126.0386 - val_loss: 112.7419\n",
      "Epoch 11616/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 125.9820 - val_loss: 112.6991\n",
      "Epoch 11617/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 125.9253 - val_loss: 112.6565\n",
      "Epoch 11618/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 125.8689 - val_loss: 112.6137\n",
      "Epoch 11619/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 125.8123 - val_loss: 112.5710\n",
      "Epoch 11620/100000\n",
      "11/11 [==============================] - 0s 783us/step - loss: 125.7558 - val_loss: 112.5284\n",
      "Epoch 11621/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 125.6993 - val_loss: 112.4857\n",
      "Epoch 11622/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 125.6429 - val_loss: 112.4431\n",
      "Epoch 11623/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 125.5865 - val_loss: 112.4006\n",
      "Epoch 11624/100000\n",
      "11/11 [==============================] - 0s 999us/step - loss: 125.5301 - val_loss: 112.3580\n",
      "Epoch 11625/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 125.4737 - val_loss: 112.3155\n",
      "Epoch 11626/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 125.4174 - val_loss: 112.2731\n",
      "Epoch 11627/100000\n",
      "11/11 [==============================] - 0s 732us/step - loss: 125.3612 - val_loss: 112.2306\n",
      "Epoch 11628/100000\n",
      "11/11 [==============================] - 0s 662us/step - loss: 125.3049 - val_loss: 112.1882\n",
      "Epoch 11629/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 125.2486 - val_loss: 112.1458\n",
      "Epoch 11630/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 125.1924 - val_loss: 112.1035\n",
      "Epoch 11631/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 125.1363 - val_loss: 112.0611\n",
      "Epoch 11632/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 125.0802 - val_loss: 112.0189\n",
      "Epoch 11633/100000\n",
      "11/11 [==============================] - 0s 782us/step - loss: 125.0241 - val_loss: 111.9767\n",
      "Epoch 11634/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 124.9681 - val_loss: 111.9344\n",
      "Epoch 11635/100000\n",
      "11/11 [==============================] - 0s 796us/step - loss: 124.9120 - val_loss: 111.8922\n",
      "Epoch 11636/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 124.8560 - val_loss: 111.8500\n",
      "Epoch 11637/100000\n",
      "11/11 [==============================] - 0s 717us/step - loss: 124.8000 - val_loss: 111.8079\n",
      "Epoch 11638/100000\n",
      "11/11 [==============================] - 0s 838us/step - loss: 124.7440 - val_loss: 111.7658\n",
      "Epoch 11639/100000\n",
      "11/11 [==============================] - 0s 838us/step - loss: 124.6881 - val_loss: 111.7237\n",
      "Epoch 11640/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 124.6322 - val_loss: 111.6816\n",
      "Epoch 11641/100000\n",
      "11/11 [==============================] - 0s 759us/step - loss: 124.5763 - val_loss: 111.6397\n",
      "Epoch 11642/100000\n",
      "11/11 [==============================] - 0s 622us/step - loss: 124.5206 - val_loss: 111.5977\n",
      "Epoch 11643/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 124.4648 - val_loss: 111.5557\n",
      "Epoch 11644/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 124.4090 - val_loss: 111.5138\n",
      "Epoch 11645/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 124.3533 - val_loss: 111.4719\n",
      "Epoch 11646/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 124.2976 - val_loss: 111.4300\n",
      "Epoch 11647/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 124.2419 - val_loss: 111.3882\n",
      "Epoch 11648/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 124.1862 - val_loss: 111.3464\n",
      "Epoch 11649/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 124.1306 - val_loss: 111.3045\n",
      "Epoch 11650/100000\n",
      "11/11 [==============================] - 0s 661us/step - loss: 124.0751 - val_loss: 111.2628\n",
      "Epoch 11651/100000\n",
      "11/11 [==============================] - 0s 673us/step - loss: 124.0195 - val_loss: 111.2211\n",
      "Epoch 11652/100000\n",
      "11/11 [==============================] - 0s 684us/step - loss: 123.9640 - val_loss: 111.1794\n",
      "Epoch 11653/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 123.9085 - val_loss: 111.1377\n",
      "Epoch 11654/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 123.8530 - val_loss: 111.0961\n",
      "Epoch 11655/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 123.7976 - val_loss: 111.0545\n",
      "Epoch 11656/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 123.7422 - val_loss: 111.0130\n",
      "Epoch 11657/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 123.6869 - val_loss: 110.9715\n",
      "Epoch 11658/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 123.6315 - val_loss: 110.9299\n",
      "Epoch 11659/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 123.5762 - val_loss: 110.8884\n",
      "Epoch 11660/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 123.5209 - val_loss: 110.8470\n",
      "Epoch 11661/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 123.4656 - val_loss: 110.8056\n",
      "Epoch 11662/100000\n",
      "11/11 [==============================] - 0s 918us/step - loss: 123.4104 - val_loss: 110.7642\n",
      "Epoch 11663/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 123.3553 - val_loss: 110.7228\n",
      "Epoch 11664/100000\n",
      "11/11 [==============================] - 0s 985us/step - loss: 123.3001 - val_loss: 110.6815\n",
      "Epoch 11665/100000\n",
      "11/11 [==============================] - 0s 966us/step - loss: 123.2450 - val_loss: 110.6402\n",
      "Epoch 11666/100000\n",
      "11/11 [==============================] - 0s 772us/step - loss: 123.1899 - val_loss: 110.5989\n",
      "Epoch 11667/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 123.1348 - val_loss: 110.5577\n",
      "Epoch 11668/100000\n",
      "11/11 [==============================] - 0s 991us/step - loss: 123.0798 - val_loss: 110.5165\n",
      "Epoch 11669/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 123.0248 - val_loss: 110.4753\n",
      "Epoch 11670/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 122.9698 - val_loss: 110.4342\n",
      "Epoch 11671/100000\n",
      "11/11 [==============================] - 0s 737us/step - loss: 122.9149 - val_loss: 110.3930\n",
      "Epoch 11672/100000\n",
      "11/11 [==============================] - 0s 772us/step - loss: 122.8600 - val_loss: 110.3520\n",
      "Epoch 11673/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 122.8052 - val_loss: 110.3108\n",
      "Epoch 11674/100000\n",
      "11/11 [==============================] - 0s 981us/step - loss: 122.7503 - val_loss: 110.2699\n",
      "Epoch 11675/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 122.6955 - val_loss: 110.2288\n",
      "Epoch 11676/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 122.6407 - val_loss: 110.1880\n",
      "Epoch 11677/100000\n",
      "11/11 [==============================] - 0s 724us/step - loss: 122.5859 - val_loss: 110.1469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11678/100000\n",
      "11/11 [==============================] - 0s 688us/step - loss: 122.5312 - val_loss: 110.1062\n",
      "Epoch 11679/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 122.4765 - val_loss: 110.0651\n",
      "Epoch 11680/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 122.4219 - val_loss: 110.0245\n",
      "Epoch 11681/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 122.3672 - val_loss: 109.9833\n",
      "Epoch 11682/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 122.3126 - val_loss: 109.9430\n",
      "Epoch 11683/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 122.2580 - val_loss: 109.9016\n",
      "Epoch 11684/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 122.2035 - val_loss: 109.8617\n",
      "Epoch 11685/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 122.1490 - val_loss: 109.8201\n",
      "Epoch 11686/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 122.0946 - val_loss: 109.7806\n",
      "Epoch 11687/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 122.0401 - val_loss: 109.7386\n",
      "Epoch 11688/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 121.9857 - val_loss: 109.6996\n",
      "Epoch 11689/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 121.9314 - val_loss: 109.6574\n",
      "Epoch 11690/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 121.8770 - val_loss: 109.6185\n",
      "Epoch 11691/100000\n",
      "11/11 [==============================] - 0s 977us/step - loss: 121.8226 - val_loss: 109.5763\n",
      "Epoch 11692/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 121.7684 - val_loss: 109.5374\n",
      "Epoch 11693/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 121.7140 - val_loss: 109.4956\n",
      "Epoch 11694/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 121.6597 - val_loss: 109.4560\n",
      "Epoch 11695/100000\n",
      "11/11 [==============================] - 0s 787us/step - loss: 121.6055 - val_loss: 109.4153\n",
      "Epoch 11696/100000\n",
      "11/11 [==============================] - 0s 921us/step - loss: 121.5512 - val_loss: 109.3747\n",
      "Epoch 11697/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 121.4971 - val_loss: 109.3351\n",
      "Epoch 11698/100000\n",
      "11/11 [==============================] - 0s 777us/step - loss: 121.4431 - val_loss: 109.2938\n",
      "Epoch 11699/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 121.3889 - val_loss: 109.2547\n",
      "Epoch 11700/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 121.3350 - val_loss: 109.2134\n",
      "Epoch 11701/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 121.2808 - val_loss: 109.1739\n",
      "Epoch 11702/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 121.2268 - val_loss: 109.1333\n",
      "Epoch 11703/100000\n",
      "11/11 [==============================] - 0s 698us/step - loss: 121.1728 - val_loss: 109.0931\n",
      "Epoch 11704/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 121.1189 - val_loss: 109.0534\n",
      "Epoch 11705/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 121.0650 - val_loss: 109.0126\n",
      "Epoch 11706/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 121.0111 - val_loss: 108.9734\n",
      "Epoch 11707/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 120.9573 - val_loss: 108.9326\n",
      "Epoch 11708/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 120.9034 - val_loss: 108.8931\n",
      "Epoch 11709/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 120.8496 - val_loss: 108.8528\n",
      "Epoch 11710/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 120.7958 - val_loss: 108.8129\n",
      "Epoch 11711/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 120.7421 - val_loss: 108.7732\n",
      "Epoch 11712/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 120.6884 - val_loss: 108.7329\n",
      "Epoch 11713/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 120.6348 - val_loss: 108.6936\n",
      "Epoch 11714/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 120.5811 - val_loss: 108.6531\n",
      "Epoch 11715/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 120.5274 - val_loss: 108.6138\n",
      "Epoch 11716/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 120.4739 - val_loss: 108.5738\n",
      "Epoch 11717/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 120.4204 - val_loss: 108.5341\n",
      "Epoch 11718/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 120.3668 - val_loss: 108.4945\n",
      "Epoch 11719/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 120.3133 - val_loss: 108.4546\n",
      "Epoch 11720/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 120.2599 - val_loss: 108.4153\n",
      "Epoch 11721/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 120.2065 - val_loss: 108.3752\n",
      "Epoch 11722/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 120.1530 - val_loss: 108.3359\n",
      "Epoch 11723/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 120.0997 - val_loss: 108.2961\n",
      "Epoch 11724/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 120.0463 - val_loss: 108.2566\n",
      "Epoch 11725/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 119.9930 - val_loss: 108.2172\n",
      "Epoch 11726/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 119.9397 - val_loss: 108.1775\n",
      "Epoch 11727/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 119.8865 - val_loss: 108.1383\n",
      "Epoch 11728/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 119.8332 - val_loss: 108.0986\n",
      "Epoch 11729/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 119.7800 - val_loss: 108.0594\n",
      "Epoch 11730/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 119.7269 - val_loss: 108.0199\n",
      "Epoch 11731/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 119.6738 - val_loss: 107.9806\n",
      "Epoch 11732/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 119.6207 - val_loss: 107.9413\n",
      "Epoch 11733/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 119.5676 - val_loss: 107.9019\n",
      "Epoch 11734/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 119.5145 - val_loss: 107.8628\n",
      "Epoch 11735/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 119.4615 - val_loss: 107.8234\n",
      "Epoch 11736/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 119.4085 - val_loss: 107.7844\n",
      "Epoch 11737/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 119.3556 - val_loss: 107.7451\n",
      "Epoch 11738/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 119.3027 - val_loss: 107.7061\n",
      "Epoch 11739/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 119.2498 - val_loss: 107.6669\n",
      "Epoch 11740/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 119.1969 - val_loss: 107.6278\n",
      "Epoch 11741/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 119.1440 - val_loss: 107.5888\n",
      "Epoch 11742/100000\n",
      "11/11 [==============================] - 0s 652us/step - loss: 119.0912 - val_loss: 107.5497\n",
      "Epoch 11743/100000\n",
      "11/11 [==============================] - 0s 674us/step - loss: 119.0385 - val_loss: 107.5108\n",
      "Epoch 11744/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 118.9858 - val_loss: 107.4717\n",
      "Epoch 11745/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 118.9330 - val_loss: 107.4329\n",
      "Epoch 11746/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 118.8803 - val_loss: 107.3939\n",
      "Epoch 11747/100000\n",
      "11/11 [==============================] - 0s 951us/step - loss: 118.8277 - val_loss: 107.3550\n",
      "Epoch 11748/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 118.7750 - val_loss: 107.3163\n",
      "Epoch 11749/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 118.7224 - val_loss: 107.2774\n",
      "Epoch 11750/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 118.6699 - val_loss: 107.2387\n",
      "Epoch 11751/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 118.6174 - val_loss: 107.1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11752/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 118.5648 - val_loss: 107.1612\n",
      "Epoch 11753/100000\n",
      "11/11 [==============================] - 0s 854us/step - loss: 118.5123 - val_loss: 107.1224\n",
      "Epoch 11754/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 118.4599 - val_loss: 107.0838\n",
      "Epoch 11755/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 118.4074 - val_loss: 107.0451\n",
      "Epoch 11756/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 118.3550 - val_loss: 107.0066\n",
      "Epoch 11757/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 118.3028 - val_loss: 106.9679\n",
      "Epoch 11758/100000\n",
      "11/11 [==============================] - 0s 630us/step - loss: 118.2503 - val_loss: 106.9294\n",
      "Epoch 11759/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 118.1980 - val_loss: 106.8909\n",
      "Epoch 11760/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 118.1458 - val_loss: 106.8523\n",
      "Epoch 11761/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 118.0935 - val_loss: 106.8139\n",
      "Epoch 11762/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 118.0413 - val_loss: 106.7755\n",
      "Epoch 11763/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 117.9892 - val_loss: 106.7371\n",
      "Epoch 11764/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 117.9370 - val_loss: 106.6987\n",
      "Epoch 11765/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 117.8848 - val_loss: 106.6603\n",
      "Epoch 11766/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 117.8327 - val_loss: 106.6220\n",
      "Epoch 11767/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 117.7807 - val_loss: 106.5836\n",
      "Epoch 11768/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 117.7286 - val_loss: 106.5455\n",
      "Epoch 11769/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 117.6766 - val_loss: 106.5072\n",
      "Epoch 11770/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 117.6246 - val_loss: 106.4690\n",
      "Epoch 11771/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 117.5726 - val_loss: 106.4309\n",
      "Epoch 11772/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 117.5208 - val_loss: 106.3927\n",
      "Epoch 11773/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 117.4689 - val_loss: 106.3546\n",
      "Epoch 11774/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 117.4170 - val_loss: 106.3165\n",
      "Epoch 11775/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 117.3652 - val_loss: 106.2785\n",
      "Epoch 11776/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 117.3134 - val_loss: 106.2404\n",
      "Epoch 11777/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 117.2616 - val_loss: 106.2024\n",
      "Epoch 11778/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 117.2098 - val_loss: 106.1644\n",
      "Epoch 11779/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 117.1581 - val_loss: 106.1265\n",
      "Epoch 11780/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 117.1065 - val_loss: 106.0886\n",
      "Epoch 11781/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 117.0548 - val_loss: 106.0507\n",
      "Epoch 11782/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 117.0031 - val_loss: 106.0129\n",
      "Epoch 11783/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 116.9516 - val_loss: 105.9750\n",
      "Epoch 11784/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 116.8999 - val_loss: 105.9373\n",
      "Epoch 11785/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 116.8485 - val_loss: 105.8994\n",
      "Epoch 11786/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 116.7969 - val_loss: 105.8617\n",
      "Epoch 11787/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 116.7454 - val_loss: 105.8240\n",
      "Epoch 11788/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 116.6939 - val_loss: 105.7864\n",
      "Epoch 11789/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 116.6426 - val_loss: 105.7487\n",
      "Epoch 11790/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 116.5912 - val_loss: 105.7110\n",
      "Epoch 11791/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 116.5398 - val_loss: 105.6734\n",
      "Epoch 11792/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 116.4885 - val_loss: 105.6359\n",
      "Epoch 11793/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 116.4371 - val_loss: 105.5984\n",
      "Epoch 11794/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 116.3859 - val_loss: 105.5609\n",
      "Epoch 11795/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 116.3346 - val_loss: 105.5233\n",
      "Epoch 11796/100000\n",
      "11/11 [==============================] - 0s 631us/step - loss: 116.2834 - val_loss: 105.4859\n",
      "Epoch 11797/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 116.2322 - val_loss: 105.4485\n",
      "Epoch 11798/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 116.1811 - val_loss: 105.4110\n",
      "Epoch 11799/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 116.1299 - val_loss: 105.3737\n",
      "Epoch 11800/100000\n",
      "11/11 [==============================] - 0s 608us/step - loss: 116.0788 - val_loss: 105.3364\n",
      "Epoch 11801/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 116.0278 - val_loss: 105.2991\n",
      "Epoch 11802/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 115.9767 - val_loss: 105.2618\n",
      "Epoch 11803/100000\n",
      "11/11 [==============================] - 0s 580us/step - loss: 115.9257 - val_loss: 105.2246\n",
      "Epoch 11804/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 115.8747 - val_loss: 105.1873\n",
      "Epoch 11805/100000\n",
      "11/11 [==============================] - 0s 910us/step - loss: 115.8237 - val_loss: 105.1501\n",
      "Epoch 11806/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 115.7728 - val_loss: 105.1130\n",
      "Epoch 11807/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 115.7219 - val_loss: 105.0758\n",
      "Epoch 11808/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 115.6710 - val_loss: 105.0387\n",
      "Epoch 11809/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 115.6201 - val_loss: 105.0017\n",
      "Epoch 11810/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 115.5694 - val_loss: 104.9645\n",
      "Epoch 11811/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 115.5186 - val_loss: 104.9275\n",
      "Epoch 11812/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 115.4678 - val_loss: 104.8906\n",
      "Epoch 11813/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 115.4171 - val_loss: 104.8536\n",
      "Epoch 11814/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 115.3664 - val_loss: 104.8166\n",
      "Epoch 11815/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 115.3157 - val_loss: 104.7798\n",
      "Epoch 11816/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 115.2651 - val_loss: 104.7429\n",
      "Epoch 11817/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 115.2145 - val_loss: 104.7061\n",
      "Epoch 11818/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 115.1639 - val_loss: 104.6692\n",
      "Epoch 11819/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 115.1134 - val_loss: 104.6324\n",
      "Epoch 11820/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 115.0629 - val_loss: 104.5957\n",
      "Epoch 11821/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 115.0124 - val_loss: 104.5589\n",
      "Epoch 11822/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 114.9619 - val_loss: 104.5223\n",
      "Epoch 11823/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 114.9115 - val_loss: 104.4855\n",
      "Epoch 11824/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 114.8611 - val_loss: 104.4489\n",
      "Epoch 11825/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 114.8106 - val_loss: 104.4123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11826/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 114.7603 - val_loss: 104.3757\n",
      "Epoch 11827/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 114.7100 - val_loss: 104.3391\n",
      "Epoch 11828/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 114.6597 - val_loss: 104.3026\n",
      "Epoch 11829/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 114.6094 - val_loss: 104.2660\n",
      "Epoch 11830/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 114.5592 - val_loss: 104.2295\n",
      "Epoch 11831/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 114.5089 - val_loss: 104.1931\n",
      "Epoch 11832/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 114.4588 - val_loss: 104.1567\n",
      "Epoch 11833/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 114.4086 - val_loss: 104.1202\n",
      "Epoch 11834/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 114.3585 - val_loss: 104.0839\n",
      "Epoch 11835/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 114.3085 - val_loss: 104.0476\n",
      "Epoch 11836/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 114.2584 - val_loss: 104.0113\n",
      "Epoch 11837/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 114.2083 - val_loss: 103.9750\n",
      "Epoch 11838/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 114.1583 - val_loss: 103.9387\n",
      "Epoch 11839/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 114.1083 - val_loss: 103.9025\n",
      "Epoch 11840/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 114.0584 - val_loss: 103.8664\n",
      "Epoch 11841/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 114.0085 - val_loss: 103.8301\n",
      "Epoch 11842/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 113.9586 - val_loss: 103.7940\n",
      "Epoch 11843/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 113.9088 - val_loss: 103.7579\n",
      "Epoch 11844/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 113.8589 - val_loss: 103.7218\n",
      "Epoch 11845/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 113.8091 - val_loss: 103.6858\n",
      "Epoch 11846/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 113.7593 - val_loss: 103.6498\n",
      "Epoch 11847/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 113.7096 - val_loss: 103.6137\n",
      "Epoch 11848/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 113.6599 - val_loss: 103.5778\n",
      "Epoch 11849/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 113.6102 - val_loss: 103.5418\n",
      "Epoch 11850/100000\n",
      "11/11 [==============================] - 0s 191us/step - loss: 113.5605 - val_loss: 103.5059\n",
      "Epoch 11851/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 113.5109 - val_loss: 103.4700\n",
      "Epoch 11852/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 113.4613 - val_loss: 103.4342\n",
      "Epoch 11853/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 113.4117 - val_loss: 103.3984\n",
      "Epoch 11854/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 113.3622 - val_loss: 103.3625\n",
      "Epoch 11855/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 113.3126 - val_loss: 103.3268\n",
      "Epoch 11856/100000\n",
      "11/11 [==============================] - 0s 738us/step - loss: 113.2632 - val_loss: 103.2910\n",
      "Epoch 11857/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 113.2137 - val_loss: 103.2553\n",
      "Epoch 11858/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 113.1643 - val_loss: 103.2196\n",
      "Epoch 11859/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 113.1149 - val_loss: 103.1839\n",
      "Epoch 11860/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 113.0655 - val_loss: 103.1483\n",
      "Epoch 11861/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 113.0161 - val_loss: 103.1127\n",
      "Epoch 11862/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 112.9668 - val_loss: 103.0772\n",
      "Epoch 11863/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 112.9175 - val_loss: 103.0416\n",
      "Epoch 11864/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 112.8683 - val_loss: 103.0061\n",
      "Epoch 11865/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 112.8190 - val_loss: 102.9705\n",
      "Epoch 11866/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 112.7698 - val_loss: 102.9350\n",
      "Epoch 11867/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 112.7206 - val_loss: 102.8996\n",
      "Epoch 11868/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 112.6715 - val_loss: 102.8642\n",
      "Epoch 11869/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 112.6224 - val_loss: 102.8288\n",
      "Epoch 11870/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 112.5732 - val_loss: 102.7935\n",
      "Epoch 11871/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 112.5242 - val_loss: 102.7581\n",
      "Epoch 11872/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 112.4752 - val_loss: 102.7229\n",
      "Epoch 11873/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 112.4262 - val_loss: 102.6876\n",
      "Epoch 11874/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 112.3772 - val_loss: 102.6523\n",
      "Epoch 11875/100000\n",
      "11/11 [==============================] - 0s 599us/step - loss: 112.3282 - val_loss: 102.6171\n",
      "Epoch 11876/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 112.2794 - val_loss: 102.5820\n",
      "Epoch 11877/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 112.2304 - val_loss: 102.5467\n",
      "Epoch 11878/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 112.1815 - val_loss: 102.5117\n",
      "Epoch 11879/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 112.1327 - val_loss: 102.4764\n",
      "Epoch 11880/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 112.0839 - val_loss: 102.4416\n",
      "Epoch 11881/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 112.0352 - val_loss: 102.4063\n",
      "Epoch 11882/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 111.9864 - val_loss: 102.3715\n",
      "Epoch 11883/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 111.9376 - val_loss: 102.3363\n",
      "Epoch 11884/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 111.8890 - val_loss: 102.3016\n",
      "Epoch 11885/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 111.8403 - val_loss: 102.2663\n",
      "Epoch 11886/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 111.7917 - val_loss: 102.2318\n",
      "Epoch 11887/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 111.7430 - val_loss: 102.1964\n",
      "Epoch 11888/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 111.6944 - val_loss: 102.1621\n",
      "Epoch 11889/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 111.6459 - val_loss: 102.1266\n",
      "Epoch 11890/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 111.5974 - val_loss: 102.0926\n",
      "Epoch 11891/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 111.5489 - val_loss: 102.0569\n",
      "Epoch 11892/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 111.5004 - val_loss: 102.0233\n",
      "Epoch 11893/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 111.4520 - val_loss: 101.9873\n",
      "Epoch 11894/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 111.4035 - val_loss: 101.9541\n",
      "Epoch 11895/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 111.3552 - val_loss: 101.9177\n",
      "Epoch 11896/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 111.3068 - val_loss: 101.8850\n",
      "Epoch 11897/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 111.2585 - val_loss: 101.8483\n",
      "Epoch 11898/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 111.2102 - val_loss: 101.8161\n",
      "Epoch 11899/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 615us/step - loss: 111.1620 - val_loss: 101.7791\n",
      "Epoch 11900/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 111.1138 - val_loss: 101.7472\n",
      "Epoch 11901/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 111.0655 - val_loss: 101.7101\n",
      "Epoch 11902/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 111.0173 - val_loss: 101.6781\n",
      "Epoch 11903/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 110.9691 - val_loss: 101.6414\n",
      "Epoch 11904/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 110.9210 - val_loss: 101.6087\n",
      "Epoch 11905/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 110.8728 - val_loss: 101.5732\n",
      "Epoch 11906/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 110.8247 - val_loss: 101.5394\n",
      "Epoch 11907/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 110.7767 - val_loss: 101.5052\n",
      "Epoch 11908/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 110.7287 - val_loss: 101.4703\n",
      "Epoch 11909/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 110.6807 - val_loss: 101.4371\n",
      "Epoch 11910/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 110.6328 - val_loss: 101.4015\n",
      "Epoch 11911/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 110.5848 - val_loss: 101.3687\n",
      "Epoch 11912/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 110.5368 - val_loss: 101.3331\n",
      "Epoch 11913/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 110.4890 - val_loss: 101.3002\n",
      "Epoch 11914/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 110.4411 - val_loss: 101.2651\n",
      "Epoch 11915/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 110.3933 - val_loss: 101.2315\n",
      "Epoch 11916/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 110.3455 - val_loss: 101.1974\n",
      "Epoch 11917/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 110.2977 - val_loss: 101.1631\n",
      "Epoch 11918/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 110.2500 - val_loss: 101.1297\n",
      "Epoch 11919/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 110.2023 - val_loss: 101.0948\n",
      "Epoch 11920/100000\n",
      "11/11 [==============================] - 0s 628us/step - loss: 110.1546 - val_loss: 101.0617\n",
      "Epoch 11921/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 110.1069 - val_loss: 101.0269\n",
      "Epoch 11922/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 110.0593 - val_loss: 100.9938\n",
      "Epoch 11923/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 110.0117 - val_loss: 100.9592\n",
      "Epoch 11924/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 109.9641 - val_loss: 100.9257\n",
      "Epoch 11925/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 109.9165 - val_loss: 100.8918\n",
      "Epoch 11926/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 109.8690 - val_loss: 100.8578\n",
      "Epoch 11927/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 109.8215 - val_loss: 100.8244\n",
      "Epoch 11928/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 109.7741 - val_loss: 100.7901\n",
      "Epoch 11929/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 109.7267 - val_loss: 100.7570\n",
      "Epoch 11930/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 109.6793 - val_loss: 100.7227\n",
      "Epoch 11931/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 109.6319 - val_loss: 100.6895\n",
      "Epoch 11932/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 109.5845 - val_loss: 100.6554\n",
      "Epoch 11933/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 109.5372 - val_loss: 100.6220\n",
      "Epoch 11934/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 109.4898 - val_loss: 100.5883\n",
      "Epoch 11935/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 109.4426 - val_loss: 100.5547\n",
      "Epoch 11936/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 109.3953 - val_loss: 100.5213\n",
      "Epoch 11937/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 109.3482 - val_loss: 100.4875\n",
      "Epoch 11938/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 109.3010 - val_loss: 100.4544\n",
      "Epoch 11939/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 109.2538 - val_loss: 100.4206\n",
      "Epoch 11940/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 109.2067 - val_loss: 100.3874\n",
      "Epoch 11941/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 109.1595 - val_loss: 100.3537\n",
      "Epoch 11942/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 109.1125 - val_loss: 100.3206\n",
      "Epoch 11943/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 109.0655 - val_loss: 100.2870\n",
      "Epoch 11944/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 109.0184 - val_loss: 100.2538\n",
      "Epoch 11945/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 108.9714 - val_loss: 100.2204\n",
      "Epoch 11946/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 108.9244 - val_loss: 100.1871\n",
      "Epoch 11947/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 108.8775 - val_loss: 100.1540\n",
      "Epoch 11948/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 108.8306 - val_loss: 100.1206\n",
      "Epoch 11949/100000\n",
      "11/11 [==============================] - 0s 749us/step - loss: 108.7837 - val_loss: 100.0876\n",
      "Epoch 11950/100000\n",
      "11/11 [==============================] - 0s 668us/step - loss: 108.7369 - val_loss: 100.0542\n",
      "Epoch 11951/100000\n",
      "11/11 [==============================] - 0s 983us/step - loss: 108.6901 - val_loss: 100.0212\n",
      "Epoch 11952/100000\n",
      "11/11 [==============================] - 0s 669us/step - loss: 108.6433 - val_loss: 99.9880\n",
      "Epoch 11953/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 108.5965 - val_loss: 99.9550\n",
      "Epoch 11954/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 108.5497 - val_loss: 99.9218\n",
      "Epoch 11955/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 108.5030 - val_loss: 99.8888\n",
      "Epoch 11956/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 108.4563 - val_loss: 99.8558\n",
      "Epoch 11957/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 108.4097 - val_loss: 99.8228\n",
      "Epoch 11958/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 108.3630 - val_loss: 99.7899\n",
      "Epoch 11959/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 108.3163 - val_loss: 99.7569\n",
      "Epoch 11960/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 108.2698 - val_loss: 99.7241\n",
      "Epoch 11961/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 108.2232 - val_loss: 99.6911\n",
      "Epoch 11962/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 108.1768 - val_loss: 99.6584\n",
      "Epoch 11963/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 108.1302 - val_loss: 99.6254\n",
      "Epoch 11964/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 108.0837 - val_loss: 99.5927\n",
      "Epoch 11965/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 108.0373 - val_loss: 99.5598\n",
      "Epoch 11966/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 107.9909 - val_loss: 99.5272\n",
      "Epoch 11967/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 107.9445 - val_loss: 99.4944\n",
      "Epoch 11968/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 107.8981 - val_loss: 99.4617\n",
      "Epoch 11969/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 107.8518 - val_loss: 99.4291\n",
      "Epoch 11970/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 107.8055 - val_loss: 99.3964\n",
      "Epoch 11971/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 107.7592 - val_loss: 99.3638\n",
      "Epoch 11972/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 107.7130 - val_loss: 99.3312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11973/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 107.6667 - val_loss: 99.2987\n",
      "Epoch 11974/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 107.6205 - val_loss: 99.2661\n",
      "Epoch 11975/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 107.5743 - val_loss: 99.2336\n",
      "Epoch 11976/100000\n",
      "11/11 [==============================] - 0s 580us/step - loss: 107.5282 - val_loss: 99.2011\n",
      "Epoch 11977/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 107.4821 - val_loss: 99.1687\n",
      "Epoch 11978/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 107.4360 - val_loss: 99.1362\n",
      "Epoch 11979/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 107.3899 - val_loss: 99.1038\n",
      "Epoch 11980/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 107.3439 - val_loss: 99.0715\n",
      "Epoch 11981/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 107.2979 - val_loss: 99.0391\n",
      "Epoch 11982/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 107.2519 - val_loss: 99.0068\n",
      "Epoch 11983/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 107.2060 - val_loss: 98.9744\n",
      "Epoch 11984/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 107.1600 - val_loss: 98.9422\n",
      "Epoch 11985/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 107.1141 - val_loss: 98.9099\n",
      "Epoch 11986/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 107.0682 - val_loss: 98.8778\n",
      "Epoch 11987/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 107.0224 - val_loss: 98.8455\n",
      "Epoch 11988/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 106.9766 - val_loss: 98.8134\n",
      "Epoch 11989/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 106.9308 - val_loss: 98.7812\n",
      "Epoch 11990/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 106.8850 - val_loss: 98.7492\n",
      "Epoch 11991/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 106.8393 - val_loss: 98.7170\n",
      "Epoch 11992/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 106.7935 - val_loss: 98.6850\n",
      "Epoch 11993/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 106.7479 - val_loss: 98.6529\n",
      "Epoch 11994/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 106.7022 - val_loss: 98.6209\n",
      "Epoch 11995/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 106.6566 - val_loss: 98.5889\n",
      "Epoch 11996/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 106.6110 - val_loss: 98.5570\n",
      "Epoch 11997/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 106.5654 - val_loss: 98.5250\n",
      "Epoch 11998/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 106.5198 - val_loss: 98.4931\n",
      "Epoch 11999/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 106.4743 - val_loss: 98.4613\n",
      "Epoch 12000/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 106.4289 - val_loss: 98.4294\n",
      "Epoch 12001/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 106.3834 - val_loss: 98.3976\n",
      "Epoch 12002/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 106.3379 - val_loss: 98.3658\n",
      "Epoch 12003/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 106.2925 - val_loss: 98.3340\n",
      "Epoch 12004/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 106.2471 - val_loss: 98.3022\n",
      "Epoch 12005/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 106.2017 - val_loss: 98.2705\n",
      "Epoch 12006/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 106.1564 - val_loss: 98.2387\n",
      "Epoch 12007/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 106.1111 - val_loss: 98.2071\n",
      "Epoch 12008/100000\n",
      "11/11 [==============================] - 0s 642us/step - loss: 106.0658 - val_loss: 98.1755\n",
      "Epoch 12009/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 106.0206 - val_loss: 98.1439\n",
      "Epoch 12010/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 105.9754 - val_loss: 98.1122\n",
      "Epoch 12011/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 105.9301 - val_loss: 98.0807\n",
      "Epoch 12012/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 105.8850 - val_loss: 98.0491\n",
      "Epoch 12013/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 105.8398 - val_loss: 98.0177\n",
      "Epoch 12014/100000\n",
      "11/11 [==============================] - 0s 654us/step - loss: 105.7947 - val_loss: 97.9861\n",
      "Epoch 12015/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 105.7496 - val_loss: 97.9546\n",
      "Epoch 12016/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 105.7045 - val_loss: 97.9232\n",
      "Epoch 12017/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 105.6595 - val_loss: 97.8918\n",
      "Epoch 12018/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 105.6145 - val_loss: 97.8604\n",
      "Epoch 12019/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 105.5695 - val_loss: 97.8291\n",
      "Epoch 12020/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 105.5245 - val_loss: 97.7977\n",
      "Epoch 12021/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 105.4796 - val_loss: 97.7664\n",
      "Epoch 12022/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 105.4347 - val_loss: 97.7351\n",
      "Epoch 12023/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 105.3899 - val_loss: 97.7039\n",
      "Epoch 12024/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 105.3450 - val_loss: 97.6726\n",
      "Epoch 12025/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 105.3002 - val_loss: 97.6414\n",
      "Epoch 12026/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 105.2553 - val_loss: 97.6102\n",
      "Epoch 12027/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 105.2106 - val_loss: 97.5791\n",
      "Epoch 12028/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 105.1658 - val_loss: 97.5478\n",
      "Epoch 12029/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 105.1210 - val_loss: 97.5169\n",
      "Epoch 12030/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 105.0764 - val_loss: 97.4857\n",
      "Epoch 12031/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 105.0317 - val_loss: 97.4548\n",
      "Epoch 12032/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 104.9872 - val_loss: 97.4236\n",
      "Epoch 12033/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 104.9425 - val_loss: 97.3927\n",
      "Epoch 12034/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 104.8979 - val_loss: 97.3616\n",
      "Epoch 12035/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 104.8534 - val_loss: 97.3308\n",
      "Epoch 12036/100000\n",
      "11/11 [==============================] - 0s 589us/step - loss: 104.8088 - val_loss: 97.2996\n",
      "Epoch 12037/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 104.7643 - val_loss: 97.2690\n",
      "Epoch 12038/100000\n",
      "11/11 [==============================] - 0s 634us/step - loss: 104.7198 - val_loss: 97.2378\n",
      "Epoch 12039/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 104.6753 - val_loss: 97.2073\n",
      "Epoch 12040/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 104.6310 - val_loss: 97.1761\n",
      "Epoch 12041/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 104.5865 - val_loss: 97.1457\n",
      "Epoch 12042/100000\n",
      "11/11 [==============================] - 0s 607us/step - loss: 104.5422 - val_loss: 97.1146\n",
      "Epoch 12043/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 104.4979 - val_loss: 97.0842\n",
      "Epoch 12044/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 104.4535 - val_loss: 97.0530\n",
      "Epoch 12045/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 104.4092 - val_loss: 97.0228\n",
      "Epoch 12046/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 104.3649 - val_loss: 96.9915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12047/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 104.3207 - val_loss: 96.9616\n",
      "Epoch 12048/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 104.2765 - val_loss: 96.9302\n",
      "Epoch 12049/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 104.2323 - val_loss: 96.9004\n",
      "Epoch 12050/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 104.1881 - val_loss: 96.8688\n",
      "Epoch 12051/100000\n",
      "11/11 [==============================] - 0s 649us/step - loss: 104.1440 - val_loss: 96.8395\n",
      "Epoch 12052/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 104.0999 - val_loss: 96.8077\n",
      "Epoch 12053/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 104.0558 - val_loss: 96.7786\n",
      "Epoch 12054/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 104.0117 - val_loss: 96.7464\n",
      "Epoch 12055/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 103.9677 - val_loss: 96.7179\n",
      "Epoch 12056/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 103.9237 - val_loss: 96.6854\n",
      "Epoch 12057/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 103.8797 - val_loss: 96.6574\n",
      "Epoch 12058/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 103.8358 - val_loss: 96.6244\n",
      "Epoch 12059/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 103.7919 - val_loss: 96.5969\n",
      "Epoch 12060/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 103.7480 - val_loss: 96.5636\n",
      "Epoch 12061/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 103.7042 - val_loss: 96.5365\n",
      "Epoch 12062/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 103.6604 - val_loss: 96.5031\n",
      "Epoch 12063/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 103.6165 - val_loss: 96.4758\n",
      "Epoch 12064/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 103.5727 - val_loss: 96.4430\n",
      "Epoch 12065/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 103.5289 - val_loss: 96.4149\n",
      "Epoch 12066/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 103.4852 - val_loss: 96.3832\n",
      "Epoch 12067/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 103.4414 - val_loss: 96.3540\n",
      "Epoch 12068/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 103.3977 - val_loss: 96.3236\n",
      "Epoch 12069/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 103.3540 - val_loss: 96.2932\n",
      "Epoch 12070/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 103.3104 - val_loss: 96.2640\n",
      "Epoch 12071/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 103.2668 - val_loss: 96.2328\n",
      "Epoch 12072/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 103.2233 - val_loss: 96.2042\n",
      "Epoch 12073/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 103.1796 - val_loss: 96.1727\n",
      "Epoch 12074/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 103.1362 - val_loss: 96.1443\n",
      "Epoch 12075/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 103.0927 - val_loss: 96.1128\n",
      "Epoch 12076/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 103.0491 - val_loss: 96.0841\n",
      "Epoch 12077/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 103.0057 - val_loss: 96.0534\n",
      "Epoch 12078/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 102.9622 - val_loss: 96.0239\n",
      "Epoch 12079/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 102.9188 - val_loss: 95.9940\n",
      "Epoch 12080/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 102.8755 - val_loss: 95.9639\n",
      "Epoch 12081/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 102.8321 - val_loss: 95.9347\n",
      "Epoch 12082/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 102.7888 - val_loss: 95.9041\n",
      "Epoch 12083/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 102.7455 - val_loss: 95.8753\n",
      "Epoch 12084/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 102.7022 - val_loss: 95.8446\n",
      "Epoch 12085/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 102.6590 - val_loss: 95.8158\n",
      "Epoch 12086/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 102.6158 - val_loss: 95.7852\n",
      "Epoch 12087/100000\n",
      "11/11 [==============================] - 0s 648us/step - loss: 102.5725 - val_loss: 95.7562\n",
      "Epoch 12088/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 102.5294 - val_loss: 95.7262\n",
      "Epoch 12089/100000\n",
      "11/11 [==============================] - 0s 709us/step - loss: 102.4863 - val_loss: 95.6967\n",
      "Epoch 12090/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 102.4431 - val_loss: 95.6672\n",
      "Epoch 12091/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 102.4001 - val_loss: 95.6374\n",
      "Epoch 12092/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 102.3570 - val_loss: 95.6082\n",
      "Epoch 12093/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 102.3139 - val_loss: 95.5782\n",
      "Epoch 12094/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 102.2709 - val_loss: 95.5493\n",
      "Epoch 12095/100000\n",
      "11/11 [==============================] - 0s 619us/step - loss: 102.2279 - val_loss: 95.5192\n",
      "Epoch 12096/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 102.1850 - val_loss: 95.4903\n",
      "Epoch 12097/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 102.1420 - val_loss: 95.4604\n",
      "Epoch 12098/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 102.0992 - val_loss: 95.4314\n",
      "Epoch 12099/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 102.0563 - val_loss: 95.4017\n",
      "Epoch 12100/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 102.0134 - val_loss: 95.3726\n",
      "Epoch 12101/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 101.9706 - val_loss: 95.3432\n",
      "Epoch 12102/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 101.9278 - val_loss: 95.3138\n",
      "Epoch 12103/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 101.8851 - val_loss: 95.2847\n",
      "Epoch 12104/100000\n",
      "11/11 [==============================] - 0s 588us/step - loss: 101.8423 - val_loss: 95.2551\n",
      "Epoch 12105/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 101.7995 - val_loss: 95.2263\n",
      "Epoch 12106/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 101.7568 - val_loss: 95.1967\n",
      "Epoch 12107/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 101.7141 - val_loss: 95.1679\n",
      "Epoch 12108/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 101.6715 - val_loss: 95.1384\n",
      "Epoch 12109/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 101.6288 - val_loss: 95.1096\n",
      "Epoch 12110/100000\n",
      "11/11 [==============================] - 0s 599us/step - loss: 101.5862 - val_loss: 95.0803\n",
      "Epoch 12111/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 101.5437 - val_loss: 95.0513\n",
      "Epoch 12112/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 101.5011 - val_loss: 95.0222\n",
      "Epoch 12113/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 101.4586 - val_loss: 94.9932\n",
      "Epoch 12114/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 101.4161 - val_loss: 94.9642\n",
      "Epoch 12115/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 101.3737 - val_loss: 94.9351\n",
      "Epoch 12116/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 101.3312 - val_loss: 94.9063\n",
      "Epoch 12117/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 101.2888 - val_loss: 94.8772\n",
      "Epoch 12118/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 101.2464 - val_loss: 94.8485\n",
      "Epoch 12119/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 101.2040 - val_loss: 94.8194\n",
      "Epoch 12120/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 101.1617 - val_loss: 94.7907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12121/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 101.1194 - val_loss: 94.7617\n",
      "Epoch 12122/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 101.0770 - val_loss: 94.7330\n",
      "Epoch 12123/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 101.0348 - val_loss: 94.7041\n",
      "Epoch 12124/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 100.9926 - val_loss: 94.6755\n",
      "Epoch 12125/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 100.9503 - val_loss: 94.6466\n",
      "Epoch 12126/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 100.9082 - val_loss: 94.6180\n",
      "Epoch 12127/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 100.8660 - val_loss: 94.5892\n",
      "Epoch 12128/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 100.8238 - val_loss: 94.5605\n",
      "Epoch 12129/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 100.7817 - val_loss: 94.5319\n",
      "Epoch 12130/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 100.7397 - val_loss: 94.5033\n",
      "Epoch 12131/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 100.6976 - val_loss: 94.4747\n",
      "Epoch 12132/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 100.6555 - val_loss: 94.4460\n",
      "Epoch 12133/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 100.6135 - val_loss: 94.4176\n",
      "Epoch 12134/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 100.5716 - val_loss: 94.3890\n",
      "Epoch 12135/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 100.5296 - val_loss: 94.3605\n",
      "Epoch 12136/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 100.4877 - val_loss: 94.3320\n",
      "Epoch 12137/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 100.4458 - val_loss: 94.3036\n",
      "Epoch 12138/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 100.4039 - val_loss: 94.2750\n",
      "Epoch 12139/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 100.3620 - val_loss: 94.2467\n",
      "Epoch 12140/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 100.3202 - val_loss: 94.2183\n",
      "Epoch 12141/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 100.2784 - val_loss: 94.1899\n",
      "Epoch 12142/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 100.2366 - val_loss: 94.1616\n",
      "Epoch 12143/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 100.1949 - val_loss: 94.1333\n",
      "Epoch 12144/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 100.1532 - val_loss: 94.1050\n",
      "Epoch 12145/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 100.1114 - val_loss: 94.0767\n",
      "Epoch 12146/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 100.0697 - val_loss: 94.0484\n",
      "Epoch 12147/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 100.0280 - val_loss: 94.0202\n",
      "Epoch 12148/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 99.9865 - val_loss: 93.9920\n",
      "Epoch 12149/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 99.9448 - val_loss: 93.9638\n",
      "Epoch 12150/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 99.9033 - val_loss: 93.9356\n",
      "Epoch 12151/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 99.8617 - val_loss: 93.9075\n",
      "Epoch 12152/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 99.8202 - val_loss: 93.8794\n",
      "Epoch 12153/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 99.7787 - val_loss: 93.8513\n",
      "Epoch 12154/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 99.7372 - val_loss: 93.8233\n",
      "Epoch 12155/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 99.6958 - val_loss: 93.7951\n",
      "Epoch 12156/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 99.6543 - val_loss: 93.7672\n",
      "Epoch 12157/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 99.6129 - val_loss: 93.7391\n",
      "Epoch 12158/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 99.5715 - val_loss: 93.7112\n",
      "Epoch 12159/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 99.5301 - val_loss: 93.6832\n",
      "Epoch 12160/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 99.4888 - val_loss: 93.6553\n",
      "Epoch 12161/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 99.4475 - val_loss: 93.6273\n",
      "Epoch 12162/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 99.4063 - val_loss: 93.5995\n",
      "Epoch 12163/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 99.3650 - val_loss: 93.5716\n",
      "Epoch 12164/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 99.3238 - val_loss: 93.5439\n",
      "Epoch 12165/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 99.2826 - val_loss: 93.5160\n",
      "Epoch 12166/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 99.2414 - val_loss: 93.4882\n",
      "Epoch 12167/100000\n",
      "11/11 [==============================] - 0s 198us/step - loss: 99.2002 - val_loss: 93.4605\n",
      "Epoch 12168/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 99.1592 - val_loss: 93.4326\n",
      "Epoch 12169/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 99.1180 - val_loss: 93.4050\n",
      "Epoch 12170/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 99.0770 - val_loss: 93.3773\n",
      "Epoch 12171/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 99.0359 - val_loss: 93.3496\n",
      "Epoch 12172/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 98.9949 - val_loss: 93.3219\n",
      "Epoch 12173/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 98.9539 - val_loss: 93.2944\n",
      "Epoch 12174/100000\n",
      "11/11 [==============================] - 0s 623us/step - loss: 98.9129 - val_loss: 93.2667\n",
      "Epoch 12175/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 98.8720 - val_loss: 93.2392\n",
      "Epoch 12176/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 98.8310 - val_loss: 93.2115\n",
      "Epoch 12177/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 98.7901 - val_loss: 93.1841\n",
      "Epoch 12178/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 98.7492 - val_loss: 93.1564\n",
      "Epoch 12179/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 98.7084 - val_loss: 93.1291\n",
      "Epoch 12180/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 98.6676 - val_loss: 93.1014\n",
      "Epoch 12181/100000\n",
      "11/11 [==============================] - 0s 629us/step - loss: 98.6267 - val_loss: 93.0741\n",
      "Epoch 12182/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 98.5859 - val_loss: 93.0466\n",
      "Epoch 12183/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 98.5453 - val_loss: 93.0193\n",
      "Epoch 12184/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 98.5045 - val_loss: 92.9918\n",
      "Epoch 12185/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 98.4638 - val_loss: 92.9646\n",
      "Epoch 12186/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 98.4232 - val_loss: 92.9370\n",
      "Epoch 12187/100000\n",
      "11/11 [==============================] - 0s 614us/step - loss: 98.3825 - val_loss: 92.9100\n",
      "Epoch 12188/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 98.3419 - val_loss: 92.8825\n",
      "Epoch 12189/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 98.3013 - val_loss: 92.8554\n",
      "Epoch 12190/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 98.2607 - val_loss: 92.8279\n",
      "Epoch 12191/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 98.2202 - val_loss: 92.8010\n",
      "Epoch 12192/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 98.1796 - val_loss: 92.7734\n",
      "Epoch 12193/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 98.1390 - val_loss: 92.7466\n",
      "Epoch 12194/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 98.0986 - val_loss: 92.7191\n",
      "Epoch 12195/100000\n",
      "11/11 [==============================] - 0s 619us/step - loss: 98.0582 - val_loss: 92.6924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12196/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 98.0177 - val_loss: 92.6648\n",
      "Epoch 12197/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 97.9773 - val_loss: 92.6382\n",
      "Epoch 12198/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 97.9369 - val_loss: 92.6105\n",
      "Epoch 12199/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 97.8966 - val_loss: 92.5842\n",
      "Epoch 12200/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 97.8562 - val_loss: 92.5564\n",
      "Epoch 12201/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 97.8160 - val_loss: 92.5303\n",
      "Epoch 12202/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 97.7757 - val_loss: 92.5023\n",
      "Epoch 12203/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 97.7355 - val_loss: 92.4765\n",
      "Epoch 12204/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 97.6952 - val_loss: 92.4482\n",
      "Epoch 12205/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 97.6550 - val_loss: 92.4228\n",
      "Epoch 12206/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 97.6148 - val_loss: 92.3942\n",
      "Epoch 12207/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 97.5747 - val_loss: 92.3693\n",
      "Epoch 12208/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 97.5346 - val_loss: 92.3403\n",
      "Epoch 12209/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 97.4944 - val_loss: 92.3159\n",
      "Epoch 12210/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 97.4543 - val_loss: 92.2864\n",
      "Epoch 12211/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 97.4142 - val_loss: 92.2626\n",
      "Epoch 12212/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 97.3742 - val_loss: 92.2327\n",
      "Epoch 12213/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 97.3343 - val_loss: 92.2093\n",
      "Epoch 12214/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 97.2943 - val_loss: 92.1792\n",
      "Epoch 12215/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 97.2543 - val_loss: 92.1559\n",
      "Epoch 12216/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 97.2144 - val_loss: 92.1260\n",
      "Epoch 12217/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 97.1744 - val_loss: 92.1025\n",
      "Epoch 12218/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 97.1346 - val_loss: 92.0732\n",
      "Epoch 12219/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 97.0947 - val_loss: 92.0487\n",
      "Epoch 12220/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 97.0548 - val_loss: 92.0206\n",
      "Epoch 12221/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 97.0150 - val_loss: 91.9950\n",
      "Epoch 12222/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 96.9752 - val_loss: 91.9682\n",
      "Epoch 12223/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 96.9355 - val_loss: 91.9414\n",
      "Epoch 12224/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 96.8957 - val_loss: 91.9157\n",
      "Epoch 12225/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 96.8560 - val_loss: 91.8880\n",
      "Epoch 12226/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 96.8163 - val_loss: 91.8631\n",
      "Epoch 12227/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 96.7766 - val_loss: 91.8351\n",
      "Epoch 12228/100000\n",
      "11/11 [==============================] - 0s 636us/step - loss: 96.7370 - val_loss: 91.8103\n",
      "Epoch 12229/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 96.6974 - val_loss: 91.7823\n",
      "Epoch 12230/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 96.6577 - val_loss: 91.7574\n",
      "Epoch 12231/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 96.6182 - val_loss: 91.7298\n",
      "Epoch 12232/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 96.5786 - val_loss: 91.7044\n",
      "Epoch 12233/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 96.5391 - val_loss: 91.6776\n",
      "Epoch 12234/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 96.4996 - val_loss: 91.6514\n",
      "Epoch 12235/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 96.4602 - val_loss: 91.6253\n",
      "Epoch 12236/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 96.4207 - val_loss: 91.5986\n",
      "Epoch 12237/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 96.3813 - val_loss: 91.5731\n",
      "Epoch 12238/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 96.3419 - val_loss: 91.5460\n",
      "Epoch 12239/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 96.3025 - val_loss: 91.5207\n",
      "Epoch 12240/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 96.2631 - val_loss: 91.4936\n",
      "Epoch 12241/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 96.2238 - val_loss: 91.4684\n",
      "Epoch 12242/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 96.1845 - val_loss: 91.4415\n",
      "Epoch 12243/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 96.1453 - val_loss: 91.4160\n",
      "Epoch 12244/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 96.1060 - val_loss: 91.3895\n",
      "Epoch 12245/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 96.0668 - val_loss: 91.3637\n",
      "Epoch 12246/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 96.0275 - val_loss: 91.3375\n",
      "Epoch 12247/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 95.9883 - val_loss: 91.3114\n",
      "Epoch 12248/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 95.9492 - val_loss: 91.2856\n",
      "Epoch 12249/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 95.9100 - val_loss: 91.2593\n",
      "Epoch 12250/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 95.8709 - val_loss: 91.2338\n",
      "Epoch 12251/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 95.8318 - val_loss: 91.2074\n",
      "Epoch 12252/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 95.7928 - val_loss: 91.1820\n",
      "Epoch 12253/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 95.7538 - val_loss: 91.1556\n",
      "Epoch 12254/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 95.7148 - val_loss: 91.1302\n",
      "Epoch 12255/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 95.6758 - val_loss: 91.1039\n",
      "Epoch 12256/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 95.6368 - val_loss: 91.0785\n",
      "Epoch 12257/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 95.5979 - val_loss: 91.0524\n",
      "Epoch 12258/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 95.5589 - val_loss: 91.0267\n",
      "Epoch 12259/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 95.5200 - val_loss: 91.0009\n",
      "Epoch 12260/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 95.4812 - val_loss: 90.9751\n",
      "Epoch 12261/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 95.4423 - val_loss: 90.9495\n",
      "Epoch 12262/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 95.4035 - val_loss: 90.9236\n",
      "Epoch 12263/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 95.3647 - val_loss: 90.8982\n",
      "Epoch 12264/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 95.3259 - val_loss: 90.8722\n",
      "Epoch 12265/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 95.2872 - val_loss: 90.8469\n",
      "Epoch 12266/100000\n",
      "11/11 [==============================] - 0s 766us/step - loss: 95.2484 - val_loss: 90.8211\n",
      "Epoch 12267/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 95.2098 - val_loss: 90.7957\n",
      "Epoch 12268/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 95.1711 - val_loss: 90.7699\n",
      "Epoch 12269/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 95.1324 - val_loss: 90.7445\n",
      "Epoch 12270/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 95.0938 - val_loss: 90.7188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12271/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 95.0551 - val_loss: 90.6934\n",
      "Epoch 12272/100000\n",
      "11/11 [==============================] - 0s 593us/step - loss: 95.0166 - val_loss: 90.6679\n",
      "Epoch 12273/100000\n",
      "11/11 [==============================] - 0s 813us/step - loss: 94.9781 - val_loss: 90.6423\n",
      "Epoch 12274/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 94.9395 - val_loss: 90.6170\n",
      "Epoch 12275/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 94.9010 - val_loss: 90.5915\n",
      "Epoch 12276/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 94.8625 - val_loss: 90.5661\n",
      "Epoch 12277/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 94.8240 - val_loss: 90.5406\n",
      "Epoch 12278/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 94.7856 - val_loss: 90.5154\n",
      "Epoch 12279/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 94.7472 - val_loss: 90.4899\n",
      "Epoch 12280/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 94.7088 - val_loss: 90.4646\n",
      "Epoch 12281/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 94.6704 - val_loss: 90.4392\n",
      "Epoch 12282/100000\n",
      "11/11 [==============================] - 0s 642us/step - loss: 94.6321 - val_loss: 90.4140\n",
      "Epoch 12283/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 94.5937 - val_loss: 90.3886\n",
      "Epoch 12284/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 94.5555 - val_loss: 90.3634\n",
      "Epoch 12285/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 94.5172 - val_loss: 90.3381\n",
      "Epoch 12286/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 94.4789 - val_loss: 90.3129\n",
      "Epoch 12287/100000\n",
      "11/11 [==============================] - 0s 636us/step - loss: 94.4407 - val_loss: 90.2877\n",
      "Epoch 12288/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 94.4025 - val_loss: 90.2625\n",
      "Epoch 12289/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 94.3643 - val_loss: 90.2374\n",
      "Epoch 12290/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 94.3261 - val_loss: 90.2122\n",
      "Epoch 12291/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 94.2880 - val_loss: 90.1871\n",
      "Epoch 12292/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 94.2499 - val_loss: 90.1620\n",
      "Epoch 12293/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 94.2118 - val_loss: 90.1369\n",
      "Epoch 12294/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 94.1738 - val_loss: 90.1118\n",
      "Epoch 12295/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 94.1357 - val_loss: 90.0868\n",
      "Epoch 12296/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 94.0977 - val_loss: 90.0617\n",
      "Epoch 12297/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 94.0597 - val_loss: 90.0368\n",
      "Epoch 12298/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 94.0217 - val_loss: 90.0117\n",
      "Epoch 12299/100000\n",
      "11/11 [==============================] - 0s 594us/step - loss: 93.9838 - val_loss: 89.9869\n",
      "Epoch 12300/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 93.9459 - val_loss: 89.9618\n",
      "Epoch 12301/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 93.9080 - val_loss: 89.9370\n",
      "Epoch 12302/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 93.8700 - val_loss: 89.9120\n",
      "Epoch 12303/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 93.8323 - val_loss: 89.8872\n",
      "Epoch 12304/100000\n",
      "11/11 [==============================] - 0s 899us/step - loss: 93.7944 - val_loss: 89.8622\n",
      "Epoch 12305/100000\n",
      "11/11 [==============================] - 0s 725us/step - loss: 93.7566 - val_loss: 89.8375\n",
      "Epoch 12306/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 93.7188 - val_loss: 89.8126\n",
      "Epoch 12307/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 93.6811 - val_loss: 89.7878\n",
      "Epoch 12308/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 93.6433 - val_loss: 89.7630\n",
      "Epoch 12309/100000\n",
      "11/11 [==============================] - 0s 839us/step - loss: 93.6056 - val_loss: 89.7383\n",
      "Epoch 12310/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 93.5679 - val_loss: 89.7135\n",
      "Epoch 12311/100000\n",
      "11/11 [==============================] - 0s 656us/step - loss: 93.5303 - val_loss: 89.6888\n",
      "Epoch 12312/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 93.4926 - val_loss: 89.6640\n",
      "Epoch 12313/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 93.4550 - val_loss: 89.6394\n",
      "Epoch 12314/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 93.4174 - val_loss: 89.6146\n",
      "Epoch 12315/100000\n",
      "11/11 [==============================] - 0s 804us/step - loss: 93.3798 - val_loss: 89.5900\n",
      "Epoch 12316/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 93.3423 - val_loss: 89.5654\n",
      "Epoch 12317/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 93.3048 - val_loss: 89.5407\n",
      "Epoch 12318/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 93.2673 - val_loss: 89.5161\n",
      "Epoch 12319/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 93.2298 - val_loss: 89.4916\n",
      "Epoch 12320/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 93.1923 - val_loss: 89.4669\n",
      "Epoch 12321/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 93.1548 - val_loss: 89.4424\n",
      "Epoch 12322/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 93.1175 - val_loss: 89.4179\n",
      "Epoch 12323/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 93.0801 - val_loss: 89.3934\n",
      "Epoch 12324/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 93.0427 - val_loss: 89.3689\n",
      "Epoch 12325/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 93.0054 - val_loss: 89.3443\n",
      "Epoch 12326/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 92.9680 - val_loss: 89.3200\n",
      "Epoch 12327/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 92.9307 - val_loss: 89.2955\n",
      "Epoch 12328/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 92.8935 - val_loss: 89.2712\n",
      "Epoch 12329/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 92.8562 - val_loss: 89.2467\n",
      "Epoch 12330/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 92.8190 - val_loss: 89.2224\n",
      "Epoch 12331/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 92.7818 - val_loss: 89.1980\n",
      "Epoch 12332/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 92.7446 - val_loss: 89.1737\n",
      "Epoch 12333/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 92.7075 - val_loss: 89.1493\n",
      "Epoch 12334/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 92.6703 - val_loss: 89.1250\n",
      "Epoch 12335/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 92.6332 - val_loss: 89.1007\n",
      "Epoch 12336/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 92.5961 - val_loss: 89.0765\n",
      "Epoch 12337/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 92.5591 - val_loss: 89.0522\n",
      "Epoch 12338/100000\n",
      "11/11 [==============================] - 0s 735us/step - loss: 92.5221 - val_loss: 89.0280\n",
      "Epoch 12339/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 92.4851 - val_loss: 89.0038\n",
      "Epoch 12340/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 92.4480 - val_loss: 88.9795\n",
      "Epoch 12341/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 92.4110 - val_loss: 88.9554\n",
      "Epoch 12342/100000\n",
      "11/11 [==============================] - 0s 728us/step - loss: 92.3741 - val_loss: 88.9312\n",
      "Epoch 12343/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 92.3372 - val_loss: 88.9071\n",
      "Epoch 12344/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 92.3002 - val_loss: 88.8829\n",
      "Epoch 12345/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 92.2634 - val_loss: 88.8589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12346/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 92.2266 - val_loss: 88.8347\n",
      "Epoch 12347/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 92.1897 - val_loss: 88.8108\n",
      "Epoch 12348/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 92.1529 - val_loss: 88.7865\n",
      "Epoch 12349/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 92.1161 - val_loss: 88.7627\n",
      "Epoch 12350/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 92.0793 - val_loss: 88.7385\n",
      "Epoch 12351/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 92.0426 - val_loss: 88.7147\n",
      "Epoch 12352/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 92.0059 - val_loss: 88.6905\n",
      "Epoch 12353/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 91.9692 - val_loss: 88.6668\n",
      "Epoch 12354/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 91.9325 - val_loss: 88.6425\n",
      "Epoch 12355/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 91.8958 - val_loss: 88.6189\n",
      "Epoch 12356/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 91.8592 - val_loss: 88.5947\n",
      "Epoch 12357/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 91.8226 - val_loss: 88.5711\n",
      "Epoch 12358/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 91.7860 - val_loss: 88.5469\n",
      "Epoch 12359/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 91.7494 - val_loss: 88.5234\n",
      "Epoch 12360/100000\n",
      "11/11 [==============================] - 0s 642us/step - loss: 91.7129 - val_loss: 88.4991\n",
      "Epoch 12361/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 91.6764 - val_loss: 88.4758\n",
      "Epoch 12362/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 91.6399 - val_loss: 88.4515\n",
      "Epoch 12363/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 91.6034 - val_loss: 88.4282\n",
      "Epoch 12364/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 91.5669 - val_loss: 88.4039\n",
      "Epoch 12365/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 91.5305 - val_loss: 88.3807\n",
      "Epoch 12366/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 91.4941 - val_loss: 88.3563\n",
      "Epoch 12367/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 91.4577 - val_loss: 88.3333\n",
      "Epoch 12368/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 91.4214 - val_loss: 88.3089\n",
      "Epoch 12369/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 91.3851 - val_loss: 88.2860\n",
      "Epoch 12370/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 91.3488 - val_loss: 88.2614\n",
      "Epoch 12371/100000\n",
      "11/11 [==============================] - 0s 607us/step - loss: 91.3124 - val_loss: 88.2387\n",
      "Epoch 12372/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 91.2762 - val_loss: 88.2140\n",
      "Epoch 12373/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.2399 - val_loss: 88.1915\n",
      "Epoch 12374/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 91.2037 - val_loss: 88.1667\n",
      "Epoch 12375/100000\n",
      "11/11 [==============================] - 0s 928us/step - loss: 91.1675 - val_loss: 88.1444\n",
      "Epoch 12376/100000\n",
      "11/11 [==============================] - 0s 898us/step - loss: 91.1313 - val_loss: 88.1195\n",
      "Epoch 12377/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.0951 - val_loss: 88.0974\n",
      "Epoch 12378/100000\n",
      "11/11 [==============================] - 0s 705us/step - loss: 91.0591 - val_loss: 88.0723\n",
      "Epoch 12379/100000\n",
      "11/11 [==============================] - 0s 675us/step - loss: 91.0230 - val_loss: 88.0504\n",
      "Epoch 12380/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 90.9868 - val_loss: 88.0252\n",
      "Epoch 12381/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 90.9508 - val_loss: 88.0035\n",
      "Epoch 12382/100000\n",
      "11/11 [==============================] - 0s 564us/step - loss: 90.9147 - val_loss: 87.9781\n",
      "Epoch 12383/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.8786 - val_loss: 87.9567\n",
      "Epoch 12384/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 90.8427 - val_loss: 87.9311\n",
      "Epoch 12385/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 90.8066 - val_loss: 87.9099\n",
      "Epoch 12386/100000\n",
      "11/11 [==============================] - 0s 985us/step - loss: 90.7707 - val_loss: 87.8843\n",
      "Epoch 12387/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 90.7348 - val_loss: 87.8632\n",
      "Epoch 12388/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 90.6989 - val_loss: 87.8375\n",
      "Epoch 12389/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 90.6630 - val_loss: 87.8165\n",
      "Epoch 12390/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 90.6271 - val_loss: 87.7909\n",
      "Epoch 12391/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 90.5913 - val_loss: 87.7698\n",
      "Epoch 12392/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 90.5555 - val_loss: 87.7443\n",
      "Epoch 12393/100000\n",
      "11/11 [==============================] - 0s 564us/step - loss: 90.5196 - val_loss: 87.7231\n",
      "Epoch 12394/100000\n",
      "11/11 [==============================] - 0s 736us/step - loss: 90.4839 - val_loss: 87.6980\n",
      "Epoch 12395/100000\n",
      "11/11 [==============================] - 0s 766us/step - loss: 90.4481 - val_loss: 87.6764\n",
      "Epoch 12396/100000\n",
      "11/11 [==============================] - 0s 594us/step - loss: 90.4124 - val_loss: 87.6516\n",
      "Epoch 12397/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 90.3767 - val_loss: 87.6297\n",
      "Epoch 12398/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 90.3410 - val_loss: 87.6054\n",
      "Epoch 12399/100000\n",
      "11/11 [==============================] - 0s 763us/step - loss: 90.3053 - val_loss: 87.5831\n",
      "Epoch 12400/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 90.2697 - val_loss: 87.5593\n",
      "Epoch 12401/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 90.2340 - val_loss: 87.5364\n",
      "Epoch 12402/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 90.1984 - val_loss: 87.5132\n",
      "Epoch 12403/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 90.1628 - val_loss: 87.4900\n",
      "Epoch 12404/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 90.1273 - val_loss: 87.4671\n",
      "Epoch 12405/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 90.0917 - val_loss: 87.4436\n",
      "Epoch 12406/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 90.0562 - val_loss: 87.4210\n",
      "Epoch 12407/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 90.0207 - val_loss: 87.3973\n",
      "Epoch 12408/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 89.9852 - val_loss: 87.3749\n",
      "Epoch 12409/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 89.9498 - val_loss: 87.3512\n",
      "Epoch 12410/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 89.9144 - val_loss: 87.3288\n",
      "Epoch 12411/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 89.8790 - val_loss: 87.3051\n",
      "Epoch 12412/100000\n",
      "11/11 [==============================] - 0s 637us/step - loss: 89.8436 - val_loss: 87.2828\n",
      "Epoch 12413/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 89.8082 - val_loss: 87.2591\n",
      "Epoch 12414/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 89.7728 - val_loss: 87.2368\n",
      "Epoch 12415/100000\n",
      "11/11 [==============================] - 0s 675us/step - loss: 89.7376 - val_loss: 87.2132\n",
      "Epoch 12416/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 89.7023 - val_loss: 87.1908\n",
      "Epoch 12417/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 89.6670 - val_loss: 87.1674\n",
      "Epoch 12418/100000\n",
      "11/11 [==============================] - 0s 756us/step - loss: 89.6317 - val_loss: 87.1449\n",
      "Epoch 12419/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 89.5965 - val_loss: 87.1216\n",
      "Epoch 12420/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 89.5612 - val_loss: 87.0990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12421/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 89.5261 - val_loss: 87.0759\n",
      "Epoch 12422/100000\n",
      "11/11 [==============================] - 0s 741us/step - loss: 89.4909 - val_loss: 87.0531\n",
      "Epoch 12423/100000\n",
      "11/11 [==============================] - 0s 937us/step - loss: 89.4558 - val_loss: 87.0303\n",
      "Epoch 12424/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 89.4207 - val_loss: 87.0074\n",
      "Epoch 12425/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 89.3855 - val_loss: 86.9847\n",
      "Epoch 12426/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 89.3504 - val_loss: 86.9617\n",
      "Epoch 12427/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 89.3154 - val_loss: 86.9391\n",
      "Epoch 12428/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 89.2803 - val_loss: 86.9161\n",
      "Epoch 12429/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 89.2453 - val_loss: 86.8936\n",
      "Epoch 12430/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 89.2103 - val_loss: 86.8706\n",
      "Epoch 12431/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 89.1753 - val_loss: 86.8481\n",
      "Epoch 12432/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 89.1404 - val_loss: 86.8251\n",
      "Epoch 12433/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 89.1055 - val_loss: 86.8027\n",
      "Epoch 12434/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 89.0706 - val_loss: 86.7797\n",
      "Epoch 12435/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 89.0357 - val_loss: 86.7573\n",
      "Epoch 12436/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 89.0008 - val_loss: 86.7344\n",
      "Epoch 12437/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 88.9660 - val_loss: 86.7120\n",
      "Epoch 12438/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 88.9312 - val_loss: 86.6891\n",
      "Epoch 12439/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 88.8964 - val_loss: 86.6667\n",
      "Epoch 12440/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 88.8616 - val_loss: 86.6439\n",
      "Epoch 12441/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 88.8268 - val_loss: 86.6215\n",
      "Epoch 12442/100000\n",
      "11/11 [==============================] - 0s 649us/step - loss: 88.7921 - val_loss: 86.5988\n",
      "Epoch 12443/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 88.7574 - val_loss: 86.5763\n",
      "Epoch 12444/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 88.7227 - val_loss: 86.5536\n",
      "Epoch 12445/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 88.6880 - val_loss: 86.5312\n",
      "Epoch 12446/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 88.6533 - val_loss: 86.5086\n",
      "Epoch 12447/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 88.6187 - val_loss: 86.4861\n",
      "Epoch 12448/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 88.5841 - val_loss: 86.4636\n",
      "Epoch 12449/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 88.5495 - val_loss: 86.4410\n",
      "Epoch 12450/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 88.5149 - val_loss: 86.4186\n",
      "Epoch 12451/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 88.4804 - val_loss: 86.3961\n",
      "Epoch 12452/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 88.4459 - val_loss: 86.3737\n",
      "Epoch 12453/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 88.4114 - val_loss: 86.3511\n",
      "Epoch 12454/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 88.3768 - val_loss: 86.3288\n",
      "Epoch 12455/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 88.3424 - val_loss: 86.3063\n",
      "Epoch 12456/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 88.3080 - val_loss: 86.2840\n",
      "Epoch 12457/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 88.2735 - val_loss: 86.2614\n",
      "Epoch 12458/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 88.2391 - val_loss: 86.2393\n",
      "Epoch 12459/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 88.2047 - val_loss: 86.2167\n",
      "Epoch 12460/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 88.1704 - val_loss: 86.1944\n",
      "Epoch 12461/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 88.1360 - val_loss: 86.1720\n",
      "Epoch 12462/100000\n",
      "11/11 [==============================] - 0s 607us/step - loss: 88.1017 - val_loss: 86.1499\n",
      "Epoch 12463/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 88.0675 - val_loss: 86.1273\n",
      "Epoch 12464/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 88.0331 - val_loss: 86.1051\n",
      "Epoch 12465/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 87.9989 - val_loss: 86.0827\n",
      "Epoch 12466/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 87.9647 - val_loss: 86.0606\n",
      "Epoch 12467/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 87.9305 - val_loss: 86.0381\n",
      "Epoch 12468/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 87.8963 - val_loss: 86.0160\n",
      "Epoch 12469/100000\n",
      "11/11 [==============================] - 0s 756us/step - loss: 87.8621 - val_loss: 85.9936\n",
      "Epoch 12470/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 87.8279 - val_loss: 85.9715\n",
      "Epoch 12471/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 87.7938 - val_loss: 85.9492\n",
      "Epoch 12472/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 87.7597 - val_loss: 85.9270\n",
      "Epoch 12473/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 87.7256 - val_loss: 85.9047\n",
      "Epoch 12474/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 87.6915 - val_loss: 85.8826\n",
      "Epoch 12475/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 87.6575 - val_loss: 85.8604\n",
      "Epoch 12476/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 87.6235 - val_loss: 85.8382\n",
      "Epoch 12477/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 87.5894 - val_loss: 85.8160\n",
      "Epoch 12478/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 87.5555 - val_loss: 85.7940\n",
      "Epoch 12479/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 87.5215 - val_loss: 85.7717\n",
      "Epoch 12480/100000\n",
      "11/11 [==============================] - 0s 749us/step - loss: 87.4875 - val_loss: 85.7497\n",
      "Epoch 12481/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 87.4537 - val_loss: 85.7274\n",
      "Epoch 12482/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 87.4197 - val_loss: 85.7054\n",
      "Epoch 12483/100000\n",
      "11/11 [==============================] - 0s 697us/step - loss: 87.3858 - val_loss: 85.6832\n",
      "Epoch 12484/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 87.3520 - val_loss: 85.6612\n",
      "Epoch 12485/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 87.3182 - val_loss: 85.6391\n",
      "Epoch 12486/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 87.2844 - val_loss: 85.6171\n",
      "Epoch 12487/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 87.2505 - val_loss: 85.5949\n",
      "Epoch 12488/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 87.2167 - val_loss: 85.5729\n",
      "Epoch 12489/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 87.1830 - val_loss: 85.5509\n",
      "Epoch 12490/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 87.1493 - val_loss: 85.5289\n",
      "Epoch 12491/100000\n",
      "11/11 [==============================] - 0s 794us/step - loss: 87.1156 - val_loss: 85.5067\n",
      "Epoch 12492/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 87.0818 - val_loss: 85.4848\n",
      "Epoch 12493/100000\n",
      "11/11 [==============================] - 0s 876us/step - loss: 87.0482 - val_loss: 85.4628\n",
      "Epoch 12494/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 87.0145 - val_loss: 85.4408\n",
      "Epoch 12495/100000\n",
      "11/11 [==============================] - 0s 861us/step - loss: 86.9809 - val_loss: 85.4188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12496/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 86.9473 - val_loss: 85.3968\n",
      "Epoch 12497/100000\n",
      "11/11 [==============================] - 0s 867us/step - loss: 86.9136 - val_loss: 85.3749\n",
      "Epoch 12498/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 86.8801 - val_loss: 85.3529\n",
      "Epoch 12499/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 86.8465 - val_loss: 85.3310\n",
      "Epoch 12500/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 86.8130 - val_loss: 85.3090\n",
      "Epoch 12501/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 86.7794 - val_loss: 85.2872\n",
      "Epoch 12502/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 86.7460 - val_loss: 85.2652\n",
      "Epoch 12503/100000\n",
      "11/11 [==============================] - 0s 660us/step - loss: 86.7125 - val_loss: 85.2433\n",
      "Epoch 12504/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 86.6790 - val_loss: 85.2214\n",
      "Epoch 12505/100000\n",
      "11/11 [==============================] - 0s 949us/step - loss: 86.6456 - val_loss: 85.1996\n",
      "Epoch 12506/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 86.6122 - val_loss: 85.1776\n",
      "Epoch 12507/100000\n",
      "11/11 [==============================] - 0s 733us/step - loss: 86.5788 - val_loss: 85.1558\n",
      "Epoch 12508/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 86.5454 - val_loss: 85.1339\n",
      "Epoch 12509/100000\n",
      "11/11 [==============================] - 0s 979us/step - loss: 86.5121 - val_loss: 85.1121\n",
      "Epoch 12510/100000\n",
      "11/11 [==============================] - 0s 588us/step - loss: 86.4787 - val_loss: 85.0902\n",
      "Epoch 12511/100000\n",
      "11/11 [==============================] - 0s 801us/step - loss: 86.4454 - val_loss: 85.0683\n",
      "Epoch 12512/100000\n",
      "11/11 [==============================] - 0s 741us/step - loss: 86.4121 - val_loss: 85.0466\n",
      "Epoch 12513/100000\n",
      "11/11 [==============================] - 0s 564us/step - loss: 86.3788 - val_loss: 85.0247\n",
      "Epoch 12514/100000\n",
      "11/11 [==============================] - 0s 694us/step - loss: 86.3456 - val_loss: 85.0029\n",
      "Epoch 12515/100000\n",
      "11/11 [==============================] - 0s 819us/step - loss: 86.3123 - val_loss: 84.9810\n",
      "Epoch 12516/100000\n",
      "11/11 [==============================] - 0s 607us/step - loss: 86.2791 - val_loss: 84.9594\n",
      "Epoch 12517/100000\n",
      "11/11 [==============================] - 0s 872us/step - loss: 86.2460 - val_loss: 84.9375\n",
      "Epoch 12518/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 86.2127 - val_loss: 84.9158\n",
      "Epoch 12519/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 86.1796 - val_loss: 84.8939\n",
      "Epoch 12520/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 86.1464 - val_loss: 84.8722\n",
      "Epoch 12521/100000\n",
      "11/11 [==============================] - 0s 590us/step - loss: 86.1133 - val_loss: 84.8503\n",
      "Epoch 12522/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 86.0802 - val_loss: 84.8287\n",
      "Epoch 12523/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 86.0472 - val_loss: 84.8069\n",
      "Epoch 12524/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 86.0141 - val_loss: 84.7852\n",
      "Epoch 12525/100000\n",
      "11/11 [==============================] - 0s 829us/step - loss: 85.9810 - val_loss: 84.7634\n",
      "Epoch 12526/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 85.9480 - val_loss: 84.7417\n",
      "Epoch 12527/100000\n",
      "11/11 [==============================] - 0s 763us/step - loss: 85.9150 - val_loss: 84.7199\n",
      "Epoch 12528/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 85.8820 - val_loss: 84.6983\n",
      "Epoch 12529/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 85.8491 - val_loss: 84.6765\n",
      "Epoch 12530/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 85.8161 - val_loss: 84.6549\n",
      "Epoch 12531/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 85.7832 - val_loss: 84.6331\n",
      "Epoch 12532/100000\n",
      "11/11 [==============================] - 0s 637us/step - loss: 85.7503 - val_loss: 84.6114\n",
      "Epoch 12533/100000\n",
      "11/11 [==============================] - 0s 875us/step - loss: 85.7174 - val_loss: 84.5897\n",
      "Epoch 12534/100000\n",
      "11/11 [==============================] - 0s 988us/step - loss: 85.6845 - val_loss: 84.5681\n",
      "Epoch 12535/100000\n",
      "11/11 [==============================] - 0s 623us/step - loss: 85.6517 - val_loss: 84.5464\n",
      "Epoch 12536/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 85.6189 - val_loss: 84.5247\n",
      "Epoch 12537/100000\n",
      "11/11 [==============================] - 0s 918us/step - loss: 85.5861 - val_loss: 84.5031\n",
      "Epoch 12538/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 85.5533 - val_loss: 84.4814\n",
      "Epoch 12539/100000\n",
      "11/11 [==============================] - 0s 675us/step - loss: 85.5205 - val_loss: 84.4599\n",
      "Epoch 12540/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 85.4878 - val_loss: 84.4381\n",
      "Epoch 12541/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 85.4550 - val_loss: 84.4165\n",
      "Epoch 12542/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 85.4223 - val_loss: 84.3948\n",
      "Epoch 12543/100000\n",
      "11/11 [==============================] - 0s 730us/step - loss: 85.3896 - val_loss: 84.3733\n",
      "Epoch 12544/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 85.3569 - val_loss: 84.3516\n",
      "Epoch 12545/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 85.3243 - val_loss: 84.3301\n",
      "Epoch 12546/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 85.2917 - val_loss: 84.3084\n",
      "Epoch 12547/100000\n",
      "11/11 [==============================] - 0s 682us/step - loss: 85.2591 - val_loss: 84.2868\n",
      "Epoch 12548/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 85.2265 - val_loss: 84.2652\n",
      "Epoch 12549/100000\n",
      "11/11 [==============================] - 0s 862us/step - loss: 85.1939 - val_loss: 84.2436\n",
      "Epoch 12550/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 85.1613 - val_loss: 84.2221\n",
      "Epoch 12551/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 85.1288 - val_loss: 84.2004\n",
      "Epoch 12552/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 85.0963 - val_loss: 84.1789\n",
      "Epoch 12553/100000\n",
      "11/11 [==============================] - 0s 662us/step - loss: 85.0638 - val_loss: 84.1572\n",
      "Epoch 12554/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 85.0312 - val_loss: 84.1357\n",
      "Epoch 12555/100000\n",
      "11/11 [==============================] - 0s 764us/step - loss: 84.9988 - val_loss: 84.1140\n",
      "Epoch 12556/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 84.9663 - val_loss: 84.0926\n",
      "Epoch 12557/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 84.9340 - val_loss: 84.0709\n",
      "Epoch 12558/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 84.9015 - val_loss: 84.0495\n",
      "Epoch 12559/100000\n",
      "11/11 [==============================] - 0s 741us/step - loss: 84.8691 - val_loss: 84.0278\n",
      "Epoch 12560/100000\n",
      "11/11 [==============================] - 0s 919us/step - loss: 84.8368 - val_loss: 84.0064\n",
      "Epoch 12561/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 84.8044 - val_loss: 83.9847\n",
      "Epoch 12562/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 84.7721 - val_loss: 83.9632\n",
      "Epoch 12563/100000\n",
      "11/11 [==============================] - 0s 692us/step - loss: 84.7397 - val_loss: 83.9416\n",
      "Epoch 12564/100000\n",
      "11/11 [==============================] - 0s 903us/step - loss: 84.7074 - val_loss: 83.9201\n",
      "Epoch 12565/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 84.6752 - val_loss: 83.8986\n",
      "Epoch 12566/100000\n",
      "11/11 [==============================] - 0s 668us/step - loss: 84.6429 - val_loss: 83.8769\n",
      "Epoch 12567/100000\n",
      "11/11 [==============================] - 0s 896us/step - loss: 84.6106 - val_loss: 83.8556\n",
      "Epoch 12568/100000\n",
      "11/11 [==============================] - 0s 648us/step - loss: 84.5784 - val_loss: 83.8339\n",
      "Epoch 12569/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 84.5462 - val_loss: 83.8125\n",
      "Epoch 12570/100000\n",
      "11/11 [==============================] - 0s 615us/step - loss: 84.5141 - val_loss: 83.7908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12571/100000\n",
      "11/11 [==============================] - 0s 877us/step - loss: 84.4819 - val_loss: 83.7695\n",
      "Epoch 12572/100000\n",
      "11/11 [==============================] - 0s 644us/step - loss: 84.4497 - val_loss: 83.7478\n",
      "Epoch 12573/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 84.4176 - val_loss: 83.7264\n",
      "Epoch 12574/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 84.3855 - val_loss: 83.7048\n",
      "Epoch 12575/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 84.3533 - val_loss: 83.6833\n",
      "Epoch 12576/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 84.3213 - val_loss: 83.6618\n",
      "Epoch 12577/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 84.2892 - val_loss: 83.6403\n",
      "Epoch 12578/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 84.2572 - val_loss: 83.6187\n",
      "Epoch 12579/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 84.2252 - val_loss: 83.5972\n",
      "Epoch 12580/100000\n",
      "11/11 [==============================] - 0s 881us/step - loss: 84.1931 - val_loss: 83.5757\n",
      "Epoch 12581/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 84.1612 - val_loss: 83.5541\n",
      "Epoch 12582/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 84.1292 - val_loss: 83.5327\n",
      "Epoch 12583/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 84.0973 - val_loss: 83.5111\n",
      "Epoch 12584/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 84.0653 - val_loss: 83.4897\n",
      "Epoch 12585/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 84.0334 - val_loss: 83.4682\n",
      "Epoch 12586/100000\n",
      "11/11 [==============================] - 0s 806us/step - loss: 84.0016 - val_loss: 83.4466\n",
      "Epoch 12587/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 83.9696 - val_loss: 83.4251\n",
      "Epoch 12588/100000\n",
      "11/11 [==============================] - 0s 679us/step - loss: 83.9378 - val_loss: 83.4036\n",
      "Epoch 12589/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 83.9059 - val_loss: 83.3821\n",
      "Epoch 12590/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 83.8741 - val_loss: 83.3605\n",
      "Epoch 12591/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 83.8422 - val_loss: 83.3391\n",
      "Epoch 12592/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 83.8105 - val_loss: 83.3175\n",
      "Epoch 12593/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 83.7787 - val_loss: 83.2961\n",
      "Epoch 12594/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 83.7469 - val_loss: 83.2745\n",
      "Epoch 12595/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 83.7152 - val_loss: 83.2531\n",
      "Epoch 12596/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 83.6835 - val_loss: 83.2315\n",
      "Epoch 12597/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 83.6518 - val_loss: 83.2100\n",
      "Epoch 12598/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 83.6201 - val_loss: 83.1884\n",
      "Epoch 12599/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 83.5885 - val_loss: 83.1669\n",
      "Epoch 12600/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 83.5568 - val_loss: 83.1454\n",
      "Epoch 12601/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 83.5251 - val_loss: 83.1238\n",
      "Epoch 12602/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 83.4935 - val_loss: 83.1024\n",
      "Epoch 12603/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 83.4619 - val_loss: 83.0808\n",
      "Epoch 12604/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 83.4304 - val_loss: 83.0594\n",
      "Epoch 12605/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 83.3988 - val_loss: 83.0378\n",
      "Epoch 12606/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 83.3673 - val_loss: 83.0163\n",
      "Epoch 12607/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 83.3357 - val_loss: 82.9947\n",
      "Epoch 12608/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 83.3042 - val_loss: 82.9732\n",
      "Epoch 12609/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 83.2727 - val_loss: 82.9516\n",
      "Epoch 12610/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 83.2412 - val_loss: 82.9301\n",
      "Epoch 12611/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 83.2098 - val_loss: 82.9085\n",
      "Epoch 12612/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 83.1783 - val_loss: 82.8870\n",
      "Epoch 12613/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 83.1469 - val_loss: 82.8655\n",
      "Epoch 12614/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 83.1155 - val_loss: 82.8438\n",
      "Epoch 12615/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 83.0841 - val_loss: 82.8223\n",
      "Epoch 12616/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 83.0527 - val_loss: 82.8007\n",
      "Epoch 12617/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 83.0213 - val_loss: 82.7792\n",
      "Epoch 12618/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 82.9900 - val_loss: 82.7576\n",
      "Epoch 12619/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 82.9587 - val_loss: 82.7360\n",
      "Epoch 12620/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 82.9274 - val_loss: 82.7144\n",
      "Epoch 12621/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 82.8961 - val_loss: 82.6928\n",
      "Epoch 12622/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 82.8648 - val_loss: 82.6713\n",
      "Epoch 12623/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 82.8336 - val_loss: 82.6496\n",
      "Epoch 12624/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 82.8023 - val_loss: 82.6281\n",
      "Epoch 12625/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 82.7711 - val_loss: 82.6064\n",
      "Epoch 12626/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 82.7399 - val_loss: 82.5848\n",
      "Epoch 12627/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 82.7086 - val_loss: 82.5631\n",
      "Epoch 12628/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 82.6775 - val_loss: 82.5415\n",
      "Epoch 12629/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 82.6463 - val_loss: 82.5199\n",
      "Epoch 12630/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 82.6152 - val_loss: 82.4982\n",
      "Epoch 12631/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 82.5840 - val_loss: 82.4767\n",
      "Epoch 12632/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 82.5530 - val_loss: 82.4550\n",
      "Epoch 12633/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 82.5219 - val_loss: 82.4334\n",
      "Epoch 12634/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 82.4908 - val_loss: 82.4117\n",
      "Epoch 12635/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 82.4597 - val_loss: 82.3900\n",
      "Epoch 12636/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 82.4287 - val_loss: 82.3683\n",
      "Epoch 12637/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 82.3976 - val_loss: 82.3466\n",
      "Epoch 12638/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 82.3667 - val_loss: 82.3250\n",
      "Epoch 12639/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 82.3356 - val_loss: 82.3032\n",
      "Epoch 12640/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 82.3047 - val_loss: 82.2816\n",
      "Epoch 12641/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 82.2737 - val_loss: 82.2597\n",
      "Epoch 12642/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 82.2428 - val_loss: 82.2381\n",
      "Epoch 12643/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 82.2118 - val_loss: 82.2163\n",
      "Epoch 12644/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 82.1809 - val_loss: 82.1946\n",
      "Epoch 12645/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 82.1500 - val_loss: 82.1729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12646/100000\n",
      "11/11 [==============================] - 0s 670us/step - loss: 82.1191 - val_loss: 82.1511\n",
      "Epoch 12647/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 82.0882 - val_loss: 82.1294\n",
      "Epoch 12648/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 82.0574 - val_loss: 82.1076\n",
      "Epoch 12649/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 82.0265 - val_loss: 82.0859\n",
      "Epoch 12650/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 81.9957 - val_loss: 82.0640\n",
      "Epoch 12651/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 81.9649 - val_loss: 82.0423\n",
      "Epoch 12652/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 81.9341 - val_loss: 82.0204\n",
      "Epoch 12653/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 81.9033 - val_loss: 81.9987\n",
      "Epoch 12654/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 81.8726 - val_loss: 81.9769\n",
      "Epoch 12655/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 81.8418 - val_loss: 81.9550\n",
      "Epoch 12656/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 81.8111 - val_loss: 81.9332\n",
      "Epoch 12657/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 81.7804 - val_loss: 81.9113\n",
      "Epoch 12658/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 81.7497 - val_loss: 81.8895\n",
      "Epoch 12659/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 81.7190 - val_loss: 81.8676\n",
      "Epoch 12660/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 81.6883 - val_loss: 81.8456\n",
      "Epoch 12661/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 81.6576 - val_loss: 81.8238\n",
      "Epoch 12662/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 81.6270 - val_loss: 81.8018\n",
      "Epoch 12663/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 81.5964 - val_loss: 81.7800\n",
      "Epoch 12664/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 81.5658 - val_loss: 81.7579\n",
      "Epoch 12665/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 81.5352 - val_loss: 81.7361\n",
      "Epoch 12666/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 81.5046 - val_loss: 81.7141\n",
      "Epoch 12667/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 81.4741 - val_loss: 81.6922\n",
      "Epoch 12668/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 81.4435 - val_loss: 81.6701\n",
      "Epoch 12669/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 81.4130 - val_loss: 81.6481\n",
      "Epoch 12670/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 81.3824 - val_loss: 81.6262\n",
      "Epoch 12671/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 81.3519 - val_loss: 81.6041\n",
      "Epoch 12672/100000\n",
      "11/11 [==============================] - 0s 649us/step - loss: 81.3214 - val_loss: 81.5822\n",
      "Epoch 12673/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 81.2910 - val_loss: 81.5601\n",
      "Epoch 12674/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 81.2605 - val_loss: 81.5381\n",
      "Epoch 12675/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 81.2300 - val_loss: 81.5159\n",
      "Epoch 12676/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 81.1996 - val_loss: 81.4940\n",
      "Epoch 12677/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 81.1692 - val_loss: 81.4718\n",
      "Epoch 12678/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 81.1388 - val_loss: 81.4497\n",
      "Epoch 12679/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 81.1084 - val_loss: 81.4276\n",
      "Epoch 12680/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 81.0780 - val_loss: 81.4054\n",
      "Epoch 12681/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 81.0476 - val_loss: 81.3833\n",
      "Epoch 12682/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 81.0173 - val_loss: 81.3612\n",
      "Epoch 12683/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 80.9870 - val_loss: 81.3390\n",
      "Epoch 12684/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 80.9566 - val_loss: 81.3167\n",
      "Epoch 12685/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 80.9263 - val_loss: 81.2946\n",
      "Epoch 12686/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 80.8960 - val_loss: 81.2725\n",
      "Epoch 12687/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 80.8658 - val_loss: 81.2502\n",
      "Epoch 12688/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 80.8355 - val_loss: 81.2279\n",
      "Epoch 12689/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 80.8052 - val_loss: 81.2057\n",
      "Epoch 12690/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 80.7750 - val_loss: 81.1835\n",
      "Epoch 12691/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 80.7448 - val_loss: 81.1611\n",
      "Epoch 12692/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 80.7146 - val_loss: 81.1389\n",
      "Epoch 12693/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 80.6844 - val_loss: 81.1165\n",
      "Epoch 12694/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 80.6542 - val_loss: 81.0942\n",
      "Epoch 12695/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 80.6240 - val_loss: 81.0719\n",
      "Epoch 12696/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 80.5938 - val_loss: 81.0496\n",
      "Epoch 12697/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 80.5637 - val_loss: 81.0271\n",
      "Epoch 12698/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 80.5336 - val_loss: 81.0048\n",
      "Epoch 12699/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 80.5035 - val_loss: 80.9823\n",
      "Epoch 12700/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 80.4734 - val_loss: 80.9600\n",
      "Epoch 12701/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 80.4433 - val_loss: 80.9375\n",
      "Epoch 12702/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 80.4132 - val_loss: 80.9151\n",
      "Epoch 12703/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 80.3831 - val_loss: 80.8926\n",
      "Epoch 12704/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 80.3531 - val_loss: 80.8701\n",
      "Epoch 12705/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 80.3230 - val_loss: 80.8476\n",
      "Epoch 12706/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 80.2930 - val_loss: 80.8251\n",
      "Epoch 12707/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 80.2630 - val_loss: 80.8026\n",
      "Epoch 12708/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 80.2330 - val_loss: 80.7800\n",
      "Epoch 12709/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 80.2030 - val_loss: 80.7575\n",
      "Epoch 12710/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 80.1730 - val_loss: 80.7349\n",
      "Epoch 12711/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 80.1431 - val_loss: 80.7123\n",
      "Epoch 12712/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 80.1131 - val_loss: 80.6898\n",
      "Epoch 12713/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 80.0832 - val_loss: 80.6670\n",
      "Epoch 12714/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 80.0532 - val_loss: 80.6445\n",
      "Epoch 12715/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 80.0234 - val_loss: 80.6218\n",
      "Epoch 12716/100000\n",
      "11/11 [==============================] - 0s 639us/step - loss: 79.9935 - val_loss: 80.5992\n",
      "Epoch 12717/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 79.9636 - val_loss: 80.5764\n",
      "Epoch 12718/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 79.9337 - val_loss: 80.5538\n",
      "Epoch 12719/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 79.9039 - val_loss: 80.5310\n",
      "Epoch 12720/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 79.8740 - val_loss: 80.5083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12721/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 79.8442 - val_loss: 80.4856\n",
      "Epoch 12722/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 79.8143 - val_loss: 80.4628\n",
      "Epoch 12723/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 79.7845 - val_loss: 80.4401\n",
      "Epoch 12724/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 79.7547 - val_loss: 80.4172\n",
      "Epoch 12725/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 79.7249 - val_loss: 80.3945\n",
      "Epoch 12726/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 79.6952 - val_loss: 80.3716\n",
      "Epoch 12727/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 79.6654 - val_loss: 80.3487\n",
      "Epoch 12728/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 79.6356 - val_loss: 80.3259\n",
      "Epoch 12729/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 79.6059 - val_loss: 80.3030\n",
      "Epoch 12730/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 79.5762 - val_loss: 80.2802\n",
      "Epoch 12731/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 79.5465 - val_loss: 80.2572\n",
      "Epoch 12732/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 79.5168 - val_loss: 80.2344\n",
      "Epoch 12733/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 79.4871 - val_loss: 80.2114\n",
      "Epoch 12734/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 79.4574 - val_loss: 80.1885\n",
      "Epoch 12735/100000\n",
      "11/11 [==============================] - 0s 628us/step - loss: 79.4278 - val_loss: 80.1656\n",
      "Epoch 12736/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 79.3981 - val_loss: 80.1426\n",
      "Epoch 12737/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 79.3684 - val_loss: 80.1196\n",
      "Epoch 12738/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 79.3388 - val_loss: 80.0966\n",
      "Epoch 12739/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 79.3091 - val_loss: 80.0736\n",
      "Epoch 12740/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 79.2796 - val_loss: 80.0506\n",
      "Epoch 12741/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 79.2499 - val_loss: 80.0276\n",
      "Epoch 12742/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 79.2204 - val_loss: 80.0045\n",
      "Epoch 12743/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 79.1908 - val_loss: 79.9815\n",
      "Epoch 12744/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 79.1612 - val_loss: 79.9583\n",
      "Epoch 12745/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 79.1316 - val_loss: 79.9353\n",
      "Epoch 12746/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 79.1021 - val_loss: 79.9122\n",
      "Epoch 12747/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 79.0725 - val_loss: 79.8891\n",
      "Epoch 12748/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 79.0430 - val_loss: 79.8660\n",
      "Epoch 12749/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 79.0135 - val_loss: 79.8428\n",
      "Epoch 12750/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 78.9840 - val_loss: 79.8198\n",
      "Epoch 12751/100000\n",
      "11/11 [==============================] - 0s 618us/step - loss: 78.9545 - val_loss: 79.7966\n",
      "Epoch 12752/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 78.9251 - val_loss: 79.7735\n",
      "Epoch 12753/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 78.8956 - val_loss: 79.7503\n",
      "Epoch 12754/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 78.8661 - val_loss: 79.7271\n",
      "Epoch 12755/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 78.8366 - val_loss: 79.7040\n",
      "Epoch 12756/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 78.8072 - val_loss: 79.6808\n",
      "Epoch 12757/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 78.7778 - val_loss: 79.6577\n",
      "Epoch 12758/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 78.7484 - val_loss: 79.6344\n",
      "Epoch 12759/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 78.7190 - val_loss: 79.6113\n",
      "Epoch 12760/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 78.6896 - val_loss: 79.5881\n",
      "Epoch 12761/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 78.6602 - val_loss: 79.5649\n",
      "Epoch 12762/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 78.6308 - val_loss: 79.5417\n",
      "Epoch 12763/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 78.6015 - val_loss: 79.5185\n",
      "Epoch 12764/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 78.5721 - val_loss: 79.4953\n",
      "Epoch 12765/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 78.5428 - val_loss: 79.4721\n",
      "Epoch 12766/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 78.5135 - val_loss: 79.4489\n",
      "Epoch 12767/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 78.4842 - val_loss: 79.4257\n",
      "Epoch 12768/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 78.4549 - val_loss: 79.4025\n",
      "Epoch 12769/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 78.4255 - val_loss: 79.3793\n",
      "Epoch 12770/100000\n",
      "11/11 [==============================] - 0s 619us/step - loss: 78.3963 - val_loss: 79.3561\n",
      "Epoch 12771/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 78.3670 - val_loss: 79.3329\n",
      "Epoch 12772/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 78.3377 - val_loss: 79.3097\n",
      "Epoch 12773/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 78.3085 - val_loss: 79.2865\n",
      "Epoch 12774/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 78.2792 - val_loss: 79.2632\n",
      "Epoch 12775/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 78.2500 - val_loss: 79.2401\n",
      "Epoch 12776/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 78.2208 - val_loss: 79.2168\n",
      "Epoch 12777/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 78.1916 - val_loss: 79.1938\n",
      "Epoch 12778/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 78.1624 - val_loss: 79.1704\n",
      "Epoch 12779/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 78.1332 - val_loss: 79.1474\n",
      "Epoch 12780/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 78.1040 - val_loss: 79.1241\n",
      "Epoch 12781/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 78.0749 - val_loss: 79.1010\n",
      "Epoch 12782/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 78.0457 - val_loss: 79.0778\n",
      "Epoch 12783/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 78.0166 - val_loss: 79.0546\n",
      "Epoch 12784/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 77.9875 - val_loss: 79.0315\n",
      "Epoch 12785/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 77.9584 - val_loss: 79.0083\n",
      "Epoch 12786/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 77.9293 - val_loss: 78.9853\n",
      "Epoch 12787/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 77.9002 - val_loss: 78.9620\n",
      "Epoch 12788/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 77.8711 - val_loss: 78.9390\n",
      "Epoch 12789/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 77.8420 - val_loss: 78.9158\n",
      "Epoch 12790/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 77.8130 - val_loss: 78.8928\n",
      "Epoch 12791/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 77.7839 - val_loss: 78.8697\n",
      "Epoch 12792/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 77.7548 - val_loss: 78.8466\n",
      "Epoch 12793/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 77.7258 - val_loss: 78.8236\n",
      "Epoch 12794/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 77.6968 - val_loss: 78.8004\n",
      "Epoch 12795/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 77.6678 - val_loss: 78.7775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12796/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 77.6388 - val_loss: 78.7543\n",
      "Epoch 12797/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 77.6098 - val_loss: 78.7314\n",
      "Epoch 12798/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 77.5808 - val_loss: 78.7083\n",
      "Epoch 12799/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 77.5519 - val_loss: 78.6855\n",
      "Epoch 12800/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 77.5229 - val_loss: 78.6622\n",
      "Epoch 12801/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 77.4939 - val_loss: 78.6394\n",
      "Epoch 12802/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 77.4650 - val_loss: 78.6162\n",
      "Epoch 12803/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 77.4361 - val_loss: 78.5934\n",
      "Epoch 12804/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 77.4072 - val_loss: 78.5703\n",
      "Epoch 12805/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 77.3782 - val_loss: 78.5474\n",
      "Epoch 12806/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 77.3494 - val_loss: 78.5245\n",
      "Epoch 12807/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 77.3205 - val_loss: 78.5015\n",
      "Epoch 12808/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 77.2916 - val_loss: 78.4786\n",
      "Epoch 12809/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 77.2628 - val_loss: 78.4556\n",
      "Epoch 12810/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 77.2339 - val_loss: 78.4328\n",
      "Epoch 12811/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 77.2051 - val_loss: 78.4098\n",
      "Epoch 12812/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 77.1762 - val_loss: 78.3870\n",
      "Epoch 12813/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 77.1474 - val_loss: 78.3641\n",
      "Epoch 12814/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 77.1186 - val_loss: 78.3412\n",
      "Epoch 12815/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 77.0898 - val_loss: 78.3184\n",
      "Epoch 12816/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 77.0610 - val_loss: 78.2955\n",
      "Epoch 12817/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 77.0322 - val_loss: 78.2728\n",
      "Epoch 12818/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 77.0034 - val_loss: 78.2498\n",
      "Epoch 12819/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 76.9746 - val_loss: 78.2271\n",
      "Epoch 12820/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 76.9459 - val_loss: 78.2042\n",
      "Epoch 12821/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 76.9172 - val_loss: 78.1816\n",
      "Epoch 12822/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 76.8885 - val_loss: 78.1586\n",
      "Epoch 12823/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 76.8597 - val_loss: 78.1361\n",
      "Epoch 12824/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 76.8311 - val_loss: 78.1131\n",
      "Epoch 12825/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 76.8024 - val_loss: 78.0906\n",
      "Epoch 12826/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 76.7736 - val_loss: 78.0676\n",
      "Epoch 12827/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 76.7450 - val_loss: 78.0451\n",
      "Epoch 12828/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 76.7163 - val_loss: 78.0221\n",
      "Epoch 12829/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 76.6877 - val_loss: 77.9997\n",
      "Epoch 12830/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 76.6590 - val_loss: 77.9767\n",
      "Epoch 12831/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 76.6304 - val_loss: 77.9543\n",
      "Epoch 12832/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 76.6018 - val_loss: 77.9313\n",
      "Epoch 12833/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 76.5732 - val_loss: 77.9091\n",
      "Epoch 12834/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 76.5445 - val_loss: 77.8859\n",
      "Epoch 12835/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 76.5160 - val_loss: 77.8639\n",
      "Epoch 12836/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 76.4874 - val_loss: 77.8404\n",
      "Epoch 12837/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 76.4588 - val_loss: 77.8187\n",
      "Epoch 12838/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 76.4303 - val_loss: 77.7951\n",
      "Epoch 12839/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 76.4017 - val_loss: 77.7738\n",
      "Epoch 12840/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 76.3731 - val_loss: 77.7495\n",
      "Epoch 12841/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 76.3446 - val_loss: 77.7290\n",
      "Epoch 12842/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 76.3161 - val_loss: 77.7039\n",
      "Epoch 12843/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 76.2875 - val_loss: 77.6844\n",
      "Epoch 12844/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 76.2590 - val_loss: 77.6580\n",
      "Epoch 12845/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 76.2306 - val_loss: 77.6403\n",
      "Epoch 12846/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 76.2021 - val_loss: 77.6117\n",
      "Epoch 12847/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 76.1737 - val_loss: 77.5969\n",
      "Epoch 12848/100000\n",
      "11/11 [==============================] - 0s 695us/step - loss: 76.1453 - val_loss: 77.5646\n",
      "Epoch 12849/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 76.1168 - val_loss: 77.5546\n",
      "Epoch 12850/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 76.0883 - val_loss: 77.5163\n",
      "Epoch 12851/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 76.0599 - val_loss: 77.5140\n",
      "Epoch 12852/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 76.0316 - val_loss: 77.4668\n",
      "Epoch 12853/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 76.0032 - val_loss: 77.4748\n",
      "Epoch 12854/100000\n",
      "11/11 [==============================] - 0s 190us/step - loss: 75.9749 - val_loss: 77.4177\n",
      "Epoch 12855/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 75.9465 - val_loss: 77.4332\n",
      "Epoch 12856/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 75.9182 - val_loss: 77.3750\n",
      "Epoch 12857/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 75.8898 - val_loss: 77.3828\n",
      "Epoch 12858/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 75.8614 - val_loss: 77.3424\n",
      "Epoch 12859/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 75.8329 - val_loss: 77.3247\n",
      "Epoch 12860/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 75.8046 - val_loss: 77.3117\n",
      "Epoch 12861/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 75.7763 - val_loss: 77.2698\n",
      "Epoch 12862/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 75.7480 - val_loss: 77.2720\n",
      "Epoch 12863/100000\n",
      "11/11 [==============================] - 0s 197us/step - loss: 75.7197 - val_loss: 77.2263\n",
      "Epoch 12864/100000\n",
      "11/11 [==============================] - 0s 199us/step - loss: 75.6914 - val_loss: 77.2202\n",
      "Epoch 12865/100000\n",
      "11/11 [==============================] - 0s 202us/step - loss: 75.6631 - val_loss: 77.1919\n",
      "Epoch 12866/100000\n",
      "11/11 [==============================] - 0s 195us/step - loss: 75.6348 - val_loss: 77.1641\n",
      "Epoch 12867/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 75.6066 - val_loss: 77.1556\n",
      "Epoch 12868/100000\n",
      "11/11 [==============================] - 0s 179us/step - loss: 75.5784 - val_loss: 77.1150\n",
      "Epoch 12869/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 75.5501 - val_loss: 77.1094\n",
      "Epoch 12870/100000\n",
      "11/11 [==============================] - 0s 199us/step - loss: 75.5218 - val_loss: 77.0760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12871/100000\n",
      "11/11 [==============================] - 0s 198us/step - loss: 75.4936 - val_loss: 77.0565\n",
      "Epoch 12872/100000\n",
      "11/11 [==============================] - 0s 187us/step - loss: 75.4654 - val_loss: 77.0399\n",
      "Epoch 12873/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 75.4372 - val_loss: 77.0060\n",
      "Epoch 12874/100000\n",
      "11/11 [==============================] - 0s 194us/step - loss: 75.4090 - val_loss: 76.9977\n",
      "Epoch 12875/100000\n",
      "11/11 [==============================] - 0s 195us/step - loss: 75.3809 - val_loss: 76.9638\n",
      "Epoch 12876/100000\n",
      "11/11 [==============================] - 0s 178us/step - loss: 75.3528 - val_loss: 76.9486\n",
      "Epoch 12877/100000\n",
      "11/11 [==============================] - 0s 185us/step - loss: 75.3246 - val_loss: 76.9262\n",
      "Epoch 12878/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 75.2965 - val_loss: 76.8985\n",
      "Epoch 12879/100000\n",
      "11/11 [==============================] - 0s 193us/step - loss: 75.2683 - val_loss: 76.8861\n",
      "Epoch 12880/100000\n",
      "11/11 [==============================] - 0s 199us/step - loss: 75.2403 - val_loss: 76.8537\n",
      "Epoch 12881/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 75.2122 - val_loss: 76.8399\n",
      "Epoch 12882/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 75.1840 - val_loss: 76.8138\n",
      "Epoch 12883/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 75.1560 - val_loss: 76.7909\n",
      "Epoch 12884/100000\n",
      "11/11 [==============================] - 0s 191us/step - loss: 75.1279 - val_loss: 76.7739\n",
      "Epoch 12885/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 75.0999 - val_loss: 76.7442\n",
      "Epoch 12886/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 75.0718 - val_loss: 76.7299\n",
      "Epoch 12887/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 75.0438 - val_loss: 76.7018\n",
      "Epoch 12888/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 75.0158 - val_loss: 76.6824\n",
      "Epoch 12889/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 74.9878 - val_loss: 76.6612\n",
      "Epoch 12890/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 74.9598 - val_loss: 76.6352\n",
      "Epoch 12891/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 74.9318 - val_loss: 76.6188\n",
      "Epoch 12892/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 74.9038 - val_loss: 76.5910\n",
      "Epoch 12893/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 74.8759 - val_loss: 76.5734\n",
      "Epoch 12894/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 74.8479 - val_loss: 76.5493\n",
      "Epoch 12895/100000\n",
      "11/11 [==============================] - 0s 187us/step - loss: 74.8200 - val_loss: 76.5269\n",
      "Epoch 12896/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 74.7921 - val_loss: 76.5077\n",
      "Epoch 12897/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 74.7641 - val_loss: 76.4817\n",
      "Epoch 12898/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 74.7362 - val_loss: 76.4643\n",
      "Epoch 12899/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 74.7083 - val_loss: 76.4386\n",
      "Epoch 12900/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 74.6804 - val_loss: 76.4191\n",
      "Epoch 12901/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 74.6525 - val_loss: 76.3968\n",
      "Epoch 12902/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 74.6246 - val_loss: 76.3736\n",
      "Epoch 12903/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 74.5968 - val_loss: 76.3544\n",
      "Epoch 12904/100000\n",
      "11/11 [==============================] - 0s 589us/step - loss: 74.5689 - val_loss: 76.3293\n",
      "Epoch 12905/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 74.5411 - val_loss: 76.3107\n",
      "Epoch 12906/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 74.5133 - val_loss: 76.2863\n",
      "Epoch 12907/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 74.4854 - val_loss: 76.2658\n",
      "Epoch 12908/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 74.4577 - val_loss: 76.2441\n",
      "Epoch 12909/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 74.4299 - val_loss: 76.2208\n",
      "Epoch 12910/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 74.4020 - val_loss: 76.2013\n",
      "Epoch 12911/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 74.3743 - val_loss: 76.1769\n",
      "Epoch 12912/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 74.3466 - val_loss: 76.1575\n",
      "Epoch 12913/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 74.3188 - val_loss: 76.1339\n",
      "Epoch 12914/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 74.2911 - val_loss: 76.1132\n",
      "Epoch 12915/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 74.2633 - val_loss: 76.0913\n",
      "Epoch 12916/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 74.2356 - val_loss: 76.0688\n",
      "Epoch 12917/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 74.2079 - val_loss: 76.0485\n",
      "Epoch 12918/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 74.1802 - val_loss: 76.0250\n",
      "Epoch 12919/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 74.1525 - val_loss: 76.0051\n",
      "Epoch 12920/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 74.1248 - val_loss: 75.9819\n",
      "Epoch 12921/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 74.0971 - val_loss: 75.9613\n",
      "Epoch 12922/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 74.0695 - val_loss: 75.9392\n",
      "Epoch 12923/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 74.0418 - val_loss: 75.9175\n",
      "Epoch 12924/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 74.0142 - val_loss: 75.8965\n",
      "Epoch 12925/100000\n",
      "11/11 [==============================] - 0s 581us/step - loss: 73.9866 - val_loss: 75.8738\n",
      "Epoch 12926/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 73.9590 - val_loss: 75.8534\n",
      "Epoch 12927/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 73.9313 - val_loss: 75.8306\n",
      "Epoch 12928/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 73.9038 - val_loss: 75.8101\n",
      "Epoch 12929/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 73.8762 - val_loss: 75.7876\n",
      "Epoch 12930/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 73.8487 - val_loss: 75.7667\n",
      "Epoch 12931/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 73.8211 - val_loss: 75.7448\n",
      "Epoch 12932/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 73.7935 - val_loss: 75.7232\n",
      "Epoch 12933/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 73.7660 - val_loss: 75.7020\n",
      "Epoch 12934/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 73.7384 - val_loss: 75.6798\n",
      "Epoch 12935/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 73.7109 - val_loss: 75.6591\n",
      "Epoch 12936/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 73.6834 - val_loss: 75.6368\n",
      "Epoch 12937/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 73.6559 - val_loss: 75.6161\n",
      "Epoch 12938/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 73.6284 - val_loss: 75.5938\n",
      "Epoch 12939/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 73.6010 - val_loss: 75.5730\n",
      "Epoch 12940/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 73.5735 - val_loss: 75.5510\n",
      "Epoch 12941/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 73.5460 - val_loss: 75.5299\n",
      "Epoch 12942/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 73.5186 - val_loss: 75.5083\n",
      "Epoch 12943/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 73.4912 - val_loss: 75.4869\n",
      "Epoch 12944/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 73.4638 - val_loss: 75.4656\n",
      "Epoch 12945/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 73.4363 - val_loss: 75.4440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12946/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 73.4089 - val_loss: 75.4228\n",
      "Epoch 12947/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 73.3815 - val_loss: 75.4011\n",
      "Epoch 12948/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 73.3541 - val_loss: 75.3801\n",
      "Epoch 12949/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 73.3268 - val_loss: 75.3584\n",
      "Epoch 12950/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 73.2994 - val_loss: 75.3373\n",
      "Epoch 12951/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 73.2721 - val_loss: 75.3158\n",
      "Epoch 12952/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 73.2448 - val_loss: 75.2946\n",
      "Epoch 12953/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 73.2174 - val_loss: 75.2731\n",
      "Epoch 12954/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 73.1901 - val_loss: 75.2519\n",
      "Epoch 12955/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 73.1628 - val_loss: 75.2305\n",
      "Epoch 12956/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 73.1355 - val_loss: 75.2093\n",
      "Epoch 12957/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 73.1082 - val_loss: 75.1879\n",
      "Epoch 12958/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 73.0809 - val_loss: 75.1666\n",
      "Epoch 12959/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 73.0537 - val_loss: 75.1455\n",
      "Epoch 12960/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 73.0265 - val_loss: 75.1241\n",
      "Epoch 12961/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 72.9992 - val_loss: 75.1030\n",
      "Epoch 12962/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 72.9719 - val_loss: 75.0816\n",
      "Epoch 12963/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 72.9447 - val_loss: 75.0606\n",
      "Epoch 12964/100000\n",
      "11/11 [==============================] - 0s 589us/step - loss: 72.9175 - val_loss: 75.0391\n",
      "Epoch 12965/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 72.8903 - val_loss: 75.0184\n",
      "Epoch 12966/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 72.8631 - val_loss: 74.9966\n",
      "Epoch 12967/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 72.8360 - val_loss: 74.9762\n",
      "Epoch 12968/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 72.8088 - val_loss: 74.9542\n",
      "Epoch 12969/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 72.7817 - val_loss: 74.9340\n",
      "Epoch 12970/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 72.7545 - val_loss: 74.9117\n",
      "Epoch 12971/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 72.7274 - val_loss: 74.8920\n",
      "Epoch 12972/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 72.7003 - val_loss: 74.8691\n",
      "Epoch 12973/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 72.6732 - val_loss: 74.8502\n",
      "Epoch 12974/100000\n",
      "11/11 [==============================] - 0s 667us/step - loss: 72.6461 - val_loss: 74.8264\n",
      "Epoch 12975/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 72.6190 - val_loss: 74.8087\n",
      "Epoch 12976/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 72.5919 - val_loss: 74.7834\n",
      "Epoch 12977/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 72.5649 - val_loss: 74.7677\n",
      "Epoch 12978/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 72.5378 - val_loss: 74.7397\n",
      "Epoch 12979/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 72.5108 - val_loss: 74.7277\n",
      "Epoch 12980/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 72.4837 - val_loss: 74.6950\n",
      "Epoch 12981/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 72.4567 - val_loss: 74.6893\n",
      "Epoch 12982/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 72.4298 - val_loss: 74.6485\n",
      "Epoch 12983/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 72.4028 - val_loss: 74.6533\n",
      "Epoch 12984/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 72.3758 - val_loss: 74.5993\n",
      "Epoch 12985/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 72.3489 - val_loss: 74.6205\n",
      "Epoch 12986/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 72.3220 - val_loss: 74.5485\n",
      "Epoch 12987/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 72.2951 - val_loss: 74.5868\n",
      "Epoch 12988/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 72.2682 - val_loss: 74.5051\n",
      "Epoch 12989/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 72.2413 - val_loss: 74.5394\n",
      "Epoch 12990/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 72.2142 - val_loss: 74.4804\n",
      "Epoch 12991/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 72.1871 - val_loss: 74.4745\n",
      "Epoch 12992/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 72.1601 - val_loss: 74.4639\n",
      "Epoch 12993/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 72.1333 - val_loss: 74.4127\n",
      "Epoch 12994/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 72.1065 - val_loss: 74.4323\n",
      "Epoch 12995/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 72.0797 - val_loss: 74.3727\n",
      "Epoch 12996/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 72.0527 - val_loss: 74.3770\n",
      "Epoch 12997/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 72.0258 - val_loss: 74.3502\n",
      "Epoch 12998/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 71.9989 - val_loss: 74.3153\n",
      "Epoch 12999/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 71.9721 - val_loss: 74.3214\n",
      "Epoch 13000/100000\n",
      "11/11 [==============================] - 0s 664us/step - loss: 71.9453 - val_loss: 74.2698\n",
      "Epoch 13001/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 71.9185 - val_loss: 74.2727\n",
      "Epoch 13002/100000\n",
      "11/11 [==============================] - 0s 618us/step - loss: 71.8916 - val_loss: 74.2422\n",
      "Epoch 13003/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 71.8648 - val_loss: 74.2154\n",
      "Epoch 13004/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 71.8381 - val_loss: 74.2133\n",
      "Epoch 13005/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 71.8113 - val_loss: 74.1692\n",
      "Epoch 13006/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 71.7846 - val_loss: 74.1690\n",
      "Epoch 13007/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 71.7578 - val_loss: 74.1378\n",
      "Epoch 13008/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 71.7310 - val_loss: 74.1156\n",
      "Epoch 13009/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 71.7043 - val_loss: 74.1074\n",
      "Epoch 13010/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 71.6776 - val_loss: 74.0689\n",
      "Epoch 13011/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 71.6509 - val_loss: 74.0653\n",
      "Epoch 13012/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 71.6242 - val_loss: 74.0341\n",
      "Epoch 13013/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 71.5975 - val_loss: 74.0147\n",
      "Epoch 13014/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 71.5708 - val_loss: 74.0017\n",
      "Epoch 13015/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 71.5442 - val_loss: 73.9678\n",
      "Epoch 13016/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 71.5175 - val_loss: 73.9611\n",
      "Epoch 13017/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 71.4909 - val_loss: 73.9301\n",
      "Epoch 13018/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 71.4642 - val_loss: 73.9130\n",
      "Epoch 13019/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 71.4377 - val_loss: 73.8960\n",
      "Epoch 13020/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 71.4111 - val_loss: 73.8664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13021/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 71.3845 - val_loss: 73.8570\n",
      "Epoch 13022/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 71.3579 - val_loss: 73.8267\n",
      "Epoch 13023/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 71.3313 - val_loss: 73.8118\n",
      "Epoch 13024/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 71.3048 - val_loss: 73.7912\n",
      "Epoch 13025/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 71.2782 - val_loss: 73.7659\n",
      "Epoch 13026/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 71.2517 - val_loss: 73.7534\n",
      "Epoch 13027/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 71.2251 - val_loss: 73.7244\n",
      "Epoch 13028/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 71.1986 - val_loss: 73.7105\n",
      "Epoch 13029/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 71.1721 - val_loss: 73.6872\n",
      "Epoch 13030/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 71.1456 - val_loss: 73.6656\n",
      "Epoch 13031/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 71.1191 - val_loss: 73.6496\n",
      "Epoch 13032/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 71.0926 - val_loss: 73.6227\n",
      "Epoch 13033/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 71.0661 - val_loss: 73.6087\n",
      "Epoch 13034/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 71.0396 - val_loss: 73.5833\n",
      "Epoch 13035/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 71.0132 - val_loss: 73.5651\n",
      "Epoch 13036/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 70.9867 - val_loss: 73.5454\n",
      "Epoch 13037/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 70.9603 - val_loss: 73.5217\n",
      "Epoch 13038/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 70.9338 - val_loss: 73.5060\n",
      "Epoch 13039/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 70.9074 - val_loss: 73.4807\n",
      "Epoch 13040/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 70.8810 - val_loss: 73.4643\n",
      "Epoch 13041/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 70.8546 - val_loss: 73.4417\n",
      "Epoch 13042/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 70.8283 - val_loss: 73.4215\n",
      "Epoch 13043/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 70.8019 - val_loss: 73.4029\n",
      "Epoch 13044/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 70.7755 - val_loss: 73.3796\n",
      "Epoch 13045/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 70.7492 - val_loss: 73.3628\n",
      "Epoch 13046/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 70.7228 - val_loss: 73.3392\n",
      "Epoch 13047/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 70.6965 - val_loss: 73.3213\n",
      "Epoch 13048/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 70.6702 - val_loss: 73.3000\n",
      "Epoch 13049/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 70.6439 - val_loss: 73.2795\n",
      "Epoch 13050/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 70.6176 - val_loss: 73.2606\n",
      "Epoch 13051/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 70.5913 - val_loss: 73.2381\n",
      "Epoch 13052/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 70.5650 - val_loss: 73.2203\n",
      "Epoch 13053/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 70.5388 - val_loss: 73.1978\n",
      "Epoch 13054/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 70.5126 - val_loss: 73.1793\n",
      "Epoch 13055/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 70.4863 - val_loss: 73.1581\n",
      "Epoch 13056/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 70.4601 - val_loss: 73.1381\n",
      "Epoch 13057/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 70.4339 - val_loss: 73.1186\n",
      "Epoch 13058/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 70.4077 - val_loss: 73.0971\n",
      "Epoch 13059/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 70.3815 - val_loss: 73.0787\n",
      "Epoch 13060/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 70.3553 - val_loss: 73.0567\n",
      "Epoch 13061/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 70.3291 - val_loss: 73.0382\n",
      "Epoch 13062/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 70.3030 - val_loss: 73.0168\n",
      "Epoch 13063/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 70.2768 - val_loss: 72.9975\n",
      "Epoch 13064/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 70.2506 - val_loss: 72.9772\n",
      "Epoch 13065/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 70.2246 - val_loss: 72.9568\n",
      "Epoch 13066/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 70.1984 - val_loss: 72.9375\n",
      "Epoch 13067/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 70.1723 - val_loss: 72.9163\n",
      "Epoch 13068/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 70.1462 - val_loss: 72.8975\n",
      "Epoch 13069/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 70.1201 - val_loss: 72.8763\n",
      "Epoch 13070/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 70.0940 - val_loss: 72.8571\n",
      "Epoch 13071/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 70.0679 - val_loss: 72.8364\n",
      "Epoch 13072/100000\n",
      "11/11 [==============================] - 0s 626us/step - loss: 70.0419 - val_loss: 72.8168\n",
      "Epoch 13073/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 70.0159 - val_loss: 72.7966\n",
      "Epoch 13074/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 69.9898 - val_loss: 72.7765\n",
      "Epoch 13075/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 69.9637 - val_loss: 72.7568\n",
      "Epoch 13076/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 69.9377 - val_loss: 72.7364\n",
      "Epoch 13077/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 69.9117 - val_loss: 72.7170\n",
      "Epoch 13078/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 69.8856 - val_loss: 72.6963\n",
      "Epoch 13079/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 69.8597 - val_loss: 72.6772\n",
      "Epoch 13080/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 69.8337 - val_loss: 72.6564\n",
      "Epoch 13081/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 69.8077 - val_loss: 72.6373\n",
      "Epoch 13082/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 69.7817 - val_loss: 72.6167\n",
      "Epoch 13083/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 69.7558 - val_loss: 72.5975\n",
      "Epoch 13084/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 69.7299 - val_loss: 72.5770\n",
      "Epoch 13085/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 69.7039 - val_loss: 72.5576\n",
      "Epoch 13086/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 69.6780 - val_loss: 72.5375\n",
      "Epoch 13087/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 69.6521 - val_loss: 72.5177\n",
      "Epoch 13088/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 69.6263 - val_loss: 72.4979\n",
      "Epoch 13089/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 69.6004 - val_loss: 72.4780\n",
      "Epoch 13090/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 69.5745 - val_loss: 72.4584\n",
      "Epoch 13091/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 69.5487 - val_loss: 72.4383\n",
      "Epoch 13092/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 69.5228 - val_loss: 72.4189\n",
      "Epoch 13093/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 69.4970 - val_loss: 72.3988\n",
      "Epoch 13094/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 69.4711 - val_loss: 72.3793\n",
      "Epoch 13095/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 69.4453 - val_loss: 72.3593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13096/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 69.4195 - val_loss: 72.3398\n",
      "Epoch 13097/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 69.3937 - val_loss: 72.3199\n",
      "Epoch 13098/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 69.3680 - val_loss: 72.3003\n",
      "Epoch 13099/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 69.3422 - val_loss: 72.2804\n",
      "Epoch 13100/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 69.3165 - val_loss: 72.2610\n",
      "Epoch 13101/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 69.2906 - val_loss: 72.2409\n",
      "Epoch 13102/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 69.2648 - val_loss: 72.2217\n",
      "Epoch 13103/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 69.2391 - val_loss: 72.2014\n",
      "Epoch 13104/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 69.2134 - val_loss: 72.1827\n",
      "Epoch 13105/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 69.1877 - val_loss: 72.1618\n",
      "Epoch 13106/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 69.1620 - val_loss: 72.1437\n",
      "Epoch 13107/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 69.1363 - val_loss: 72.1222\n",
      "Epoch 13108/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 69.1106 - val_loss: 72.1051\n",
      "Epoch 13109/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 69.0849 - val_loss: 72.0821\n",
      "Epoch 13110/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 69.0593 - val_loss: 72.0672\n",
      "Epoch 13111/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 69.0336 - val_loss: 72.0413\n",
      "Epoch 13112/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 69.0080 - val_loss: 72.0305\n",
      "Epoch 13113/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 68.9824 - val_loss: 71.9989\n",
      "Epoch 13114/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 68.9567 - val_loss: 71.9960\n",
      "Epoch 13115/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 68.9311 - val_loss: 71.9534\n",
      "Epoch 13116/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 68.9055 - val_loss: 71.9660\n",
      "Epoch 13117/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 68.8800 - val_loss: 71.9024\n",
      "Epoch 13118/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 68.8545 - val_loss: 71.9434\n",
      "Epoch 13119/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 68.8290 - val_loss: 71.8452\n",
      "Epoch 13120/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 68.8037 - val_loss: 71.9232\n",
      "Epoch 13121/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 68.7784 - val_loss: 71.7993\n",
      "Epoch 13122/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 68.7528 - val_loss: 71.8736\n",
      "Epoch 13123/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 68.7270 - val_loss: 71.7969\n",
      "Epoch 13124/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 68.7011 - val_loss: 71.7846\n",
      "Epoch 13125/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 68.6755 - val_loss: 71.8067\n",
      "Epoch 13126/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 68.6503 - val_loss: 71.7178\n",
      "Epoch 13127/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 68.6250 - val_loss: 71.7661\n",
      "Epoch 13128/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 68.5993 - val_loss: 71.7083\n",
      "Epoch 13129/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 68.5737 - val_loss: 71.6831\n",
      "Epoch 13130/100000\n",
      "11/11 [==============================] - 0s 644us/step - loss: 68.5483 - val_loss: 71.7059\n",
      "Epoch 13131/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 68.5230 - val_loss: 71.6299\n",
      "Epoch 13132/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 68.4975 - val_loss: 71.6524\n",
      "Epoch 13133/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 68.4719 - val_loss: 71.6238\n",
      "Epoch 13134/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 68.4465 - val_loss: 71.5793\n",
      "Epoch 13135/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 68.4212 - val_loss: 71.6039\n",
      "Epoch 13136/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 68.3959 - val_loss: 71.5461\n",
      "Epoch 13137/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 68.3704 - val_loss: 71.5416\n",
      "Epoch 13138/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 68.3450 - val_loss: 71.5374\n",
      "Epoch 13139/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 68.3197 - val_loss: 71.4849\n",
      "Epoch 13140/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 68.2944 - val_loss: 71.4994\n",
      "Epoch 13141/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 68.2690 - val_loss: 71.4641\n",
      "Epoch 13142/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 68.2436 - val_loss: 71.4375\n",
      "Epoch 13143/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 68.2183 - val_loss: 71.4438\n",
      "Epoch 13144/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 68.1930 - val_loss: 71.3962\n",
      "Epoch 13145/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 68.1677 - val_loss: 71.3937\n",
      "Epoch 13146/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 68.1424 - val_loss: 71.3770\n",
      "Epoch 13147/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 68.1171 - val_loss: 71.3392\n",
      "Epoch 13148/100000\n",
      "11/11 [==============================] - 0s 588us/step - loss: 68.0918 - val_loss: 71.3436\n",
      "Epoch 13149/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 68.0666 - val_loss: 71.3080\n",
      "Epoch 13150/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 68.0413 - val_loss: 71.2903\n",
      "Epoch 13151/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 68.0161 - val_loss: 71.2838\n",
      "Epoch 13152/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 67.9908 - val_loss: 71.2455\n",
      "Epoch 13153/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 67.9656 - val_loss: 71.2421\n",
      "Epoch 13154/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 67.9404 - val_loss: 71.2184\n",
      "Epoch 13155/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 67.9152 - val_loss: 71.1920\n",
      "Epoch 13156/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 67.8901 - val_loss: 71.1879\n",
      "Epoch 13157/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 67.8649 - val_loss: 71.1546\n",
      "Epoch 13158/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 67.8397 - val_loss: 71.1428\n",
      "Epoch 13159/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 67.8146 - val_loss: 71.1267\n",
      "Epoch 13160/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 67.7894 - val_loss: 71.0974\n",
      "Epoch 13161/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 67.7643 - val_loss: 71.0909\n",
      "Epoch 13162/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 67.7392 - val_loss: 71.0635\n",
      "Epoch 13163/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 67.7141 - val_loss: 71.0455\n",
      "Epoch 13164/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 67.6890 - val_loss: 71.0328\n",
      "Epoch 13165/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 67.6639 - val_loss: 71.0038\n",
      "Epoch 13166/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 67.6388 - val_loss: 70.9939\n",
      "Epoch 13167/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 67.6138 - val_loss: 70.9708\n",
      "Epoch 13168/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 67.5887 - val_loss: 70.9498\n",
      "Epoch 13169/100000\n",
      "11/11 [==============================] - 0s 694us/step - loss: 67.5636 - val_loss: 70.9377\n",
      "Epoch 13170/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 67.5386 - val_loss: 70.9106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13171/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 67.5136 - val_loss: 70.8977\n",
      "Epoch 13172/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 67.4886 - val_loss: 70.8775\n",
      "Epoch 13173/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 67.4636 - val_loss: 70.8554\n",
      "Epoch 13174/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 67.4385 - val_loss: 70.8428\n",
      "Epoch 13175/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 67.4136 - val_loss: 70.8177\n",
      "Epoch 13176/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 67.3886 - val_loss: 70.8028\n",
      "Epoch 13177/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 67.3636 - val_loss: 70.7839\n",
      "Epoch 13178/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 67.3387 - val_loss: 70.7619\n",
      "Epoch 13179/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 67.3137 - val_loss: 70.7483\n",
      "Epoch 13180/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 67.2888 - val_loss: 70.7247\n",
      "Epoch 13181/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 67.2639 - val_loss: 70.7088\n",
      "Epoch 13182/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 67.2390 - val_loss: 70.6901\n",
      "Epoch 13183/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 67.2141 - val_loss: 70.6688\n",
      "Epoch 13184/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 67.1891 - val_loss: 70.6540\n",
      "Epoch 13185/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 67.1642 - val_loss: 70.6315\n",
      "Epoch 13186/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 67.1393 - val_loss: 70.6151\n",
      "Epoch 13187/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 67.1145 - val_loss: 70.5963\n",
      "Epoch 13188/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 67.0897 - val_loss: 70.5758\n",
      "Epoch 13189/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 67.0648 - val_loss: 70.5602\n",
      "Epoch 13190/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 67.0400 - val_loss: 70.5386\n",
      "Epoch 13191/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 67.0152 - val_loss: 70.5221\n",
      "Epoch 13192/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 66.9904 - val_loss: 70.5030\n",
      "Epoch 13193/100000\n",
      "11/11 [==============================] - 0s 801us/step - loss: 66.9656 - val_loss: 70.4834\n",
      "Epoch 13194/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 66.9408 - val_loss: 70.4669\n",
      "Epoch 13195/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 66.9160 - val_loss: 70.4460\n",
      "Epoch 13196/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 66.8913 - val_loss: 70.4296\n",
      "Epoch 13197/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 66.8665 - val_loss: 70.4099\n",
      "Epoch 13198/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 66.8418 - val_loss: 70.3914\n",
      "Epoch 13199/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 66.8170 - val_loss: 70.3740\n",
      "Epoch 13200/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 66.7923 - val_loss: 70.3538\n",
      "Epoch 13201/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 66.7676 - val_loss: 70.3371\n",
      "Epoch 13202/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 66.7429 - val_loss: 70.3172\n",
      "Epoch 13203/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 66.7182 - val_loss: 70.2993\n",
      "Epoch 13204/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 66.6935 - val_loss: 70.2811\n",
      "Epoch 13205/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 66.6688 - val_loss: 70.2618\n",
      "Epoch 13206/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 66.6441 - val_loss: 70.2447\n",
      "Epoch 13207/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 66.6195 - val_loss: 70.2249\n",
      "Epoch 13208/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 66.5948 - val_loss: 70.2076\n",
      "Epoch 13209/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 66.5702 - val_loss: 70.1888\n",
      "Epoch 13210/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 66.5456 - val_loss: 70.1702\n",
      "Epoch 13211/100000\n",
      "11/11 [==============================] - 0s 765us/step - loss: 66.5210 - val_loss: 70.1526\n",
      "Epoch 13212/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 66.4964 - val_loss: 70.1333\n",
      "Epoch 13213/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 66.4718 - val_loss: 70.1160\n",
      "Epoch 13214/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 66.4472 - val_loss: 70.0969\n",
      "Epoch 13215/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 66.4226 - val_loss: 70.0791\n",
      "Epoch 13216/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 66.3981 - val_loss: 70.0606\n",
      "Epoch 13217/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 66.3735 - val_loss: 70.0422\n",
      "Epoch 13218/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 66.3490 - val_loss: 70.0243\n",
      "Epoch 13219/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 66.3244 - val_loss: 70.0055\n",
      "Epoch 13220/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 66.2999 - val_loss: 69.9878\n",
      "Epoch 13221/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 66.2754 - val_loss: 69.9693\n",
      "Epoch 13222/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 66.2509 - val_loss: 69.9512\n",
      "Epoch 13223/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 66.2264 - val_loss: 69.9330\n",
      "Epoch 13224/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 66.2019 - val_loss: 69.9146\n",
      "Epoch 13225/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 66.1774 - val_loss: 69.8968\n",
      "Epoch 13226/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 66.1530 - val_loss: 69.8783\n",
      "Epoch 13227/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 66.1286 - val_loss: 69.8606\n",
      "Epoch 13228/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 66.1041 - val_loss: 69.8420\n",
      "Epoch 13229/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 66.0797 - val_loss: 69.8243\n",
      "Epoch 13230/100000\n",
      "11/11 [==============================] - 0s 750us/step - loss: 66.0553 - val_loss: 69.8060\n",
      "Epoch 13231/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 66.0309 - val_loss: 69.7879\n",
      "Epoch 13232/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 66.0065 - val_loss: 69.7700\n",
      "Epoch 13233/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 65.9821 - val_loss: 69.7516\n",
      "Epoch 13234/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 65.9577 - val_loss: 69.7339\n",
      "Epoch 13235/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 65.9333 - val_loss: 69.7155\n",
      "Epoch 13236/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 65.9090 - val_loss: 69.6979\n",
      "Epoch 13237/100000\n",
      "11/11 [==============================] - 0s 593us/step - loss: 65.8847 - val_loss: 69.6796\n",
      "Epoch 13238/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 65.8603 - val_loss: 69.6618\n",
      "Epoch 13239/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 65.8360 - val_loss: 69.6437\n",
      "Epoch 13240/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 65.8117 - val_loss: 69.6257\n",
      "Epoch 13241/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 65.7874 - val_loss: 69.6078\n",
      "Epoch 13242/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 65.7631 - val_loss: 69.5898\n",
      "Epoch 13243/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 65.7389 - val_loss: 69.5720\n",
      "Epoch 13244/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 65.7145 - val_loss: 69.5539\n",
      "Epoch 13245/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 65.6903 - val_loss: 69.5363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13246/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 65.6660 - val_loss: 69.5180\n",
      "Epoch 13247/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 65.6417 - val_loss: 69.5005\n",
      "Epoch 13248/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 65.6175 - val_loss: 69.4822\n",
      "Epoch 13249/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 65.5933 - val_loss: 69.4649\n",
      "Epoch 13250/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 65.5691 - val_loss: 69.4464\n",
      "Epoch 13251/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 65.5449 - val_loss: 69.4293\n",
      "Epoch 13252/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 65.5207 - val_loss: 69.4107\n",
      "Epoch 13253/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 65.4965 - val_loss: 69.3938\n",
      "Epoch 13254/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 65.4724 - val_loss: 69.3750\n",
      "Epoch 13255/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 65.4482 - val_loss: 69.3583\n",
      "Epoch 13256/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 65.4240 - val_loss: 69.3393\n",
      "Epoch 13257/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 65.3999 - val_loss: 69.3230\n",
      "Epoch 13258/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 65.3758 - val_loss: 69.3037\n",
      "Epoch 13259/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 65.3517 - val_loss: 69.2877\n",
      "Epoch 13260/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 65.3275 - val_loss: 69.2681\n",
      "Epoch 13261/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 65.3035 - val_loss: 69.2526\n",
      "Epoch 13262/100000\n",
      "11/11 [==============================] - 0s 593us/step - loss: 65.2794 - val_loss: 69.2323\n",
      "Epoch 13263/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 65.2553 - val_loss: 69.2176\n",
      "Epoch 13264/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 65.2312 - val_loss: 69.1965\n",
      "Epoch 13265/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 65.2072 - val_loss: 69.1829\n",
      "Epoch 13266/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 65.1832 - val_loss: 69.1605\n",
      "Epoch 13267/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 65.1591 - val_loss: 69.1486\n",
      "Epoch 13268/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 65.1351 - val_loss: 69.1239\n",
      "Epoch 13269/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 65.1111 - val_loss: 69.1151\n",
      "Epoch 13270/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 65.0870 - val_loss: 69.0866\n",
      "Epoch 13271/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 65.0631 - val_loss: 69.0829\n",
      "Epoch 13272/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 65.0391 - val_loss: 69.0477\n",
      "Epoch 13273/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 65.0151 - val_loss: 69.0528\n",
      "Epoch 13274/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 64.9911 - val_loss: 69.0062\n",
      "Epoch 13275/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 64.9672 - val_loss: 69.0264\n",
      "Epoch 13276/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 64.9433 - val_loss: 68.9604\n",
      "Epoch 13277/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 64.9194 - val_loss: 69.0049\n",
      "Epoch 13278/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 64.8956 - val_loss: 68.9108\n",
      "Epoch 13279/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 64.8718 - val_loss: 68.9851\n",
      "Epoch 13280/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 64.8480 - val_loss: 68.8663\n",
      "Epoch 13281/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 64.8242 - val_loss: 68.9503\n",
      "Epoch 13282/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 64.8002 - val_loss: 68.8481\n",
      "Epoch 13283/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 64.7762 - val_loss: 68.8835\n",
      "Epoch 13284/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 64.7520 - val_loss: 68.8543\n",
      "Epoch 13285/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 64.7282 - val_loss: 68.8086\n",
      "Epoch 13286/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 64.7044 - val_loss: 68.8485\n",
      "Epoch 13287/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 64.6807 - val_loss: 68.7621\n",
      "Epoch 13288/100000\n",
      "11/11 [==============================] - 0s 615us/step - loss: 64.6569 - val_loss: 68.8048\n",
      "Epoch 13289/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 64.6330 - val_loss: 68.7521\n",
      "Epoch 13290/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 64.6091 - val_loss: 68.7364\n",
      "Epoch 13291/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 64.5853 - val_loss: 68.7478\n",
      "Epoch 13292/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 64.5616 - val_loss: 68.6827\n",
      "Epoch 13293/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 64.5379 - val_loss: 68.7154\n",
      "Epoch 13294/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 64.5141 - val_loss: 68.6620\n",
      "Epoch 13295/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 64.4903 - val_loss: 68.6570\n",
      "Epoch 13296/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 64.4665 - val_loss: 68.6534\n",
      "Epoch 13297/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 64.4428 - val_loss: 68.6041\n",
      "Epoch 13298/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 64.4192 - val_loss: 68.6258\n",
      "Epoch 13299/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 64.3954 - val_loss: 68.5764\n",
      "Epoch 13300/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 64.3717 - val_loss: 68.5752\n",
      "Epoch 13301/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 64.3480 - val_loss: 68.5620\n",
      "Epoch 13302/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 64.3243 - val_loss: 68.5241\n",
      "Epoch 13303/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 64.3007 - val_loss: 68.5362\n",
      "Epoch 13304/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 64.2770 - val_loss: 68.4912\n",
      "Epoch 13305/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 64.2533 - val_loss: 68.4916\n",
      "Epoch 13306/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 64.2296 - val_loss: 68.4714\n",
      "Epoch 13307/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 64.2061 - val_loss: 68.4430\n",
      "Epoch 13308/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 64.1824 - val_loss: 68.4465\n",
      "Epoch 13309/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 64.1588 - val_loss: 68.4065\n",
      "Epoch 13310/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 64.1352 - val_loss: 68.4075\n",
      "Epoch 13311/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 64.1116 - val_loss: 68.3822\n",
      "Epoch 13312/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 64.0881 - val_loss: 68.3623\n",
      "Epoch 13313/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 64.0645 - val_loss: 68.3576\n",
      "Epoch 13314/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 64.0410 - val_loss: 68.3234\n",
      "Epoch 13315/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 64.0174 - val_loss: 68.3232\n",
      "Epoch 13316/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 63.9939 - val_loss: 68.2946\n",
      "Epoch 13317/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 63.9704 - val_loss: 68.2816\n",
      "Epoch 13318/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 63.9468 - val_loss: 68.2688\n",
      "Epoch 13319/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 63.9234 - val_loss: 68.2415\n",
      "Epoch 13320/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 63.8999 - val_loss: 68.2378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13321/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 63.8764 - val_loss: 68.2085\n",
      "Epoch 13322/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 63.8529 - val_loss: 68.1999\n",
      "Epoch 13323/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 63.8294 - val_loss: 68.1802\n",
      "Epoch 13324/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 63.8060 - val_loss: 68.1603\n",
      "Epoch 13325/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 63.7826 - val_loss: 68.1509\n",
      "Epoch 13326/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 63.7591 - val_loss: 68.1242\n",
      "Epoch 13327/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 63.7357 - val_loss: 68.1169\n",
      "Epoch 13328/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 63.7123 - val_loss: 68.0931\n",
      "Epoch 13329/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 63.6889 - val_loss: 68.0795\n",
      "Epoch 13330/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 63.6655 - val_loss: 68.0637\n",
      "Epoch 13331/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 63.6421 - val_loss: 68.0422\n",
      "Epoch 13332/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 63.6187 - val_loss: 68.0325\n",
      "Epoch 13333/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 63.5954 - val_loss: 68.0081\n",
      "Epoch 13334/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 63.5720 - val_loss: 67.9981\n",
      "Epoch 13335/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 63.5487 - val_loss: 67.9768\n",
      "Epoch 13336/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 63.5253 - val_loss: 67.9618\n",
      "Epoch 13337/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 63.5020 - val_loss: 67.9462\n",
      "Epoch 13338/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 63.4787 - val_loss: 67.9261\n",
      "Epoch 13339/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 63.4555 - val_loss: 67.9144\n",
      "Epoch 13340/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 63.4321 - val_loss: 67.8921\n",
      "Epoch 13341/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 63.4089 - val_loss: 67.8806\n",
      "Epoch 13342/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 63.3856 - val_loss: 67.8600\n",
      "Epoch 13343/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 63.3623 - val_loss: 67.8456\n",
      "Epoch 13344/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 63.3391 - val_loss: 67.8287\n",
      "Epoch 13345/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 63.3159 - val_loss: 67.8106\n",
      "Epoch 13346/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 63.2926 - val_loss: 67.7969\n",
      "Epoch 13347/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 63.2694 - val_loss: 67.7765\n",
      "Epoch 13348/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 63.2462 - val_loss: 67.7641\n",
      "Epoch 13349/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 63.2231 - val_loss: 67.7438\n",
      "Epoch 13350/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 63.1999 - val_loss: 67.7303\n",
      "Epoch 13351/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 63.1767 - val_loss: 67.7118\n",
      "Epoch 13352/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 63.1535 - val_loss: 67.6961\n",
      "Epoch 13353/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 63.1303 - val_loss: 67.6799\n",
      "Epoch 13354/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 63.1071 - val_loss: 67.6621\n",
      "Epoch 13355/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 63.0840 - val_loss: 67.6477\n",
      "Epoch 13356/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 63.0609 - val_loss: 67.6287\n",
      "Epoch 13357/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 63.0378 - val_loss: 67.6150\n",
      "Epoch 13358/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 63.0147 - val_loss: 67.5958\n",
      "Epoch 13359/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 62.9915 - val_loss: 67.5819\n",
      "Epoch 13360/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 62.9685 - val_loss: 67.5635\n",
      "Epoch 13361/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 62.9454 - val_loss: 67.5486\n",
      "Epoch 13362/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 62.9224 - val_loss: 67.5313\n",
      "Epoch 13363/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 62.8993 - val_loss: 67.5153\n",
      "Epoch 13364/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 62.8763 - val_loss: 67.4991\n",
      "Epoch 13365/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 62.8532 - val_loss: 67.4822\n",
      "Epoch 13366/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 62.8303 - val_loss: 67.4668\n",
      "Epoch 13367/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 62.8072 - val_loss: 67.4493\n",
      "Epoch 13368/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 62.7842 - val_loss: 67.4344\n",
      "Epoch 13369/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 62.7612 - val_loss: 67.4167\n",
      "Epoch 13370/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 62.7383 - val_loss: 67.4019\n",
      "Epoch 13371/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 62.7153 - val_loss: 67.3842\n",
      "Epoch 13372/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 62.6923 - val_loss: 67.3694\n",
      "Epoch 13373/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 62.6694 - val_loss: 67.3517\n",
      "Epoch 13374/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 62.6464 - val_loss: 67.3369\n",
      "Epoch 13375/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 62.6235 - val_loss: 67.3192\n",
      "Epoch 13376/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 62.6005 - val_loss: 67.3045\n",
      "Epoch 13377/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 62.5776 - val_loss: 67.2869\n",
      "Epoch 13378/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 62.5547 - val_loss: 67.2721\n",
      "Epoch 13379/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 62.5318 - val_loss: 67.2546\n",
      "Epoch 13380/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 62.5089 - val_loss: 67.2399\n",
      "Epoch 13381/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 62.4861 - val_loss: 67.2222\n",
      "Epoch 13382/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 62.4632 - val_loss: 67.2078\n",
      "Epoch 13383/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 62.4404 - val_loss: 67.1899\n",
      "Epoch 13384/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 62.4176 - val_loss: 67.1758\n",
      "Epoch 13385/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 62.3947 - val_loss: 67.1576\n",
      "Epoch 13386/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 62.3719 - val_loss: 67.1440\n",
      "Epoch 13387/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 62.3491 - val_loss: 67.1252\n",
      "Epoch 13388/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 62.3263 - val_loss: 67.1125\n",
      "Epoch 13389/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 62.3036 - val_loss: 67.0924\n",
      "Epoch 13390/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 62.2807 - val_loss: 67.0813\n",
      "Epoch 13391/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 62.2580 - val_loss: 67.0594\n",
      "Epoch 13392/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 62.2352 - val_loss: 67.0507\n",
      "Epoch 13393/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 62.2125 - val_loss: 67.0258\n",
      "Epoch 13394/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 62.1898 - val_loss: 67.0210\n",
      "Epoch 13395/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 62.1670 - val_loss: 66.9909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13396/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 62.1443 - val_loss: 66.9931\n",
      "Epoch 13397/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 62.1216 - val_loss: 66.9539\n",
      "Epoch 13398/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 62.0989 - val_loss: 66.9681\n",
      "Epoch 13399/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 62.0763 - val_loss: 66.9133\n",
      "Epoch 13400/100000\n",
      "11/11 [==============================] - 0s 199us/step - loss: 62.0536 - val_loss: 66.9480\n",
      "Epoch 13401/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 62.0310 - val_loss: 66.8674\n",
      "Epoch 13402/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 62.0084 - val_loss: 66.9337\n",
      "Epoch 13403/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 61.9859 - val_loss: 66.8180\n",
      "Epoch 13404/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 61.9634 - val_loss: 66.9177\n",
      "Epoch 13405/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 61.9409 - val_loss: 66.7816\n",
      "Epoch 13406/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 61.9183 - val_loss: 66.8746\n",
      "Epoch 13407/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 61.8955 - val_loss: 66.7814\n",
      "Epoch 13408/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 61.8726 - val_loss: 66.7967\n",
      "Epoch 13409/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 61.8499 - val_loss: 66.7989\n",
      "Epoch 13410/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 61.8274 - val_loss: 66.7253\n",
      "Epoch 13411/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 61.8050 - val_loss: 66.7880\n",
      "Epoch 13412/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 61.7825 - val_loss: 66.6965\n",
      "Epoch 13413/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 61.7598 - val_loss: 66.7307\n",
      "Epoch 13414/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 61.7372 - val_loss: 66.7028\n",
      "Epoch 13415/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 61.7146 - val_loss: 66.6608\n",
      "Epoch 13416/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 61.6922 - val_loss: 66.6975\n",
      "Epoch 13417/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 61.6698 - val_loss: 66.6225\n",
      "Epoch 13418/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 61.6473 - val_loss: 66.6529\n",
      "Epoch 13419/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 61.6246 - val_loss: 66.6186\n",
      "Epoch 13420/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 61.6021 - val_loss: 66.5910\n",
      "Epoch 13421/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 61.5797 - val_loss: 66.6115\n",
      "Epoch 13422/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 61.5573 - val_loss: 66.5507\n",
      "Epoch 13423/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 61.5349 - val_loss: 66.5735\n",
      "Epoch 13424/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 61.5124 - val_loss: 66.5388\n",
      "Epoch 13425/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 61.4899 - val_loss: 66.5185\n",
      "Epoch 13426/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 61.4675 - val_loss: 66.5277\n",
      "Epoch 13427/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 61.4451 - val_loss: 66.4776\n",
      "Epoch 13428/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 61.4228 - val_loss: 66.4938\n",
      "Epoch 13429/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 61.4004 - val_loss: 66.4595\n",
      "Epoch 13430/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 61.3780 - val_loss: 66.4446\n",
      "Epoch 13431/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 61.3556 - val_loss: 66.4448\n",
      "Epoch 13432/100000\n",
      "11/11 [==============================] - 0s 581us/step - loss: 61.3333 - val_loss: 66.4039\n",
      "Epoch 13433/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 61.3109 - val_loss: 66.4143\n",
      "Epoch 13434/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 61.2886 - val_loss: 66.3809\n",
      "Epoch 13435/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 61.2663 - val_loss: 66.3706\n",
      "Epoch 13436/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 61.2440 - val_loss: 66.3636\n",
      "Epoch 13437/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 61.2217 - val_loss: 66.3304\n",
      "Epoch 13438/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 61.1994 - val_loss: 66.3359\n",
      "Epoch 13439/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 61.1771 - val_loss: 66.3036\n",
      "Epoch 13440/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 61.1548 - val_loss: 66.2965\n",
      "Epoch 13441/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 61.1326 - val_loss: 66.2833\n",
      "Epoch 13442/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 61.1103 - val_loss: 66.2572\n",
      "Epoch 13443/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 61.0881 - val_loss: 66.2574\n",
      "Epoch 13444/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 61.0659 - val_loss: 66.2267\n",
      "Epoch 13445/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 61.0436 - val_loss: 66.2221\n",
      "Epoch 13446/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 61.0214 - val_loss: 66.2033\n",
      "Epoch 13447/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 60.9992 - val_loss: 66.1840\n",
      "Epoch 13448/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 60.9770 - val_loss: 66.1784\n",
      "Epoch 13449/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 60.9549 - val_loss: 66.1511\n",
      "Epoch 13450/100000\n",
      "11/11 [==============================] - 0s 201us/step - loss: 60.9327 - val_loss: 66.1469\n",
      "Epoch 13451/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 60.9105 - val_loss: 66.1246\n",
      "Epoch 13452/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 60.8884 - val_loss: 66.1112\n",
      "Epoch 13453/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 60.8663 - val_loss: 66.0996\n",
      "Epoch 13454/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 60.8441 - val_loss: 66.0770\n",
      "Epoch 13455/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 60.8220 - val_loss: 66.0710\n",
      "Epoch 13456/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 60.7999 - val_loss: 66.0475\n",
      "Epoch 13457/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 60.7778 - val_loss: 66.0381\n",
      "Epoch 13458/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 60.7557 - val_loss: 66.0211\n",
      "Epoch 13459/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 60.7336 - val_loss: 66.0041\n",
      "Epoch 13460/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 60.7116 - val_loss: 65.9940\n",
      "Epoch 13461/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 60.6895 - val_loss: 65.9723\n",
      "Epoch 13462/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 60.6675 - val_loss: 65.9638\n",
      "Epoch 13463/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 60.6454 - val_loss: 65.9436\n",
      "Epoch 13464/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 60.6234 - val_loss: 65.9313\n",
      "Epoch 13465/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 60.6014 - val_loss: 65.9164\n",
      "Epoch 13466/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 60.5794 - val_loss: 65.8988\n",
      "Epoch 13467/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 60.5574 - val_loss: 65.8881\n",
      "Epoch 13468/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 60.5354 - val_loss: 65.8682\n",
      "Epoch 13469/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 60.5134 - val_loss: 65.8578\n",
      "Epoch 13470/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 60.4915 - val_loss: 65.8395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13471/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 60.4695 - val_loss: 65.8263\n",
      "Epoch 13472/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 60.4476 - val_loss: 65.8115\n",
      "Epoch 13473/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 60.4256 - val_loss: 65.7949\n",
      "Epoch 13474/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 60.4037 - val_loss: 65.7830\n",
      "Epoch 13475/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 60.3818 - val_loss: 65.7645\n",
      "Epoch 13476/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 60.3599 - val_loss: 65.7532\n",
      "Epoch 13477/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 60.3380 - val_loss: 65.7354\n",
      "Epoch 13478/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 60.3161 - val_loss: 65.7224\n",
      "Epoch 13479/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 60.2942 - val_loss: 65.7070\n",
      "Epoch 13480/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 60.2724 - val_loss: 65.6916\n",
      "Epoch 13481/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 60.2505 - val_loss: 65.6784\n",
      "Epoch 13482/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 60.2287 - val_loss: 65.6614\n",
      "Epoch 13483/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 60.2069 - val_loss: 65.6491\n",
      "Epoch 13484/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 60.1850 - val_loss: 65.6319\n",
      "Epoch 13485/100000\n",
      "11/11 [==============================] - 0s 639us/step - loss: 60.1632 - val_loss: 65.6192\n",
      "Epoch 13486/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 60.1414 - val_loss: 65.6031\n",
      "Epoch 13487/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 60.1197 - val_loss: 65.5890\n",
      "Epoch 13488/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 60.0978 - val_loss: 65.5744\n",
      "Epoch 13489/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 60.0761 - val_loss: 65.5591\n",
      "Epoch 13490/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 60.0543 - val_loss: 65.5455\n",
      "Epoch 13491/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 60.0325 - val_loss: 65.5294\n",
      "Epoch 13492/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 60.0108 - val_loss: 65.5164\n",
      "Epoch 13493/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 59.9891 - val_loss: 65.5000\n",
      "Epoch 13494/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 59.9673 - val_loss: 65.4871\n",
      "Epoch 13495/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 59.9456 - val_loss: 65.4709\n",
      "Epoch 13496/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 59.9239 - val_loss: 65.4577\n",
      "Epoch 13497/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 59.9022 - val_loss: 65.4421\n",
      "Epoch 13498/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 59.8806 - val_loss: 65.4282\n",
      "Epoch 13499/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 59.8589 - val_loss: 65.4133\n",
      "Epoch 13500/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 59.8372 - val_loss: 65.3987\n",
      "Epoch 13501/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 59.8156 - val_loss: 65.3845\n",
      "Epoch 13502/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 59.7939 - val_loss: 65.3694\n",
      "Epoch 13503/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 59.7723 - val_loss: 65.3557\n",
      "Epoch 13504/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 59.7506 - val_loss: 65.3403\n",
      "Epoch 13505/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 59.7290 - val_loss: 65.3270\n",
      "Epoch 13506/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 59.7075 - val_loss: 65.3113\n",
      "Epoch 13507/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 59.6859 - val_loss: 65.2981\n",
      "Epoch 13508/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 59.6642 - val_loss: 65.2823\n",
      "Epoch 13509/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 59.6427 - val_loss: 65.2692\n",
      "Epoch 13510/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 59.6211 - val_loss: 65.2535\n",
      "Epoch 13511/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 59.5996 - val_loss: 65.2403\n",
      "Epoch 13512/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 59.5780 - val_loss: 65.2249\n",
      "Epoch 13513/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 59.5565 - val_loss: 65.2115\n",
      "Epoch 13514/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 59.5350 - val_loss: 65.1962\n",
      "Epoch 13515/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 59.5135 - val_loss: 65.1828\n",
      "Epoch 13516/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 59.4920 - val_loss: 65.1675\n",
      "Epoch 13517/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 59.4705 - val_loss: 65.1542\n",
      "Epoch 13518/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 59.4490 - val_loss: 65.1388\n",
      "Epoch 13519/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 59.4275 - val_loss: 65.1257\n",
      "Epoch 13520/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 59.4061 - val_loss: 65.1101\n",
      "Epoch 13521/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 59.3846 - val_loss: 65.0973\n",
      "Epoch 13522/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 59.3632 - val_loss: 65.0815\n",
      "Epoch 13523/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 59.3417 - val_loss: 65.0690\n",
      "Epoch 13524/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 59.3203 - val_loss: 65.0528\n",
      "Epoch 13525/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 59.2989 - val_loss: 65.0409\n",
      "Epoch 13526/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 59.2775 - val_loss: 65.0240\n",
      "Epoch 13527/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 59.2561 - val_loss: 65.0131\n",
      "Epoch 13528/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 59.2347 - val_loss: 64.9949\n",
      "Epoch 13529/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 59.2133 - val_loss: 64.9856\n",
      "Epoch 13530/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 59.1920 - val_loss: 64.9656\n",
      "Epoch 13531/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 59.1706 - val_loss: 64.9586\n",
      "Epoch 13532/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 59.1492 - val_loss: 64.9356\n",
      "Epoch 13533/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 59.1279 - val_loss: 64.9326\n",
      "Epoch 13534/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 59.1066 - val_loss: 64.9046\n",
      "Epoch 13535/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 59.0853 - val_loss: 64.9081\n",
      "Epoch 13536/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 59.0640 - val_loss: 64.8719\n",
      "Epoch 13537/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 59.0427 - val_loss: 64.8859\n",
      "Epoch 13538/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 59.0214 - val_loss: 64.8362\n",
      "Epoch 13539/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 59.0002 - val_loss: 64.8679\n",
      "Epoch 13540/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 58.9790 - val_loss: 64.7959\n",
      "Epoch 13541/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 58.9578 - val_loss: 64.8551\n",
      "Epoch 13542/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 58.9366 - val_loss: 64.7511\n",
      "Epoch 13543/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 58.9156 - val_loss: 64.8449\n",
      "Epoch 13544/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 58.8945 - val_loss: 64.7102\n",
      "Epoch 13545/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 58.8733 - val_loss: 64.8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13546/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 58.8521 - val_loss: 64.6955\n",
      "Epoch 13547/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 58.8307 - val_loss: 64.7611\n",
      "Epoch 13548/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 58.8093 - val_loss: 64.7118\n",
      "Epoch 13549/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 58.7880 - val_loss: 64.6850\n",
      "Epoch 13550/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 58.7668 - val_loss: 64.7242\n",
      "Epoch 13551/100000\n",
      "11/11 [==============================] - 0s 692us/step - loss: 58.7458 - val_loss: 64.6330\n",
      "Epoch 13552/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 58.7248 - val_loss: 64.6991\n",
      "Epoch 13553/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 58.7036 - val_loss: 64.6228\n",
      "Epoch 13554/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 58.6823 - val_loss: 64.6378\n",
      "Epoch 13555/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 58.6611 - val_loss: 64.6328\n",
      "Epoch 13556/100000\n",
      "11/11 [==============================] - 0s 724us/step - loss: 58.6400 - val_loss: 64.5784\n",
      "Epoch 13557/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 58.6191 - val_loss: 64.6224\n",
      "Epoch 13558/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 58.5980 - val_loss: 64.5518\n",
      "Epoch 13559/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 58.5769 - val_loss: 64.5775\n",
      "Epoch 13560/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 58.5558 - val_loss: 64.5517\n",
      "Epoch 13561/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 58.5347 - val_loss: 64.5219\n",
      "Epoch 13562/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 58.5137 - val_loss: 64.5452\n",
      "Epoch 13563/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 58.4927 - val_loss: 64.4867\n",
      "Epoch 13564/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 58.4717 - val_loss: 64.5117\n",
      "Epoch 13565/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 58.4506 - val_loss: 64.4761\n",
      "Epoch 13566/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 58.4295 - val_loss: 64.4624\n",
      "Epoch 13567/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 58.4086 - val_loss: 64.4685\n",
      "Epoch 13568/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 58.3876 - val_loss: 64.4230\n",
      "Epoch 13569/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 58.3666 - val_loss: 64.4426\n",
      "Epoch 13570/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 58.3456 - val_loss: 64.4039\n",
      "Epoch 13571/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 58.3247 - val_loss: 64.4006\n",
      "Epoch 13572/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 58.3037 - val_loss: 64.3929\n",
      "Epoch 13573/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 58.2828 - val_loss: 64.3605\n",
      "Epoch 13574/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 58.2619 - val_loss: 64.3722\n",
      "Epoch 13575/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 58.2410 - val_loss: 64.3347\n",
      "Epoch 13576/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 58.2200 - val_loss: 64.3373\n",
      "Epoch 13577/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 58.1991 - val_loss: 64.3194\n",
      "Epoch 13578/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 58.1783 - val_loss: 64.2987\n",
      "Epoch 13579/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 58.1574 - val_loss: 64.3010\n",
      "Epoch 13580/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 58.1365 - val_loss: 64.2683\n",
      "Epoch 13581/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 58.1157 - val_loss: 64.2722\n",
      "Epoch 13582/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 58.0948 - val_loss: 64.2476\n",
      "Epoch 13583/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 58.0739 - val_loss: 64.2368\n",
      "Epoch 13584/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 58.0531 - val_loss: 64.2291\n",
      "Epoch 13585/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 58.0323 - val_loss: 64.2038\n",
      "Epoch 13586/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 58.0115 - val_loss: 64.2049\n",
      "Epoch 13587/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 57.9907 - val_loss: 64.1782\n",
      "Epoch 13588/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 57.9699 - val_loss: 64.1739\n",
      "Epoch 13589/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 57.9491 - val_loss: 64.1575\n",
      "Epoch 13590/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 57.9283 - val_loss: 64.1411\n",
      "Epoch 13591/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 57.9076 - val_loss: 64.1357\n",
      "Epoch 13592/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 57.8868 - val_loss: 64.1119\n",
      "Epoch 13593/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 57.8661 - val_loss: 64.1092\n",
      "Epoch 13594/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 57.8454 - val_loss: 64.0877\n",
      "Epoch 13595/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 57.8246 - val_loss: 64.0788\n",
      "Epoch 13596/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 57.8039 - val_loss: 64.0658\n",
      "Epoch 13597/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 57.7832 - val_loss: 64.0483\n",
      "Epoch 13598/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 57.7625 - val_loss: 64.0420\n",
      "Epoch 13599/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 57.7418 - val_loss: 64.0208\n",
      "Epoch 13600/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 57.7212 - val_loss: 64.0149\n",
      "Epoch 13601/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 57.7005 - val_loss: 63.9965\n",
      "Epoch 13602/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 57.6798 - val_loss: 63.9857\n",
      "Epoch 13603/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 57.6591 - val_loss: 63.9732\n",
      "Epoch 13604/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 57.6385 - val_loss: 63.9568\n",
      "Epoch 13605/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 57.6178 - val_loss: 63.9486\n",
      "Epoch 13606/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 57.5973 - val_loss: 63.9300\n",
      "Epoch 13607/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 57.5766 - val_loss: 63.9220\n",
      "Epoch 13608/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 57.5561 - val_loss: 63.9052\n",
      "Epoch 13609/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 57.5355 - val_loss: 63.8940\n",
      "Epoch 13610/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 57.5149 - val_loss: 63.8810\n",
      "Epoch 13611/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 57.4943 - val_loss: 63.8661\n",
      "Epoch 13612/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 57.4738 - val_loss: 63.8564\n",
      "Epoch 13613/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 57.4532 - val_loss: 63.8393\n",
      "Epoch 13614/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 57.4327 - val_loss: 63.8305\n",
      "Epoch 13615/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 57.4121 - val_loss: 63.8139\n",
      "Epoch 13616/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 57.3916 - val_loss: 63.8035\n",
      "Epoch 13617/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 57.3711 - val_loss: 63.7891\n",
      "Epoch 13618/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 57.3505 - val_loss: 63.7763\n",
      "Epoch 13619/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 57.3301 - val_loss: 63.7644\n",
      "Epoch 13620/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 57.3096 - val_loss: 63.7495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13621/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 57.2891 - val_loss: 63.7391\n",
      "Epoch 13622/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 57.2687 - val_loss: 63.7235\n",
      "Epoch 13623/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 57.2482 - val_loss: 63.7132\n",
      "Epoch 13624/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 57.2277 - val_loss: 63.6981\n",
      "Epoch 13625/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 57.2073 - val_loss: 63.6869\n",
      "Epoch 13626/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 57.1868 - val_loss: 63.6732\n",
      "Epoch 13627/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 57.1664 - val_loss: 63.6605\n",
      "Epoch 13628/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 57.1460 - val_loss: 63.6482\n",
      "Epoch 13629/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 57.1256 - val_loss: 63.6344\n",
      "Epoch 13630/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 57.1053 - val_loss: 63.6231\n",
      "Epoch 13631/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 57.0849 - val_loss: 63.6086\n",
      "Epoch 13632/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 57.0645 - val_loss: 63.5975\n",
      "Epoch 13633/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 57.0441 - val_loss: 63.5832\n",
      "Epoch 13634/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 57.0238 - val_loss: 63.5718\n",
      "Epoch 13635/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 57.0034 - val_loss: 63.5580\n",
      "Epoch 13636/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 56.9831 - val_loss: 63.5461\n",
      "Epoch 13637/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 56.9627 - val_loss: 63.5329\n",
      "Epoch 13638/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 56.9424 - val_loss: 63.5205\n",
      "Epoch 13639/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 56.9221 - val_loss: 63.5079\n",
      "Epoch 13640/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 56.9019 - val_loss: 63.4950\n",
      "Epoch 13641/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 56.8816 - val_loss: 63.4828\n",
      "Epoch 13642/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 56.8613 - val_loss: 63.4696\n",
      "Epoch 13643/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 56.8410 - val_loss: 63.4576\n",
      "Epoch 13644/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 56.8208 - val_loss: 63.4444\n",
      "Epoch 13645/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 56.8005 - val_loss: 63.4324\n",
      "Epoch 13646/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 56.7802 - val_loss: 63.4192\n",
      "Epoch 13647/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 56.7600 - val_loss: 63.4073\n",
      "Epoch 13648/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 56.7398 - val_loss: 63.3941\n",
      "Epoch 13649/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 56.7196 - val_loss: 63.3822\n",
      "Epoch 13650/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 56.6994 - val_loss: 63.3691\n",
      "Epoch 13651/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 56.6792 - val_loss: 63.3572\n",
      "Epoch 13652/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 56.6590 - val_loss: 63.3441\n",
      "Epoch 13653/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 56.6388 - val_loss: 63.3321\n",
      "Epoch 13654/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 56.6186 - val_loss: 63.3193\n",
      "Epoch 13655/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 56.5985 - val_loss: 63.3072\n",
      "Epoch 13656/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 56.5783 - val_loss: 63.2945\n",
      "Epoch 13657/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 56.5582 - val_loss: 63.2823\n",
      "Epoch 13658/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 56.5380 - val_loss: 63.2697\n",
      "Epoch 13659/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 56.5179 - val_loss: 63.2575\n",
      "Epoch 13660/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 56.4978 - val_loss: 63.2449\n",
      "Epoch 13661/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 56.4777 - val_loss: 63.2328\n",
      "Epoch 13662/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 56.4576 - val_loss: 63.2201\n",
      "Epoch 13663/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 56.4375 - val_loss: 63.2082\n",
      "Epoch 13664/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 56.4174 - val_loss: 63.1954\n",
      "Epoch 13665/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 56.3973 - val_loss: 63.1836\n",
      "Epoch 13666/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 56.3773 - val_loss: 63.1709\n",
      "Epoch 13667/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 56.3573 - val_loss: 63.1591\n",
      "Epoch 13668/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 56.3372 - val_loss: 63.1462\n",
      "Epoch 13669/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 56.3172 - val_loss: 63.1346\n",
      "Epoch 13670/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 56.2971 - val_loss: 63.1216\n",
      "Epoch 13671/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 56.2772 - val_loss: 63.1103\n",
      "Epoch 13672/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 56.2571 - val_loss: 63.0970\n",
      "Epoch 13673/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 56.2371 - val_loss: 63.0861\n",
      "Epoch 13674/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 56.2171 - val_loss: 63.0723\n",
      "Epoch 13675/100000\n",
      "11/11 [==============================] - 0s 203us/step - loss: 56.1971 - val_loss: 63.0621\n",
      "Epoch 13676/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 56.1772 - val_loss: 63.0475\n",
      "Epoch 13677/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 56.1572 - val_loss: 63.0384\n",
      "Epoch 13678/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 56.1373 - val_loss: 63.0224\n",
      "Epoch 13679/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 56.1173 - val_loss: 63.0153\n",
      "Epoch 13680/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 56.0974 - val_loss: 62.9968\n",
      "Epoch 13681/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 56.0775 - val_loss: 62.9929\n",
      "Epoch 13682/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 56.0576 - val_loss: 62.9701\n",
      "Epoch 13683/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 56.0376 - val_loss: 62.9721\n",
      "Epoch 13684/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 56.0178 - val_loss: 62.9415\n",
      "Epoch 13685/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 55.9979 - val_loss: 62.9542\n",
      "Epoch 13686/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 55.9780 - val_loss: 62.9092\n",
      "Epoch 13687/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 55.9582 - val_loss: 62.9414\n",
      "Epoch 13688/100000\n",
      "11/11 [==============================] - 0s 668us/step - loss: 55.9384 - val_loss: 62.8706\n",
      "Epoch 13689/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 55.9186 - val_loss: 62.9367\n",
      "Epoch 13690/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 55.8988 - val_loss: 62.8235\n",
      "Epoch 13691/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 55.8792 - val_loss: 62.9397\n",
      "Epoch 13692/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 55.8596 - val_loss: 62.7764\n",
      "Epoch 13693/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 55.8400 - val_loss: 62.9277\n",
      "Epoch 13694/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 55.8203 - val_loss: 62.7657\n",
      "Epoch 13695/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 55.8001 - val_loss: 62.8601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13696/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 55.7799 - val_loss: 62.8076\n",
      "Epoch 13697/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 55.7599 - val_loss: 62.7651\n",
      "Epoch 13698/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 55.7403 - val_loss: 62.8388\n",
      "Epoch 13699/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 55.7208 - val_loss: 62.7176\n",
      "Epoch 13700/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 55.7010 - val_loss: 62.8002\n",
      "Epoch 13701/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 55.6811 - val_loss: 62.7385\n",
      "Epoch 13702/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 55.6611 - val_loss: 62.7172\n",
      "Epoch 13703/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 55.6415 - val_loss: 62.7642\n",
      "Epoch 13704/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 55.6219 - val_loss: 62.6704\n",
      "Epoch 13705/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 55.6022 - val_loss: 62.7300\n",
      "Epoch 13706/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 55.5824 - val_loss: 62.6838\n",
      "Epoch 13707/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 55.5626 - val_loss: 62.6595\n",
      "Epoch 13708/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 55.5429 - val_loss: 62.6980\n",
      "Epoch 13709/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 55.5234 - val_loss: 62.6227\n",
      "Epoch 13710/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 55.5037 - val_loss: 62.6613\n",
      "Epoch 13711/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 55.4840 - val_loss: 62.6317\n",
      "Epoch 13712/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 55.4643 - val_loss: 62.6014\n",
      "Epoch 13713/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 55.4447 - val_loss: 62.6338\n",
      "Epoch 13714/100000\n",
      "11/11 [==============================] - 0s 672us/step - loss: 55.4251 - val_loss: 62.5732\n",
      "Epoch 13715/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 55.4054 - val_loss: 62.5946\n",
      "Epoch 13716/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 55.3858 - val_loss: 62.5775\n",
      "Epoch 13717/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 55.3661 - val_loss: 62.5439\n",
      "Epoch 13718/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 55.3466 - val_loss: 62.5698\n",
      "Epoch 13719/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 55.3271 - val_loss: 62.5218\n",
      "Epoch 13720/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 55.3074 - val_loss: 62.5306\n",
      "Epoch 13721/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 55.2878 - val_loss: 62.5213\n",
      "Epoch 13722/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 55.2683 - val_loss: 62.4880\n",
      "Epoch 13723/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 55.2488 - val_loss: 62.5071\n",
      "Epoch 13724/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 55.2292 - val_loss: 62.4695\n",
      "Epoch 13725/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 55.2097 - val_loss: 62.4698\n",
      "Epoch 13726/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 55.1901 - val_loss: 62.4643\n",
      "Epoch 13727/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 55.1706 - val_loss: 62.4333\n",
      "Epoch 13728/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 55.1511 - val_loss: 62.4461\n",
      "Epoch 13729/100000\n",
      "11/11 [==============================] - 0s 620us/step - loss: 55.1316 - val_loss: 62.4158\n",
      "Epoch 13730/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 55.1121 - val_loss: 62.4110\n",
      "Epoch 13731/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 55.0926 - val_loss: 62.4064\n",
      "Epoch 13732/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 55.0731 - val_loss: 62.3786\n",
      "Epoch 13733/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 55.0537 - val_loss: 62.3859\n",
      "Epoch 13734/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 55.0342 - val_loss: 62.3607\n",
      "Epoch 13735/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 55.0147 - val_loss: 62.3534\n",
      "Epoch 13736/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 54.9954 - val_loss: 62.3483\n",
      "Epoch 13737/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 54.9758 - val_loss: 62.3238\n",
      "Epoch 13738/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 54.9565 - val_loss: 62.3271\n",
      "Epoch 13739/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 54.9370 - val_loss: 62.3051\n",
      "Epoch 13740/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 54.9176 - val_loss: 62.2970\n",
      "Epoch 13741/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 54.8982 - val_loss: 62.2905\n",
      "Epoch 13742/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 54.8788 - val_loss: 62.2691\n",
      "Epoch 13743/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 54.8595 - val_loss: 62.2693\n",
      "Epoch 13744/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 54.8401 - val_loss: 62.2494\n",
      "Epoch 13745/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 54.8207 - val_loss: 62.2413\n",
      "Epoch 13746/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 54.8014 - val_loss: 62.2331\n",
      "Epoch 13747/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 54.7820 - val_loss: 62.2143\n",
      "Epoch 13748/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 54.7627 - val_loss: 62.2121\n",
      "Epoch 13749/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 54.7434 - val_loss: 62.1936\n",
      "Epoch 13750/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 54.7240 - val_loss: 62.1857\n",
      "Epoch 13751/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 54.7047 - val_loss: 62.1759\n",
      "Epoch 13752/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 54.6855 - val_loss: 62.1596\n",
      "Epoch 13753/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 54.6661 - val_loss: 62.1553\n",
      "Epoch 13754/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 54.6469 - val_loss: 62.1380\n",
      "Epoch 13755/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 54.6276 - val_loss: 62.1305\n",
      "Epoch 13756/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 54.6083 - val_loss: 62.1193\n",
      "Epoch 13757/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 54.5890 - val_loss: 62.1051\n",
      "Epoch 13758/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 54.5698 - val_loss: 62.0990\n",
      "Epoch 13759/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 54.5506 - val_loss: 62.0827\n",
      "Epoch 13760/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 54.5313 - val_loss: 62.0755\n",
      "Epoch 13761/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 54.5121 - val_loss: 62.0630\n",
      "Epoch 13762/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 54.4929 - val_loss: 62.0507\n",
      "Epoch 13763/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 54.4736 - val_loss: 62.0429\n",
      "Epoch 13764/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 54.4544 - val_loss: 62.0278\n",
      "Epoch 13765/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 54.4352 - val_loss: 62.0204\n",
      "Epoch 13766/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 54.4161 - val_loss: 62.0072\n",
      "Epoch 13767/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 54.3969 - val_loss: 61.9966\n",
      "Epoch 13768/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 54.3777 - val_loss: 61.9869\n",
      "Epoch 13769/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 54.3586 - val_loss: 61.9735\n",
      "Epoch 13770/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 54.3395 - val_loss: 61.9654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13771/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 54.3203 - val_loss: 61.9520\n",
      "Epoch 13772/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 54.3012 - val_loss: 61.9425\n",
      "Epoch 13773/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 54.2820 - val_loss: 61.9314\n",
      "Epoch 13774/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 54.2629 - val_loss: 61.9195\n",
      "Epoch 13775/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 54.2438 - val_loss: 61.9104\n",
      "Epoch 13776/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 54.2247 - val_loss: 61.8974\n",
      "Epoch 13777/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 54.2056 - val_loss: 61.8884\n",
      "Epoch 13778/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 54.1866 - val_loss: 61.8764\n",
      "Epoch 13779/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 54.1675 - val_loss: 61.8657\n",
      "Epoch 13780/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 54.1484 - val_loss: 61.8555\n",
      "Epoch 13781/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 54.1293 - val_loss: 61.8433\n",
      "Epoch 13782/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 54.1103 - val_loss: 61.8342\n",
      "Epoch 13783/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 54.0913 - val_loss: 61.8218\n",
      "Epoch 13784/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 54.0722 - val_loss: 61.8120\n",
      "Epoch 13785/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 54.0532 - val_loss: 61.8009\n",
      "Epoch 13786/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 54.0342 - val_loss: 61.7898\n",
      "Epoch 13787/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 54.0152 - val_loss: 61.7798\n",
      "Epoch 13788/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 53.9962 - val_loss: 61.7680\n",
      "Epoch 13789/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 53.9772 - val_loss: 61.7582\n",
      "Epoch 13790/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 53.9582 - val_loss: 61.7467\n",
      "Epoch 13791/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 53.9393 - val_loss: 61.7364\n",
      "Epoch 13792/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 53.9203 - val_loss: 61.7257\n",
      "Epoch 13793/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 53.9014 - val_loss: 61.7145\n",
      "Epoch 13794/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 53.8824 - val_loss: 61.7045\n",
      "Epoch 13795/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 53.8634 - val_loss: 61.6930\n",
      "Epoch 13796/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 53.8445 - val_loss: 61.6831\n",
      "Epoch 13797/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 53.8256 - val_loss: 61.6719\n",
      "Epoch 13798/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 53.8067 - val_loss: 61.6614\n",
      "Epoch 13799/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 53.7878 - val_loss: 61.6509\n",
      "Epoch 13800/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 53.7689 - val_loss: 61.6399\n",
      "Epoch 13801/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 53.7500 - val_loss: 61.6297\n",
      "Epoch 13802/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 53.7312 - val_loss: 61.6186\n",
      "Epoch 13803/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 53.7122 - val_loss: 61.6085\n",
      "Epoch 13804/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 53.6934 - val_loss: 61.5975\n",
      "Epoch 13805/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 53.6746 - val_loss: 61.5871\n",
      "Epoch 13806/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 53.6558 - val_loss: 61.5765\n",
      "Epoch 13807/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 53.6369 - val_loss: 61.5658\n",
      "Epoch 13808/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 53.6181 - val_loss: 61.5554\n",
      "Epoch 13809/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 53.5993 - val_loss: 61.5446\n",
      "Epoch 13810/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 53.5805 - val_loss: 61.5342\n",
      "Epoch 13811/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 53.5616 - val_loss: 61.5235\n",
      "Epoch 13812/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 53.5429 - val_loss: 61.5131\n",
      "Epoch 13813/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 53.5241 - val_loss: 61.5026\n",
      "Epoch 13814/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 53.5053 - val_loss: 61.4919\n",
      "Epoch 13815/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 53.4865 - val_loss: 61.4817\n",
      "Epoch 13816/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 53.4678 - val_loss: 61.4709\n",
      "Epoch 13817/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 53.4490 - val_loss: 61.4606\n",
      "Epoch 13818/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 53.4303 - val_loss: 61.4500\n",
      "Epoch 13819/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 53.4115 - val_loss: 61.4395\n",
      "Epoch 13820/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 53.3928 - val_loss: 61.4291\n",
      "Epoch 13821/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 53.3741 - val_loss: 61.4185\n",
      "Epoch 13822/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 53.3554 - val_loss: 61.4082\n",
      "Epoch 13823/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 53.3367 - val_loss: 61.3976\n",
      "Epoch 13824/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 53.3180 - val_loss: 61.3874\n",
      "Epoch 13825/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 53.2993 - val_loss: 61.3767\n",
      "Epoch 13826/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 53.2807 - val_loss: 61.3665\n",
      "Epoch 13827/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 53.2620 - val_loss: 61.3558\n",
      "Epoch 13828/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 53.2434 - val_loss: 61.3457\n",
      "Epoch 13829/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 53.2247 - val_loss: 61.3350\n",
      "Epoch 13830/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 53.2061 - val_loss: 61.3249\n",
      "Epoch 13831/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 53.1874 - val_loss: 61.3143\n",
      "Epoch 13832/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 53.1688 - val_loss: 61.3040\n",
      "Epoch 13833/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 53.1502 - val_loss: 61.2937\n",
      "Epoch 13834/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 53.1316 - val_loss: 61.2832\n",
      "Epoch 13835/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 53.1130 - val_loss: 61.2730\n",
      "Epoch 13836/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 53.0944 - val_loss: 61.2625\n",
      "Epoch 13837/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 53.0759 - val_loss: 61.2524\n",
      "Epoch 13838/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 53.0573 - val_loss: 61.2417\n",
      "Epoch 13839/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 53.0387 - val_loss: 61.2318\n",
      "Epoch 13840/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 53.0201 - val_loss: 61.2211\n",
      "Epoch 13841/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 53.0016 - val_loss: 61.2110\n",
      "Epoch 13842/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 52.9831 - val_loss: 61.2006\n",
      "Epoch 13843/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 52.9646 - val_loss: 61.1903\n",
      "Epoch 13844/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 52.9460 - val_loss: 61.1801\n",
      "Epoch 13845/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 52.9276 - val_loss: 61.1696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13846/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 52.9091 - val_loss: 61.1596\n",
      "Epoch 13847/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 52.8906 - val_loss: 61.1490\n",
      "Epoch 13848/100000\n",
      "11/11 [==============================] - 0s 687us/step - loss: 52.8720 - val_loss: 61.1390\n",
      "Epoch 13849/100000\n",
      "11/11 [==============================] - 0s 203us/step - loss: 52.8536 - val_loss: 61.1285\n",
      "Epoch 13850/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 52.8352 - val_loss: 61.1185\n",
      "Epoch 13851/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 52.8167 - val_loss: 61.1080\n",
      "Epoch 13852/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 52.7982 - val_loss: 61.0979\n",
      "Epoch 13853/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 52.7798 - val_loss: 61.0876\n",
      "Epoch 13854/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 52.7614 - val_loss: 61.0773\n",
      "Epoch 13855/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 52.7430 - val_loss: 61.0672\n",
      "Epoch 13856/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 52.7245 - val_loss: 61.0568\n",
      "Epoch 13857/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 52.7061 - val_loss: 61.0469\n",
      "Epoch 13858/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 52.6878 - val_loss: 61.0362\n",
      "Epoch 13859/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 52.6693 - val_loss: 61.0265\n",
      "Epoch 13860/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 52.6510 - val_loss: 61.0158\n",
      "Epoch 13861/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 52.6326 - val_loss: 61.0061\n",
      "Epoch 13862/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 52.6142 - val_loss: 60.9953\n",
      "Epoch 13863/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 52.5959 - val_loss: 60.9859\n",
      "Epoch 13864/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 52.5776 - val_loss: 60.9748\n",
      "Epoch 13865/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 52.5592 - val_loss: 60.9656\n",
      "Epoch 13866/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 52.5409 - val_loss: 60.9544\n",
      "Epoch 13867/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 52.5226 - val_loss: 60.9453\n",
      "Epoch 13868/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 52.5043 - val_loss: 60.9339\n",
      "Epoch 13869/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 52.4860 - val_loss: 60.9250\n",
      "Epoch 13870/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 52.4677 - val_loss: 60.9136\n",
      "Epoch 13871/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 52.4494 - val_loss: 60.9047\n",
      "Epoch 13872/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 52.4311 - val_loss: 60.8932\n",
      "Epoch 13873/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 52.4129 - val_loss: 60.8844\n",
      "Epoch 13874/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 52.3946 - val_loss: 60.8728\n",
      "Epoch 13875/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 52.3764 - val_loss: 60.8644\n",
      "Epoch 13876/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 52.3581 - val_loss: 60.8523\n",
      "Epoch 13877/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 52.3399 - val_loss: 60.8443\n",
      "Epoch 13878/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 52.3217 - val_loss: 60.8318\n",
      "Epoch 13879/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 52.3035 - val_loss: 60.8245\n",
      "Epoch 13880/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 52.2853 - val_loss: 60.8110\n",
      "Epoch 13881/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 52.2671 - val_loss: 60.8049\n",
      "Epoch 13882/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 52.2489 - val_loss: 60.7900\n",
      "Epoch 13883/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 52.2307 - val_loss: 60.7857\n",
      "Epoch 13884/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 52.2126 - val_loss: 60.7685\n",
      "Epoch 13885/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 52.1944 - val_loss: 60.7671\n",
      "Epoch 13886/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 52.1762 - val_loss: 60.7462\n",
      "Epoch 13887/100000\n",
      "11/11 [==============================] - 0s 636us/step - loss: 52.1581 - val_loss: 60.7496\n",
      "Epoch 13888/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 52.1400 - val_loss: 60.7226\n",
      "Epoch 13889/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 52.1219 - val_loss: 60.7336\n",
      "Epoch 13890/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 52.1038 - val_loss: 60.6971\n",
      "Epoch 13891/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 52.0857 - val_loss: 60.7201\n",
      "Epoch 13892/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 52.0676 - val_loss: 60.6684\n",
      "Epoch 13893/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 52.0495 - val_loss: 60.7108\n",
      "Epoch 13894/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 52.0315 - val_loss: 60.6352\n",
      "Epoch 13895/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 52.0135 - val_loss: 60.7066\n",
      "Epoch 13896/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 51.9955 - val_loss: 60.5977\n",
      "Epoch 13897/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 51.9776 - val_loss: 60.7045\n",
      "Epoch 13898/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 51.9597 - val_loss: 60.5637\n",
      "Epoch 13899/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 51.9417 - val_loss: 60.6900\n",
      "Epoch 13900/100000\n",
      "11/11 [==============================] - 0s 637us/step - loss: 51.9237 - val_loss: 60.5527\n",
      "Epoch 13901/100000\n",
      "11/11 [==============================] - 0s 590us/step - loss: 51.9056 - val_loss: 60.6432\n",
      "Epoch 13902/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 51.8873 - val_loss: 60.5737\n",
      "Epoch 13903/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 51.8692 - val_loss: 60.5740\n",
      "Epoch 13904/100000\n",
      "11/11 [==============================] - 0s 614us/step - loss: 51.8511 - val_loss: 60.5991\n",
      "Epoch 13905/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 51.8332 - val_loss: 60.5193\n",
      "Epoch 13906/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 51.8154 - val_loss: 60.5950\n",
      "Epoch 13907/100000\n",
      "11/11 [==============================] - 0s 607us/step - loss: 51.7975 - val_loss: 60.5028\n",
      "Epoch 13908/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 51.7794 - val_loss: 60.5515\n",
      "Epoch 13909/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 51.7614 - val_loss: 60.5172\n",
      "Epoch 13910/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 51.7434 - val_loss: 60.4939\n",
      "Epoch 13911/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 51.7255 - val_loss: 60.5275\n",
      "Epoch 13912/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 51.7076 - val_loss: 60.4575\n",
      "Epoch 13913/100000\n",
      "11/11 [==============================] - 0s 699us/step - loss: 51.6898 - val_loss: 60.5073\n",
      "Epoch 13914/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 51.6718 - val_loss: 60.4532\n",
      "Epoch 13915/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 51.6539 - val_loss: 60.4616\n",
      "Epoch 13916/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 51.6360 - val_loss: 60.4612\n",
      "Epoch 13917/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 51.6181 - val_loss: 60.4189\n",
      "Epoch 13918/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 51.6003 - val_loss: 60.4532\n",
      "Epoch 13919/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 51.5825 - val_loss: 60.3997\n",
      "Epoch 13920/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 51.5646 - val_loss: 60.4207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13921/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 51.5467 - val_loss: 60.3988\n",
      "Epoch 13922/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 51.5289 - val_loss: 60.3799\n",
      "Epoch 13923/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 51.5111 - val_loss: 60.3949\n",
      "Epoch 13924/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 51.4933 - val_loss: 60.3517\n",
      "Epoch 13925/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 51.4755 - val_loss: 60.3735\n",
      "Epoch 13926/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 51.4577 - val_loss: 60.3412\n",
      "Epoch 13927/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 51.4399 - val_loss: 60.3392\n",
      "Epoch 13928/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 51.4221 - val_loss: 60.3362\n",
      "Epoch 13929/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 51.4044 - val_loss: 60.3076\n",
      "Epoch 13930/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 51.3866 - val_loss: 60.3220\n",
      "Epoch 13931/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 51.3689 - val_loss: 60.2886\n",
      "Epoch 13932/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 51.3511 - val_loss: 60.2951\n",
      "Epoch 13933/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 51.3334 - val_loss: 60.2789\n",
      "Epoch 13934/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 51.3156 - val_loss: 60.2641\n",
      "Epoch 13935/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 51.2979 - val_loss: 60.2675\n",
      "Epoch 13936/100000\n",
      "11/11 [==============================] - 0s 253us/step - loss: 51.2802 - val_loss: 60.2395\n",
      "Epoch 13937/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 51.2625 - val_loss: 60.2469\n",
      "Epoch 13938/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 51.2448 - val_loss: 60.2240\n",
      "Epoch 13939/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 51.2271 - val_loss: 60.2195\n",
      "Epoch 13940/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 51.2095 - val_loss: 60.2118\n",
      "Epoch 13941/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 51.1918 - val_loss: 60.1929\n",
      "Epoch 13942/100000\n",
      "11/11 [==============================] - 0s 791us/step - loss: 51.1742 - val_loss: 60.1955\n",
      "Epoch 13943/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 51.1565 - val_loss: 60.1724\n",
      "Epoch 13944/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 51.1389 - val_loss: 60.1728\n",
      "Epoch 13945/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 51.1213 - val_loss: 60.1572\n",
      "Epoch 13946/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 51.1037 - val_loss: 60.1472\n",
      "Epoch 13947/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 51.0860 - val_loss: 60.1421\n",
      "Epoch 13948/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 51.0684 - val_loss: 60.1236\n",
      "Epoch 13949/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 51.0509 - val_loss: 60.1232\n",
      "Epoch 13950/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 51.0333 - val_loss: 60.1045\n",
      "Epoch 13951/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 51.0157 - val_loss: 60.1002\n",
      "Epoch 13952/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 50.9981 - val_loss: 60.0881\n",
      "Epoch 13953/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 50.9806 - val_loss: 60.0761\n",
      "Epoch 13954/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 50.9630 - val_loss: 60.0710\n",
      "Epoch 13955/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 50.9454 - val_loss: 60.0543\n",
      "Epoch 13956/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 50.9279 - val_loss: 60.0510\n",
      "Epoch 13957/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 50.9104 - val_loss: 60.0354\n",
      "Epoch 13958/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 50.8928 - val_loss: 60.0285\n",
      "Epoch 13959/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 50.8753 - val_loss: 60.0179\n",
      "Epoch 13960/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 50.8578 - val_loss: 60.0058\n",
      "Epoch 13961/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 50.8403 - val_loss: 59.9998\n",
      "Epoch 13962/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 50.8229 - val_loss: 59.9846\n",
      "Epoch 13963/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 50.8054 - val_loss: 59.9795\n",
      "Epoch 13964/100000\n",
      "11/11 [==============================] - 0s 604us/step - loss: 50.7879 - val_loss: 59.9654\n",
      "Epoch 13965/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 50.7705 - val_loss: 59.9577\n",
      "Epoch 13966/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 50.7530 - val_loss: 59.9470\n",
      "Epoch 13967/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 50.7355 - val_loss: 59.9356\n",
      "Epoch 13968/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 50.7181 - val_loss: 59.9283\n",
      "Epoch 13969/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 50.7007 - val_loss: 59.9146\n",
      "Epoch 13970/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 50.6833 - val_loss: 59.9081\n",
      "Epoch 13971/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 50.6659 - val_loss: 59.8949\n",
      "Epoch 13972/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 50.6485 - val_loss: 59.8868\n",
      "Epoch 13973/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 50.6311 - val_loss: 59.8760\n",
      "Epoch 13974/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 50.6137 - val_loss: 59.8653\n",
      "Epoch 13975/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 50.5963 - val_loss: 59.8567\n",
      "Epoch 13976/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 50.5789 - val_loss: 59.8444\n",
      "Epoch 13977/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 50.5616 - val_loss: 59.8366\n",
      "Epoch 13978/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 50.5442 - val_loss: 59.8243\n",
      "Epoch 13979/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 50.5269 - val_loss: 59.8158\n",
      "Epoch 13980/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 50.5095 - val_loss: 59.8048\n",
      "Epoch 13981/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 50.4922 - val_loss: 59.7946\n",
      "Epoch 13982/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 50.4748 - val_loss: 59.7852\n",
      "Epoch 13983/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 50.4575 - val_loss: 59.7736\n",
      "Epoch 13984/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 50.4402 - val_loss: 59.7652\n",
      "Epoch 13985/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 50.4229 - val_loss: 59.7532\n",
      "Epoch 13986/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 50.4056 - val_loss: 59.7446\n",
      "Epoch 13987/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 50.3883 - val_loss: 59.7333\n",
      "Epoch 13988/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 50.3711 - val_loss: 59.7236\n",
      "Epoch 13989/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 50.3538 - val_loss: 59.7135\n",
      "Epoch 13990/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 50.3365 - val_loss: 59.7026\n",
      "Epoch 13991/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 50.3193 - val_loss: 59.6935\n",
      "Epoch 13992/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 50.3020 - val_loss: 59.6821\n",
      "Epoch 13993/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 50.2848 - val_loss: 59.6730\n",
      "Epoch 13994/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 50.2676 - val_loss: 59.6619\n",
      "Epoch 13995/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 50.2504 - val_loss: 59.6523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13996/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 50.2331 - val_loss: 59.6417\n",
      "Epoch 13997/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 50.2159 - val_loss: 59.6315\n",
      "Epoch 13998/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 50.1987 - val_loss: 59.6216\n",
      "Epoch 13999/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 50.1816 - val_loss: 59.6107\n",
      "Epoch 14000/100000\n",
      "11/11 [==============================] - 0s 199us/step - loss: 50.1643 - val_loss: 59.6013\n",
      "Epoch 14001/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 50.1472 - val_loss: 59.5901\n",
      "Epoch 14002/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 50.1300 - val_loss: 59.5807\n",
      "Epoch 14003/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 50.1128 - val_loss: 59.5697\n",
      "Epoch 14004/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 50.0957 - val_loss: 59.5600\n",
      "Epoch 14005/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 50.0785 - val_loss: 59.5494\n",
      "Epoch 14006/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 50.0613 - val_loss: 59.5392\n",
      "Epoch 14007/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 50.0442 - val_loss: 59.5290\n",
      "Epoch 14008/100000\n",
      "11/11 [==============================] - 0s 203us/step - loss: 50.0271 - val_loss: 59.5185\n",
      "Epoch 14009/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 50.0099 - val_loss: 59.5084\n",
      "Epoch 14010/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 49.9928 - val_loss: 59.4979\n",
      "Epoch 14011/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 49.9757 - val_loss: 59.4876\n",
      "Epoch 14012/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 49.9586 - val_loss: 59.4774\n",
      "Epoch 14013/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 49.9415 - val_loss: 59.4670\n",
      "Epoch 14014/100000\n",
      "11/11 [==============================] - 0s 604us/step - loss: 49.9244 - val_loss: 59.4568\n",
      "Epoch 14015/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 49.9073 - val_loss: 59.4462\n",
      "Epoch 14016/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 49.8902 - val_loss: 59.4361\n",
      "Epoch 14017/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 49.8732 - val_loss: 59.4255\n",
      "Epoch 14018/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 49.8561 - val_loss: 59.4153\n",
      "Epoch 14019/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 49.8390 - val_loss: 59.4048\n",
      "Epoch 14020/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 49.8220 - val_loss: 59.3946\n",
      "Epoch 14021/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 49.8050 - val_loss: 59.3841\n",
      "Epoch 14022/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 49.7879 - val_loss: 59.3737\n",
      "Epoch 14023/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 49.7709 - val_loss: 59.3633\n",
      "Epoch 14024/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 49.7538 - val_loss: 59.3530\n",
      "Epoch 14025/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 49.7369 - val_loss: 59.3425\n",
      "Epoch 14026/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 49.7198 - val_loss: 59.3321\n",
      "Epoch 14027/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 49.7029 - val_loss: 59.3217\n",
      "Epoch 14028/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 49.6858 - val_loss: 59.3112\n",
      "Epoch 14029/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 49.6689 - val_loss: 59.3009\n",
      "Epoch 14030/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 49.6519 - val_loss: 59.2902\n",
      "Epoch 14031/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 49.6349 - val_loss: 59.2800\n",
      "Epoch 14032/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 49.6179 - val_loss: 59.2693\n",
      "Epoch 14033/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 49.6009 - val_loss: 59.2589\n",
      "Epoch 14034/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 49.5840 - val_loss: 59.2485\n",
      "Epoch 14035/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 49.5670 - val_loss: 59.2378\n",
      "Epoch 14036/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 49.5500 - val_loss: 59.2275\n",
      "Epoch 14037/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 49.5331 - val_loss: 59.2167\n",
      "Epoch 14038/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 49.5161 - val_loss: 59.2065\n",
      "Epoch 14039/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 49.4992 - val_loss: 59.1957\n",
      "Epoch 14040/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 49.4822 - val_loss: 59.1853\n",
      "Epoch 14041/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 49.4653 - val_loss: 59.1745\n",
      "Epoch 14042/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 49.4484 - val_loss: 59.1642\n",
      "Epoch 14043/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 49.4315 - val_loss: 59.1534\n",
      "Epoch 14044/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 49.4146 - val_loss: 59.1431\n",
      "Epoch 14045/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 49.3976 - val_loss: 59.1321\n",
      "Epoch 14046/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 49.3807 - val_loss: 59.1219\n",
      "Epoch 14047/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 49.3638 - val_loss: 59.1109\n",
      "Epoch 14048/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 49.3469 - val_loss: 59.1006\n",
      "Epoch 14049/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 49.3301 - val_loss: 59.0898\n",
      "Epoch 14050/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 49.3132 - val_loss: 59.0793\n",
      "Epoch 14051/100000\n",
      "11/11 [==============================] - 0s 602us/step - loss: 49.2963 - val_loss: 59.0685\n",
      "Epoch 14052/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 49.2794 - val_loss: 59.0578\n",
      "Epoch 14053/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 49.2625 - val_loss: 59.0473\n",
      "Epoch 14054/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 49.2456 - val_loss: 59.0362\n",
      "Epoch 14055/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 49.2288 - val_loss: 59.0261\n",
      "Epoch 14056/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 49.2120 - val_loss: 59.0147\n",
      "Epoch 14057/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 49.1951 - val_loss: 59.0047\n",
      "Epoch 14058/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 49.1783 - val_loss: 58.9931\n",
      "Epoch 14059/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 49.1614 - val_loss: 58.9833\n",
      "Epoch 14060/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 49.1446 - val_loss: 58.9717\n",
      "Epoch 14061/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 49.1278 - val_loss: 58.9616\n",
      "Epoch 14062/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 49.1110 - val_loss: 58.9503\n",
      "Epoch 14063/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 49.0941 - val_loss: 58.9398\n",
      "Epoch 14064/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 49.0773 - val_loss: 58.9289\n",
      "Epoch 14065/100000\n",
      "11/11 [==============================] - 0s 580us/step - loss: 49.0605 - val_loss: 58.9180\n",
      "Epoch 14066/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 49.0436 - val_loss: 58.9073\n",
      "Epoch 14067/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 49.0268 - val_loss: 58.8961\n",
      "Epoch 14068/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 49.0100 - val_loss: 58.8856\n",
      "Epoch 14069/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 48.9932 - val_loss: 58.8743\n",
      "Epoch 14070/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 48.9764 - val_loss: 58.8638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14071/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 48.9596 - val_loss: 58.8525\n",
      "Epoch 14072/100000\n",
      "11/11 [==============================] - 0s 730us/step - loss: 48.9428 - val_loss: 58.8419\n",
      "Epoch 14073/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 48.9260 - val_loss: 58.8307\n",
      "Epoch 14074/100000\n",
      "11/11 [==============================] - 0s 711us/step - loss: 48.9093 - val_loss: 58.8200\n",
      "Epoch 14075/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 48.8925 - val_loss: 58.8088\n",
      "Epoch 14076/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 48.8757 - val_loss: 58.7979\n",
      "Epoch 14077/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 48.8589 - val_loss: 58.7868\n",
      "Epoch 14078/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 48.8421 - val_loss: 58.7759\n",
      "Epoch 14079/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 48.8254 - val_loss: 58.7647\n",
      "Epoch 14080/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 48.8085 - val_loss: 58.7538\n",
      "Epoch 14081/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 48.7918 - val_loss: 58.7425\n",
      "Epoch 14082/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 48.7750 - val_loss: 58.7317\n",
      "Epoch 14083/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 48.7582 - val_loss: 58.7202\n",
      "Epoch 14084/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 48.7414 - val_loss: 58.7094\n",
      "Epoch 14085/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 48.7247 - val_loss: 58.6979\n",
      "Epoch 14086/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 48.7079 - val_loss: 58.6870\n",
      "Epoch 14087/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 48.6911 - val_loss: 58.6755\n",
      "Epoch 14088/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 48.6744 - val_loss: 58.6647\n",
      "Epoch 14089/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 48.6576 - val_loss: 58.6531\n",
      "Epoch 14090/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 48.6408 - val_loss: 58.6422\n",
      "Epoch 14091/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 48.6241 - val_loss: 58.6306\n",
      "Epoch 14092/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 48.6073 - val_loss: 58.6195\n",
      "Epoch 14093/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 48.5906 - val_loss: 58.6081\n",
      "Epoch 14094/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 48.5737 - val_loss: 58.5968\n",
      "Epoch 14095/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 48.5570 - val_loss: 58.5855\n",
      "Epoch 14096/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 48.5403 - val_loss: 58.5740\n",
      "Epoch 14097/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 48.5235 - val_loss: 58.5627\n",
      "Epoch 14098/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 48.5067 - val_loss: 58.5513\n",
      "Epoch 14099/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 48.4900 - val_loss: 58.5397\n",
      "Epoch 14100/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 48.4732 - val_loss: 58.5284\n",
      "Epoch 14101/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 48.4565 - val_loss: 58.5166\n",
      "Epoch 14102/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 48.4397 - val_loss: 58.5055\n",
      "Epoch 14103/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 48.4229 - val_loss: 58.4935\n",
      "Epoch 14104/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 48.4062 - val_loss: 58.4824\n",
      "Epoch 14105/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 48.3894 - val_loss: 58.4703\n",
      "Epoch 14106/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 48.3726 - val_loss: 58.4592\n",
      "Epoch 14107/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 48.3559 - val_loss: 58.4471\n",
      "Epoch 14108/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 48.3391 - val_loss: 58.4359\n",
      "Epoch 14109/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 48.3223 - val_loss: 58.4238\n",
      "Epoch 14110/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 48.3055 - val_loss: 58.4124\n",
      "Epoch 14111/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 48.2888 - val_loss: 58.4005\n",
      "Epoch 14112/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 48.2720 - val_loss: 58.3887\n",
      "Epoch 14113/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 48.2552 - val_loss: 58.3770\n",
      "Epoch 14114/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 48.2385 - val_loss: 58.3649\n",
      "Epoch 14115/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 48.2217 - val_loss: 58.3534\n",
      "Epoch 14116/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 48.2049 - val_loss: 58.3410\n",
      "Epoch 14117/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 48.1881 - val_loss: 58.3296\n",
      "Epoch 14118/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 48.1713 - val_loss: 58.3172\n",
      "Epoch 14119/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 48.1545 - val_loss: 58.3055\n",
      "Epoch 14120/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 48.1377 - val_loss: 58.2933\n",
      "Epoch 14121/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 48.1209 - val_loss: 58.2815\n",
      "Epoch 14122/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 48.1041 - val_loss: 58.2692\n",
      "Epoch 14123/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 48.0873 - val_loss: 58.2572\n",
      "Epoch 14124/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 48.0705 - val_loss: 58.2449\n",
      "Epoch 14125/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 48.0537 - val_loss: 58.2329\n",
      "Epoch 14126/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 48.0369 - val_loss: 58.2205\n",
      "Epoch 14127/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 48.0201 - val_loss: 58.2085\n",
      "Epoch 14128/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 48.0032 - val_loss: 58.1960\n",
      "Epoch 14129/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 47.9864 - val_loss: 58.1838\n",
      "Epoch 14130/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 47.9696 - val_loss: 58.1713\n",
      "Epoch 14131/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 47.9527 - val_loss: 58.1589\n",
      "Epoch 14132/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 47.9359 - val_loss: 58.1467\n",
      "Epoch 14133/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 47.9191 - val_loss: 58.1339\n",
      "Epoch 14134/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 47.9022 - val_loss: 58.1217\n",
      "Epoch 14135/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 47.8854 - val_loss: 58.1088\n",
      "Epoch 14136/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 47.8685 - val_loss: 58.0964\n",
      "Epoch 14137/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 47.8516 - val_loss: 58.0836\n",
      "Epoch 14138/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 47.8347 - val_loss: 58.0710\n",
      "Epoch 14139/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 47.8178 - val_loss: 58.0583\n",
      "Epoch 14140/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 47.8009 - val_loss: 58.0454\n",
      "Epoch 14141/100000\n",
      "11/11 [==============================] - 0s 287us/step - loss: 47.7840 - val_loss: 58.0329\n",
      "Epoch 14142/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 47.7672 - val_loss: 58.0196\n",
      "Epoch 14143/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 47.7502 - val_loss: 58.0072\n",
      "Epoch 14144/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 47.7333 - val_loss: 57.9937\n",
      "Epoch 14145/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 47.7164 - val_loss: 57.9812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14146/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 47.6994 - val_loss: 57.9677\n",
      "Epoch 14147/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 47.6825 - val_loss: 57.9548\n",
      "Epoch 14148/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 47.6656 - val_loss: 57.9416\n",
      "Epoch 14149/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 47.6485 - val_loss: 57.9282\n",
      "Epoch 14150/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 47.6316 - val_loss: 57.9153\n",
      "Epoch 14151/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 47.6146 - val_loss: 57.9017\n",
      "Epoch 14152/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 47.5976 - val_loss: 57.8884\n",
      "Epoch 14153/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 47.5806 - val_loss: 57.8751\n",
      "Epoch 14154/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 47.5636 - val_loss: 57.8613\n",
      "Epoch 14155/100000\n",
      "11/11 [==============================] - 0s 581us/step - loss: 47.5466 - val_loss: 57.8482\n",
      "Epoch 14156/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 47.5295 - val_loss: 57.8342\n",
      "Epoch 14157/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 47.5125 - val_loss: 57.8208\n",
      "Epoch 14158/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 47.4954 - val_loss: 57.8071\n",
      "Epoch 14159/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 47.4784 - val_loss: 57.7932\n",
      "Epoch 14160/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 47.4613 - val_loss: 57.7795\n",
      "Epoch 14161/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 47.4442 - val_loss: 57.7656\n",
      "Epoch 14162/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 47.4272 - val_loss: 57.7516\n",
      "Epoch 14163/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 47.4100 - val_loss: 57.7376\n",
      "Epoch 14164/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 47.3929 - val_loss: 57.7235\n",
      "Epoch 14165/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 47.3758 - val_loss: 57.7094\n",
      "Epoch 14166/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 47.3587 - val_loss: 57.6952\n",
      "Epoch 14167/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 47.3415 - val_loss: 57.6808\n",
      "Epoch 14168/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 47.3243 - val_loss: 57.6667\n",
      "Epoch 14169/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 47.3071 - val_loss: 57.6519\n",
      "Epoch 14170/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 47.2900 - val_loss: 57.6379\n",
      "Epoch 14171/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 47.2727 - val_loss: 57.6228\n",
      "Epoch 14172/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 47.2555 - val_loss: 57.6086\n",
      "Epoch 14173/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 47.2382 - val_loss: 57.5936\n",
      "Epoch 14174/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 47.2211 - val_loss: 57.5789\n",
      "Epoch 14175/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 47.2038 - val_loss: 57.5640\n",
      "Epoch 14176/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 47.1865 - val_loss: 57.5490\n",
      "Epoch 14177/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 47.1692 - val_loss: 57.5342\n",
      "Epoch 14178/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 47.1519 - val_loss: 57.5187\n",
      "Epoch 14179/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 47.1345 - val_loss: 57.5039\n",
      "Epoch 14180/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 47.1172 - val_loss: 57.4884\n",
      "Epoch 14181/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 47.0998 - val_loss: 57.4731\n",
      "Epoch 14182/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 47.0825 - val_loss: 57.4577\n",
      "Epoch 14183/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 47.0651 - val_loss: 57.4421\n",
      "Epoch 14184/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 47.0477 - val_loss: 57.4266\n",
      "Epoch 14185/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 47.0303 - val_loss: 57.4108\n",
      "Epoch 14186/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 47.0128 - val_loss: 57.3949\n",
      "Epoch 14187/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 46.9954 - val_loss: 57.3792\n",
      "Epoch 14188/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 46.9779 - val_loss: 57.3630\n",
      "Epoch 14189/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 46.9604 - val_loss: 57.3472\n",
      "Epoch 14190/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 46.9429 - val_loss: 57.3308\n",
      "Epoch 14191/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 46.9254 - val_loss: 57.3146\n",
      "Epoch 14192/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 46.9078 - val_loss: 57.2982\n",
      "Epoch 14193/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 46.8902 - val_loss: 57.2817\n",
      "Epoch 14194/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 46.8726 - val_loss: 57.2652\n",
      "Epoch 14195/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 46.8551 - val_loss: 57.2484\n",
      "Epoch 14196/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 46.8374 - val_loss: 57.2316\n",
      "Epoch 14197/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 46.8198 - val_loss: 57.2147\n",
      "Epoch 14198/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 46.8021 - val_loss: 57.1977\n",
      "Epoch 14199/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 46.7844 - val_loss: 57.1806\n",
      "Epoch 14200/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 46.7667 - val_loss: 57.1633\n",
      "Epoch 14201/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 46.7490 - val_loss: 57.1460\n",
      "Epoch 14202/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 46.7312 - val_loss: 57.1286\n",
      "Epoch 14203/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 46.7135 - val_loss: 57.1108\n",
      "Epoch 14204/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 46.6957 - val_loss: 57.0934\n",
      "Epoch 14205/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 46.6778 - val_loss: 57.0753\n",
      "Epoch 14206/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 46.6600 - val_loss: 57.0575\n",
      "Epoch 14207/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 46.6421 - val_loss: 57.0395\n",
      "Epoch 14208/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 46.6243 - val_loss: 57.0211\n",
      "Epoch 14209/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 46.6064 - val_loss: 57.0030\n",
      "Epoch 14210/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 46.5884 - val_loss: 56.9844\n",
      "Epoch 14211/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 46.5704 - val_loss: 56.9660\n",
      "Epoch 14212/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 46.5525 - val_loss: 56.9472\n",
      "Epoch 14213/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 46.5345 - val_loss: 56.9283\n",
      "Epoch 14214/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 46.5164 - val_loss: 56.9094\n",
      "Epoch 14215/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 46.4984 - val_loss: 56.8903\n",
      "Epoch 14216/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 46.4804 - val_loss: 56.8710\n",
      "Epoch 14217/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 46.4623 - val_loss: 56.8517\n",
      "Epoch 14218/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 46.4441 - val_loss: 56.8320\n",
      "Epoch 14219/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 46.4260 - val_loss: 56.8124\n",
      "Epoch 14220/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 46.4078 - val_loss: 56.7925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14221/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 46.3896 - val_loss: 56.7726\n",
      "Epoch 14222/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 46.3713 - val_loss: 56.7525\n",
      "Epoch 14223/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 46.3531 - val_loss: 56.7322\n",
      "Epoch 14224/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 46.3348 - val_loss: 56.7118\n",
      "Epoch 14225/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 46.3165 - val_loss: 56.6912\n",
      "Epoch 14226/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 46.2982 - val_loss: 56.6704\n",
      "Epoch 14227/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 46.2798 - val_loss: 56.6496\n",
      "Epoch 14228/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 46.2614 - val_loss: 56.6285\n",
      "Epoch 14229/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 46.2430 - val_loss: 56.6073\n",
      "Epoch 14230/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 46.2246 - val_loss: 56.5859\n",
      "Epoch 14231/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 46.2061 - val_loss: 56.5644\n",
      "Epoch 14232/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 46.1876 - val_loss: 56.5427\n",
      "Epoch 14233/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 46.1690 - val_loss: 56.5208\n",
      "Epoch 14234/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 46.1505 - val_loss: 56.4988\n",
      "Epoch 14235/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 46.1319 - val_loss: 56.4765\n",
      "Epoch 14236/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 46.1132 - val_loss: 56.4541\n",
      "Epoch 14237/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 46.0946 - val_loss: 56.4317\n",
      "Epoch 14238/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 46.0759 - val_loss: 56.4088\n",
      "Epoch 14239/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 46.0572 - val_loss: 56.3859\n",
      "Epoch 14240/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 46.0384 - val_loss: 56.3628\n",
      "Epoch 14241/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 46.0196 - val_loss: 56.3394\n",
      "Epoch 14242/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 46.0008 - val_loss: 56.3159\n",
      "Epoch 14243/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 45.9819 - val_loss: 56.2923\n",
      "Epoch 14244/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 45.9631 - val_loss: 56.2684\n",
      "Epoch 14245/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 45.9441 - val_loss: 56.2443\n",
      "Epoch 14246/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 45.9252 - val_loss: 56.2201\n",
      "Epoch 14247/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 45.9062 - val_loss: 56.1956\n",
      "Epoch 14248/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 45.8872 - val_loss: 56.1710\n",
      "Epoch 14249/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 45.8681 - val_loss: 56.1462\n",
      "Epoch 14250/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 45.8490 - val_loss: 56.1211\n",
      "Epoch 14251/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 45.8299 - val_loss: 56.0958\n",
      "Epoch 14252/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 45.8107 - val_loss: 56.0704\n",
      "Epoch 14253/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 45.7915 - val_loss: 56.0447\n",
      "Epoch 14254/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 45.7722 - val_loss: 56.0187\n",
      "Epoch 14255/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 45.7530 - val_loss: 55.9927\n",
      "Epoch 14256/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 45.7336 - val_loss: 55.9663\n",
      "Epoch 14257/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 45.7142 - val_loss: 55.9398\n",
      "Epoch 14258/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 45.6948 - val_loss: 55.9132\n",
      "Epoch 14259/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 45.6754 - val_loss: 55.8861\n",
      "Epoch 14260/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 45.6559 - val_loss: 55.8589\n",
      "Epoch 14261/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 45.6364 - val_loss: 55.8315\n",
      "Epoch 14262/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 45.6168 - val_loss: 55.8037\n",
      "Epoch 14263/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 45.5972 - val_loss: 55.7760\n",
      "Epoch 14264/100000\n",
      "11/11 [==============================] - 0s 238us/step - loss: 45.5775 - val_loss: 55.7477\n",
      "Epoch 14265/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 45.5578 - val_loss: 55.7194\n",
      "Epoch 14266/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 45.5380 - val_loss: 55.6909\n",
      "Epoch 14267/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 45.5182 - val_loss: 55.6619\n",
      "Epoch 14268/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 45.4983 - val_loss: 55.6329\n",
      "Epoch 14269/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 45.4784 - val_loss: 55.6035\n",
      "Epoch 14270/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 45.4585 - val_loss: 55.5739\n",
      "Epoch 14271/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 45.4385 - val_loss: 55.5440\n",
      "Epoch 14272/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 45.4184 - val_loss: 55.5140\n",
      "Epoch 14273/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 45.3983 - val_loss: 55.4835\n",
      "Epoch 14274/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 45.3781 - val_loss: 55.4529\n",
      "Epoch 14275/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 45.3579 - val_loss: 55.4220\n",
      "Epoch 14276/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 45.3376 - val_loss: 55.3909\n",
      "Epoch 14277/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 45.3173 - val_loss: 55.3595\n",
      "Epoch 14278/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 45.2969 - val_loss: 55.3277\n",
      "Epoch 14279/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 45.2765 - val_loss: 55.2958\n",
      "Epoch 14280/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 45.2560 - val_loss: 55.2635\n",
      "Epoch 14281/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 45.2354 - val_loss: 55.2310\n",
      "Epoch 14282/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 45.2148 - val_loss: 55.1981\n",
      "Epoch 14283/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 45.1941 - val_loss: 55.1649\n",
      "Epoch 14284/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 45.1734 - val_loss: 55.1316\n",
      "Epoch 14285/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 45.1525 - val_loss: 55.0978\n",
      "Epoch 14286/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 45.1316 - val_loss: 55.0637\n",
      "Epoch 14287/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 45.1107 - val_loss: 55.0295\n",
      "Epoch 14288/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 45.0897 - val_loss: 54.9947\n",
      "Epoch 14289/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 45.0686 - val_loss: 54.9598\n",
      "Epoch 14290/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 45.0474 - val_loss: 54.9245\n",
      "Epoch 14291/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 45.0261 - val_loss: 54.8888\n",
      "Epoch 14292/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 45.0048 - val_loss: 54.8530\n",
      "Epoch 14293/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 44.9834 - val_loss: 54.8167\n",
      "Epoch 14294/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 44.9619 - val_loss: 54.7800\n",
      "Epoch 14295/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 44.9403 - val_loss: 54.7431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14296/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 44.9187 - val_loss: 54.7058\n",
      "Epoch 14297/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 44.8969 - val_loss: 54.6680\n",
      "Epoch 14298/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 44.8751 - val_loss: 54.6302\n",
      "Epoch 14299/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 44.8532 - val_loss: 54.5918\n",
      "Epoch 14300/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 44.8312 - val_loss: 54.5530\n",
      "Epoch 14301/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 44.8091 - val_loss: 54.5140\n",
      "Epoch 14302/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 44.7868 - val_loss: 54.4744\n",
      "Epoch 14303/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 44.7645 - val_loss: 54.4346\n",
      "Epoch 14304/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 44.7422 - val_loss: 54.3945\n",
      "Epoch 14305/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 44.7196 - val_loss: 54.3538\n",
      "Epoch 14306/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 44.6970 - val_loss: 54.3128\n",
      "Epoch 14307/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 44.6743 - val_loss: 54.2715\n",
      "Epoch 14308/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 44.6515 - val_loss: 54.2296\n",
      "Epoch 14309/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 44.6286 - val_loss: 54.1874\n",
      "Epoch 14310/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 44.6055 - val_loss: 54.1449\n",
      "Epoch 14311/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 44.5824 - val_loss: 54.1017\n",
      "Epoch 14312/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 44.5591 - val_loss: 54.0583\n",
      "Epoch 14313/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 44.5357 - val_loss: 54.0144\n",
      "Epoch 14314/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 44.5121 - val_loss: 53.9700\n",
      "Epoch 14315/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 44.4884 - val_loss: 53.9255\n",
      "Epoch 14316/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 44.4647 - val_loss: 53.8802\n",
      "Epoch 14317/100000\n",
      "11/11 [==============================] - 0s 664us/step - loss: 44.4407 - val_loss: 53.8346\n",
      "Epoch 14318/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 44.4167 - val_loss: 53.7887\n",
      "Epoch 14319/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 44.3925 - val_loss: 53.7420\n",
      "Epoch 14320/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 44.3681 - val_loss: 53.6952\n",
      "Epoch 14321/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 44.3436 - val_loss: 53.6478\n",
      "Epoch 14322/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 44.3190 - val_loss: 53.5998\n",
      "Epoch 14323/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 44.2941 - val_loss: 53.5516\n",
      "Epoch 14324/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 44.2692 - val_loss: 53.5029\n",
      "Epoch 14325/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 44.2440 - val_loss: 53.4535\n",
      "Epoch 14326/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 44.2188 - val_loss: 53.4040\n",
      "Epoch 14327/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 44.1933 - val_loss: 53.3537\n",
      "Epoch 14328/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 44.1677 - val_loss: 53.3031\n",
      "Epoch 14329/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 44.1419 - val_loss: 53.2522\n",
      "Epoch 14330/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 44.1160 - val_loss: 53.2007\n",
      "Epoch 14331/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 44.0899 - val_loss: 53.1487\n",
      "Epoch 14332/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 44.0635 - val_loss: 53.0964\n",
      "Epoch 14333/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 44.0370 - val_loss: 53.0436\n",
      "Epoch 14334/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 44.0103 - val_loss: 52.9904\n",
      "Epoch 14335/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 43.9835 - val_loss: 52.9367\n",
      "Epoch 14336/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 43.9564 - val_loss: 52.8826\n",
      "Epoch 14337/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 43.9291 - val_loss: 52.8281\n",
      "Epoch 14338/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 43.9017 - val_loss: 52.7733\n",
      "Epoch 14339/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 43.8740 - val_loss: 52.7181\n",
      "Epoch 14340/100000\n",
      "11/11 [==============================] - 0s 217us/step - loss: 43.8462 - val_loss: 52.6625\n",
      "Epoch 14341/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 43.8181 - val_loss: 52.6066\n",
      "Epoch 14342/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 43.7898 - val_loss: 52.5504\n",
      "Epoch 14343/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 43.7613 - val_loss: 52.4939\n",
      "Epoch 14344/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 43.7327 - val_loss: 52.4371\n",
      "Epoch 14345/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 43.7038 - val_loss: 52.3802\n",
      "Epoch 14346/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 43.6747 - val_loss: 52.3228\n",
      "Epoch 14347/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 43.6454 - val_loss: 52.2654\n",
      "Epoch 14348/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 43.6159 - val_loss: 52.2079\n",
      "Epoch 14349/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 43.5862 - val_loss: 52.1501\n",
      "Epoch 14350/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 43.5563 - val_loss: 52.0924\n",
      "Epoch 14351/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 43.5261 - val_loss: 52.0348\n",
      "Epoch 14352/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 43.4959 - val_loss: 51.9768\n",
      "Epoch 14353/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 43.4653 - val_loss: 51.9193\n",
      "Epoch 14354/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 43.4346 - val_loss: 51.8618\n",
      "Epoch 14355/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 43.4038 - val_loss: 51.8042\n",
      "Epoch 14356/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 43.3727 - val_loss: 51.7472\n",
      "Epoch 14357/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 43.3415 - val_loss: 51.6902\n",
      "Epoch 14358/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 43.3101 - val_loss: 51.6335\n",
      "Epoch 14359/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 43.2786 - val_loss: 51.5774\n",
      "Epoch 14360/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 43.2469 - val_loss: 51.5216\n",
      "Epoch 14361/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 43.2151 - val_loss: 51.4662\n",
      "Epoch 14362/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 43.1831 - val_loss: 51.4116\n",
      "Epoch 14363/100000\n",
      "11/11 [==============================] - 0s 564us/step - loss: 43.1510 - val_loss: 51.3574\n",
      "Epoch 14364/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 43.1189 - val_loss: 51.3040\n",
      "Epoch 14365/100000\n",
      "11/11 [==============================] - 0s 655us/step - loss: 43.0866 - val_loss: 51.2513\n",
      "Epoch 14366/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 43.0543 - val_loss: 51.1993\n",
      "Epoch 14367/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 43.0219 - val_loss: 51.1482\n",
      "Epoch 14368/100000\n",
      "11/11 [==============================] - 0s 877us/step - loss: 42.9895 - val_loss: 51.0979\n",
      "Epoch 14369/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 42.9570 - val_loss: 51.0484\n",
      "Epoch 14370/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 42.9245 - val_loss: 51.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14371/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 42.8920 - val_loss: 50.9524\n",
      "Epoch 14372/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 42.8596 - val_loss: 50.9058\n",
      "Epoch 14373/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 42.8271 - val_loss: 50.8601\n",
      "Epoch 14374/100000\n",
      "11/11 [==============================] - 0s 793us/step - loss: 42.7947 - val_loss: 50.8156\n",
      "Epoch 14375/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 42.7624 - val_loss: 50.7719\n",
      "Epoch 14376/100000\n",
      "11/11 [==============================] - 0s 707us/step - loss: 42.7301 - val_loss: 50.7291\n",
      "Epoch 14377/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 42.6979 - val_loss: 50.6873\n",
      "Epoch 14378/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 42.6658 - val_loss: 50.6463\n",
      "Epoch 14379/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 42.6338 - val_loss: 50.6061\n",
      "Epoch 14380/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 42.6018 - val_loss: 50.5669\n",
      "Epoch 14381/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 42.5701 - val_loss: 50.5283\n",
      "Epoch 14382/100000\n",
      "11/11 [==============================] - 0s 708us/step - loss: 42.5384 - val_loss: 50.4903\n",
      "Epoch 14383/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 42.5069 - val_loss: 50.4530\n",
      "Epoch 14384/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 42.4754 - val_loss: 50.4163\n",
      "Epoch 14385/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 42.4441 - val_loss: 50.3799\n",
      "Epoch 14386/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 42.4129 - val_loss: 50.3441\n",
      "Epoch 14387/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 42.3818 - val_loss: 50.3086\n",
      "Epoch 14388/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 42.3508 - val_loss: 50.2734\n",
      "Epoch 14389/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 42.3199 - val_loss: 50.2383\n",
      "Epoch 14390/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 42.2891 - val_loss: 50.2035\n",
      "Epoch 14391/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 42.2583 - val_loss: 50.1688\n",
      "Epoch 14392/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 42.2277 - val_loss: 50.1343\n",
      "Epoch 14393/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 42.1970 - val_loss: 50.0996\n",
      "Epoch 14394/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 42.1665 - val_loss: 50.0653\n",
      "Epoch 14395/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 42.1359 - val_loss: 50.0309\n",
      "Epoch 14396/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 42.1055 - val_loss: 49.9965\n",
      "Epoch 14397/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 42.0750 - val_loss: 49.9623\n",
      "Epoch 14398/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 42.0445 - val_loss: 49.9281\n",
      "Epoch 14399/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 42.0141 - val_loss: 49.8941\n",
      "Epoch 14400/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 41.9837 - val_loss: 49.8602\n",
      "Epoch 14401/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 41.9533 - val_loss: 49.8264\n",
      "Epoch 14402/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 41.9229 - val_loss: 49.7929\n",
      "Epoch 14403/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 41.8924 - val_loss: 49.7595\n",
      "Epoch 14404/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 41.8620 - val_loss: 49.7265\n",
      "Epoch 14405/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 41.8315 - val_loss: 49.6937\n",
      "Epoch 14406/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 41.8011 - val_loss: 49.6610\n",
      "Epoch 14407/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 41.7706 - val_loss: 49.6288\n",
      "Epoch 14408/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 41.7401 - val_loss: 49.5969\n",
      "Epoch 14409/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 41.7097 - val_loss: 49.5652\n",
      "Epoch 14410/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 41.6792 - val_loss: 49.5338\n",
      "Epoch 14411/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 41.6487 - val_loss: 49.5028\n",
      "Epoch 14412/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 41.6182 - val_loss: 49.4719\n",
      "Epoch 14413/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 41.5876 - val_loss: 49.4414\n",
      "Epoch 14414/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 41.5571 - val_loss: 49.4111\n",
      "Epoch 14415/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 41.5267 - val_loss: 49.3809\n",
      "Epoch 14416/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 41.4962 - val_loss: 49.3510\n",
      "Epoch 14417/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 41.4657 - val_loss: 49.3212\n",
      "Epoch 14418/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 41.4352 - val_loss: 49.2915\n",
      "Epoch 14419/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 41.4047 - val_loss: 49.2620\n",
      "Epoch 14420/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 41.3742 - val_loss: 49.2324\n",
      "Epoch 14421/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 41.3438 - val_loss: 49.2029\n",
      "Epoch 14422/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 41.3133 - val_loss: 49.1735\n",
      "Epoch 14423/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 41.2828 - val_loss: 49.1439\n",
      "Epoch 14424/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 41.2523 - val_loss: 49.1145\n",
      "Epoch 14425/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 41.2219 - val_loss: 49.0848\n",
      "Epoch 14426/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 41.1914 - val_loss: 49.0553\n",
      "Epoch 14427/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 41.1610 - val_loss: 49.0256\n",
      "Epoch 14428/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 41.1306 - val_loss: 48.9958\n",
      "Epoch 14429/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 41.1002 - val_loss: 48.9662\n",
      "Epoch 14430/100000\n",
      "11/11 [==============================] - 0s 718us/step - loss: 41.0698 - val_loss: 48.9362\n",
      "Epoch 14431/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 41.0394 - val_loss: 48.9065\n",
      "Epoch 14432/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 41.0090 - val_loss: 48.8766\n",
      "Epoch 14433/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 40.9786 - val_loss: 48.8467\n",
      "Epoch 14434/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 40.9483 - val_loss: 48.8170\n",
      "Epoch 14435/100000\n",
      "11/11 [==============================] - 0s 235us/step - loss: 40.9179 - val_loss: 48.7869\n",
      "Epoch 14436/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 40.8876 - val_loss: 48.7573\n",
      "Epoch 14437/100000\n",
      "11/11 [==============================] - 0s 630us/step - loss: 40.8572 - val_loss: 48.7274\n",
      "Epoch 14438/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 40.8269 - val_loss: 48.6978\n",
      "Epoch 14439/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 40.7966 - val_loss: 48.6681\n",
      "Epoch 14440/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 40.7664 - val_loss: 48.6386\n",
      "Epoch 14441/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 40.7361 - val_loss: 48.6092\n",
      "Epoch 14442/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 40.7058 - val_loss: 48.5798\n",
      "Epoch 14443/100000\n",
      "11/11 [==============================] - 0s 680us/step - loss: 40.6755 - val_loss: 48.5506\n",
      "Epoch 14444/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 40.6453 - val_loss: 48.5214\n",
      "Epoch 14445/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 40.6151 - val_loss: 48.4925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14446/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 40.5849 - val_loss: 48.4634\n",
      "Epoch 14447/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 40.5547 - val_loss: 48.4348\n",
      "Epoch 14448/100000\n",
      "11/11 [==============================] - 0s 862us/step - loss: 40.5245 - val_loss: 48.4060\n",
      "Epoch 14449/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 40.4944 - val_loss: 48.3777\n",
      "Epoch 14450/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 40.4643 - val_loss: 48.3490\n",
      "Epoch 14451/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 40.4341 - val_loss: 48.3208\n",
      "Epoch 14452/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 40.4041 - val_loss: 48.2926\n",
      "Epoch 14453/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 40.3740 - val_loss: 48.2644\n",
      "Epoch 14454/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 40.3439 - val_loss: 48.2365\n",
      "Epoch 14455/100000\n",
      "11/11 [==============================] - 0s 733us/step - loss: 40.3139 - val_loss: 48.2083\n",
      "Epoch 14456/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 40.2839 - val_loss: 48.1807\n",
      "Epoch 14457/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 40.2539 - val_loss: 48.1527\n",
      "Epoch 14458/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 40.2239 - val_loss: 48.1251\n",
      "Epoch 14459/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 40.1940 - val_loss: 48.0974\n",
      "Epoch 14460/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 40.1640 - val_loss: 48.0697\n",
      "Epoch 14461/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 40.1341 - val_loss: 48.0424\n",
      "Epoch 14462/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 40.1042 - val_loss: 48.0146\n",
      "Epoch 14463/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 40.0743 - val_loss: 47.9874\n",
      "Epoch 14464/100000\n",
      "11/11 [==============================] - 0s 619us/step - loss: 40.0445 - val_loss: 47.9599\n",
      "Epoch 14465/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 40.0146 - val_loss: 47.9327\n",
      "Epoch 14466/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 39.9848 - val_loss: 47.9054\n",
      "Epoch 14467/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 39.9551 - val_loss: 47.8783\n",
      "Epoch 14468/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 39.9253 - val_loss: 47.8511\n",
      "Epoch 14469/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 39.8956 - val_loss: 47.8242\n",
      "Epoch 14470/100000\n",
      "11/11 [==============================] - 0s 249us/step - loss: 39.8659 - val_loss: 47.7971\n",
      "Epoch 14471/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 39.8362 - val_loss: 47.7703\n",
      "Epoch 14472/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 39.8065 - val_loss: 47.7434\n",
      "Epoch 14473/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 39.7769 - val_loss: 47.7168\n",
      "Epoch 14474/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 39.7473 - val_loss: 47.6900\n",
      "Epoch 14475/100000\n",
      "11/11 [==============================] - 0s 678us/step - loss: 39.7177 - val_loss: 47.6634\n",
      "Epoch 14476/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 39.6882 - val_loss: 47.6369\n",
      "Epoch 14477/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 39.6587 - val_loss: 47.6103\n",
      "Epoch 14478/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 39.6291 - val_loss: 47.5842\n",
      "Epoch 14479/100000\n",
      "11/11 [==============================] - 0s 582us/step - loss: 39.5997 - val_loss: 47.5577\n",
      "Epoch 14480/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 39.5702 - val_loss: 47.5318\n",
      "Epoch 14481/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 39.5408 - val_loss: 47.5054\n",
      "Epoch 14482/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 39.5114 - val_loss: 47.4796\n",
      "Epoch 14483/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 39.4820 - val_loss: 47.4535\n",
      "Epoch 14484/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 39.4527 - val_loss: 47.4277\n",
      "Epoch 14485/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 39.4234 - val_loss: 47.4018\n",
      "Epoch 14486/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 39.3941 - val_loss: 47.3760\n",
      "Epoch 14487/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 39.3648 - val_loss: 47.3506\n",
      "Epoch 14488/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 39.3356 - val_loss: 47.3248\n",
      "Epoch 14489/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 39.3065 - val_loss: 47.2995\n",
      "Epoch 14490/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 39.2773 - val_loss: 47.2739\n",
      "Epoch 14491/100000\n",
      "11/11 [==============================] - 0s 593us/step - loss: 39.2481 - val_loss: 47.2487\n",
      "Epoch 14492/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 39.2190 - val_loss: 47.2232\n",
      "Epoch 14493/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 39.1899 - val_loss: 47.1980\n",
      "Epoch 14494/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 39.1609 - val_loss: 47.1729\n",
      "Epoch 14495/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 39.1319 - val_loss: 47.1477\n",
      "Epoch 14496/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 39.1028 - val_loss: 47.1228\n",
      "Epoch 14497/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 39.0739 - val_loss: 47.0977\n",
      "Epoch 14498/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 39.0449 - val_loss: 47.0729\n",
      "Epoch 14499/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 39.0160 - val_loss: 47.0480\n",
      "Epoch 14500/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 38.9872 - val_loss: 47.0232\n",
      "Epoch 14501/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 38.9583 - val_loss: 46.9984\n",
      "Epoch 14502/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 38.9295 - val_loss: 46.9738\n",
      "Epoch 14503/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 38.9007 - val_loss: 46.9491\n",
      "Epoch 14504/100000\n",
      "11/11 [==============================] - 0s 604us/step - loss: 38.8719 - val_loss: 46.9246\n",
      "Epoch 14505/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 38.8433 - val_loss: 46.9001\n",
      "Epoch 14506/100000\n",
      "11/11 [==============================] - 0s 702us/step - loss: 38.8145 - val_loss: 46.8757\n",
      "Epoch 14507/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 38.7859 - val_loss: 46.8513\n",
      "Epoch 14508/100000\n",
      "11/11 [==============================] - 0s 579us/step - loss: 38.7573 - val_loss: 46.8271\n",
      "Epoch 14509/100000\n",
      "11/11 [==============================] - 0s 623us/step - loss: 38.7286 - val_loss: 46.8026\n",
      "Epoch 14510/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 38.7001 - val_loss: 46.7788\n",
      "Epoch 14511/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 38.6715 - val_loss: 46.7542\n",
      "Epoch 14512/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 38.6430 - val_loss: 46.7307\n",
      "Epoch 14513/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 38.6146 - val_loss: 46.7061\n",
      "Epoch 14514/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 38.5861 - val_loss: 46.6828\n",
      "Epoch 14515/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 38.5576 - val_loss: 46.6584\n",
      "Epoch 14516/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 38.5293 - val_loss: 46.6351\n",
      "Epoch 14517/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 38.5009 - val_loss: 46.6108\n",
      "Epoch 14518/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 38.4726 - val_loss: 46.5876\n",
      "Epoch 14519/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 38.4443 - val_loss: 46.5636\n",
      "Epoch 14520/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 38.4161 - val_loss: 46.5403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14521/100000\n",
      "11/11 [==============================] - 0s 643us/step - loss: 38.3878 - val_loss: 46.5166\n",
      "Epoch 14522/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 38.3596 - val_loss: 46.4933\n",
      "Epoch 14523/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 38.3314 - val_loss: 46.4699\n",
      "Epoch 14524/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 38.3033 - val_loss: 46.4466\n",
      "Epoch 14525/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 38.2752 - val_loss: 46.4233\n",
      "Epoch 14526/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 38.2471 - val_loss: 46.4001\n",
      "Epoch 14527/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 38.2190 - val_loss: 46.3769\n",
      "Epoch 14528/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 38.1910 - val_loss: 46.3538\n",
      "Epoch 14529/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 38.1630 - val_loss: 46.3309\n",
      "Epoch 14530/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 38.1351 - val_loss: 46.3078\n",
      "Epoch 14531/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 38.1072 - val_loss: 46.2850\n",
      "Epoch 14532/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 38.0793 - val_loss: 46.2619\n",
      "Epoch 14533/100000\n",
      "11/11 [==============================] - 0s 700us/step - loss: 38.0514 - val_loss: 46.2396\n",
      "Epoch 14534/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 38.0236 - val_loss: 46.2162\n",
      "Epoch 14535/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 37.9958 - val_loss: 46.1943\n",
      "Epoch 14536/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 37.9680 - val_loss: 46.1707\n",
      "Epoch 14537/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 37.9403 - val_loss: 46.1492\n",
      "Epoch 14538/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 37.9126 - val_loss: 46.1254\n",
      "Epoch 14539/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 37.8849 - val_loss: 46.1045\n",
      "Epoch 14540/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 37.8573 - val_loss: 46.0802\n",
      "Epoch 14541/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 37.8297 - val_loss: 46.0600\n",
      "Epoch 14542/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 37.8021 - val_loss: 46.0352\n",
      "Epoch 14543/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 37.7746 - val_loss: 46.0159\n",
      "Epoch 14544/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 37.7471 - val_loss: 45.9901\n",
      "Epoch 14545/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 37.7196 - val_loss: 45.9724\n",
      "Epoch 14546/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 37.6921 - val_loss: 45.9448\n",
      "Epoch 14547/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 37.6647 - val_loss: 45.9295\n",
      "Epoch 14548/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 37.6373 - val_loss: 45.8992\n",
      "Epoch 14549/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 37.6100 - val_loss: 45.8874\n",
      "Epoch 14550/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 37.5826 - val_loss: 45.8529\n",
      "Epoch 14551/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 37.5554 - val_loss: 45.8469\n",
      "Epoch 14552/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 37.5281 - val_loss: 45.8054\n",
      "Epoch 14553/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 37.5009 - val_loss: 45.8082\n",
      "Epoch 14554/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 37.4738 - val_loss: 45.7560\n",
      "Epoch 14555/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 37.4466 - val_loss: 45.7721\n",
      "Epoch 14556/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 37.4195 - val_loss: 45.7045\n",
      "Epoch 14557/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 37.3924 - val_loss: 45.7381\n",
      "Epoch 14558/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 37.3654 - val_loss: 45.6528\n",
      "Epoch 14559/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 37.3384 - val_loss: 45.7020\n",
      "Epoch 14560/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 37.3115 - val_loss: 45.6079\n",
      "Epoch 14561/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 37.2845 - val_loss: 45.6542\n",
      "Epoch 14562/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 37.2574 - val_loss: 45.5786\n",
      "Epoch 14563/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 37.2304 - val_loss: 45.5907\n",
      "Epoch 14564/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 37.2034 - val_loss: 45.5604\n",
      "Epoch 14565/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 37.1765 - val_loss: 45.5244\n",
      "Epoch 14566/100000\n",
      "11/11 [==============================] - 0s 709us/step - loss: 37.1498 - val_loss: 45.5366\n",
      "Epoch 14567/100000\n",
      "11/11 [==============================] - 0s 630us/step - loss: 37.1230 - val_loss: 45.4717\n",
      "Epoch 14568/100000\n",
      "11/11 [==============================] - 0s 895us/step - loss: 37.0963 - val_loss: 45.4955\n",
      "Epoch 14569/100000\n",
      "11/11 [==============================] - 0s 742us/step - loss: 37.0695 - val_loss: 45.4382\n",
      "Epoch 14570/100000\n",
      "11/11 [==============================] - 0s 697us/step - loss: 37.0428 - val_loss: 45.4382\n",
      "Epoch 14571/100000\n",
      "11/11 [==============================] - 0s 900us/step - loss: 37.0160 - val_loss: 45.4150\n",
      "Epoch 14572/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 36.9894 - val_loss: 45.3792\n",
      "Epoch 14573/100000\n",
      "11/11 [==============================] - 0s 835us/step - loss: 36.9628 - val_loss: 45.3854\n",
      "Epoch 14574/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.9363 - val_loss: 45.3327\n",
      "Epoch 14575/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.9097 - val_loss: 45.3407\n",
      "Epoch 14576/100000\n",
      "11/11 [==============================] - 0s 686us/step - loss: 36.8831 - val_loss: 45.3007\n",
      "Epoch 14577/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.8566 - val_loss: 45.2863\n",
      "Epoch 14578/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 36.8302 - val_loss: 45.2729\n",
      "Epoch 14579/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.8037 - val_loss: 45.2349\n",
      "Epoch 14580/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 36.7773 - val_loss: 45.2370\n",
      "Epoch 14581/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.7510 - val_loss: 45.1948\n",
      "Epoch 14582/100000\n",
      "11/11 [==============================] - 0s 755us/step - loss: 36.7246 - val_loss: 45.1902\n",
      "Epoch 14583/100000\n",
      "11/11 [==============================] - 0s 809us/step - loss: 36.6983 - val_loss: 45.1631\n",
      "Epoch 14584/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 36.6720 - val_loss: 45.1395\n",
      "Epoch 14585/100000\n",
      "11/11 [==============================] - 0s 762us/step - loss: 36.6457 - val_loss: 45.1305\n",
      "Epoch 14586/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 36.6195 - val_loss: 45.0944\n",
      "Epoch 14587/100000\n",
      "11/11 [==============================] - 0s 749us/step - loss: 36.5933 - val_loss: 45.0903\n",
      "Epoch 14588/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 36.5671 - val_loss: 45.0576\n",
      "Epoch 14589/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 36.5410 - val_loss: 45.0438\n",
      "Epoch 14590/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 36.5149 - val_loss: 45.0246\n",
      "Epoch 14591/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 36.4888 - val_loss: 44.9975\n",
      "Epoch 14592/100000\n",
      "11/11 [==============================] - 0s 503us/step - loss: 36.4627 - val_loss: 44.9884\n",
      "Epoch 14593/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 36.4367 - val_loss: 44.9565\n",
      "Epoch 14594/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 36.4107 - val_loss: 44.9465\n",
      "Epoch 14595/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 36.3847 - val_loss: 44.9207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14596/100000\n",
      "11/11 [==============================] - 0s 746us/step - loss: 36.3588 - val_loss: 44.9017\n",
      "Epoch 14597/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 36.3329 - val_loss: 44.8859\n",
      "Epoch 14598/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 36.3070 - val_loss: 44.8588\n",
      "Epoch 14599/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 36.2812 - val_loss: 44.8478\n",
      "Epoch 14600/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 36.2553 - val_loss: 44.8201\n",
      "Epoch 14601/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 36.2295 - val_loss: 44.8060\n",
      "Epoch 14602/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 36.2037 - val_loss: 44.7842\n",
      "Epoch 14603/100000\n",
      "11/11 [==============================] - 0s 610us/step - loss: 36.1780 - val_loss: 44.7632\n",
      "Epoch 14604/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 36.1523 - val_loss: 44.7480\n",
      "Epoch 14605/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 36.1266 - val_loss: 44.7225\n",
      "Epoch 14606/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 36.1009 - val_loss: 44.7092\n",
      "Epoch 14607/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 36.0753 - val_loss: 44.6847\n",
      "Epoch 14608/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 36.0497 - val_loss: 44.6682\n",
      "Epoch 14609/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 36.0242 - val_loss: 44.6486\n",
      "Epoch 14610/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 35.9986 - val_loss: 44.6272\n",
      "Epoch 14611/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 35.9731 - val_loss: 44.6117\n",
      "Epoch 14612/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 35.9476 - val_loss: 44.5878\n",
      "Epoch 14613/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 35.9221 - val_loss: 44.5728\n",
      "Epoch 14614/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 35.8967 - val_loss: 44.5506\n",
      "Epoch 14615/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 35.8713 - val_loss: 44.5328\n",
      "Epoch 14616/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 35.8459 - val_loss: 44.5142\n",
      "Epoch 14617/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 35.8206 - val_loss: 44.4929\n",
      "Epoch 14618/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 35.7952 - val_loss: 44.4770\n",
      "Epoch 14619/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 35.7700 - val_loss: 44.4546\n",
      "Epoch 14620/100000\n",
      "11/11 [==============================] - 0s 765us/step - loss: 35.7447 - val_loss: 44.4385\n",
      "Epoch 14621/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 35.7194 - val_loss: 44.4177\n",
      "Epoch 14622/100000\n",
      "11/11 [==============================] - 0s 630us/step - loss: 35.6942 - val_loss: 44.3994\n",
      "Epoch 14623/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 35.6690 - val_loss: 44.3811\n",
      "Epoch 14624/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 35.6438 - val_loss: 44.3607\n",
      "Epoch 14625/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 35.6187 - val_loss: 44.3440\n",
      "Epoch 14626/100000\n",
      "11/11 [==============================] - 0s 674us/step - loss: 35.5936 - val_loss: 44.3230\n",
      "Epoch 14627/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 35.5685 - val_loss: 44.3062\n",
      "Epoch 14628/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 35.5434 - val_loss: 44.2861\n",
      "Epoch 14629/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 35.5184 - val_loss: 44.2679\n",
      "Epoch 14630/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 35.4934 - val_loss: 44.2496\n",
      "Epoch 14631/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 35.4685 - val_loss: 44.2300\n",
      "Epoch 14632/100000\n",
      "11/11 [==============================] - 0s 901us/step - loss: 35.4435 - val_loss: 44.2128\n",
      "Epoch 14633/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 35.4185 - val_loss: 44.1927\n",
      "Epoch 14634/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 35.3936 - val_loss: 44.1755\n",
      "Epoch 14635/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 35.3688 - val_loss: 44.1561\n",
      "Epoch 14636/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 35.3439 - val_loss: 44.1379\n",
      "Epoch 14637/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 35.3191 - val_loss: 44.1198\n",
      "Epoch 14638/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 35.2943 - val_loss: 44.1006\n",
      "Epoch 14639/100000\n",
      "11/11 [==============================] - 0s 651us/step - loss: 35.2695 - val_loss: 44.0833\n",
      "Epoch 14640/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 35.2448 - val_loss: 44.0638\n",
      "Epoch 14641/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 35.2201 - val_loss: 44.0465\n",
      "Epoch 14642/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 35.1954 - val_loss: 44.0274\n",
      "Epoch 14643/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 35.1708 - val_loss: 44.0096\n",
      "Epoch 14644/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 35.1461 - val_loss: 43.9913\n",
      "Epoch 14645/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 35.1215 - val_loss: 43.9729\n",
      "Epoch 14646/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 35.0969 - val_loss: 43.9552\n",
      "Epoch 14647/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 35.0723 - val_loss: 43.9364\n",
      "Epoch 14648/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 35.0478 - val_loss: 43.9191\n",
      "Epoch 14649/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 35.0233 - val_loss: 43.9002\n",
      "Epoch 14650/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 34.9988 - val_loss: 43.8828\n",
      "Epoch 14651/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 34.9743 - val_loss: 43.8643\n",
      "Epoch 14652/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 34.9499 - val_loss: 43.8465\n",
      "Epoch 14653/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 34.9255 - val_loss: 43.8286\n",
      "Epoch 14654/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 34.9011 - val_loss: 43.8103\n",
      "Epoch 14655/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 34.8767 - val_loss: 43.7929\n",
      "Epoch 14656/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 34.8524 - val_loss: 43.7744\n",
      "Epoch 14657/100000\n",
      "11/11 [==============================] - 0s 659us/step - loss: 34.8281 - val_loss: 43.7571\n",
      "Epoch 14658/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 34.8038 - val_loss: 43.7389\n",
      "Epoch 14659/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 34.7795 - val_loss: 43.7213\n",
      "Epoch 14660/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 34.7553 - val_loss: 43.7035\n",
      "Epoch 14661/100000\n",
      "11/11 [==============================] - 0s 698us/step - loss: 34.7311 - val_loss: 43.6855\n",
      "Epoch 14662/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 34.7068 - val_loss: 43.6682\n",
      "Epoch 14663/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 34.6827 - val_loss: 43.6500\n",
      "Epoch 14664/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 34.6586 - val_loss: 43.6328\n",
      "Epoch 14665/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 34.6344 - val_loss: 43.6148\n",
      "Epoch 14666/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 34.6103 - val_loss: 43.5974\n",
      "Epoch 14667/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 34.5863 - val_loss: 43.5797\n",
      "Epoch 14668/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 34.5622 - val_loss: 43.5621\n",
      "Epoch 14669/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 34.5382 - val_loss: 43.5447\n",
      "Epoch 14670/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 34.5142 - val_loss: 43.5270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14671/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 34.4903 - val_loss: 43.5097\n",
      "Epoch 14672/100000\n",
      "11/11 [==============================] - 0s 556us/step - loss: 34.4663 - val_loss: 43.4920\n",
      "Epoch 14673/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 34.4424 - val_loss: 43.4748\n",
      "Epoch 14674/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 34.4185 - val_loss: 43.4571\n",
      "Epoch 14675/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 34.3946 - val_loss: 43.4400\n",
      "Epoch 14676/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 34.3708 - val_loss: 43.4224\n",
      "Epoch 14677/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 34.3469 - val_loss: 43.4052\n",
      "Epoch 14678/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 34.3231 - val_loss: 43.3878\n",
      "Epoch 14679/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 34.2993 - val_loss: 43.3704\n",
      "Epoch 14680/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 34.2756 - val_loss: 43.3534\n",
      "Epoch 14681/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 34.2519 - val_loss: 43.3360\n",
      "Epoch 14682/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 34.2281 - val_loss: 43.3188\n",
      "Epoch 14683/100000\n",
      "11/11 [==============================] - 0s 628us/step - loss: 34.2045 - val_loss: 43.3016\n",
      "Epoch 14684/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 34.1808 - val_loss: 43.2844\n",
      "Epoch 14685/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 34.1571 - val_loss: 43.2673\n",
      "Epoch 14686/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 34.1335 - val_loss: 43.2501\n",
      "Epoch 14687/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 34.1099 - val_loss: 43.2331\n",
      "Epoch 14688/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 34.0863 - val_loss: 43.2159\n",
      "Epoch 14689/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 34.0628 - val_loss: 43.1989\n",
      "Epoch 14690/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 34.0392 - val_loss: 43.1818\n",
      "Epoch 14691/100000\n",
      "11/11 [==============================] - 0s 707us/step - loss: 34.0157 - val_loss: 43.1648\n",
      "Epoch 14692/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 33.9923 - val_loss: 43.1479\n",
      "Epoch 14693/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 33.9688 - val_loss: 43.1308\n",
      "Epoch 14694/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 33.9453 - val_loss: 43.1140\n",
      "Epoch 14695/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 33.9219 - val_loss: 43.0969\n",
      "Epoch 14696/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 33.8985 - val_loss: 43.0802\n",
      "Epoch 14697/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 33.8752 - val_loss: 43.0631\n",
      "Epoch 14698/100000\n",
      "11/11 [==============================] - 0s 622us/step - loss: 33.8518 - val_loss: 43.0464\n",
      "Epoch 14699/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 33.8285 - val_loss: 43.0295\n",
      "Epoch 14700/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 33.8052 - val_loss: 43.0127\n",
      "Epoch 14701/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 33.7819 - val_loss: 42.9959\n",
      "Epoch 14702/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 33.7586 - val_loss: 42.9791\n",
      "Epoch 14703/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 33.7354 - val_loss: 42.9624\n",
      "Epoch 14704/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 33.7122 - val_loss: 42.9457\n",
      "Epoch 14705/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 33.6890 - val_loss: 42.9289\n",
      "Epoch 14706/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 33.6658 - val_loss: 42.9123\n",
      "Epoch 14707/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 33.6427 - val_loss: 42.8956\n",
      "Epoch 14708/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 33.6195 - val_loss: 42.8790\n",
      "Epoch 14709/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 33.5965 - val_loss: 42.8624\n",
      "Epoch 14710/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 33.5734 - val_loss: 42.8457\n",
      "Epoch 14711/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 33.5503 - val_loss: 42.8292\n",
      "Epoch 14712/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 33.5273 - val_loss: 42.8125\n",
      "Epoch 14713/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 33.5043 - val_loss: 42.7961\n",
      "Epoch 14714/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 33.4813 - val_loss: 42.7794\n",
      "Epoch 14715/100000\n",
      "11/11 [==============================] - 0s 678us/step - loss: 33.4583 - val_loss: 42.7631\n",
      "Epoch 14716/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.4354 - val_loss: 42.7465\n",
      "Epoch 14717/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.4124 - val_loss: 42.7301\n",
      "Epoch 14718/100000\n",
      "11/11 [==============================] - 0s 722us/step - loss: 33.3895 - val_loss: 42.7136\n",
      "Epoch 14719/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.3666 - val_loss: 42.6972\n",
      "Epoch 14720/100000\n",
      "11/11 [==============================] - 0s 804us/step - loss: 33.3437 - val_loss: 42.6809\n",
      "Epoch 14721/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.3209 - val_loss: 42.6643\n",
      "Epoch 14722/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 33.2981 - val_loss: 42.6482\n",
      "Epoch 14723/100000\n",
      "11/11 [==============================] - 0s 767us/step - loss: 33.2753 - val_loss: 42.6316\n",
      "Epoch 14724/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 33.2525 - val_loss: 42.6155\n",
      "Epoch 14725/100000\n",
      "11/11 [==============================] - 0s 710us/step - loss: 33.2297 - val_loss: 42.5990\n",
      "Epoch 14726/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 33.2070 - val_loss: 42.5828\n",
      "Epoch 14727/100000\n",
      "11/11 [==============================] - 0s 862us/step - loss: 33.1843 - val_loss: 42.5665\n",
      "Epoch 14728/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 33.1616 - val_loss: 42.5503\n",
      "Epoch 14729/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 33.1389 - val_loss: 42.5342\n",
      "Epoch 14730/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.1162 - val_loss: 42.5178\n",
      "Epoch 14731/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.0936 - val_loss: 42.5018\n",
      "Epoch 14732/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 33.0710 - val_loss: 42.4854\n",
      "Epoch 14733/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 33.0484 - val_loss: 42.4694\n",
      "Epoch 14734/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.0259 - val_loss: 42.4533\n",
      "Epoch 14735/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.0033 - val_loss: 42.4370\n",
      "Epoch 14736/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.9807 - val_loss: 42.4210\n",
      "Epoch 14737/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.9582 - val_loss: 42.4049\n",
      "Epoch 14738/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.9358 - val_loss: 42.3889\n",
      "Epoch 14739/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.9133 - val_loss: 42.3728\n",
      "Epoch 14740/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 32.8908 - val_loss: 42.3566\n",
      "Epoch 14741/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 32.8684 - val_loss: 42.3409\n",
      "Epoch 14742/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 32.8460 - val_loss: 42.3245\n",
      "Epoch 14743/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.8236 - val_loss: 42.3089\n",
      "Epoch 14744/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 32.8012 - val_loss: 42.2926\n",
      "Epoch 14745/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.7789 - val_loss: 42.2769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14746/100000\n",
      "11/11 [==============================] - 0s 907us/step - loss: 32.7565 - val_loss: 42.2609\n",
      "Epoch 14747/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 32.7342 - val_loss: 42.2451\n",
      "Epoch 14748/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.7120 - val_loss: 42.2292\n",
      "Epoch 14749/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 32.6897 - val_loss: 42.2132\n",
      "Epoch 14750/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 32.6674 - val_loss: 42.1975\n",
      "Epoch 14751/100000\n",
      "11/11 [==============================] - 0s 718us/step - loss: 32.6452 - val_loss: 42.1814\n",
      "Epoch 14752/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 32.6230 - val_loss: 42.1659\n",
      "Epoch 14753/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.6008 - val_loss: 42.1497\n",
      "Epoch 14754/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 32.5786 - val_loss: 42.1342\n",
      "Epoch 14755/100000\n",
      "11/11 [==============================] - 0s 647us/step - loss: 32.5565 - val_loss: 42.1182\n",
      "Epoch 14756/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.5343 - val_loss: 42.1026\n",
      "Epoch 14757/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.5122 - val_loss: 42.0868\n",
      "Epoch 14758/100000\n",
      "11/11 [==============================] - 0s 743us/step - loss: 32.4902 - val_loss: 42.0711\n",
      "Epoch 14759/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 32.4681 - val_loss: 42.0554\n",
      "Epoch 14760/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.4460 - val_loss: 42.0396\n",
      "Epoch 14761/100000\n",
      "11/11 [==============================] - 0s 814us/step - loss: 32.4240 - val_loss: 42.0240\n",
      "Epoch 14762/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 32.4020 - val_loss: 42.0082\n",
      "Epoch 14763/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.3800 - val_loss: 41.9927\n",
      "Epoch 14764/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 32.3580 - val_loss: 41.9769\n",
      "Epoch 14765/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.3360 - val_loss: 41.9615\n",
      "Epoch 14766/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 32.3141 - val_loss: 41.9457\n",
      "Epoch 14767/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 32.2921 - val_loss: 41.9302\n",
      "Epoch 14768/100000\n",
      "11/11 [==============================] - 0s 883us/step - loss: 32.2703 - val_loss: 41.9146\n",
      "Epoch 14769/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 32.2484 - val_loss: 41.8990\n",
      "Epoch 14770/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.2265 - val_loss: 41.8836\n",
      "Epoch 14771/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.2047 - val_loss: 41.8678\n",
      "Epoch 14772/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.1829 - val_loss: 41.8526\n",
      "Epoch 14773/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.1610 - val_loss: 41.8368\n",
      "Epoch 14774/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.1392 - val_loss: 41.8216\n",
      "Epoch 14775/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.1175 - val_loss: 41.8059\n",
      "Epoch 14776/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 32.0957 - val_loss: 41.7906\n",
      "Epoch 14777/100000\n",
      "11/11 [==============================] - 0s 719us/step - loss: 32.0740 - val_loss: 41.7750\n",
      "Epoch 14778/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 32.0523 - val_loss: 41.7597\n",
      "Epoch 14779/100000\n",
      "11/11 [==============================] - 0s 958us/step - loss: 32.0306 - val_loss: 41.7442\n",
      "Epoch 14780/100000\n",
      "11/11 [==============================] - 0s 768us/step - loss: 32.0090 - val_loss: 41.7287\n",
      "Epoch 14781/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.9873 - val_loss: 41.7135\n",
      "Epoch 14782/100000\n",
      "11/11 [==============================] - 0s 674us/step - loss: 31.9656 - val_loss: 41.6979\n",
      "Epoch 14783/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 31.9440 - val_loss: 41.6827\n",
      "Epoch 14784/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.9224 - val_loss: 41.6673\n",
      "Epoch 14785/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 31.9008 - val_loss: 41.6521\n",
      "Epoch 14786/100000\n",
      "11/11 [==============================] - 0s 652us/step - loss: 31.8793 - val_loss: 41.6366\n",
      "Epoch 14787/100000\n",
      "11/11 [==============================] - 0s 750us/step - loss: 31.8577 - val_loss: 41.6214\n",
      "Epoch 14788/100000\n",
      "11/11 [==============================] - 0s 872us/step - loss: 31.8362 - val_loss: 41.6060\n",
      "Epoch 14789/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 31.8147 - val_loss: 41.5908\n",
      "Epoch 14790/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 31.7932 - val_loss: 41.5755\n",
      "Epoch 14791/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.7717 - val_loss: 41.5602\n",
      "Epoch 14792/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 31.7503 - val_loss: 41.5450\n",
      "Epoch 14793/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.7288 - val_loss: 41.5297\n",
      "Epoch 14794/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.7074 - val_loss: 41.5147\n",
      "Epoch 14795/100000\n",
      "11/11 [==============================] - 0s 705us/step - loss: 31.6860 - val_loss: 41.4992\n",
      "Epoch 14796/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.6646 - val_loss: 41.4842\n",
      "Epoch 14797/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.6432 - val_loss: 41.4689\n",
      "Epoch 14798/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 31.6219 - val_loss: 41.4538\n",
      "Epoch 14799/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 31.6006 - val_loss: 41.4386\n",
      "Epoch 14800/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 31.5792 - val_loss: 41.4235\n",
      "Epoch 14801/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.5579 - val_loss: 41.4084\n",
      "Epoch 14802/100000\n",
      "11/11 [==============================] - 0s 757us/step - loss: 31.5367 - val_loss: 41.3933\n",
      "Epoch 14803/100000\n",
      "11/11 [==============================] - 0s 673us/step - loss: 31.5154 - val_loss: 41.3781\n",
      "Epoch 14804/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.4941 - val_loss: 41.3631\n",
      "Epoch 14805/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.4729 - val_loss: 41.3479\n",
      "Epoch 14806/100000\n",
      "11/11 [==============================] - 0s 791us/step - loss: 31.4517 - val_loss: 41.3330\n",
      "Epoch 14807/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 31.4305 - val_loss: 41.3177\n",
      "Epoch 14808/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 31.4093 - val_loss: 41.3029\n",
      "Epoch 14809/100000\n",
      "11/11 [==============================] - 0s 794us/step - loss: 31.3882 - val_loss: 41.2877\n",
      "Epoch 14810/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 31.3670 - val_loss: 41.2728\n",
      "Epoch 14811/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.3459 - val_loss: 41.2578\n",
      "Epoch 14812/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 31.3248 - val_loss: 41.2426\n",
      "Epoch 14813/100000\n",
      "11/11 [==============================] - 0s 789us/step - loss: 31.3037 - val_loss: 41.2279\n",
      "Epoch 14814/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.2826 - val_loss: 41.2126\n",
      "Epoch 14815/100000\n",
      "11/11 [==============================] - 0s 803us/step - loss: 31.2616 - val_loss: 41.1980\n",
      "Epoch 14816/100000\n",
      "11/11 [==============================] - 0s 849us/step - loss: 31.2406 - val_loss: 41.1827\n",
      "Epoch 14817/100000\n",
      "11/11 [==============================] - 0s 781us/step - loss: 31.2195 - val_loss: 41.1680\n",
      "Epoch 14818/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 31.1985 - val_loss: 41.1529\n",
      "Epoch 14819/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.1775 - val_loss: 41.1381\n",
      "Epoch 14820/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 31.1565 - val_loss: 41.1231\n",
      "Epoch 14821/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 31.1356 - val_loss: 41.1082\n",
      "Epoch 14822/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 31.1147 - val_loss: 41.0933\n",
      "Epoch 14823/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.0937 - val_loss: 41.0785\n",
      "Epoch 14824/100000\n",
      "11/11 [==============================] - 0s 674us/step - loss: 31.0728 - val_loss: 41.0636\n",
      "Epoch 14825/100000\n",
      "11/11 [==============================] - 0s 750us/step - loss: 31.0520 - val_loss: 41.0487\n",
      "Epoch 14826/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.0311 - val_loss: 41.0338\n",
      "Epoch 14827/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.0102 - val_loss: 41.0190\n",
      "Epoch 14828/100000\n",
      "11/11 [==============================] - 0s 848us/step - loss: 30.9894 - val_loss: 41.0042\n",
      "Epoch 14829/100000\n",
      "11/11 [==============================] - 0s 733us/step - loss: 30.9685 - val_loss: 40.9894\n",
      "Epoch 14830/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 30.9477 - val_loss: 40.9746\n",
      "Epoch 14831/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 30.9269 - val_loss: 40.9597\n",
      "Epoch 14832/100000\n",
      "11/11 [==============================] - 0s 721us/step - loss: 30.9062 - val_loss: 40.9451\n",
      "Epoch 14833/100000\n",
      "11/11 [==============================] - 0s 858us/step - loss: 30.8854 - val_loss: 40.9301\n",
      "Epoch 14834/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 30.8647 - val_loss: 40.9156\n",
      "Epoch 14835/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 30.8439 - val_loss: 40.9006\n",
      "Epoch 14836/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 30.8232 - val_loss: 40.8860\n",
      "Epoch 14837/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 30.8025 - val_loss: 40.8712\n",
      "Epoch 14838/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 30.7818 - val_loss: 40.8564\n",
      "Epoch 14839/100000\n",
      "11/11 [==============================] - 0s 589us/step - loss: 30.7612 - val_loss: 40.8419\n",
      "Epoch 14840/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 30.7406 - val_loss: 40.8269\n",
      "Epoch 14841/100000\n",
      "11/11 [==============================] - 0s 988us/step - loss: 30.7199 - val_loss: 40.8125\n",
      "Epoch 14842/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 30.6993 - val_loss: 40.7976\n",
      "Epoch 14843/100000\n",
      "11/11 [==============================] - 0s 932us/step - loss: 30.6787 - val_loss: 40.7830\n",
      "Epoch 14844/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 30.6581 - val_loss: 40.7683\n",
      "Epoch 14845/100000\n",
      "11/11 [==============================] - 0s 962us/step - loss: 30.6376 - val_loss: 40.7536\n",
      "Epoch 14846/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.6170 - val_loss: 40.7390\n",
      "Epoch 14847/100000\n",
      "11/11 [==============================] - 0s 846us/step - loss: 30.5964 - val_loss: 40.7243\n",
      "Epoch 14848/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 30.5759 - val_loss: 40.7097\n",
      "Epoch 14849/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.5554 - val_loss: 40.6952\n",
      "Epoch 14850/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 30.5350 - val_loss: 40.6804\n",
      "Epoch 14851/100000\n",
      "11/11 [==============================] - 0s 672us/step - loss: 30.5145 - val_loss: 40.6660\n",
      "Epoch 14852/100000\n",
      "11/11 [==============================] - 0s 705us/step - loss: 30.4940 - val_loss: 40.6512\n",
      "Epoch 14853/100000\n",
      "11/11 [==============================] - 0s 932us/step - loss: 30.4736 - val_loss: 40.6368\n",
      "Epoch 14854/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.4532 - val_loss: 40.6220\n",
      "Epoch 14855/100000\n",
      "11/11 [==============================] - 0s 881us/step - loss: 30.4327 - val_loss: 40.6076\n",
      "Epoch 14856/100000\n",
      "11/11 [==============================] - 0s 784us/step - loss: 30.4123 - val_loss: 40.5929\n",
      "Epoch 14857/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.3920 - val_loss: 40.5785\n",
      "Epoch 14858/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.3716 - val_loss: 40.5638\n",
      "Epoch 14859/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 30.3513 - val_loss: 40.5494\n",
      "Epoch 14860/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 30.3309 - val_loss: 40.5347\n",
      "Epoch 14861/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 30.3106 - val_loss: 40.5204\n",
      "Epoch 14862/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 30.2903 - val_loss: 40.5057\n",
      "Epoch 14863/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 30.2700 - val_loss: 40.4913\n",
      "Epoch 14864/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 30.2497 - val_loss: 40.4768\n",
      "Epoch 14865/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 30.2294 - val_loss: 40.4622\n",
      "Epoch 14866/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 30.2092 - val_loss: 40.4478\n",
      "Epoch 14867/100000\n",
      "11/11 [==============================] - 0s 933us/step - loss: 30.1890 - val_loss: 40.4333\n",
      "Epoch 14868/100000\n",
      "11/11 [==============================] - 0s 842us/step - loss: 30.1688 - val_loss: 40.4188\n",
      "Epoch 14869/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.1486 - val_loss: 40.4045\n",
      "Epoch 14870/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.1284 - val_loss: 40.3898\n",
      "Epoch 14871/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.1082 - val_loss: 40.3757\n",
      "Epoch 14872/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 30.0881 - val_loss: 40.3610\n",
      "Epoch 14873/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.0679 - val_loss: 40.3467\n",
      "Epoch 14874/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.0478 - val_loss: 40.3323\n",
      "Epoch 14875/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 30.0277 - val_loss: 40.3178\n",
      "Epoch 14876/100000\n",
      "11/11 [==============================] - 0s 897us/step - loss: 30.0075 - val_loss: 40.3035\n",
      "Epoch 14877/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 29.9875 - val_loss: 40.2889\n",
      "Epoch 14878/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 29.9674 - val_loss: 40.2748\n",
      "Epoch 14879/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 29.9474 - val_loss: 40.2602\n",
      "Epoch 14880/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 29.9273 - val_loss: 40.2460\n",
      "Epoch 14881/100000\n",
      "11/11 [==============================] - 0s 900us/step - loss: 29.9073 - val_loss: 40.2315\n",
      "Epoch 14882/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 29.8872 - val_loss: 40.2172\n",
      "Epoch 14883/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 29.8673 - val_loss: 40.2028\n",
      "Epoch 14884/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 29.8473 - val_loss: 40.1885\n",
      "Epoch 14885/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 29.8273 - val_loss: 40.1741\n",
      "Epoch 14886/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 29.8074 - val_loss: 40.1599\n",
      "Epoch 14887/100000\n",
      "11/11 [==============================] - 0s 820us/step - loss: 29.7874 - val_loss: 40.1454\n",
      "Epoch 14888/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 29.7675 - val_loss: 40.1313\n",
      "Epoch 14889/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 29.7476 - val_loss: 40.1168\n",
      "Epoch 14890/100000\n",
      "11/11 [==============================] - 0s 725us/step - loss: 29.7277 - val_loss: 40.1027\n",
      "Epoch 14891/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 29.7078 - val_loss: 40.0882\n",
      "Epoch 14892/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 29.6879 - val_loss: 40.0740\n",
      "Epoch 14893/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 29.6681 - val_loss: 40.0598\n",
      "Epoch 14894/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 29.6483 - val_loss: 40.0454\n",
      "Epoch 14895/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 29.6284 - val_loss: 40.0313\n",
      "Epoch 14896/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 29.6086 - val_loss: 40.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14897/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 29.5888 - val_loss: 40.0028\n",
      "Epoch 14898/100000\n",
      "11/11 [==============================] - 0s 759us/step - loss: 29.5690 - val_loss: 39.9883\n",
      "Epoch 14899/100000\n",
      "11/11 [==============================] - 0s 756us/step - loss: 29.5493 - val_loss: 39.9744\n",
      "Epoch 14900/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 29.5295 - val_loss: 39.9598\n",
      "Epoch 14901/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 29.5097 - val_loss: 39.9458\n",
      "Epoch 14902/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 29.4900 - val_loss: 39.9314\n",
      "Epoch 14903/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 29.4703 - val_loss: 39.9174\n",
      "Epoch 14904/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 29.4506 - val_loss: 39.9030\n",
      "Epoch 14905/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 29.4309 - val_loss: 39.8889\n",
      "Epoch 14906/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 29.4112 - val_loss: 39.8747\n",
      "Epoch 14907/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 29.3915 - val_loss: 39.8606\n",
      "Epoch 14908/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 29.3719 - val_loss: 39.8463\n",
      "Epoch 14909/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 29.3523 - val_loss: 39.8323\n",
      "Epoch 14910/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 29.3326 - val_loss: 39.8179\n",
      "Epoch 14911/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 29.3130 - val_loss: 39.8040\n",
      "Epoch 14912/100000\n",
      "11/11 [==============================] - 0s 631us/step - loss: 29.2934 - val_loss: 39.7896\n",
      "Epoch 14913/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 29.2738 - val_loss: 39.7757\n",
      "Epoch 14914/100000\n",
      "11/11 [==============================] - 0s 659us/step - loss: 29.2543 - val_loss: 39.7613\n",
      "Epoch 14915/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 29.2347 - val_loss: 39.7473\n",
      "Epoch 14916/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 29.2151 - val_loss: 39.7331\n",
      "Epoch 14917/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 29.1956 - val_loss: 39.7190\n",
      "Epoch 14918/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 29.1761 - val_loss: 39.7048\n",
      "Epoch 14919/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 29.1566 - val_loss: 39.6908\n",
      "Epoch 14920/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 29.1371 - val_loss: 39.6766\n",
      "Epoch 14921/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 29.1176 - val_loss: 39.6627\n",
      "Epoch 14922/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 29.0982 - val_loss: 39.6485\n",
      "Epoch 14923/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 29.0787 - val_loss: 39.6345\n",
      "Epoch 14924/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 29.0593 - val_loss: 39.6203\n",
      "Epoch 14925/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 29.0398 - val_loss: 39.6063\n",
      "Epoch 14926/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 29.0204 - val_loss: 39.5923\n",
      "Epoch 14927/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 29.0010 - val_loss: 39.5780\n",
      "Epoch 14928/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 28.9816 - val_loss: 39.5642\n",
      "Epoch 14929/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 28.9622 - val_loss: 39.5499\n",
      "Epoch 14930/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 28.9429 - val_loss: 39.5362\n",
      "Epoch 14931/100000\n",
      "11/11 [==============================] - 0s 729us/step - loss: 28.9235 - val_loss: 39.5218\n",
      "Epoch 14932/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 28.9042 - val_loss: 39.5082\n",
      "Epoch 14933/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 28.8848 - val_loss: 39.4937\n",
      "Epoch 14934/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 28.8656 - val_loss: 39.4801\n",
      "Epoch 14935/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 28.8463 - val_loss: 39.4657\n",
      "Epoch 14936/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 28.8270 - val_loss: 39.4521\n",
      "Epoch 14937/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 28.8077 - val_loss: 39.4378\n",
      "Epoch 14938/100000\n",
      "11/11 [==============================] - 0s 891us/step - loss: 28.7884 - val_loss: 39.4239\n",
      "Epoch 14939/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 28.7691 - val_loss: 39.4099\n",
      "Epoch 14940/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 28.7499 - val_loss: 39.3959\n",
      "Epoch 14941/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 28.7307 - val_loss: 39.3820\n",
      "Epoch 14942/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 28.7115 - val_loss: 39.3679\n",
      "Epoch 14943/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 28.6923 - val_loss: 39.3542\n",
      "Epoch 14944/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 28.6731 - val_loss: 39.3399\n",
      "Epoch 14945/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 28.6539 - val_loss: 39.3264\n",
      "Epoch 14946/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 28.6348 - val_loss: 39.3120\n",
      "Epoch 14947/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 28.6156 - val_loss: 39.2984\n",
      "Epoch 14948/100000\n",
      "11/11 [==============================] - 0s 607us/step - loss: 28.5965 - val_loss: 39.2842\n",
      "Epoch 14949/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 28.5773 - val_loss: 39.2704\n",
      "Epoch 14950/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 28.5582 - val_loss: 39.2565\n",
      "Epoch 14951/100000\n",
      "11/11 [==============================] - 0s 839us/step - loss: 28.5391 - val_loss: 39.2425\n",
      "Epoch 14952/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 28.5200 - val_loss: 39.2287\n",
      "Epoch 14953/100000\n",
      "11/11 [==============================] - 0s 621us/step - loss: 28.5009 - val_loss: 39.2147\n",
      "Epoch 14954/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 28.4819 - val_loss: 39.2010\n",
      "Epoch 14955/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 28.4628 - val_loss: 39.1869\n",
      "Epoch 14956/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 28.4438 - val_loss: 39.1732\n",
      "Epoch 14957/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 28.4247 - val_loss: 39.1591\n",
      "Epoch 14958/100000\n",
      "11/11 [==============================] - 0s 818us/step - loss: 28.4057 - val_loss: 39.1455\n",
      "Epoch 14959/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 28.3867 - val_loss: 39.1314\n",
      "Epoch 14960/100000\n",
      "11/11 [==============================] - 0s 822us/step - loss: 28.3677 - val_loss: 39.1177\n",
      "Epoch 14961/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 28.3487 - val_loss: 39.1037\n",
      "Epoch 14962/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 28.3298 - val_loss: 39.0901\n",
      "Epoch 14963/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 28.3108 - val_loss: 39.0761\n",
      "Epoch 14964/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 28.2919 - val_loss: 39.0624\n",
      "Epoch 14965/100000\n",
      "11/11 [==============================] - 0s 682us/step - loss: 28.2729 - val_loss: 39.0484\n",
      "Epoch 14966/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 28.2540 - val_loss: 39.0348\n",
      "Epoch 14967/100000\n",
      "11/11 [==============================] - 0s 682us/step - loss: 28.2351 - val_loss: 39.0208\n",
      "Epoch 14968/100000\n",
      "11/11 [==============================] - 0s 857us/step - loss: 28.2162 - val_loss: 39.0072\n",
      "Epoch 14969/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 28.1973 - val_loss: 38.9932\n",
      "Epoch 14970/100000\n",
      "11/11 [==============================] - 0s 620us/step - loss: 28.1784 - val_loss: 38.9796\n",
      "Epoch 14971/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 28.1595 - val_loss: 38.9656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14972/100000\n",
      "11/11 [==============================] - 0s 643us/step - loss: 28.1407 - val_loss: 38.9520\n",
      "Epoch 14973/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 28.1219 - val_loss: 38.9381\n",
      "Epoch 14974/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 28.1030 - val_loss: 38.9244\n",
      "Epoch 14975/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 28.0842 - val_loss: 38.9106\n",
      "Epoch 14976/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 28.0654 - val_loss: 38.8969\n",
      "Epoch 14977/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 28.0466 - val_loss: 38.8833\n",
      "Epoch 14978/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 28.0278 - val_loss: 38.8693\n",
      "Epoch 14979/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 28.0090 - val_loss: 38.8560\n",
      "Epoch 14980/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 27.9903 - val_loss: 38.8417\n",
      "Epoch 14981/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 27.9715 - val_loss: 38.8286\n",
      "Epoch 14982/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 27.9528 - val_loss: 38.8143\n",
      "Epoch 14983/100000\n",
      "11/11 [==============================] - 0s 681us/step - loss: 27.9341 - val_loss: 38.8013\n",
      "Epoch 14984/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 27.9153 - val_loss: 38.7869\n",
      "Epoch 14985/100000\n",
      "11/11 [==============================] - 0s 669us/step - loss: 27.8966 - val_loss: 38.7739\n",
      "Epoch 14986/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.8779 - val_loss: 38.7597\n",
      "Epoch 14987/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.8593 - val_loss: 38.7464\n",
      "Epoch 14988/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.8406 - val_loss: 38.7325\n",
      "Epoch 14989/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.8219 - val_loss: 38.7189\n",
      "Epoch 14990/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.8033 - val_loss: 38.7054\n",
      "Epoch 14991/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.7846 - val_loss: 38.6914\n",
      "Epoch 14992/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.7660 - val_loss: 38.6783\n",
      "Epoch 14993/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 27.7474 - val_loss: 38.6641\n",
      "Epoch 14994/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 27.7288 - val_loss: 38.6510\n",
      "Epoch 14995/100000\n",
      "11/11 [==============================] - 0s 825us/step - loss: 27.7102 - val_loss: 38.6369\n",
      "Epoch 14996/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 27.6916 - val_loss: 38.6238\n",
      "Epoch 14997/100000\n",
      "11/11 [==============================] - 0s 614us/step - loss: 27.6731 - val_loss: 38.6098\n",
      "Epoch 14998/100000\n",
      "11/11 [==============================] - 0s 704us/step - loss: 27.6545 - val_loss: 38.5966\n",
      "Epoch 14999/100000\n",
      "11/11 [==============================] - 0s 710us/step - loss: 27.6359 - val_loss: 38.5827\n",
      "Epoch 15000/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 27.6174 - val_loss: 38.5694\n",
      "Epoch 15001/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 27.5989 - val_loss: 38.5556\n",
      "Epoch 15002/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.5804 - val_loss: 38.5423\n",
      "Epoch 15003/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 27.5618 - val_loss: 38.5286\n",
      "Epoch 15004/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.5434 - val_loss: 38.5152\n",
      "Epoch 15005/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 27.5249 - val_loss: 38.5015\n",
      "Epoch 15006/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.5064 - val_loss: 38.4882\n",
      "Epoch 15007/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.4879 - val_loss: 38.4745\n",
      "Epoch 15008/100000\n",
      "11/11 [==============================] - 0s 994us/step - loss: 27.4695 - val_loss: 38.4612\n",
      "Epoch 15009/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.4511 - val_loss: 38.4475\n",
      "Epoch 15010/100000\n",
      "11/11 [==============================] - 0s 580us/step - loss: 27.4326 - val_loss: 38.4342\n",
      "Epoch 15011/100000\n",
      "11/11 [==============================] - 0s 685us/step - loss: 27.4142 - val_loss: 38.4206\n",
      "Epoch 15012/100000\n",
      "11/11 [==============================] - 0s 680us/step - loss: 27.3958 - val_loss: 38.4072\n",
      "Epoch 15013/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 27.3774 - val_loss: 38.3937\n",
      "Epoch 15014/100000\n",
      "11/11 [==============================] - 0s 898us/step - loss: 27.3590 - val_loss: 38.3803\n",
      "Epoch 15015/100000\n",
      "11/11 [==============================] - 0s 938us/step - loss: 27.3407 - val_loss: 38.3669\n",
      "Epoch 15016/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.3223 - val_loss: 38.3534\n",
      "Epoch 15017/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.3040 - val_loss: 38.3400\n",
      "Epoch 15018/100000\n",
      "11/11 [==============================] - 0s 844us/step - loss: 27.2856 - val_loss: 38.3267\n",
      "Epoch 15019/100000\n",
      "11/11 [==============================] - 0s 716us/step - loss: 27.2673 - val_loss: 38.3132\n",
      "Epoch 15020/100000\n",
      "11/11 [==============================] - 0s 786us/step - loss: 27.2490 - val_loss: 38.2999\n",
      "Epoch 15021/100000\n",
      "11/11 [==============================] - 0s 879us/step - loss: 27.2307 - val_loss: 38.2865\n",
      "Epoch 15022/100000\n",
      "11/11 [==============================] - 0s 802us/step - loss: 27.2124 - val_loss: 38.2731\n",
      "Epoch 15023/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.1941 - val_loss: 38.2598\n",
      "Epoch 15024/100000\n",
      "11/11 [==============================] - 0s 741us/step - loss: 27.1758 - val_loss: 38.2464\n",
      "Epoch 15025/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 27.1575 - val_loss: 38.2331\n",
      "Epoch 15026/100000\n",
      "11/11 [==============================] - 0s 844us/step - loss: 27.1393 - val_loss: 38.2197\n",
      "Epoch 15027/100000\n",
      "11/11 [==============================] - 0s 834us/step - loss: 27.1211 - val_loss: 38.2064\n",
      "Epoch 15028/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.1028 - val_loss: 38.1932\n",
      "Epoch 15029/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.0846 - val_loss: 38.1797\n",
      "Epoch 15030/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 27.0664 - val_loss: 38.1665\n",
      "Epoch 15031/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 27.0482 - val_loss: 38.1533\n",
      "Epoch 15032/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.0300 - val_loss: 38.1399\n",
      "Epoch 15033/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.0118 - val_loss: 38.1268\n",
      "Epoch 15034/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.9937 - val_loss: 38.1135\n",
      "Epoch 15035/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.9755 - val_loss: 38.1003\n",
      "Epoch 15036/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.9574 - val_loss: 38.0870\n",
      "Epoch 15037/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.9392 - val_loss: 38.0738\n",
      "Epoch 15038/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.9211 - val_loss: 38.0606\n",
      "Epoch 15039/100000\n",
      "11/11 [==============================] - 0s 975us/step - loss: 26.9030 - val_loss: 38.0474\n",
      "Epoch 15040/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 26.8849 - val_loss: 38.0342\n",
      "Epoch 15041/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 26.8668 - val_loss: 38.0210\n",
      "Epoch 15042/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 26.8487 - val_loss: 38.0079\n",
      "Epoch 15043/100000\n",
      "11/11 [==============================] - 0s 308us/step - loss: 26.8307 - val_loss: 37.9947\n",
      "Epoch 15044/100000\n",
      "11/11 [==============================] - 0s 862us/step - loss: 26.8126 - val_loss: 37.9816\n",
      "Epoch 15045/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 26.7946 - val_loss: 37.9684\n",
      "Epoch 15046/100000\n",
      "11/11 [==============================] - 0s 859us/step - loss: 26.7765 - val_loss: 37.9553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15047/100000\n",
      "11/11 [==============================] - 0s 992us/step - loss: 26.7585 - val_loss: 37.9422\n",
      "Epoch 15048/100000\n",
      "11/11 [==============================] - 0s 858us/step - loss: 26.7405 - val_loss: 37.9291\n",
      "Epoch 15049/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.7225 - val_loss: 37.9160\n",
      "Epoch 15050/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.7045 - val_loss: 37.9029\n",
      "Epoch 15051/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.6865 - val_loss: 37.8899\n",
      "Epoch 15052/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 26.6685 - val_loss: 37.8768\n",
      "Epoch 15053/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.6505 - val_loss: 37.8638\n",
      "Epoch 15054/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.6326 - val_loss: 37.8507\n",
      "Epoch 15055/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.6146 - val_loss: 37.8378\n",
      "Epoch 15056/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.5967 - val_loss: 37.8246\n",
      "Epoch 15057/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.5788 - val_loss: 37.8119\n",
      "Epoch 15058/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.5609 - val_loss: 37.7986\n",
      "Epoch 15059/100000\n",
      "11/11 [==============================] - 0s 634us/step - loss: 26.5430 - val_loss: 37.7860\n",
      "Epoch 15060/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 26.5251 - val_loss: 37.7726\n",
      "Epoch 15061/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 26.5072 - val_loss: 37.7601\n",
      "Epoch 15062/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 26.4893 - val_loss: 37.7467\n",
      "Epoch 15063/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.4715 - val_loss: 37.7343\n",
      "Epoch 15064/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.4536 - val_loss: 37.7207\n",
      "Epoch 15065/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.4358 - val_loss: 37.7087\n",
      "Epoch 15066/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.4180 - val_loss: 37.6946\n",
      "Epoch 15067/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.4002 - val_loss: 37.6832\n",
      "Epoch 15068/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.3824 - val_loss: 37.6686\n",
      "Epoch 15069/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.3646 - val_loss: 37.6579\n",
      "Epoch 15070/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.3468 - val_loss: 37.6424\n",
      "Epoch 15071/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 26.3290 - val_loss: 37.6328\n",
      "Epoch 15072/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 26.3112 - val_loss: 37.6161\n",
      "Epoch 15073/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 26.2935 - val_loss: 37.6081\n",
      "Epoch 15074/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 26.2757 - val_loss: 37.5893\n",
      "Epoch 15075/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 26.2580 - val_loss: 37.5840\n",
      "Epoch 15076/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 26.2403 - val_loss: 37.5619\n",
      "Epoch 15077/100000\n",
      "11/11 [==============================] - 0s 926us/step - loss: 26.2226 - val_loss: 37.5610\n",
      "Epoch 15078/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 26.2049 - val_loss: 37.5334\n",
      "Epoch 15079/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 26.1872 - val_loss: 37.5392\n",
      "Epoch 15080/100000\n",
      "11/11 [==============================] - 0s 784us/step - loss: 26.1695 - val_loss: 37.5033\n",
      "Epoch 15081/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 26.1519 - val_loss: 37.5196\n",
      "Epoch 15082/100000\n",
      "11/11 [==============================] - 0s 697us/step - loss: 26.1342 - val_loss: 37.4710\n",
      "Epoch 15083/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.1166 - val_loss: 37.5023\n",
      "Epoch 15084/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.0990 - val_loss: 37.4368\n",
      "Epoch 15085/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.0814 - val_loss: 37.4859\n",
      "Epoch 15086/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.0639 - val_loss: 37.4046\n",
      "Epoch 15087/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.0463 - val_loss: 37.4636\n",
      "Epoch 15088/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 26.0287 - val_loss: 37.3831\n",
      "Epoch 15089/100000\n",
      "11/11 [==============================] - 0s 963us/step - loss: 26.0111 - val_loss: 37.4265\n",
      "Epoch 15090/100000\n",
      "11/11 [==============================] - 0s 964us/step - loss: 25.9934 - val_loss: 37.3768\n",
      "Epoch 15091/100000\n",
      "11/11 [==============================] - 0s 695us/step - loss: 25.9757 - val_loss: 37.3775\n",
      "Epoch 15092/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 25.9581 - val_loss: 37.3749\n",
      "Epoch 15093/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 25.9406 - val_loss: 37.3329\n",
      "Epoch 15094/100000\n",
      "11/11 [==============================] - 0s 292us/step - loss: 25.9231 - val_loss: 37.3618\n",
      "Epoch 15095/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 25.9056 - val_loss: 37.3051\n",
      "Epoch 15096/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 25.8881 - val_loss: 37.3304\n",
      "Epoch 15097/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.8706 - val_loss: 37.2941\n",
      "Epoch 15098/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.8531 - val_loss: 37.2877\n",
      "Epoch 15099/100000\n",
      "11/11 [==============================] - 0s 880us/step - loss: 25.8355 - val_loss: 37.2865\n",
      "Epoch 15100/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 25.8181 - val_loss: 37.2497\n",
      "Epoch 15101/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.8007 - val_loss: 37.2678\n",
      "Epoch 15102/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 25.7832 - val_loss: 37.2261\n",
      "Epoch 15103/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 25.7658 - val_loss: 37.2349\n",
      "Epoch 15104/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.7483 - val_loss: 37.2136\n",
      "Epoch 15105/100000\n",
      "11/11 [==============================] - 0s 643us/step - loss: 25.7309 - val_loss: 37.1971\n",
      "Epoch 15106/100000\n",
      "11/11 [==============================] - 0s 731us/step - loss: 25.7135 - val_loss: 37.1999\n",
      "Epoch 15107/100000\n",
      "11/11 [==============================] - 0s 745us/step - loss: 25.6961 - val_loss: 37.1663\n",
      "Epoch 15108/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.6787 - val_loss: 37.1757\n",
      "Epoch 15109/100000\n",
      "11/11 [==============================] - 0s 894us/step - loss: 25.6614 - val_loss: 37.1464\n",
      "Epoch 15110/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 25.6440 - val_loss: 37.1427\n",
      "Epoch 15111/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 25.6266 - val_loss: 37.1313\n",
      "Epoch 15112/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.6092 - val_loss: 37.1097\n",
      "Epoch 15113/100000\n",
      "11/11 [==============================] - 0s 849us/step - loss: 25.5920 - val_loss: 37.1121\n",
      "Epoch 15114/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.5746 - val_loss: 37.0839\n",
      "Epoch 15115/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.5573 - val_loss: 37.0850\n",
      "Epoch 15116/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 25.5400 - val_loss: 37.0651\n",
      "Epoch 15117/100000\n",
      "11/11 [==============================] - 0s 919us/step - loss: 25.5227 - val_loss: 37.0538\n",
      "Epoch 15118/100000\n",
      "11/11 [==============================] - 0s 917us/step - loss: 25.5054 - val_loss: 37.0470\n",
      "Epoch 15119/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 25.4881 - val_loss: 37.0249\n",
      "Epoch 15120/100000\n",
      "11/11 [==============================] - 0s 677us/step - loss: 25.4709 - val_loss: 37.0244\n",
      "Epoch 15121/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 25.4536 - val_loss: 37.0017\n",
      "Epoch 15122/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 25.4364 - val_loss: 36.9965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15123/100000\n",
      "11/11 [==============================] - 0s 886us/step - loss: 25.4192 - val_loss: 36.9822\n",
      "Epoch 15124/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 25.4019 - val_loss: 36.9674\n",
      "Epoch 15125/100000\n",
      "11/11 [==============================] - 0s 586us/step - loss: 25.3847 - val_loss: 36.9617\n",
      "Epoch 15126/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 25.3675 - val_loss: 36.9412\n",
      "Epoch 15127/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 25.3503 - val_loss: 36.9375\n",
      "Epoch 15128/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 25.3331 - val_loss: 36.9190\n",
      "Epoch 15129/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 25.3160 - val_loss: 36.9101\n",
      "Epoch 15130/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 25.2988 - val_loss: 36.8985\n",
      "Epoch 15131/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 25.2817 - val_loss: 36.8829\n",
      "Epoch 15132/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 25.2645 - val_loss: 36.8765\n",
      "Epoch 15133/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 25.2474 - val_loss: 36.8584\n",
      "Epoch 15134/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 25.2303 - val_loss: 36.8517\n",
      "Epoch 15135/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 25.2132 - val_loss: 36.8363\n",
      "Epoch 15136/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 25.1961 - val_loss: 36.8254\n",
      "Epoch 15137/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 25.1790 - val_loss: 36.8148\n",
      "Epoch 15138/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 25.1619 - val_loss: 36.7996\n",
      "Epoch 15139/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 25.1449 - val_loss: 36.7919\n",
      "Epoch 15140/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 25.1278 - val_loss: 36.7757\n",
      "Epoch 15141/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 25.1108 - val_loss: 36.7673\n",
      "Epoch 15142/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 25.0937 - val_loss: 36.7534\n",
      "Epoch 15143/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 25.0767 - val_loss: 36.7418\n",
      "Epoch 15144/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 25.0597 - val_loss: 36.7314\n",
      "Epoch 15145/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 25.0427 - val_loss: 36.7170\n",
      "Epoch 15146/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 25.0257 - val_loss: 36.7083\n",
      "Epoch 15147/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 25.0087 - val_loss: 36.6935\n",
      "Epoch 15148/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 24.9917 - val_loss: 36.6841\n",
      "Epoch 15149/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 24.9748 - val_loss: 36.6710\n",
      "Epoch 15150/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 24.9578 - val_loss: 36.6593\n",
      "Epoch 15151/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 24.9409 - val_loss: 36.6486\n",
      "Epoch 15152/100000\n",
      "11/11 [==============================] - 0s 225us/step - loss: 24.9239 - val_loss: 36.6350\n",
      "Epoch 15153/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 24.9070 - val_loss: 36.6256\n",
      "Epoch 15154/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 24.8901 - val_loss: 36.6116\n",
      "Epoch 15155/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 24.8732 - val_loss: 36.6017\n",
      "Epoch 15156/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 24.8563 - val_loss: 36.5889\n",
      "Epoch 15157/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 24.8394 - val_loss: 36.5776\n",
      "Epoch 15158/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 24.8226 - val_loss: 36.5664\n",
      "Epoch 15159/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 24.8057 - val_loss: 36.5537\n",
      "Epoch 15160/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 24.7889 - val_loss: 36.5434\n",
      "Epoch 15161/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 24.7720 - val_loss: 36.5303\n",
      "Epoch 15162/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 24.7552 - val_loss: 36.5200\n",
      "Epoch 15163/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 24.7384 - val_loss: 36.5077\n",
      "Epoch 15164/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 24.7216 - val_loss: 36.4963\n",
      "Epoch 15165/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 24.7048 - val_loss: 36.4851\n",
      "Epoch 15166/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 24.6880 - val_loss: 36.4727\n",
      "Epoch 15167/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 24.6712 - val_loss: 36.4622\n",
      "Epoch 15168/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 24.6544 - val_loss: 36.4496\n",
      "Epoch 15169/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 24.6377 - val_loss: 36.4391\n",
      "Epoch 15170/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 24.6209 - val_loss: 36.4268\n",
      "Epoch 15171/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 24.6042 - val_loss: 36.4159\n",
      "Epoch 15172/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 24.5875 - val_loss: 36.4042\n",
      "Epoch 15173/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 24.5707 - val_loss: 36.3926\n",
      "Epoch 15174/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 24.5540 - val_loss: 36.3816\n",
      "Epoch 15175/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 24.5374 - val_loss: 36.3696\n",
      "Epoch 15176/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 24.5207 - val_loss: 36.3589\n",
      "Epoch 15177/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 24.5040 - val_loss: 36.3467\n",
      "Epoch 15178/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 24.4873 - val_loss: 36.3361\n",
      "Epoch 15179/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 24.4707 - val_loss: 36.3242\n",
      "Epoch 15180/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 24.4540 - val_loss: 36.3131\n",
      "Epoch 15181/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 24.4374 - val_loss: 36.3017\n",
      "Epoch 15182/100000\n",
      "11/11 [==============================] - 0s 663us/step - loss: 24.4208 - val_loss: 36.2903\n",
      "Epoch 15183/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 24.4042 - val_loss: 36.2792\n",
      "Epoch 15184/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 24.3876 - val_loss: 36.2675\n",
      "Epoch 15185/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 24.3710 - val_loss: 36.2567\n",
      "Epoch 15186/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 24.3544 - val_loss: 36.2450\n",
      "Epoch 15187/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 24.3378 - val_loss: 36.2341\n",
      "Epoch 15188/100000\n",
      "11/11 [==============================] - 0s 668us/step - loss: 24.3213 - val_loss: 36.2226\n",
      "Epoch 15189/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 24.3047 - val_loss: 36.2115\n",
      "Epoch 15190/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 24.2882 - val_loss: 36.2002\n",
      "Epoch 15191/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 24.2717 - val_loss: 36.1890\n",
      "Epoch 15192/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 24.2551 - val_loss: 36.1778\n",
      "Epoch 15193/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 24.2386 - val_loss: 36.1667\n",
      "Epoch 15194/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 24.2222 - val_loss: 36.1555\n",
      "Epoch 15195/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 24.2057 - val_loss: 36.1443\n",
      "Epoch 15196/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 24.1892 - val_loss: 36.1333\n",
      "Epoch 15197/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 24.1727 - val_loss: 36.1220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15198/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 24.1563 - val_loss: 36.1110\n",
      "Epoch 15199/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 24.1398 - val_loss: 36.0998\n",
      "Epoch 15200/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 24.1234 - val_loss: 36.0888\n",
      "Epoch 15201/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 24.1070 - val_loss: 36.0776\n",
      "Epoch 15202/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 24.0906 - val_loss: 36.0667\n",
      "Epoch 15203/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 24.0742 - val_loss: 36.0556\n",
      "Epoch 15204/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 24.0578 - val_loss: 36.0446\n",
      "Epoch 15205/100000\n",
      "11/11 [==============================] - 0s 630us/step - loss: 24.0414 - val_loss: 36.0336\n",
      "Epoch 15206/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 24.0250 - val_loss: 36.0225\n",
      "Epoch 15207/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 24.0086 - val_loss: 36.0116\n",
      "Epoch 15208/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 23.9923 - val_loss: 36.0005\n",
      "Epoch 15209/100000\n",
      "11/11 [==============================] - 0s 486us/step - loss: 23.9759 - val_loss: 35.9896\n",
      "Epoch 15210/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 23.9596 - val_loss: 35.9786\n",
      "Epoch 15211/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 23.9433 - val_loss: 35.9677\n",
      "Epoch 15212/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 23.9270 - val_loss: 35.9568\n",
      "Epoch 15213/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 23.9107 - val_loss: 35.9459\n",
      "Epoch 15214/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 23.8944 - val_loss: 35.9349\n",
      "Epoch 15215/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 23.8781 - val_loss: 35.9242\n",
      "Epoch 15216/100000\n",
      "11/11 [==============================] - 0s 656us/step - loss: 23.8619 - val_loss: 35.9131\n",
      "Epoch 15217/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 23.8456 - val_loss: 35.9025\n",
      "Epoch 15218/100000\n",
      "11/11 [==============================] - 0s 633us/step - loss: 23.8294 - val_loss: 35.8913\n",
      "Epoch 15219/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 23.8131 - val_loss: 35.8809\n",
      "Epoch 15220/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 23.7969 - val_loss: 35.8695\n",
      "Epoch 15221/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 23.7807 - val_loss: 35.8592\n",
      "Epoch 15222/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 23.7645 - val_loss: 35.8479\n",
      "Epoch 15223/100000\n",
      "11/11 [==============================] - 0s 615us/step - loss: 23.7483 - val_loss: 35.8375\n",
      "Epoch 15224/100000\n",
      "11/11 [==============================] - 0s 213us/step - loss: 23.7321 - val_loss: 35.8265\n",
      "Epoch 15225/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 23.7159 - val_loss: 35.8159\n",
      "Epoch 15226/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 23.6997 - val_loss: 35.8050\n",
      "Epoch 15227/100000\n",
      "11/11 [==============================] - 0s 659us/step - loss: 23.6836 - val_loss: 35.7945\n",
      "Epoch 15228/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.6675 - val_loss: 35.7835\n",
      "Epoch 15229/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.6513 - val_loss: 35.7730\n",
      "Epoch 15230/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.6352 - val_loss: 35.7621\n",
      "Epoch 15231/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 23.6191 - val_loss: 35.7515\n",
      "Epoch 15232/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 23.6030 - val_loss: 35.7409\n",
      "Epoch 15233/100000\n",
      "11/11 [==============================] - 0s 902us/step - loss: 23.5869 - val_loss: 35.7301\n",
      "Epoch 15234/100000\n",
      "11/11 [==============================] - 0s 721us/step - loss: 23.5708 - val_loss: 35.7197\n",
      "Epoch 15235/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 23.5548 - val_loss: 35.7087\n",
      "Epoch 15236/100000\n",
      "11/11 [==============================] - 0s 775us/step - loss: 23.5387 - val_loss: 35.6985\n",
      "Epoch 15237/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 23.5227 - val_loss: 35.6874\n",
      "Epoch 15238/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 23.5066 - val_loss: 35.6773\n",
      "Epoch 15239/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 23.4906 - val_loss: 35.6661\n",
      "Epoch 15240/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 23.4746 - val_loss: 35.6561\n",
      "Epoch 15241/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 23.4586 - val_loss: 35.6450\n",
      "Epoch 15242/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 23.4426 - val_loss: 35.6351\n",
      "Epoch 15243/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 23.4266 - val_loss: 35.6239\n",
      "Epoch 15244/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 23.4106 - val_loss: 35.6139\n",
      "Epoch 15245/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 23.3946 - val_loss: 35.6028\n",
      "Epoch 15246/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 23.3787 - val_loss: 35.5930\n",
      "Epoch 15247/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 23.3627 - val_loss: 35.5817\n",
      "Epoch 15248/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 23.3468 - val_loss: 35.5721\n",
      "Epoch 15249/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.3309 - val_loss: 35.5606\n",
      "Epoch 15250/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 23.3150 - val_loss: 35.5513\n",
      "Epoch 15251/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 23.2991 - val_loss: 35.5395\n",
      "Epoch 15252/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 23.2832 - val_loss: 35.5306\n",
      "Epoch 15253/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 23.2673 - val_loss: 35.5186\n",
      "Epoch 15254/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 23.2514 - val_loss: 35.5099\n",
      "Epoch 15255/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 23.2356 - val_loss: 35.4976\n",
      "Epoch 15256/100000\n",
      "11/11 [==============================] - 0s 951us/step - loss: 23.2197 - val_loss: 35.4891\n",
      "Epoch 15257/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.2038 - val_loss: 35.4767\n",
      "Epoch 15258/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.1880 - val_loss: 35.4685\n",
      "Epoch 15259/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.1722 - val_loss: 35.4559\n",
      "Epoch 15260/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 23.1564 - val_loss: 35.4480\n",
      "Epoch 15261/100000\n",
      "11/11 [==============================] - 0s 696us/step - loss: 23.1406 - val_loss: 35.4349\n",
      "Epoch 15262/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 23.1249 - val_loss: 35.4278\n",
      "Epoch 15263/100000\n",
      "11/11 [==============================] - 0s 614us/step - loss: 23.1091 - val_loss: 35.4138\n",
      "Epoch 15264/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 23.0933 - val_loss: 35.4077\n",
      "Epoch 15265/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 23.0775 - val_loss: 35.3925\n",
      "Epoch 15266/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 23.0618 - val_loss: 35.3879\n",
      "Epoch 15267/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 23.0460 - val_loss: 35.3709\n",
      "Epoch 15268/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 23.0303 - val_loss: 35.3687\n",
      "Epoch 15269/100000\n",
      "11/11 [==============================] - 0s 810us/step - loss: 23.0146 - val_loss: 35.3489\n",
      "Epoch 15270/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 22.9989 - val_loss: 35.3501\n",
      "Epoch 15271/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 22.9832 - val_loss: 35.3261\n",
      "Epoch 15272/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.9675 - val_loss: 35.3325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15273/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.9519 - val_loss: 35.3023\n",
      "Epoch 15274/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.9362 - val_loss: 35.3162\n",
      "Epoch 15275/100000\n",
      "11/11 [==============================] - 0s 892us/step - loss: 22.9206 - val_loss: 35.2770\n",
      "Epoch 15276/100000\n",
      "11/11 [==============================] - 0s 763us/step - loss: 22.9050 - val_loss: 35.3017\n",
      "Epoch 15277/100000\n",
      "11/11 [==============================] - 0s 903us/step - loss: 22.8894 - val_loss: 35.2503\n",
      "Epoch 15278/100000\n",
      "11/11 [==============================] - 0s 825us/step - loss: 22.8738 - val_loss: 35.2883\n",
      "Epoch 15279/100000\n",
      "11/11 [==============================] - 0s 851us/step - loss: 22.8582 - val_loss: 35.2235\n",
      "Epoch 15280/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 22.8427 - val_loss: 35.2735\n",
      "Epoch 15281/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 22.8271 - val_loss: 35.2009\n",
      "Epoch 15282/100000\n",
      "11/11 [==============================] - 0s 756us/step - loss: 22.8115 - val_loss: 35.2511\n",
      "Epoch 15283/100000\n",
      "11/11 [==============================] - 0s 939us/step - loss: 22.7959 - val_loss: 35.1883\n",
      "Epoch 15284/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.7803 - val_loss: 35.2177\n",
      "Epoch 15285/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.7647 - val_loss: 35.1849\n",
      "Epoch 15286/100000\n",
      "11/11 [==============================] - 0s 715us/step - loss: 22.7491 - val_loss: 35.1789\n",
      "Epoch 15287/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 22.7335 - val_loss: 35.1819\n",
      "Epoch 15288/100000\n",
      "11/11 [==============================] - 0s 845us/step - loss: 22.7180 - val_loss: 35.1451\n",
      "Epoch 15289/100000\n",
      "11/11 [==============================] - 0s 714us/step - loss: 22.7026 - val_loss: 35.1704\n",
      "Epoch 15290/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 22.6871 - val_loss: 35.1228\n",
      "Epoch 15291/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 22.6716 - val_loss: 35.1467\n",
      "Epoch 15292/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.6561 - val_loss: 35.1119\n",
      "Epoch 15293/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.6406 - val_loss: 35.1145\n",
      "Epoch 15294/100000\n",
      "11/11 [==============================] - 0s 873us/step - loss: 22.6252 - val_loss: 35.1051\n",
      "Epoch 15295/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.6097 - val_loss: 35.0826\n",
      "Epoch 15296/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 22.5943 - val_loss: 35.0936\n",
      "Epoch 15297/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.5789 - val_loss: 35.0586\n",
      "Epoch 15298/100000\n",
      "11/11 [==============================] - 0s 643us/step - loss: 22.5635 - val_loss: 35.0731\n",
      "Epoch 15299/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 22.5481 - val_loss: 35.0436\n",
      "Epoch 15300/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 22.5327 - val_loss: 35.0457\n",
      "Epoch 15301/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 22.5173 - val_loss: 35.0328\n",
      "Epoch 15302/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 22.5019 - val_loss: 35.0173\n",
      "Epoch 15303/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 22.4866 - val_loss: 35.0198\n",
      "Epoch 15304/100000\n",
      "11/11 [==============================] - 0s 965us/step - loss: 22.4713 - val_loss: 34.9934\n",
      "Epoch 15305/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 22.4559 - val_loss: 35.0009\n",
      "Epoch 15306/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.4406 - val_loss: 34.9757\n",
      "Epoch 15307/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.4253 - val_loss: 34.9767\n",
      "Epoch 15308/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.4099 - val_loss: 34.9617\n",
      "Epoch 15309/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 22.3947 - val_loss: 34.9510\n",
      "Epoch 15310/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 22.3794 - val_loss: 34.9475\n",
      "Epoch 15311/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.3641 - val_loss: 34.9276\n",
      "Epoch 15312/100000\n",
      "11/11 [==============================] - 0s 898us/step - loss: 22.3488 - val_loss: 34.9296\n",
      "Epoch 15313/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.3336 - val_loss: 34.9083\n",
      "Epoch 15314/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.3184 - val_loss: 34.9081\n",
      "Epoch 15315/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.3031 - val_loss: 34.8919\n",
      "Epoch 15316/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.2879 - val_loss: 34.8845\n",
      "Epoch 15317/100000\n",
      "11/11 [==============================] - 0s 940us/step - loss: 22.2727 - val_loss: 34.8763\n",
      "Epoch 15318/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 22.2575 - val_loss: 34.8617\n",
      "Epoch 15319/100000\n",
      "11/11 [==============================] - 0s 640us/step - loss: 22.2423 - val_loss: 34.8591\n",
      "Epoch 15320/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.2271 - val_loss: 34.8413\n",
      "Epoch 15321/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 22.2119 - val_loss: 34.8394\n",
      "Epoch 15322/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.1967 - val_loss: 34.8231\n",
      "Epoch 15323/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 22.1816 - val_loss: 34.8180\n",
      "Epoch 15324/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.1665 - val_loss: 34.8061\n",
      "Epoch 15325/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 22.1513 - val_loss: 34.7961\n",
      "Epoch 15326/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.1362 - val_loss: 34.7889\n",
      "Epoch 15327/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.1211 - val_loss: 34.7751\n",
      "Epoch 15328/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 22.1060 - val_loss: 34.7706\n",
      "Epoch 15329/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 22.0909 - val_loss: 34.7556\n",
      "Epoch 15330/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 22.0758 - val_loss: 34.7508\n",
      "Epoch 15331/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 22.0608 - val_loss: 34.7373\n",
      "Epoch 15332/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 22.0457 - val_loss: 34.7301\n",
      "Epoch 15333/100000\n",
      "11/11 [==============================] - 0s 925us/step - loss: 22.0306 - val_loss: 34.7196\n",
      "Epoch 15334/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 22.0156 - val_loss: 34.7093\n",
      "Epoch 15335/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 22.0006 - val_loss: 34.7017\n",
      "Epoch 15336/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 21.9856 - val_loss: 34.6892\n",
      "Epoch 15337/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 21.9706 - val_loss: 34.6831\n",
      "Epoch 15338/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 21.9556 - val_loss: 34.6699\n",
      "Epoch 15339/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 21.9406 - val_loss: 34.6637\n",
      "Epoch 15340/100000\n",
      "11/11 [==============================] - 0s 638us/step - loss: 21.9256 - val_loss: 34.6513\n",
      "Epoch 15341/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 21.9106 - val_loss: 34.6438\n",
      "Epoch 15342/100000\n",
      "11/11 [==============================] - 0s 635us/step - loss: 21.8957 - val_loss: 34.6330\n",
      "Epoch 15343/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 21.8807 - val_loss: 34.6238\n",
      "Epoch 15344/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 21.8658 - val_loss: 34.6148\n",
      "Epoch 15345/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 21.8509 - val_loss: 34.6041\n",
      "Epoch 15346/100000\n",
      "11/11 [==============================] - 0s 805us/step - loss: 21.8360 - val_loss: 34.5963\n",
      "Epoch 15347/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 21.8211 - val_loss: 34.5847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15348/100000\n",
      "11/11 [==============================] - 0s 590us/step - loss: 21.8061 - val_loss: 34.5774\n",
      "Epoch 15349/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 21.7913 - val_loss: 34.5658\n",
      "Epoch 15350/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 21.7764 - val_loss: 34.5582\n",
      "Epoch 15351/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 21.7615 - val_loss: 34.5470\n",
      "Epoch 15352/100000\n",
      "11/11 [==============================] - 0s 944us/step - loss: 21.7467 - val_loss: 34.5389\n",
      "Epoch 15353/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.7318 - val_loss: 34.5285\n",
      "Epoch 15354/100000\n",
      "11/11 [==============================] - 0s 630us/step - loss: 21.7170 - val_loss: 34.5196\n",
      "Epoch 15355/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.7022 - val_loss: 34.5099\n",
      "Epoch 15356/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 21.6874 - val_loss: 34.5003\n",
      "Epoch 15357/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 21.6725 - val_loss: 34.4914\n",
      "Epoch 15358/100000\n",
      "11/11 [==============================] - 0s 877us/step - loss: 21.6578 - val_loss: 34.4811\n",
      "Epoch 15359/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.6430 - val_loss: 34.4728\n",
      "Epoch 15360/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 21.6282 - val_loss: 34.4621\n",
      "Epoch 15361/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 21.6134 - val_loss: 34.4541\n",
      "Epoch 15362/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 21.5986 - val_loss: 34.4433\n",
      "Epoch 15363/100000\n",
      "11/11 [==============================] - 0s 753us/step - loss: 21.5839 - val_loss: 34.4353\n",
      "Epoch 15364/100000\n",
      "11/11 [==============================] - 0s 1000us/step - loss: 21.5692 - val_loss: 34.4245\n",
      "Epoch 15365/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.5545 - val_loss: 34.4164\n",
      "Epoch 15366/100000\n",
      "11/11 [==============================] - 0s 813us/step - loss: 21.5397 - val_loss: 34.4059\n",
      "Epoch 15367/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 21.5251 - val_loss: 34.3977\n",
      "Epoch 15368/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 21.5103 - val_loss: 34.3871\n",
      "Epoch 15369/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.4957 - val_loss: 34.3789\n",
      "Epoch 15370/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 21.4810 - val_loss: 34.3685\n",
      "Epoch 15371/100000\n",
      "11/11 [==============================] - 0s 619us/step - loss: 21.4663 - val_loss: 34.3601\n",
      "Epoch 15372/100000\n",
      "11/11 [==============================] - 0s 691us/step - loss: 21.4517 - val_loss: 34.3500\n",
      "Epoch 15373/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.4370 - val_loss: 34.3413\n",
      "Epoch 15374/100000\n",
      "11/11 [==============================] - 0s 978us/step - loss: 21.4224 - val_loss: 34.3315\n",
      "Epoch 15375/100000\n",
      "11/11 [==============================] - 0s 508us/step - loss: 21.4078 - val_loss: 34.3225\n",
      "Epoch 15376/100000\n",
      "11/11 [==============================] - 0s 729us/step - loss: 21.3932 - val_loss: 34.3130\n",
      "Epoch 15377/100000\n",
      "11/11 [==============================] - 0s 657us/step - loss: 21.3785 - val_loss: 34.3037\n",
      "Epoch 15378/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 21.3640 - val_loss: 34.2945\n",
      "Epoch 15379/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 21.3494 - val_loss: 34.2851\n",
      "Epoch 15380/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 21.3348 - val_loss: 34.2760\n",
      "Epoch 15381/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 21.3202 - val_loss: 34.2665\n",
      "Epoch 15382/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 21.3056 - val_loss: 34.2575\n",
      "Epoch 15383/100000\n",
      "11/11 [==============================] - 0s 753us/step - loss: 21.2911 - val_loss: 34.2479\n",
      "Epoch 15384/100000\n",
      "11/11 [==============================] - 0s 930us/step - loss: 21.2766 - val_loss: 34.2391\n",
      "Epoch 15385/100000\n",
      "11/11 [==============================] - 0s 883us/step - loss: 21.2620 - val_loss: 34.2292\n",
      "Epoch 15386/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 21.2475 - val_loss: 34.2207\n",
      "Epoch 15387/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 21.2330 - val_loss: 34.2106\n",
      "Epoch 15388/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.2185 - val_loss: 34.2024\n",
      "Epoch 15389/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.2040 - val_loss: 34.1919\n",
      "Epoch 15390/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 21.1896 - val_loss: 34.1842\n",
      "Epoch 15391/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.1751 - val_loss: 34.1732\n",
      "Epoch 15392/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 21.1606 - val_loss: 34.1660\n",
      "Epoch 15393/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.1462 - val_loss: 34.1544\n",
      "Epoch 15394/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.1318 - val_loss: 34.1481\n",
      "Epoch 15395/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 21.1173 - val_loss: 34.1353\n",
      "Epoch 15396/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 21.1029 - val_loss: 34.1305\n",
      "Epoch 15397/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.0885 - val_loss: 34.1160\n",
      "Epoch 15398/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 21.0741 - val_loss: 34.1133\n",
      "Epoch 15399/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.0597 - val_loss: 34.0963\n",
      "Epoch 15400/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 21.0453 - val_loss: 34.0967\n",
      "Epoch 15401/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.0310 - val_loss: 34.0758\n",
      "Epoch 15402/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.0166 - val_loss: 34.0810\n",
      "Epoch 15403/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 21.0022 - val_loss: 34.0542\n",
      "Epoch 15404/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.9879 - val_loss: 34.0667\n",
      "Epoch 15405/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.9736 - val_loss: 34.0311\n",
      "Epoch 15406/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.9593 - val_loss: 34.0545\n",
      "Epoch 15407/100000\n",
      "11/11 [==============================] - 0s 777us/step - loss: 20.9450 - val_loss: 34.0056\n",
      "Epoch 15408/100000\n",
      "11/11 [==============================] - 0s 995us/step - loss: 20.9307 - val_loss: 34.0447\n",
      "Epoch 15409/100000\n",
      "11/11 [==============================] - 0s 749us/step - loss: 20.9165 - val_loss: 33.9786\n",
      "Epoch 15410/100000\n",
      "11/11 [==============================] - 0s 597us/step - loss: 20.9023 - val_loss: 34.0350\n",
      "Epoch 15411/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 20.8881 - val_loss: 33.9546\n",
      "Epoch 15412/100000\n",
      "11/11 [==============================] - 0s 991us/step - loss: 20.8739 - val_loss: 34.0177\n",
      "Epoch 15413/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 20.8596 - val_loss: 33.9427\n",
      "Epoch 15414/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.8452 - val_loss: 33.9848\n",
      "Epoch 15415/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.8309 - val_loss: 33.9452\n",
      "Epoch 15416/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 20.8166 - val_loss: 33.9424\n",
      "Epoch 15417/100000\n",
      "11/11 [==============================] - 0s 723us/step - loss: 20.8023 - val_loss: 33.9495\n",
      "Epoch 15418/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 20.7882 - val_loss: 33.9065\n",
      "Epoch 15419/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.7740 - val_loss: 33.9413\n",
      "Epoch 15420/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.7599 - val_loss: 33.8878\n",
      "Epoch 15421/100000\n",
      "11/11 [==============================] - 0s 857us/step - loss: 20.7457 - val_loss: 33.9153\n",
      "Epoch 15422/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.7314 - val_loss: 33.8845\n",
      "Epoch 15423/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 880us/step - loss: 20.7172 - val_loss: 33.8797\n",
      "Epoch 15424/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 20.7031 - val_loss: 33.8832\n",
      "Epoch 15425/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 20.6890 - val_loss: 33.8489\n",
      "Epoch 15426/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 20.6749 - val_loss: 33.8708\n",
      "Epoch 15427/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 20.6608 - val_loss: 33.8320\n",
      "Epoch 15428/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 20.6467 - val_loss: 33.8450\n",
      "Epoch 15429/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 20.6325 - val_loss: 33.8256\n",
      "Epoch 15430/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 20.6184 - val_loss: 33.8143\n",
      "Epoch 15431/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 20.6043 - val_loss: 33.8186\n",
      "Epoch 15432/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 20.5903 - val_loss: 33.7892\n",
      "Epoch 15433/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 20.5762 - val_loss: 33.8026\n",
      "Epoch 15434/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 20.5622 - val_loss: 33.7742\n",
      "Epoch 15435/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 20.5481 - val_loss: 33.7776\n",
      "Epoch 15436/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 20.5341 - val_loss: 33.7648\n",
      "Epoch 15437/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 20.5200 - val_loss: 33.7507\n",
      "Epoch 15438/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 20.5060 - val_loss: 33.7536\n",
      "Epoch 15439/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 20.4920 - val_loss: 33.7291\n",
      "Epoch 15440/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 20.4780 - val_loss: 33.7355\n",
      "Epoch 15441/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 20.4640 - val_loss: 33.7144\n",
      "Epoch 15442/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 20.4500 - val_loss: 33.7123\n",
      "Epoch 15443/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 20.4361 - val_loss: 33.7026\n",
      "Epoch 15444/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 20.4221 - val_loss: 33.6886\n",
      "Epoch 15445/100000\n",
      "11/11 [==============================] - 0s 218us/step - loss: 20.4081 - val_loss: 33.6887\n",
      "Epoch 15446/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 20.3942 - val_loss: 33.6686\n",
      "Epoch 15447/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 20.3803 - val_loss: 33.6703\n",
      "Epoch 15448/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 20.3663 - val_loss: 33.6530\n",
      "Epoch 15449/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 20.3524 - val_loss: 33.6487\n",
      "Epoch 15450/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 20.3385 - val_loss: 33.6392\n",
      "Epoch 15451/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 20.3246 - val_loss: 33.6268\n",
      "Epoch 15452/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 20.3107 - val_loss: 33.6242\n",
      "Epoch 15453/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 20.2968 - val_loss: 33.6073\n",
      "Epoch 15454/100000\n",
      "11/11 [==============================] - 0s 205us/step - loss: 20.2830 - val_loss: 33.6062\n",
      "Epoch 15455/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 20.2691 - val_loss: 33.5907\n",
      "Epoch 15456/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 20.2552 - val_loss: 33.5859\n",
      "Epoch 15457/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 20.2414 - val_loss: 33.5755\n",
      "Epoch 15458/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 20.2276 - val_loss: 33.5652\n",
      "Epoch 15459/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 20.2137 - val_loss: 33.5598\n",
      "Epoch 15460/100000\n",
      "11/11 [==============================] - 0s 204us/step - loss: 20.1999 - val_loss: 33.5459\n",
      "Epoch 15461/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 20.1861 - val_loss: 33.5424\n",
      "Epoch 15462/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 20.1723 - val_loss: 33.5283\n",
      "Epoch 15463/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 20.1585 - val_loss: 33.5234\n",
      "Epoch 15464/100000\n",
      "11/11 [==============================] - 0s 623us/step - loss: 20.1447 - val_loss: 33.5120\n",
      "Epoch 15465/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 20.1309 - val_loss: 33.5036\n",
      "Epoch 15466/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 20.1172 - val_loss: 33.4958\n",
      "Epoch 15467/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 20.1034 - val_loss: 33.4843\n",
      "Epoch 15468/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 20.0897 - val_loss: 33.4789\n",
      "Epoch 15469/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 20.0759 - val_loss: 33.4660\n",
      "Epoch 15470/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 20.0622 - val_loss: 33.4608\n",
      "Epoch 15471/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 20.0485 - val_loss: 33.4487\n",
      "Epoch 15472/100000\n",
      "11/11 [==============================] - 0s 660us/step - loss: 20.0347 - val_loss: 33.4419\n",
      "Epoch 15473/100000\n",
      "11/11 [==============================] - 0s 599us/step - loss: 20.0210 - val_loss: 33.4319\n",
      "Epoch 15474/100000\n",
      "11/11 [==============================] - 0s 826us/step - loss: 20.0073 - val_loss: 33.4228\n",
      "Epoch 15475/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 19.9936 - val_loss: 33.4150\n",
      "Epoch 15476/100000\n",
      "11/11 [==============================] - 0s 884us/step - loss: 19.9800 - val_loss: 33.4041\n",
      "Epoch 15477/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 19.9663 - val_loss: 33.3976\n",
      "Epoch 15478/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 19.9526 - val_loss: 33.3861\n",
      "Epoch 15479/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.9390 - val_loss: 33.3795\n",
      "Epoch 15480/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.9253 - val_loss: 33.3687\n",
      "Epoch 15481/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 19.9117 - val_loss: 33.3610\n",
      "Epoch 15482/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 19.8980 - val_loss: 33.3514\n",
      "Epoch 15483/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.8844 - val_loss: 33.3424\n",
      "Epoch 15484/100000\n",
      "11/11 [==============================] - 0s 895us/step - loss: 19.8708 - val_loss: 33.3342\n",
      "Epoch 15485/100000\n",
      "11/11 [==============================] - 0s 542us/step - loss: 19.8572 - val_loss: 33.3240\n",
      "Epoch 15486/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 19.8436 - val_loss: 33.3166\n",
      "Epoch 15487/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 19.8300 - val_loss: 33.3059\n",
      "Epoch 15488/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 19.8165 - val_loss: 33.2987\n",
      "Epoch 15489/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 19.8029 - val_loss: 33.2882\n",
      "Epoch 15490/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 19.7893 - val_loss: 33.2805\n",
      "Epoch 15491/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 19.7757 - val_loss: 33.2706\n",
      "Epoch 15492/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 19.7622 - val_loss: 33.2623\n",
      "Epoch 15493/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 19.7487 - val_loss: 33.2531\n",
      "Epoch 15494/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 19.7351 - val_loss: 33.2440\n",
      "Epoch 15495/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 19.7216 - val_loss: 33.2355\n",
      "Epoch 15496/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 19.7081 - val_loss: 33.2259\n",
      "Epoch 15497/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 19.6946 - val_loss: 33.2178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15498/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 19.6811 - val_loss: 33.2079\n",
      "Epoch 15499/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 19.6676 - val_loss: 33.1998\n",
      "Epoch 15500/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 19.6541 - val_loss: 33.1901\n",
      "Epoch 15501/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 19.6406 - val_loss: 33.1818\n",
      "Epoch 15502/100000\n",
      "11/11 [==============================] - 0s 226us/step - loss: 19.6272 - val_loss: 33.1722\n",
      "Epoch 15503/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 19.6137 - val_loss: 33.1638\n",
      "Epoch 15504/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 19.6003 - val_loss: 33.1544\n",
      "Epoch 15505/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 19.5868 - val_loss: 33.1458\n",
      "Epoch 15506/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 19.5734 - val_loss: 33.1366\n",
      "Epoch 15507/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 19.5599 - val_loss: 33.1278\n",
      "Epoch 15508/100000\n",
      "11/11 [==============================] - 0s 227us/step - loss: 19.5465 - val_loss: 33.1186\n",
      "Epoch 15509/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 19.5331 - val_loss: 33.1099\n",
      "Epoch 15510/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 19.5197 - val_loss: 33.1007\n",
      "Epoch 15511/100000\n",
      "11/11 [==============================] - 0s 214us/step - loss: 19.5063 - val_loss: 33.0920\n",
      "Epoch 15512/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 19.4929 - val_loss: 33.0827\n",
      "Epoch 15513/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 19.4795 - val_loss: 33.0741\n",
      "Epoch 15514/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 19.4661 - val_loss: 33.0647\n",
      "Epoch 15515/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 19.4528 - val_loss: 33.0563\n",
      "Epoch 15516/100000\n",
      "11/11 [==============================] - 0s 221us/step - loss: 19.4394 - val_loss: 33.0467\n",
      "Epoch 15517/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 19.4261 - val_loss: 33.0383\n",
      "Epoch 15518/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 19.4127 - val_loss: 33.0287\n",
      "Epoch 15519/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 19.3994 - val_loss: 33.0204\n",
      "Epoch 15520/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 19.3861 - val_loss: 33.0107\n",
      "Epoch 15521/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 19.3727 - val_loss: 33.0025\n",
      "Epoch 15522/100000\n",
      "11/11 [==============================] - 0s 727us/step - loss: 19.3595 - val_loss: 32.9927\n",
      "Epoch 15523/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.3461 - val_loss: 32.9845\n",
      "Epoch 15524/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.3328 - val_loss: 32.9747\n",
      "Epoch 15525/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.3195 - val_loss: 32.9666\n",
      "Epoch 15526/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.3063 - val_loss: 32.9565\n",
      "Epoch 15527/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 19.2930 - val_loss: 32.9488\n",
      "Epoch 15528/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 19.2797 - val_loss: 32.9383\n",
      "Epoch 15529/100000\n",
      "11/11 [==============================] - 0s 712us/step - loss: 19.2664 - val_loss: 32.9311\n",
      "Epoch 15530/100000\n",
      "11/11 [==============================] - 0s 879us/step - loss: 19.2532 - val_loss: 32.9200\n",
      "Epoch 15531/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 19.2399 - val_loss: 32.9135\n",
      "Epoch 15532/100000\n",
      "11/11 [==============================] - 0s 774us/step - loss: 19.2267 - val_loss: 32.9014\n",
      "Epoch 15533/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 19.2135 - val_loss: 32.8961\n",
      "Epoch 15534/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 19.2002 - val_loss: 32.8826\n",
      "Epoch 15535/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 19.1870 - val_loss: 32.8790\n",
      "Epoch 15536/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 19.1738 - val_loss: 32.8632\n",
      "Epoch 15537/100000\n",
      "11/11 [==============================] - 0s 770us/step - loss: 19.1606 - val_loss: 32.8627\n",
      "Epoch 15538/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 19.1474 - val_loss: 32.8430\n",
      "Epoch 15539/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 19.1343 - val_loss: 32.8474\n",
      "Epoch 15540/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 19.1211 - val_loss: 32.8213\n",
      "Epoch 15541/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 19.1079 - val_loss: 32.8340\n",
      "Epoch 15542/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 19.0947 - val_loss: 32.7974\n",
      "Epoch 15543/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 19.0816 - val_loss: 32.8235\n",
      "Epoch 15544/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 19.0685 - val_loss: 32.7701\n",
      "Epoch 15545/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 19.0554 - val_loss: 32.8166\n",
      "Epoch 15546/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 19.0424 - val_loss: 32.7403\n",
      "Epoch 15547/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 19.0294 - val_loss: 32.8099\n",
      "Epoch 15548/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 19.0164 - val_loss: 32.7151\n",
      "Epoch 15549/100000\n",
      "11/11 [==============================] - 0s 228us/step - loss: 19.0033 - val_loss: 32.7911\n",
      "Epoch 15550/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 18.9901 - val_loss: 32.7090\n",
      "Epoch 15551/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 18.9768 - val_loss: 32.7489\n",
      "Epoch 15552/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 18.9635 - val_loss: 32.7216\n",
      "Epoch 15553/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 18.9503 - val_loss: 32.6987\n",
      "Epoch 15554/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 18.9373 - val_loss: 32.7291\n",
      "Epoch 15555/100000\n",
      "11/11 [==============================] - 0s 662us/step - loss: 18.9244 - val_loss: 32.6661\n",
      "Epoch 15556/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 18.9114 - val_loss: 32.7114\n",
      "Epoch 15557/100000\n",
      "11/11 [==============================] - 0s 702us/step - loss: 18.8983 - val_loss: 32.6613\n",
      "Epoch 15558/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 18.8851 - val_loss: 32.6708\n",
      "Epoch 15559/100000\n",
      "11/11 [==============================] - 0s 689us/step - loss: 18.8720 - val_loss: 32.6685\n",
      "Epoch 15560/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.8590 - val_loss: 32.6320\n",
      "Epoch 15561/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.8460 - val_loss: 32.6618\n",
      "Epoch 15562/100000\n",
      "11/11 [==============================] - 0s 908us/step - loss: 18.8331 - val_loss: 32.6140\n",
      "Epoch 15563/100000\n",
      "11/11 [==============================] - 0s 996us/step - loss: 18.8200 - val_loss: 32.6323\n",
      "Epoch 15564/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 18.8069 - val_loss: 32.6133\n",
      "Epoch 15565/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.7939 - val_loss: 32.5952\n",
      "Epoch 15566/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.7809 - val_loss: 32.6093\n",
      "Epoch 15567/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.7679 - val_loss: 32.5707\n",
      "Epoch 15568/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.7550 - val_loss: 32.5886\n",
      "Epoch 15569/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 18.7420 - val_loss: 32.5624\n",
      "Epoch 15570/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 18.7290 - val_loss: 32.5565\n",
      "Epoch 15571/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.7160 - val_loss: 32.5576\n",
      "Epoch 15572/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 18.7031 - val_loss: 32.5289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15573/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.6902 - val_loss: 32.5420\n",
      "Epoch 15574/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 18.6772 - val_loss: 32.5142\n",
      "Epoch 15575/100000\n",
      "11/11 [==============================] - 0s 855us/step - loss: 18.6642 - val_loss: 32.5152\n",
      "Epoch 15576/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 18.6513 - val_loss: 32.5063\n",
      "Epoch 15577/100000\n",
      "11/11 [==============================] - 0s 849us/step - loss: 18.6384 - val_loss: 32.4875\n",
      "Epoch 15578/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 18.6254 - val_loss: 32.4939\n",
      "Epoch 15579/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.6126 - val_loss: 32.4682\n",
      "Epoch 15580/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.5996 - val_loss: 32.4721\n",
      "Epoch 15581/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 18.5867 - val_loss: 32.4563\n",
      "Epoch 15582/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 18.5738 - val_loss: 32.4460\n",
      "Epoch 15583/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 18.5609 - val_loss: 32.4445\n",
      "Epoch 15584/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 18.5481 - val_loss: 32.4235\n",
      "Epoch 15585/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 18.5352 - val_loss: 32.4266\n",
      "Epoch 15586/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 18.5223 - val_loss: 32.4077\n",
      "Epoch 15587/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 18.5095 - val_loss: 32.4033\n",
      "Epoch 15588/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 18.4966 - val_loss: 32.3948\n",
      "Epoch 15589/100000\n",
      "11/11 [==============================] - 0s 608us/step - loss: 18.4837 - val_loss: 32.3801\n",
      "Epoch 15590/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 18.4709 - val_loss: 32.3793\n",
      "Epoch 15591/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 18.4581 - val_loss: 32.3610\n",
      "Epoch 15592/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 18.4452 - val_loss: 32.3592\n",
      "Epoch 15593/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 18.4324 - val_loss: 32.3455\n",
      "Epoch 15594/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 18.4196 - val_loss: 32.3368\n",
      "Epoch 15595/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 18.4067 - val_loss: 32.3305\n",
      "Epoch 15596/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 18.3939 - val_loss: 32.3156\n",
      "Epoch 15597/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 18.3811 - val_loss: 32.3130\n",
      "Epoch 15598/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 18.3683 - val_loss: 32.2976\n",
      "Epoch 15599/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 18.3555 - val_loss: 32.2927\n",
      "Epoch 15600/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 18.3427 - val_loss: 32.2814\n",
      "Epoch 15601/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 18.3299 - val_loss: 32.2715\n",
      "Epoch 15602/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 18.3172 - val_loss: 32.2650\n",
      "Epoch 15603/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 18.3044 - val_loss: 32.2514\n",
      "Epoch 15604/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 18.2916 - val_loss: 32.2467\n",
      "Epoch 15605/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 18.2788 - val_loss: 32.2332\n",
      "Epoch 15606/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 18.2661 - val_loss: 32.2267\n",
      "Epoch 15607/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 18.2533 - val_loss: 32.2161\n",
      "Epoch 15608/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 18.2406 - val_loss: 32.2062\n",
      "Epoch 15609/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 18.2279 - val_loss: 32.1989\n",
      "Epoch 15610/100000\n",
      "11/11 [==============================] - 0s 721us/step - loss: 18.2151 - val_loss: 32.1866\n",
      "Epoch 15611/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 18.2024 - val_loss: 32.1806\n",
      "Epoch 15612/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 18.1897 - val_loss: 32.1680\n",
      "Epoch 15613/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 18.1769 - val_loss: 32.1611\n",
      "Epoch 15614/100000\n",
      "11/11 [==============================] - 0s 625us/step - loss: 18.1642 - val_loss: 32.1502\n",
      "Epoch 15615/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 18.1515 - val_loss: 32.1411\n",
      "Epoch 15616/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 18.1388 - val_loss: 32.1325\n",
      "Epoch 15617/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 18.1261 - val_loss: 32.1213\n",
      "Epoch 15618/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 18.1134 - val_loss: 32.1142\n",
      "Epoch 15619/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 18.1007 - val_loss: 32.1022\n",
      "Epoch 15620/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 18.0880 - val_loss: 32.0951\n",
      "Epoch 15621/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 18.0754 - val_loss: 32.0839\n",
      "Epoch 15622/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 18.0627 - val_loss: 32.0755\n",
      "Epoch 15623/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 18.0500 - val_loss: 32.0658\n",
      "Epoch 15624/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 18.0374 - val_loss: 32.0558\n",
      "Epoch 15625/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 18.0247 - val_loss: 32.0474\n",
      "Epoch 15626/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 18.0121 - val_loss: 32.0365\n",
      "Epoch 15627/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 17.9994 - val_loss: 32.0285\n",
      "Epoch 15628/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 17.9868 - val_loss: 32.0175\n",
      "Epoch 15629/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 17.9741 - val_loss: 32.0093\n",
      "Epoch 15630/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 17.9615 - val_loss: 31.9988\n",
      "Epoch 15631/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 17.9489 - val_loss: 31.9899\n",
      "Epoch 15632/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 17.9362 - val_loss: 31.9802\n",
      "Epoch 15633/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 17.9236 - val_loss: 31.9705\n",
      "Epoch 15634/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 17.9110 - val_loss: 31.9614\n",
      "Epoch 15635/100000\n",
      "11/11 [==============================] - 0s 594us/step - loss: 17.8984 - val_loss: 31.9512\n",
      "Epoch 15636/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 17.8858 - val_loss: 31.9425\n",
      "Epoch 15637/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 17.8732 - val_loss: 31.9320\n",
      "Epoch 15638/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 17.8606 - val_loss: 31.9233\n",
      "Epoch 15639/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 17.8480 - val_loss: 31.9130\n",
      "Epoch 15640/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 17.8354 - val_loss: 31.9040\n",
      "Epoch 15641/100000\n",
      "11/11 [==============================] - 0s 873us/step - loss: 17.8228 - val_loss: 31.8940\n",
      "Epoch 15642/100000\n",
      "11/11 [==============================] - 0s 731us/step - loss: 17.8103 - val_loss: 31.8846\n",
      "Epoch 15643/100000\n",
      "11/11 [==============================] - 0s 765us/step - loss: 17.7977 - val_loss: 31.8751\n",
      "Epoch 15644/100000\n",
      "11/11 [==============================] - 0s 897us/step - loss: 17.7851 - val_loss: 31.8651\n",
      "Epoch 15645/100000\n",
      "11/11 [==============================] - 0s 680us/step - loss: 17.7726 - val_loss: 31.8561\n",
      "Epoch 15646/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17.7600 - val_loss: 31.8458\n",
      "Epoch 15647/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 17.7474 - val_loss: 31.8370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15648/100000\n",
      "11/11 [==============================] - 0s 551us/step - loss: 17.7349 - val_loss: 31.8263\n",
      "Epoch 15649/100000\n",
      "11/11 [==============================] - 0s 851us/step - loss: 17.7223 - val_loss: 31.8177\n",
      "Epoch 15650/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17.7098 - val_loss: 31.8071\n",
      "Epoch 15651/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 17.6972 - val_loss: 31.7983\n",
      "Epoch 15652/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17.6847 - val_loss: 31.7878\n",
      "Epoch 15653/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17.6722 - val_loss: 31.7789\n",
      "Epoch 15654/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17.6597 - val_loss: 31.7687\n",
      "Epoch 15655/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 17.6471 - val_loss: 31.7594\n",
      "Epoch 15656/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 17.6346 - val_loss: 31.7495\n",
      "Epoch 15657/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 17.6221 - val_loss: 31.7399\n",
      "Epoch 15658/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 17.6096 - val_loss: 31.7301\n",
      "Epoch 15659/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 17.5971 - val_loss: 31.7204\n",
      "Epoch 15660/100000\n",
      "11/11 [==============================] - 0s 646us/step - loss: 17.5846 - val_loss: 31.7108\n",
      "Epoch 15661/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 17.5721 - val_loss: 31.7009\n",
      "Epoch 15662/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 17.5596 - val_loss: 31.6914\n",
      "Epoch 15663/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 17.5472 - val_loss: 31.6813\n",
      "Epoch 15664/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 17.5347 - val_loss: 31.6721\n",
      "Epoch 15665/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 17.5222 - val_loss: 31.6616\n",
      "Epoch 15666/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 17.5097 - val_loss: 31.6527\n",
      "Epoch 15667/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 17.4972 - val_loss: 31.6420\n",
      "Epoch 15668/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 17.4847 - val_loss: 31.6333\n",
      "Epoch 15669/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 17.4723 - val_loss: 31.6222\n",
      "Epoch 15670/100000\n",
      "11/11 [==============================] - 0s 604us/step - loss: 17.4598 - val_loss: 31.6141\n",
      "Epoch 15671/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 17.4473 - val_loss: 31.6024\n",
      "Epoch 15672/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 17.4349 - val_loss: 31.5948\n",
      "Epoch 15673/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 17.4225 - val_loss: 31.5824\n",
      "Epoch 15674/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 17.4100 - val_loss: 31.5757\n",
      "Epoch 15675/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 17.3976 - val_loss: 31.5622\n",
      "Epoch 15676/100000\n",
      "11/11 [==============================] - 0s 673us/step - loss: 17.3852 - val_loss: 31.5569\n",
      "Epoch 15677/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 17.3727 - val_loss: 31.5415\n",
      "Epoch 15678/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 17.3603 - val_loss: 31.5386\n",
      "Epoch 15679/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 17.3479 - val_loss: 31.5200\n",
      "Epoch 15680/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 17.3355 - val_loss: 31.5212\n",
      "Epoch 15681/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 17.3231 - val_loss: 31.4974\n",
      "Epoch 15682/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 17.3107 - val_loss: 31.5054\n",
      "Epoch 15683/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 17.2983 - val_loss: 31.4726\n",
      "Epoch 15684/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 17.2859 - val_loss: 31.4923\n",
      "Epoch 15685/100000\n",
      "11/11 [==============================] - 0s 864us/step - loss: 17.2736 - val_loss: 31.4447\n",
      "Epoch 15686/100000\n",
      "11/11 [==============================] - 0s 667us/step - loss: 17.2612 - val_loss: 31.4828\n",
      "Epoch 15687/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 17.2489 - val_loss: 31.4131\n",
      "Epoch 15688/100000\n",
      "11/11 [==============================] - 0s 718us/step - loss: 17.2366 - val_loss: 31.4765\n",
      "Epoch 15689/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 17.2244 - val_loss: 31.3814\n",
      "Epoch 15690/100000\n",
      "11/11 [==============================] - 0s 621us/step - loss: 17.2122 - val_loss: 31.4643\n",
      "Epoch 15691/100000\n",
      "11/11 [==============================] - 0s 730us/step - loss: 17.1998 - val_loss: 31.3639\n",
      "Epoch 15692/100000\n",
      "11/11 [==============================] - 0s 637us/step - loss: 17.1874 - val_loss: 31.4291\n",
      "Epoch 15693/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 17.1747 - val_loss: 31.3713\n",
      "Epoch 15694/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 17.1621 - val_loss: 31.3741\n",
      "Epoch 15695/100000\n",
      "11/11 [==============================] - 0s 757us/step - loss: 17.1497 - val_loss: 31.3855\n",
      "Epoch 15696/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 17.1374 - val_loss: 31.3280\n",
      "Epoch 15697/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 17.1253 - val_loss: 31.3781\n",
      "Epoch 15698/100000\n",
      "11/11 [==============================] - 0s 744us/step - loss: 17.1129 - val_loss: 31.3121\n",
      "Epoch 15699/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 17.1005 - val_loss: 31.3401\n",
      "Epoch 15700/100000\n",
      "11/11 [==============================] - 0s 648us/step - loss: 17.0880 - val_loss: 31.3191\n",
      "Epoch 15701/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 17.0756 - val_loss: 31.2935\n",
      "Epoch 15702/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 17.0634 - val_loss: 31.3194\n",
      "Epoch 15703/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 17.0511 - val_loss: 31.2655\n",
      "Epoch 15704/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 17.0388 - val_loss: 31.2942\n",
      "Epoch 15705/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 17.0265 - val_loss: 31.2615\n",
      "Epoch 15706/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 17.0141 - val_loss: 31.2528\n",
      "Epoch 15707/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 17.0017 - val_loss: 31.2608\n",
      "Epoch 15708/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 16.9895 - val_loss: 31.2207\n",
      "Epoch 15709/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 16.9772 - val_loss: 31.2431\n",
      "Epoch 15710/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 16.9649 - val_loss: 31.2081\n",
      "Epoch 15711/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 16.9526 - val_loss: 31.2091\n",
      "Epoch 15712/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 16.9403 - val_loss: 31.2042\n",
      "Epoch 15713/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 16.9280 - val_loss: 31.1762\n",
      "Epoch 15714/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 16.9157 - val_loss: 31.1906\n",
      "Epoch 15715/100000\n",
      "11/11 [==============================] - 0s 714us/step - loss: 16.9035 - val_loss: 31.1575\n",
      "Epoch 15716/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 16.8911 - val_loss: 31.1627\n",
      "Epoch 15717/100000\n",
      "11/11 [==============================] - 0s 736us/step - loss: 16.8789 - val_loss: 31.1488\n",
      "Epoch 15718/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 16.8666 - val_loss: 31.1313\n",
      "Epoch 15719/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 16.8544 - val_loss: 31.1371\n",
      "Epoch 15720/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 16.8421 - val_loss: 31.1082\n",
      "Epoch 15721/100000\n",
      "11/11 [==============================] - 0s 796us/step - loss: 16.8298 - val_loss: 31.1145\n",
      "Epoch 15722/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 16.8176 - val_loss: 31.0950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15723/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 16.8053 - val_loss: 31.0857\n",
      "Epoch 15724/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 16.7931 - val_loss: 31.0829\n",
      "Epoch 15725/100000\n",
      "11/11 [==============================] - 0s 704us/step - loss: 16.7809 - val_loss: 31.0603\n",
      "Epoch 15726/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 16.7686 - val_loss: 31.0642\n",
      "Epoch 15727/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 16.7564 - val_loss: 31.0425\n",
      "Epoch 15728/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 16.7441 - val_loss: 31.0388\n",
      "Epoch 15729/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 16.7319 - val_loss: 31.0287\n",
      "Epoch 15730/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 16.7197 - val_loss: 31.0129\n",
      "Epoch 15731/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 16.7075 - val_loss: 31.0124\n",
      "Epoch 15732/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 16.6953 - val_loss: 30.9916\n",
      "Epoch 15733/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 16.6831 - val_loss: 30.9907\n",
      "Epoch 15734/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 16.6708 - val_loss: 30.9751\n",
      "Epoch 15735/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 16.6586 - val_loss: 30.9659\n",
      "Epoch 15736/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 16.6464 - val_loss: 30.9591\n",
      "Epoch 15737/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 16.6342 - val_loss: 30.9427\n",
      "Epoch 15738/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 16.6220 - val_loss: 30.9402\n",
      "Epoch 15739/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 16.6098 - val_loss: 30.9229\n",
      "Epoch 15740/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 16.5976 - val_loss: 30.9181\n",
      "Epoch 15741/100000\n",
      "11/11 [==============================] - 0s 229us/step - loss: 16.5854 - val_loss: 30.9056\n",
      "Epoch 15742/100000\n",
      "11/11 [==============================] - 0s 407us/step - loss: 16.5732 - val_loss: 30.8947\n",
      "Epoch 15743/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 16.5611 - val_loss: 30.8880\n",
      "Epoch 15744/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 16.5489 - val_loss: 30.8728\n",
      "Epoch 15745/100000\n",
      "11/11 [==============================] - 0s 380us/step - loss: 16.5367 - val_loss: 30.8683\n",
      "Epoch 15746/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 16.5245 - val_loss: 30.8531\n",
      "Epoch 15747/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 16.5124 - val_loss: 30.8465\n",
      "Epoch 15748/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 16.5002 - val_loss: 30.8349\n",
      "Epoch 15749/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 16.4880 - val_loss: 30.8240\n",
      "Epoch 15750/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 16.4759 - val_loss: 30.8164\n",
      "Epoch 15751/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 16.4637 - val_loss: 30.8026\n",
      "Epoch 15752/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 16.4516 - val_loss: 30.7966\n",
      "Epoch 15753/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 16.4394 - val_loss: 30.7825\n",
      "Epoch 15754/100000\n",
      "11/11 [==============================] - 0s 857us/step - loss: 16.4273 - val_loss: 30.7754\n",
      "Epoch 15755/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 16.4151 - val_loss: 30.7636\n",
      "Epoch 15756/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 16.4030 - val_loss: 30.7537\n",
      "Epoch 15757/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 16.3909 - val_loss: 30.7447\n",
      "Epoch 15758/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 16.3787 - val_loss: 30.7323\n",
      "Epoch 15759/100000\n",
      "11/11 [==============================] - 0s 666us/step - loss: 16.3666 - val_loss: 30.7250\n",
      "Epoch 15760/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 16.3545 - val_loss: 30.7118\n",
      "Epoch 15761/100000\n",
      "11/11 [==============================] - 0s 599us/step - loss: 16.3423 - val_loss: 30.7044\n",
      "Epoch 15762/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 16.3302 - val_loss: 30.6921\n",
      "Epoch 15763/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 16.3181 - val_loss: 30.6832\n",
      "Epoch 15764/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 16.3060 - val_loss: 30.6727\n",
      "Epoch 15765/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 16.2939 - val_loss: 30.6620\n",
      "Epoch 15766/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 16.2818 - val_loss: 30.6530\n",
      "Epoch 15767/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 16.2697 - val_loss: 30.6412\n",
      "Epoch 15768/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 16.2576 - val_loss: 30.6330\n",
      "Epoch 15769/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 16.2455 - val_loss: 30.6208\n",
      "Epoch 15770/100000\n",
      "11/11 [==============================] - 0s 917us/step - loss: 16.2334 - val_loss: 30.6125\n",
      "Epoch 15771/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 16.2213 - val_loss: 30.6008\n",
      "Epoch 15772/100000\n",
      "11/11 [==============================] - 0s 902us/step - loss: 16.2092 - val_loss: 30.5919\n",
      "Epoch 15773/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 16.1971 - val_loss: 30.5809\n",
      "Epoch 15774/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 16.1850 - val_loss: 30.5711\n",
      "Epoch 15775/100000\n",
      "11/11 [==============================] - 0s 708us/step - loss: 16.1730 - val_loss: 30.5610\n",
      "Epoch 15776/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 16.1609 - val_loss: 30.5504\n",
      "Epoch 15777/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 16.1488 - val_loss: 30.5409\n",
      "Epoch 15778/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 16.1367 - val_loss: 30.5298\n",
      "Epoch 15779/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 16.1247 - val_loss: 30.5207\n",
      "Epoch 15780/100000\n",
      "11/11 [==============================] - 0s 611us/step - loss: 16.1126 - val_loss: 30.5095\n",
      "Epoch 15781/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 16.1006 - val_loss: 30.5004\n",
      "Epoch 15782/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 16.0885 - val_loss: 30.4892\n",
      "Epoch 15783/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 16.0765 - val_loss: 30.4800\n",
      "Epoch 15784/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 16.0644 - val_loss: 30.4691\n",
      "Epoch 15785/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 16.0524 - val_loss: 30.4594\n",
      "Epoch 15786/100000\n",
      "11/11 [==============================] - 0s 895us/step - loss: 16.0403 - val_loss: 30.4490\n",
      "Epoch 15787/100000\n",
      "11/11 [==============================] - 0s 623us/step - loss: 16.0283 - val_loss: 30.4389\n",
      "Epoch 15788/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 16.0163 - val_loss: 30.4289\n",
      "Epoch 15789/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 16.0043 - val_loss: 30.4184\n",
      "Epoch 15790/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 15.9922 - val_loss: 30.4087\n",
      "Epoch 15791/100000\n",
      "11/11 [==============================] - 0s 584us/step - loss: 15.9802 - val_loss: 30.3980\n",
      "Epoch 15792/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 15.9682 - val_loss: 30.3886\n",
      "Epoch 15793/100000\n",
      "11/11 [==============================] - 0s 898us/step - loss: 15.9562 - val_loss: 30.3776\n",
      "Epoch 15794/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.9442 - val_loss: 30.3683\n",
      "Epoch 15795/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15.9322 - val_loss: 30.3573\n",
      "Epoch 15796/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 15.9202 - val_loss: 30.3482\n",
      "Epoch 15797/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.9082 - val_loss: 30.3368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15798/100000\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.8962 - val_loss: 30.3280\n",
      "Epoch 15799/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 15.8842 - val_loss: 30.3165\n",
      "Epoch 15800/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 15.8722 - val_loss: 30.3080\n",
      "Epoch 15801/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 15.8602 - val_loss: 30.2961\n",
      "Epoch 15802/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 15.8482 - val_loss: 30.2879\n",
      "Epoch 15803/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 15.8362 - val_loss: 30.2756\n",
      "Epoch 15804/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 15.8243 - val_loss: 30.2679\n",
      "Epoch 15805/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 15.8123 - val_loss: 30.2550\n",
      "Epoch 15806/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 15.8003 - val_loss: 30.2480\n",
      "Epoch 15807/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 15.7884 - val_loss: 30.2343\n",
      "Epoch 15808/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 15.7764 - val_loss: 30.2284\n",
      "Epoch 15809/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 15.7644 - val_loss: 30.2134\n",
      "Epoch 15810/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 15.7525 - val_loss: 30.2092\n",
      "Epoch 15811/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 15.7406 - val_loss: 30.1920\n",
      "Epoch 15812/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 15.7286 - val_loss: 30.1906\n",
      "Epoch 15813/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 15.7167 - val_loss: 30.1697\n",
      "Epoch 15814/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 15.7048 - val_loss: 30.1731\n",
      "Epoch 15815/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 15.6928 - val_loss: 30.1461\n",
      "Epoch 15816/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 15.6809 - val_loss: 30.1574\n",
      "Epoch 15817/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 15.6690 - val_loss: 30.1202\n",
      "Epoch 15818/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 15.6571 - val_loss: 30.1445\n",
      "Epoch 15819/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 15.6452 - val_loss: 30.0912\n",
      "Epoch 15820/100000\n",
      "11/11 [==============================] - 0s 593us/step - loss: 15.6334 - val_loss: 30.1354\n",
      "Epoch 15821/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 15.6216 - val_loss: 30.0589\n",
      "Epoch 15822/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 15.6098 - val_loss: 30.1285\n",
      "Epoch 15823/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 15.5981 - val_loss: 30.0283\n",
      "Epoch 15824/100000\n",
      "11/11 [==============================] - 0s 197us/step - loss: 15.5863 - val_loss: 30.1130\n",
      "Epoch 15825/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 15.5744 - val_loss: 30.0142\n",
      "Epoch 15826/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 15.5624 - val_loss: 30.0734\n",
      "Epoch 15827/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 15.5502 - val_loss: 30.0237\n",
      "Epoch 15828/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 15.5381 - val_loss: 30.0181\n",
      "Epoch 15829/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 15.5262 - val_loss: 30.0362\n",
      "Epoch 15830/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 15.5145 - val_loss: 29.9748\n",
      "Epoch 15831/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 15.5028 - val_loss: 30.0261\n",
      "Epoch 15832/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 15.4909 - val_loss: 29.9607\n",
      "Epoch 15833/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 15.4790 - val_loss: 29.9872\n",
      "Epoch 15834/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 15.4670 - val_loss: 29.9672\n",
      "Epoch 15835/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 15.4551 - val_loss: 29.9411\n",
      "Epoch 15836/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 15.4433 - val_loss: 29.9669\n",
      "Epoch 15837/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 15.4315 - val_loss: 29.9128\n",
      "Epoch 15838/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 15.4197 - val_loss: 29.9425\n",
      "Epoch 15839/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 15.4078 - val_loss: 29.9074\n",
      "Epoch 15840/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 15.3959 - val_loss: 29.9022\n",
      "Epoch 15841/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 15.3841 - val_loss: 29.9067\n",
      "Epoch 15842/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 15.3723 - val_loss: 29.8688\n",
      "Epoch 15843/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 15.3605 - val_loss: 29.8915\n",
      "Epoch 15844/100000\n",
      "11/11 [==============================] - 0s 807us/step - loss: 15.3487 - val_loss: 29.8536\n",
      "Epoch 15845/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 15.3369 - val_loss: 29.8597\n",
      "Epoch 15846/100000\n",
      "11/11 [==============================] - 0s 696us/step - loss: 15.3250 - val_loss: 29.8490\n",
      "Epoch 15847/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 15.3132 - val_loss: 29.8259\n",
      "Epoch 15848/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 15.3014 - val_loss: 29.8382\n",
      "Epoch 15849/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 15.2897 - val_loss: 29.8039\n",
      "Epoch 15850/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 15.2779 - val_loss: 29.8139\n",
      "Epoch 15851/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 15.2661 - val_loss: 29.7932\n",
      "Epoch 15852/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 15.2543 - val_loss: 29.7828\n",
      "Epoch 15853/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 15.2425 - val_loss: 29.7834\n",
      "Epoch 15854/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 15.2308 - val_loss: 29.7568\n",
      "Epoch 15855/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 15.2190 - val_loss: 29.7650\n",
      "Epoch 15856/100000\n",
      "11/11 [==============================] - 0s 702us/step - loss: 15.2072 - val_loss: 29.7403\n",
      "Epoch 15857/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 15.1955 - val_loss: 29.7386\n",
      "Epoch 15858/100000\n",
      "11/11 [==============================] - 0s 666us/step - loss: 15.1837 - val_loss: 29.7285\n",
      "Epoch 15859/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 15.1720 - val_loss: 29.7114\n",
      "Epoch 15860/100000\n",
      "11/11 [==============================] - 0s 707us/step - loss: 15.1602 - val_loss: 29.7135\n",
      "Epoch 15861/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 15.1485 - val_loss: 29.6901\n",
      "Epoch 15862/100000\n",
      "11/11 [==============================] - 0s 831us/step - loss: 15.1367 - val_loss: 29.6919\n",
      "Epoch 15863/100000\n",
      "11/11 [==============================] - 0s 927us/step - loss: 15.1250 - val_loss: 29.6747\n",
      "Epoch 15864/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 15.1133 - val_loss: 29.6667\n",
      "Epoch 15865/100000\n",
      "11/11 [==============================] - 0s 704us/step - loss: 15.1016 - val_loss: 29.6604\n",
      "Epoch 15866/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 15.0898 - val_loss: 29.6429\n",
      "Epoch 15867/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 15.0781 - val_loss: 29.6429\n",
      "Epoch 15868/100000\n",
      "11/11 [==============================] - 0s 610us/step - loss: 15.0664 - val_loss: 29.6235\n",
      "Epoch 15869/100000\n",
      "11/11 [==============================] - 0s 485us/step - loss: 15.0547 - val_loss: 29.6209\n",
      "Epoch 15870/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 15.0430 - val_loss: 29.6074\n",
      "Epoch 15871/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 15.0313 - val_loss: 29.5972\n",
      "Epoch 15872/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 15.0196 - val_loss: 29.5912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15873/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 15.0079 - val_loss: 29.5752\n",
      "Epoch 15874/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 14.9962 - val_loss: 29.5724\n",
      "Epoch 15875/100000\n",
      "11/11 [==============================] - 0s 696us/step - loss: 14.9845 - val_loss: 29.5561\n",
      "Epoch 15876/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 14.9729 - val_loss: 29.5512\n",
      "Epoch 15877/100000\n",
      "11/11 [==============================] - 0s 690us/step - loss: 14.9612 - val_loss: 29.5390\n",
      "Epoch 15878/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 14.9495 - val_loss: 29.5290\n",
      "Epoch 15879/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 14.9379 - val_loss: 29.5218\n",
      "Epoch 15880/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 14.9262 - val_loss: 29.5078\n",
      "Epoch 15881/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 14.9145 - val_loss: 29.5029\n",
      "Epoch 15882/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 14.9029 - val_loss: 29.4885\n",
      "Epoch 15883/100000\n",
      "11/11 [==============================] - 0s 223us/step - loss: 14.8912 - val_loss: 29.4825\n",
      "Epoch 15884/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 14.8796 - val_loss: 29.4704\n",
      "Epoch 15885/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 14.8679 - val_loss: 29.4614\n",
      "Epoch 15886/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 14.8563 - val_loss: 29.4526\n",
      "Epoch 15887/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 14.8447 - val_loss: 29.4406\n",
      "Epoch 15888/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 14.8331 - val_loss: 29.4341\n",
      "Epoch 15889/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 14.8215 - val_loss: 29.4207\n",
      "Epoch 15890/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 14.8098 - val_loss: 29.4146\n",
      "Epoch 15891/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 14.7982 - val_loss: 29.4019\n",
      "Epoch 15892/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 14.7866 - val_loss: 29.3942\n",
      "Epoch 15893/100000\n",
      "11/11 [==============================] - 0s 355us/step - loss: 14.7750 - val_loss: 29.3836\n",
      "Epoch 15894/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 14.7634 - val_loss: 29.3737\n",
      "Epoch 15895/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 14.7518 - val_loss: 29.3653\n",
      "Epoch 15896/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 14.7402 - val_loss: 29.3537\n",
      "Epoch 15897/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 14.7287 - val_loss: 29.3464\n",
      "Epoch 15898/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 14.7171 - val_loss: 29.3342\n",
      "Epoch 15899/100000\n",
      "11/11 [==============================] - 0s 455us/step - loss: 14.7055 - val_loss: 29.3270\n",
      "Epoch 15900/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 14.6939 - val_loss: 29.3152\n",
      "Epoch 15901/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 14.6823 - val_loss: 29.3073\n",
      "Epoch 15902/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 14.6708 - val_loss: 29.2965\n",
      "Epoch 15903/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 14.6592 - val_loss: 29.2874\n",
      "Epoch 15904/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 14.6477 - val_loss: 29.2778\n",
      "Epoch 15905/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 14.6361 - val_loss: 29.2677\n",
      "Epoch 15906/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 14.6246 - val_loss: 29.2591\n",
      "Epoch 15907/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 14.6130 - val_loss: 29.2481\n",
      "Epoch 15908/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 14.6015 - val_loss: 29.2401\n",
      "Epoch 15909/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 14.5900 - val_loss: 29.2289\n",
      "Epoch 15910/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 14.5784 - val_loss: 29.2210\n",
      "Epoch 15911/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 14.5669 - val_loss: 29.2098\n",
      "Epoch 15912/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 14.5554 - val_loss: 29.2017\n",
      "Epoch 15913/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 14.5439 - val_loss: 29.1910\n",
      "Epoch 15914/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 14.5324 - val_loss: 29.1824\n",
      "Epoch 15915/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 14.5209 - val_loss: 29.1721\n",
      "Epoch 15916/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 14.5094 - val_loss: 29.1630\n",
      "Epoch 15917/100000\n",
      "11/11 [==============================] - 0s 596us/step - loss: 14.4979 - val_loss: 29.1534\n",
      "Epoch 15918/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 14.4864 - val_loss: 29.1436\n",
      "Epoch 15919/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 14.4749 - val_loss: 29.1345\n",
      "Epoch 15920/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 14.4634 - val_loss: 29.1245\n",
      "Epoch 15921/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 14.4519 - val_loss: 29.1157\n",
      "Epoch 15922/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 14.4405 - val_loss: 29.1053\n",
      "Epoch 15923/100000\n",
      "11/11 [==============================] - 0s 689us/step - loss: 14.4290 - val_loss: 29.0968\n",
      "Epoch 15924/100000\n",
      "11/11 [==============================] - 0s 231us/step - loss: 14.4175 - val_loss: 29.0864\n",
      "Epoch 15925/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 14.4060 - val_loss: 29.0778\n",
      "Epoch 15926/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 14.3946 - val_loss: 29.0674\n",
      "Epoch 15927/100000\n",
      "11/11 [==============================] - 0s 726us/step - loss: 14.3832 - val_loss: 29.0591\n",
      "Epoch 15928/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 14.3717 - val_loss: 29.0483\n",
      "Epoch 15929/100000\n",
      "11/11 [==============================] - 0s 776us/step - loss: 14.3603 - val_loss: 29.0402\n",
      "Epoch 15930/100000\n",
      "11/11 [==============================] - 0s 894us/step - loss: 14.3488 - val_loss: 29.0293\n",
      "Epoch 15931/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.3374 - val_loss: 29.0215\n",
      "Epoch 15932/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.3259 - val_loss: 29.0101\n",
      "Epoch 15933/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.3145 - val_loss: 29.0030\n",
      "Epoch 15934/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.3031 - val_loss: 28.9910\n",
      "Epoch 15935/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.2917 - val_loss: 28.9845\n",
      "Epoch 15936/100000\n",
      "11/11 [==============================] - 0s 762us/step - loss: 14.2803 - val_loss: 28.9718\n",
      "Epoch 15937/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 14.2689 - val_loss: 28.9663\n",
      "Epoch 15938/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.2575 - val_loss: 28.9523\n",
      "Epoch 15939/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.2461 - val_loss: 28.9483\n",
      "Epoch 15940/100000\n",
      "11/11 [==============================] - 0s 825us/step - loss: 14.2347 - val_loss: 28.9324\n",
      "Epoch 15941/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 14.2233 - val_loss: 28.9310\n",
      "Epoch 15942/100000\n",
      "11/11 [==============================] - 0s 935us/step - loss: 14.2119 - val_loss: 28.9118\n",
      "Epoch 15943/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 14.2005 - val_loss: 28.9146\n",
      "Epoch 15944/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 14.1892 - val_loss: 28.8902\n",
      "Epoch 15945/100000\n",
      "11/11 [==============================] - 0s 606us/step - loss: 14.1778 - val_loss: 28.8997\n",
      "Epoch 15946/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 14.1665 - val_loss: 28.8668\n",
      "Epoch 15947/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.1551 - val_loss: 28.8872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15948/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 14.1438 - val_loss: 28.8404\n",
      "Epoch 15949/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 14.1325 - val_loss: 28.8784\n",
      "Epoch 15950/100000\n",
      "11/11 [==============================] - 0s 658us/step - loss: 14.1212 - val_loss: 28.8101\n",
      "Epoch 15951/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.1100 - val_loss: 28.8732\n",
      "Epoch 15952/100000\n",
      "11/11 [==============================] - 0s 974us/step - loss: 14.0988 - val_loss: 28.7784\n",
      "Epoch 15953/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 14.0877 - val_loss: 28.8650\n",
      "Epoch 15954/100000\n",
      "11/11 [==============================] - 0s 830us/step - loss: 14.0765 - val_loss: 28.7569\n",
      "Epoch 15955/100000\n",
      "11/11 [==============================] - 0s 653us/step - loss: 14.0651 - val_loss: 28.8375\n",
      "Epoch 15956/100000\n",
      "11/11 [==============================] - 0s 741us/step - loss: 14.0536 - val_loss: 28.7598\n",
      "Epoch 15957/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 14.0420 - val_loss: 28.7860\n",
      "Epoch 15958/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 14.0305 - val_loss: 28.7777\n",
      "Epoch 15959/100000\n",
      "11/11 [==============================] - 0s 851us/step - loss: 14.0191 - val_loss: 28.7350\n",
      "Epoch 15960/100000\n",
      "11/11 [==============================] - 0s 851us/step - loss: 14.0080 - val_loss: 28.7820\n",
      "Epoch 15961/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 13.9969 - val_loss: 28.7091\n",
      "Epoch 15962/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 13.9856 - val_loss: 28.7553\n",
      "Epoch 15963/100000\n",
      "11/11 [==============================] - 0s 464us/step - loss: 13.9742 - val_loss: 28.7118\n",
      "Epoch 15964/100000\n",
      "11/11 [==============================] - 0s 986us/step - loss: 13.9628 - val_loss: 28.7090\n",
      "Epoch 15965/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 13.9515 - val_loss: 28.7201\n",
      "Epoch 15966/100000\n",
      "11/11 [==============================] - 0s 836us/step - loss: 13.9403 - val_loss: 28.6718\n",
      "Epoch 15967/100000\n",
      "11/11 [==============================] - 0s 707us/step - loss: 13.9291 - val_loss: 28.7085\n",
      "Epoch 15968/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 13.9179 - val_loss: 28.6594\n",
      "Epoch 15969/100000\n",
      "11/11 [==============================] - 0s 917us/step - loss: 13.9065 - val_loss: 28.6734\n",
      "Epoch 15970/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 13.8952 - val_loss: 28.6619\n",
      "Epoch 15971/100000\n",
      "11/11 [==============================] - 0s 726us/step - loss: 13.8839 - val_loss: 28.6354\n",
      "Epoch 15972/100000\n",
      "11/11 [==============================] - 0s 738us/step - loss: 13.8728 - val_loss: 28.6565\n",
      "Epoch 15973/100000\n",
      "11/11 [==============================] - 0s 433us/step - loss: 13.8616 - val_loss: 28.6134\n",
      "Epoch 15974/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 13.8503 - val_loss: 28.6322\n",
      "Epoch 15975/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 13.8391 - val_loss: 28.6081\n",
      "Epoch 15976/100000\n",
      "11/11 [==============================] - 0s 676us/step - loss: 13.8278 - val_loss: 28.5979\n",
      "Epoch 15977/100000\n",
      "11/11 [==============================] - 0s 806us/step - loss: 13.8166 - val_loss: 28.6039\n",
      "Epoch 15978/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 13.8054 - val_loss: 28.5711\n",
      "Epoch 15979/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 13.7942 - val_loss: 28.5871\n",
      "Epoch 15980/100000\n",
      "11/11 [==============================] - 0s 859us/step - loss: 13.7830 - val_loss: 28.5581\n",
      "Epoch 15981/100000\n",
      "11/11 [==============================] - 0s 786us/step - loss: 13.7718 - val_loss: 28.5586\n",
      "Epoch 15982/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 13.7606 - val_loss: 28.5514\n",
      "Epoch 15983/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 13.7494 - val_loss: 28.5303\n",
      "Epoch 15984/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 13.7382 - val_loss: 28.5390\n",
      "Epoch 15985/100000\n",
      "11/11 [==============================] - 0s 836us/step - loss: 13.7271 - val_loss: 28.5112\n",
      "Epoch 15986/100000\n",
      "11/11 [==============================] - 0s 581us/step - loss: 13.7159 - val_loss: 28.5167\n",
      "Epoch 15987/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 13.7047 - val_loss: 28.5001\n",
      "Epoch 15988/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 13.6936 - val_loss: 28.4900\n",
      "Epoch 15989/100000\n",
      "11/11 [==============================] - 0s 689us/step - loss: 13.6824 - val_loss: 28.4893\n",
      "Epoch 15990/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 13.6712 - val_loss: 28.4672\n",
      "Epoch 15991/100000\n",
      "11/11 [==============================] - 0s 855us/step - loss: 13.6601 - val_loss: 28.4721\n",
      "Epoch 15992/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 13.6490 - val_loss: 28.4514\n",
      "Epoch 15993/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 13.6378 - val_loss: 28.4491\n",
      "Epoch 15994/100000\n",
      "11/11 [==============================] - 0s 766us/step - loss: 13.6267 - val_loss: 28.4390\n",
      "Epoch 15995/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 13.6155 - val_loss: 28.4252\n",
      "Epoch 15996/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 13.6044 - val_loss: 28.4249\n",
      "Epoch 15997/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 13.5933 - val_loss: 28.4054\n",
      "Epoch 15998/100000\n",
      "11/11 [==============================] - 0s 981us/step - loss: 13.5821 - val_loss: 28.4059\n",
      "Epoch 15999/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 13.5710 - val_loss: 28.3900\n",
      "Epoch 16000/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 13.5599 - val_loss: 28.3839\n",
      "Epoch 16001/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 13.5488 - val_loss: 28.3760\n",
      "Epoch 16002/100000\n",
      "11/11 [==============================] - 0s 926us/step - loss: 13.5377 - val_loss: 28.3621\n",
      "Epoch 16003/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 13.5266 - val_loss: 28.3602\n",
      "Epoch 16004/100000\n",
      "11/11 [==============================] - 0s 718us/step - loss: 13.5155 - val_loss: 28.3436\n",
      "Epoch 16005/100000\n",
      "11/11 [==============================] - 0s 268us/step - loss: 13.5044 - val_loss: 28.3412\n",
      "Epoch 16006/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 13.4933 - val_loss: 28.3275\n",
      "Epoch 16007/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 13.4823 - val_loss: 28.3205\n",
      "Epoch 16008/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 13.4712 - val_loss: 28.3123\n",
      "Epoch 16009/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 13.4601 - val_loss: 28.3000\n",
      "Epoch 16010/100000\n",
      "11/11 [==============================] - 0s 668us/step - loss: 13.4491 - val_loss: 28.2959\n",
      "Epoch 16011/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 13.4380 - val_loss: 28.2814\n",
      "Epoch 16012/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 13.4269 - val_loss: 28.2775\n",
      "Epoch 16013/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 13.4159 - val_loss: 28.2645\n",
      "Epoch 16014/100000\n",
      "11/11 [==============================] - 0s 758us/step - loss: 13.4049 - val_loss: 28.2579\n",
      "Epoch 16015/100000\n",
      "11/11 [==============================] - 0s 809us/step - loss: 13.3938 - val_loss: 28.2485\n",
      "Epoch 16016/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 13.3828 - val_loss: 28.2381\n",
      "Epoch 16017/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 13.3718 - val_loss: 28.2320\n",
      "Epoch 16018/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 13.3607 - val_loss: 28.2194\n",
      "Epoch 16019/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 13.3497 - val_loss: 28.2142\n",
      "Epoch 16020/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 13.3387 - val_loss: 28.2017\n",
      "Epoch 16021/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 13.3277 - val_loss: 28.1957\n",
      "Epoch 16022/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 13.3166 - val_loss: 28.1849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16023/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 13.3056 - val_loss: 28.1766\n",
      "Epoch 16024/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 13.2947 - val_loss: 28.1682\n",
      "Epoch 16025/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 13.2836 - val_loss: 28.1578\n",
      "Epoch 16026/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 13.2726 - val_loss: 28.1510\n",
      "Epoch 16027/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 13.2617 - val_loss: 28.1396\n",
      "Epoch 16028/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 13.2507 - val_loss: 28.1332\n",
      "Epoch 16029/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 13.2397 - val_loss: 28.1221\n",
      "Epoch 16030/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 13.2287 - val_loss: 28.1148\n",
      "Epoch 16031/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 13.2177 - val_loss: 28.1049\n",
      "Epoch 16032/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 13.2068 - val_loss: 28.0964\n",
      "Epoch 16033/100000\n",
      "11/11 [==============================] - 0s 636us/step - loss: 13.1958 - val_loss: 28.0878\n",
      "Epoch 16034/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 13.1849 - val_loss: 28.0781\n",
      "Epoch 16035/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 13.1739 - val_loss: 28.0704\n",
      "Epoch 16036/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 13.1629 - val_loss: 28.0601\n",
      "Epoch 16037/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 13.1520 - val_loss: 28.0526\n",
      "Epoch 16038/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 13.1411 - val_loss: 28.0424\n",
      "Epoch 16039/100000\n",
      "11/11 [==============================] - 0s 621us/step - loss: 13.1301 - val_loss: 28.0348\n",
      "Epoch 16040/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 13.1192 - val_loss: 28.0250\n",
      "Epoch 16041/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 13.1083 - val_loss: 28.0167\n",
      "Epoch 16042/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 13.0973 - val_loss: 28.0077\n",
      "Epoch 16043/100000\n",
      "11/11 [==============================] - 0s 610us/step - loss: 13.0864 - val_loss: 27.9988\n",
      "Epoch 16044/100000\n",
      "11/11 [==============================] - 0s 588us/step - loss: 13.0755 - val_loss: 27.9901\n",
      "Epoch 16045/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 13.0646 - val_loss: 27.9810\n",
      "Epoch 16046/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 13.0537 - val_loss: 27.9726\n",
      "Epoch 16047/100000\n",
      "11/11 [==============================] - 0s 631us/step - loss: 13.0428 - val_loss: 27.9631\n",
      "Epoch 16048/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 13.0319 - val_loss: 27.9550\n",
      "Epoch 16049/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 13.0210 - val_loss: 27.9455\n",
      "Epoch 16050/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 13.0101 - val_loss: 27.9374\n",
      "Epoch 16051/100000\n",
      "11/11 [==============================] - 0s 706us/step - loss: 12.9992 - val_loss: 27.9278\n",
      "Epoch 16052/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 12.9883 - val_loss: 27.9197\n",
      "Epoch 16053/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 12.9774 - val_loss: 27.9104\n",
      "Epoch 16054/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 12.9666 - val_loss: 27.9019\n",
      "Epoch 16055/100000\n",
      "11/11 [==============================] - 0s 755us/step - loss: 12.9557 - val_loss: 27.8929\n",
      "Epoch 16056/100000\n",
      "11/11 [==============================] - 0s 727us/step - loss: 12.9448 - val_loss: 27.8843\n",
      "Epoch 16057/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 12.9340 - val_loss: 27.8755\n",
      "Epoch 16058/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 12.9231 - val_loss: 27.8666\n",
      "Epoch 16059/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 12.9122 - val_loss: 27.8579\n",
      "Epoch 16060/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 12.9014 - val_loss: 27.8490\n",
      "Epoch 16061/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 12.8906 - val_loss: 27.8405\n",
      "Epoch 16062/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 12.8797 - val_loss: 27.8314\n",
      "Epoch 16063/100000\n",
      "11/11 [==============================] - 0s 252us/step - loss: 12.8689 - val_loss: 27.8231\n",
      "Epoch 16064/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 12.8580 - val_loss: 27.8139\n",
      "Epoch 16065/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 12.8472 - val_loss: 27.8056\n",
      "Epoch 16066/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 12.8364 - val_loss: 27.7963\n",
      "Epoch 16067/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 12.8256 - val_loss: 27.7882\n",
      "Epoch 16068/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 12.8148 - val_loss: 27.7786\n",
      "Epoch 16069/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 12.8040 - val_loss: 27.7709\n",
      "Epoch 16070/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 12.7931 - val_loss: 27.7609\n",
      "Epoch 16071/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 12.7824 - val_loss: 27.7537\n",
      "Epoch 16072/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 12.7716 - val_loss: 27.7432\n",
      "Epoch 16073/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 12.7608 - val_loss: 27.7367\n",
      "Epoch 16074/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 12.7500 - val_loss: 27.7254\n",
      "Epoch 16075/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 12.7392 - val_loss: 27.7197\n",
      "Epoch 16076/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 12.7284 - val_loss: 27.7073\n",
      "Epoch 16077/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 12.7177 - val_loss: 27.7031\n",
      "Epoch 16078/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 12.7069 - val_loss: 27.6889\n",
      "Epoch 16079/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 12.6961 - val_loss: 27.6871\n",
      "Epoch 16080/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 12.6854 - val_loss: 27.6698\n",
      "Epoch 16081/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 12.6746 - val_loss: 27.6719\n",
      "Epoch 16082/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 12.6639 - val_loss: 27.6497\n",
      "Epoch 16083/100000\n",
      "11/11 [==============================] - 0s 686us/step - loss: 12.6531 - val_loss: 27.6583\n",
      "Epoch 16084/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 12.6424 - val_loss: 27.6276\n",
      "Epoch 16085/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 12.6317 - val_loss: 27.6472\n",
      "Epoch 16086/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 12.6210 - val_loss: 27.6022\n",
      "Epoch 16087/100000\n",
      "11/11 [==============================] - 0s 695us/step - loss: 12.6103 - val_loss: 27.6404\n",
      "Epoch 16088/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 12.5997 - val_loss: 27.5720\n",
      "Epoch 16089/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 12.5891 - val_loss: 27.6386\n",
      "Epoch 16090/100000\n",
      "11/11 [==============================] - 0s 888us/step - loss: 12.5785 - val_loss: 27.5387\n",
      "Epoch 16091/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 12.5681 - val_loss: 27.6358\n",
      "Epoch 16092/100000\n",
      "11/11 [==============================] - 0s 749us/step - loss: 12.5576 - val_loss: 27.5146\n",
      "Epoch 16093/100000\n",
      "11/11 [==============================] - 0s 764us/step - loss: 12.5469 - val_loss: 27.6116\n",
      "Epoch 16094/100000\n",
      "11/11 [==============================] - 0s 634us/step - loss: 12.5360 - val_loss: 27.5203\n",
      "Epoch 16095/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 12.5249 - val_loss: 27.5558\n",
      "Epoch 16096/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 12.5139 - val_loss: 27.5470\n",
      "Epoch 16097/100000\n",
      "11/11 [==============================] - 0s 868us/step - loss: 12.5032 - val_loss: 27.4992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16098/100000\n",
      "11/11 [==============================] - 0s 739us/step - loss: 12.4928 - val_loss: 27.5569\n",
      "Epoch 16099/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 12.4823 - val_loss: 27.4752\n",
      "Epoch 16100/100000\n",
      "11/11 [==============================] - 0s 783us/step - loss: 12.4716 - val_loss: 27.5263\n",
      "Epoch 16101/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 12.4607 - val_loss: 27.4868\n",
      "Epoch 16102/100000\n",
      "11/11 [==============================] - 0s 640us/step - loss: 12.4499 - val_loss: 27.4742\n",
      "Epoch 16103/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 12.4393 - val_loss: 27.4999\n",
      "Epoch 16104/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 12.4288 - val_loss: 27.4400\n",
      "Epoch 16105/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 12.4182 - val_loss: 27.4827\n",
      "Epoch 16106/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 12.4075 - val_loss: 27.4384\n",
      "Epoch 16107/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 12.3968 - val_loss: 27.4397\n",
      "Epoch 16108/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 12.3861 - val_loss: 27.4470\n",
      "Epoch 16109/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 12.3756 - val_loss: 27.4042\n",
      "Epoch 16110/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 12.3650 - val_loss: 27.4357\n",
      "Epoch 16111/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 12.3544 - val_loss: 27.3944\n",
      "Epoch 16112/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 12.3437 - val_loss: 27.4014\n",
      "Epoch 16113/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 12.3331 - val_loss: 27.3979\n",
      "Epoch 16114/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 12.3225 - val_loss: 27.3675\n",
      "Epoch 16115/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 12.3120 - val_loss: 27.3891\n",
      "Epoch 16116/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 12.3014 - val_loss: 27.3525\n",
      "Epoch 16117/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 12.2908 - val_loss: 27.3612\n",
      "Epoch 16118/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 12.2802 - val_loss: 27.3502\n",
      "Epoch 16119/100000\n",
      "11/11 [==============================] - 0s 573us/step - loss: 12.2696 - val_loss: 27.3297\n",
      "Epoch 16120/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 12.2591 - val_loss: 27.3424\n",
      "Epoch 16121/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 12.2485 - val_loss: 27.3106\n",
      "Epoch 16122/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 12.2380 - val_loss: 27.3197\n",
      "Epoch 16123/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 12.2274 - val_loss: 27.3038\n",
      "Epoch 16124/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 12.2168 - val_loss: 27.2912\n",
      "Epoch 16125/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 12.2063 - val_loss: 27.2958\n",
      "Epoch 16126/100000\n",
      "11/11 [==============================] - 0s 405us/step - loss: 12.1958 - val_loss: 27.2699\n",
      "Epoch 16127/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 12.1852 - val_loss: 27.2775\n",
      "Epoch 16128/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 12.1747 - val_loss: 27.2588\n",
      "Epoch 16129/100000\n",
      "11/11 [==============================] - 0s 641us/step - loss: 12.1642 - val_loss: 27.2522\n",
      "Epoch 16130/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 12.1536 - val_loss: 27.2498\n",
      "Epoch 16131/100000\n",
      "11/11 [==============================] - 0s 526us/step - loss: 12.1431 - val_loss: 27.2296\n",
      "Epoch 16132/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 12.1326 - val_loss: 27.2344\n",
      "Epoch 16133/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 12.1221 - val_loss: 27.2149\n",
      "Epoch 16134/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 12.1116 - val_loss: 27.2123\n",
      "Epoch 16135/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 12.1011 - val_loss: 27.2041\n",
      "Epoch 16136/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 12.0906 - val_loss: 27.1897\n",
      "Epoch 16137/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 12.0801 - val_loss: 27.1906\n",
      "Epoch 16138/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 12.0696 - val_loss: 27.1722\n",
      "Epoch 16139/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 12.0591 - val_loss: 27.1715\n",
      "Epoch 16140/100000\n",
      "11/11 [==============================] - 0s 832us/step - loss: 12.0486 - val_loss: 27.1592\n",
      "Epoch 16141/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 12.0382 - val_loss: 27.1501\n",
      "Epoch 16142/100000\n",
      "11/11 [==============================] - 0s 635us/step - loss: 12.0277 - val_loss: 27.1463\n",
      "Epoch 16143/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 12.0172 - val_loss: 27.1308\n",
      "Epoch 16144/100000\n",
      "11/11 [==============================] - 0s 650us/step - loss: 12.0068 - val_loss: 27.1299\n",
      "Epoch 16145/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 11.9963 - val_loss: 27.1153\n",
      "Epoch 16146/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 11.9858 - val_loss: 27.1103\n",
      "Epoch 16147/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 11.9754 - val_loss: 27.1018\n",
      "Epoch 16148/100000\n",
      "11/11 [==============================] - 0s 537us/step - loss: 11.9650 - val_loss: 27.0904\n",
      "Epoch 16149/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 11.9545 - val_loss: 27.0869\n",
      "Epoch 16150/100000\n",
      "11/11 [==============================] - 0s 649us/step - loss: 11.9441 - val_loss: 27.0728\n",
      "Epoch 16151/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 11.9337 - val_loss: 27.0696\n",
      "Epoch 16152/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 11.9232 - val_loss: 27.0577\n",
      "Epoch 16153/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 11.9128 - val_loss: 27.0505\n",
      "Epoch 16154/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 11.9024 - val_loss: 27.0433\n",
      "Epoch 16155/100000\n",
      "11/11 [==============================] - 0s 499us/step - loss: 11.8920 - val_loss: 27.0319\n",
      "Epoch 16156/100000\n",
      "11/11 [==============================] - 0s 622us/step - loss: 11.8816 - val_loss: 27.0275\n",
      "Epoch 16157/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 11.8712 - val_loss: 27.0150\n",
      "Epoch 16158/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 11.8608 - val_loss: 27.0101\n",
      "Epoch 16159/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 11.8504 - val_loss: 26.9995\n",
      "Epoch 16160/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 11.8400 - val_loss: 26.9918\n",
      "Epoch 16161/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 11.8296 - val_loss: 26.9843\n",
      "Epoch 16162/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 11.8192 - val_loss: 26.9737\n",
      "Epoch 16163/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 11.8088 - val_loss: 26.9684\n",
      "Epoch 16164/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 11.7985 - val_loss: 26.9568\n",
      "Epoch 16165/100000\n",
      "11/11 [==============================] - 0s 364us/step - loss: 11.7881 - val_loss: 26.9513\n",
      "Epoch 16166/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 11.7777 - val_loss: 26.9409\n",
      "Epoch 16167/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 11.7674 - val_loss: 26.9336\n",
      "Epoch 16168/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 11.7570 - val_loss: 26.9254\n",
      "Epoch 16169/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 11.7467 - val_loss: 26.9158\n",
      "Epoch 16170/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 11.7363 - val_loss: 26.9095\n",
      "Epoch 16171/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 11.7260 - val_loss: 26.8988\n",
      "Epoch 16172/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 11.7156 - val_loss: 26.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16173/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 11.7053 - val_loss: 26.8826\n",
      "Epoch 16174/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 11.6949 - val_loss: 26.8755\n",
      "Epoch 16175/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 11.6846 - val_loss: 26.8667\n",
      "Epoch 16176/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 11.6743 - val_loss: 26.8581\n",
      "Epoch 16177/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 11.6640 - val_loss: 26.8508\n",
      "Epoch 16178/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 11.6537 - val_loss: 26.8410\n",
      "Epoch 16179/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 11.6434 - val_loss: 26.8344\n",
      "Epoch 16180/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 11.6331 - val_loss: 26.8245\n",
      "Epoch 16181/100000\n",
      "11/11 [==============================] - 0s 572us/step - loss: 11.6228 - val_loss: 26.8176\n",
      "Epoch 16182/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 11.6125 - val_loss: 26.8083\n",
      "Epoch 16183/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 11.6022 - val_loss: 26.8006\n",
      "Epoch 16184/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 11.5919 - val_loss: 26.7922\n",
      "Epoch 16185/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 11.5816 - val_loss: 26.7836\n",
      "Epoch 16186/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 11.5713 - val_loss: 26.7760\n",
      "Epoch 16187/100000\n",
      "11/11 [==============================] - 0s 293us/step - loss: 11.5611 - val_loss: 26.7668\n",
      "Epoch 16188/100000\n",
      "11/11 [==============================] - 0s 570us/step - loss: 11.5508 - val_loss: 26.7596\n",
      "Epoch 16189/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 11.5405 - val_loss: 26.7502\n",
      "Epoch 16190/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 11.5303 - val_loss: 26.7431\n",
      "Epoch 16191/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 11.5200 - val_loss: 26.7340\n",
      "Epoch 16192/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.5098 - val_loss: 26.7262\n",
      "Epoch 16193/100000\n",
      "11/11 [==============================] - 0s 611us/step - loss: 11.4995 - val_loss: 26.7179\n",
      "Epoch 16194/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 11.4893 - val_loss: 26.7094\n",
      "Epoch 16195/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.4791 - val_loss: 26.7017\n",
      "Epoch 16196/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.4688 - val_loss: 26.6927\n",
      "Epoch 16197/100000\n",
      "11/11 [==============================] - 0s 989us/step - loss: 11.4586 - val_loss: 26.6855\n",
      "Epoch 16198/100000\n",
      "11/11 [==============================] - 0s 800us/step - loss: 11.4484 - val_loss: 26.6763\n",
      "Epoch 16199/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.4382 - val_loss: 26.6690\n",
      "Epoch 16200/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 11.4279 - val_loss: 26.6598\n",
      "Epoch 16201/100000\n",
      "11/11 [==============================] - 0s 703us/step - loss: 11.4177 - val_loss: 26.6526\n",
      "Epoch 16202/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 11.4075 - val_loss: 26.6435\n",
      "Epoch 16203/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.3973 - val_loss: 26.6361\n",
      "Epoch 16204/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.3871 - val_loss: 26.6272\n",
      "Epoch 16205/100000\n",
      "11/11 [==============================] - 0s 986us/step - loss: 11.3769 - val_loss: 26.6197\n",
      "Epoch 16206/100000\n",
      "11/11 [==============================] - 0s 741us/step - loss: 11.3667 - val_loss: 26.6110\n",
      "Epoch 16207/100000\n",
      "11/11 [==============================] - 0s 813us/step - loss: 11.3565 - val_loss: 26.6031\n",
      "Epoch 16208/100000\n",
      "11/11 [==============================] - 0s 786us/step - loss: 11.3463 - val_loss: 26.5949\n",
      "Epoch 16209/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 11.3362 - val_loss: 26.5867\n",
      "Epoch 16210/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 11.3260 - val_loss: 26.5785\n",
      "Epoch 16211/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 11.3158 - val_loss: 26.5702\n",
      "Epoch 16212/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 11.3057 - val_loss: 26.5624\n",
      "Epoch 16213/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 11.2955 - val_loss: 26.5539\n",
      "Epoch 16214/100000\n",
      "11/11 [==============================] - 0s 244us/step - loss: 11.2854 - val_loss: 26.5461\n",
      "Epoch 16215/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 11.2752 - val_loss: 26.5376\n",
      "Epoch 16216/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 11.2651 - val_loss: 26.5298\n",
      "Epoch 16217/100000\n",
      "11/11 [==============================] - 0s 669us/step - loss: 11.2549 - val_loss: 26.5212\n",
      "Epoch 16218/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 11.2448 - val_loss: 26.5135\n",
      "Epoch 16219/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 11.2347 - val_loss: 26.5051\n",
      "Epoch 16220/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 11.2245 - val_loss: 26.4972\n",
      "Epoch 16221/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 11.2144 - val_loss: 26.4888\n",
      "Epoch 16222/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 11.2043 - val_loss: 26.4810\n",
      "Epoch 16223/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 11.1942 - val_loss: 26.4728\n",
      "Epoch 16224/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 11.1841 - val_loss: 26.4646\n",
      "Epoch 16225/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 11.1740 - val_loss: 26.4566\n",
      "Epoch 16226/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 11.1639 - val_loss: 26.4485\n",
      "Epoch 16227/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 11.1538 - val_loss: 26.4404\n",
      "Epoch 16228/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 11.1437 - val_loss: 26.4323\n",
      "Epoch 16229/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 11.1336 - val_loss: 26.4243\n",
      "Epoch 16230/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 11.1235 - val_loss: 26.4162\n",
      "Epoch 16231/100000\n",
      "11/11 [==============================] - 0s 505us/step - loss: 11.1135 - val_loss: 26.4080\n",
      "Epoch 16232/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 11.1034 - val_loss: 26.4000\n",
      "Epoch 16233/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.0933 - val_loss: 26.3919\n",
      "Epoch 16234/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.0833 - val_loss: 26.3839\n",
      "Epoch 16235/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.0732 - val_loss: 26.3757\n",
      "Epoch 16236/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 11.0631 - val_loss: 26.3679\n",
      "Epoch 16237/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 11.0531 - val_loss: 26.3595\n",
      "Epoch 16238/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 11.0430 - val_loss: 26.3520\n",
      "Epoch 16239/100000\n",
      "11/11 [==============================] - 0s 864us/step - loss: 11.0330 - val_loss: 26.3433\n",
      "Epoch 16240/100000\n",
      "11/11 [==============================] - 0s 687us/step - loss: 11.0230 - val_loss: 26.3362\n",
      "Epoch 16241/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 11.0129 - val_loss: 26.3269\n",
      "Epoch 16242/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 11.0029 - val_loss: 26.3205\n",
      "Epoch 16243/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 10.9929 - val_loss: 26.3104\n",
      "Epoch 16244/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 10.9829 - val_loss: 26.3051\n",
      "Epoch 16245/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 10.9729 - val_loss: 26.2934\n",
      "Epoch 16246/100000\n",
      "11/11 [==============================] - 0s 816us/step - loss: 10.9628 - val_loss: 26.2903\n",
      "Epoch 16247/100000\n",
      "11/11 [==============================] - 0s 316us/step - loss: 10.9529 - val_loss: 26.2759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16248/100000\n",
      "11/11 [==============================] - 0s 690us/step - loss: 10.9429 - val_loss: 26.2763\n",
      "Epoch 16249/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 10.9329 - val_loss: 26.2571\n",
      "Epoch 16250/100000\n",
      "11/11 [==============================] - 0s 796us/step - loss: 10.9229 - val_loss: 26.2642\n",
      "Epoch 16251/100000\n",
      "11/11 [==============================] - 0s 489us/step - loss: 10.9129 - val_loss: 26.2361\n",
      "Epoch 16252/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 10.9030 - val_loss: 26.2551\n",
      "Epoch 16253/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 10.8930 - val_loss: 26.2109\n",
      "Epoch 16254/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 10.8831 - val_loss: 26.2516\n",
      "Epoch 16255/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 10.8732 - val_loss: 26.1793\n",
      "Epoch 16256/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 10.8635 - val_loss: 26.2557\n",
      "Epoch 16257/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 10.8538 - val_loss: 26.1416\n",
      "Epoch 16258/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 10.8442 - val_loss: 26.2606\n",
      "Epoch 16259/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 10.8347 - val_loss: 26.1155\n",
      "Epoch 16260/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 10.8248 - val_loss: 26.2346\n",
      "Epoch 16261/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 10.8145 - val_loss: 26.1333\n",
      "Epoch 16262/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 10.8039 - val_loss: 26.1634\n",
      "Epoch 16263/100000\n",
      "11/11 [==============================] - 0s 566us/step - loss: 10.7935 - val_loss: 26.1770\n",
      "Epoch 16264/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 10.7838 - val_loss: 26.1009\n",
      "Epoch 16265/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 10.7744 - val_loss: 26.1842\n",
      "Epoch 16266/100000\n",
      "11/11 [==============================] - 0s 588us/step - loss: 10.7645 - val_loss: 26.0952\n",
      "Epoch 16267/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 10.7543 - val_loss: 26.1309\n",
      "Epoch 16268/100000\n",
      "11/11 [==============================] - 0s 585us/step - loss: 10.7441 - val_loss: 26.1283\n",
      "Epoch 16269/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 10.7343 - val_loss: 26.0734\n",
      "Epoch 16270/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 10.7247 - val_loss: 26.1329\n",
      "Epoch 16271/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 10.7149 - val_loss: 26.0644\n",
      "Epoch 16272/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 10.7048 - val_loss: 26.0864\n",
      "Epoch 16273/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 10.6948 - val_loss: 26.0877\n",
      "Epoch 16274/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 10.6850 - val_loss: 26.0388\n",
      "Epoch 16275/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 10.6753 - val_loss: 26.0837\n",
      "Epoch 16276/100000\n",
      "11/11 [==============================] - 0s 524us/step - loss: 10.6654 - val_loss: 26.0338\n",
      "Epoch 16277/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 10.6555 - val_loss: 26.0409\n",
      "Epoch 16278/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 10.6455 - val_loss: 26.0484\n",
      "Epoch 16279/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 10.6358 - val_loss: 26.0041\n",
      "Epoch 16280/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 10.6261 - val_loss: 26.0368\n",
      "Epoch 16281/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 10.6162 - val_loss: 26.0016\n",
      "Epoch 16282/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 10.6063 - val_loss: 25.9973\n",
      "Epoch 16283/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 10.5965 - val_loss: 26.0083\n",
      "Epoch 16284/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 10.5867 - val_loss: 25.9692\n",
      "Epoch 16285/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 10.5770 - val_loss: 25.9906\n",
      "Epoch 16286/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 10.5671 - val_loss: 25.9668\n",
      "Epoch 16287/100000\n",
      "11/11 [==============================] - 0s 591us/step - loss: 10.5573 - val_loss: 25.9559\n",
      "Epoch 16288/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 10.5475 - val_loss: 25.9670\n",
      "Epoch 16289/100000\n",
      "11/11 [==============================] - 0s 605us/step - loss: 10.5378 - val_loss: 25.9337\n",
      "Epoch 16290/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 10.5280 - val_loss: 25.9466\n",
      "Epoch 16291/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 10.5182 - val_loss: 25.9306\n",
      "Epoch 16292/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 10.5084 - val_loss: 25.9163\n",
      "Epoch 16293/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 10.4987 - val_loss: 25.9256\n",
      "Epoch 16294/100000\n",
      "11/11 [==============================] - 0s 420us/step - loss: 10.4889 - val_loss: 25.8979\n",
      "Epoch 16295/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 10.4792 - val_loss: 25.9045\n",
      "Epoch 16296/100000\n",
      "11/11 [==============================] - 0s 890us/step - loss: 10.4694 - val_loss: 25.8930\n",
      "Epoch 16297/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 10.4597 - val_loss: 25.8777\n",
      "Epoch 16298/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 10.4500 - val_loss: 25.8845\n",
      "Epoch 16299/100000\n",
      "11/11 [==============================] - 0s 492us/step - loss: 10.4402 - val_loss: 25.8614\n",
      "Epoch 16300/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 10.4305 - val_loss: 25.8636\n",
      "Epoch 16301/100000\n",
      "11/11 [==============================] - 0s 704us/step - loss: 10.4208 - val_loss: 25.8543\n",
      "Epoch 16302/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 10.4111 - val_loss: 25.8397\n",
      "Epoch 16303/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 10.4013 - val_loss: 25.8438\n",
      "Epoch 16304/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 10.3917 - val_loss: 25.8242\n",
      "Epoch 16305/100000\n",
      "11/11 [==============================] - 0s 467us/step - loss: 10.3819 - val_loss: 25.8238\n",
      "Epoch 16306/100000\n",
      "11/11 [==============================] - 0s 694us/step - loss: 10.3722 - val_loss: 25.8155\n",
      "Epoch 16307/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 10.3626 - val_loss: 25.8021\n",
      "Epoch 16308/100000\n",
      "11/11 [==============================] - 0s 546us/step - loss: 10.3528 - val_loss: 25.8036\n",
      "Epoch 16309/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 10.3432 - val_loss: 25.7869\n",
      "Epoch 16310/100000\n",
      "11/11 [==============================] - 0s 637us/step - loss: 10.3335 - val_loss: 25.7848\n",
      "Epoch 16311/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 10.3238 - val_loss: 25.7766\n",
      "Epoch 16312/100000\n",
      "11/11 [==============================] - 0s 699us/step - loss: 10.3142 - val_loss: 25.7645\n",
      "Epoch 16313/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 10.3045 - val_loss: 25.7638\n",
      "Epoch 16314/100000\n",
      "11/11 [==============================] - 0s 539us/step - loss: 10.2948 - val_loss: 25.7492\n",
      "Epoch 16315/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 10.2852 - val_loss: 25.7460\n",
      "Epoch 16316/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 10.2755 - val_loss: 25.7375\n",
      "Epoch 16317/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 10.2659 - val_loss: 25.7268\n",
      "Epoch 16318/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 10.2562 - val_loss: 25.7245\n",
      "Epoch 16319/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 10.2466 - val_loss: 25.7113\n",
      "Epoch 16320/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 10.2370 - val_loss: 25.7074\n",
      "Epoch 16321/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 10.2273 - val_loss: 25.6988\n",
      "Epoch 16322/100000\n",
      "11/11 [==============================] - 0s 498us/step - loss: 10.2177 - val_loss: 25.6893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16323/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 10.2081 - val_loss: 25.6854\n",
      "Epoch 16324/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 10.1985 - val_loss: 25.6733\n",
      "Epoch 16325/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 10.1889 - val_loss: 25.6692\n",
      "Epoch 16326/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 10.1793 - val_loss: 25.6600\n",
      "Epoch 16327/100000\n",
      "11/11 [==============================] - 0s 212us/step - loss: 10.1697 - val_loss: 25.6516\n",
      "Epoch 16328/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 10.1601 - val_loss: 25.6464\n",
      "Epoch 16329/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 10.1505 - val_loss: 25.6355\n",
      "Epoch 16330/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 10.1409 - val_loss: 25.6308\n",
      "Epoch 16331/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 10.1313 - val_loss: 25.6214\n",
      "Epoch 16332/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 10.1218 - val_loss: 25.6140\n",
      "Epoch 16333/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 10.1122 - val_loss: 25.6077\n",
      "Epoch 16334/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 10.1026 - val_loss: 25.5978\n",
      "Epoch 16335/100000\n",
      "11/11 [==============================] - 0s 683us/step - loss: 10.0931 - val_loss: 25.5927\n",
      "Epoch 16336/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 10.0835 - val_loss: 25.5830\n",
      "Epoch 16337/100000\n",
      "11/11 [==============================] - 0s 699us/step - loss: 10.0740 - val_loss: 25.5765\n",
      "Epoch 16338/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 10.0644 - val_loss: 25.5690\n",
      "Epoch 16339/100000\n",
      "11/11 [==============================] - 0s 694us/step - loss: 10.0549 - val_loss: 25.5603\n",
      "Epoch 16340/100000\n",
      "11/11 [==============================] - 0s 306us/step - loss: 10.0454 - val_loss: 25.5545\n",
      "Epoch 16341/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 10.0358 - val_loss: 25.5450\n",
      "Epoch 16342/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 10.0263 - val_loss: 25.5389\n",
      "Epoch 16343/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 10.0168 - val_loss: 25.5305\n",
      "Epoch 16344/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 10.0073 - val_loss: 25.5230\n",
      "Epoch 16345/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 9.9978 - val_loss: 25.5161\n",
      "Epoch 16346/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 9.9882 - val_loss: 25.5073\n",
      "Epoch 16347/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 9.9787 - val_loss: 25.5012\n",
      "Epoch 16348/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 9.9693 - val_loss: 25.4924\n",
      "Epoch 16349/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 9.9598 - val_loss: 25.4856\n",
      "Epoch 16350/100000\n",
      "11/11 [==============================] - 0s 258us/step - loss: 9.9503 - val_loss: 25.4779\n",
      "Epoch 16351/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.9408 - val_loss: 25.4700\n",
      "Epoch 16352/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 9.9313 - val_loss: 25.4632\n",
      "Epoch 16353/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.9218 - val_loss: 25.4547\n",
      "Epoch 16354/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.9124 - val_loss: 25.4481\n",
      "Epoch 16355/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 9.9029 - val_loss: 25.4401\n",
      "Epoch 16356/100000\n",
      "11/11 [==============================] - 0s 592us/step - loss: 9.8934 - val_loss: 25.4327\n",
      "Epoch 16357/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 9.8840 - val_loss: 25.4255\n",
      "Epoch 16358/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 9.8745 - val_loss: 25.4173\n",
      "Epoch 16359/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 9.8651 - val_loss: 25.4107\n",
      "Epoch 16360/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 9.8557 - val_loss: 25.4023\n",
      "Epoch 16361/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 9.8462 - val_loss: 25.3955\n",
      "Epoch 16362/100000\n",
      "11/11 [==============================] - 0s 495us/step - loss: 9.8368 - val_loss: 25.3877\n",
      "Epoch 16363/100000\n",
      "11/11 [==============================] - 0s 961us/step - loss: 9.8274 - val_loss: 25.3801\n",
      "Epoch 16364/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 9.8179 - val_loss: 25.3731\n",
      "Epoch 16365/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 9.8085 - val_loss: 25.3649\n",
      "Epoch 16366/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 9.7991 - val_loss: 25.3582\n",
      "Epoch 16367/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 9.7897 - val_loss: 25.3501\n",
      "Epoch 16368/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 9.7803 - val_loss: 25.3430\n",
      "Epoch 16369/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 9.7709 - val_loss: 25.3355\n",
      "Epoch 16370/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 9.7616 - val_loss: 25.3280\n",
      "Epoch 16371/100000\n",
      "11/11 [==============================] - 0s 378us/step - loss: 9.7522 - val_loss: 25.3208\n",
      "Epoch 16372/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 9.7428 - val_loss: 25.3130\n",
      "Epoch 16373/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 9.7334 - val_loss: 25.3058\n",
      "Epoch 16374/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 9.7240 - val_loss: 25.2982\n",
      "Epoch 16375/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 9.7146 - val_loss: 25.2909\n",
      "Epoch 16376/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 9.7053 - val_loss: 25.2835\n",
      "Epoch 16377/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 9.6959 - val_loss: 25.2759\n",
      "Epoch 16378/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 9.6866 - val_loss: 25.2689\n",
      "Epoch 16379/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 9.6772 - val_loss: 25.2611\n",
      "Epoch 16380/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 9.6679 - val_loss: 25.2539\n",
      "Epoch 16381/100000\n",
      "11/11 [==============================] - 0s 540us/step - loss: 9.6585 - val_loss: 25.2465\n",
      "Epoch 16382/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 9.6492 - val_loss: 25.2389\n",
      "Epoch 16383/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 9.6399 - val_loss: 25.2319\n",
      "Epoch 16384/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 9.6306 - val_loss: 25.2241\n",
      "Epoch 16385/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 9.6213 - val_loss: 25.2172\n",
      "Epoch 16386/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 9.6120 - val_loss: 25.2094\n",
      "Epoch 16387/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 9.6027 - val_loss: 25.2024\n",
      "Epoch 16388/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 9.5933 - val_loss: 25.1948\n",
      "Epoch 16389/100000\n",
      "11/11 [==============================] - 0s 658us/step - loss: 9.5840 - val_loss: 25.1876\n",
      "Epoch 16390/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 9.5748 - val_loss: 25.1802\n",
      "Epoch 16391/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 9.5655 - val_loss: 25.1728\n",
      "Epoch 16392/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 9.5562 - val_loss: 25.1656\n",
      "Epoch 16393/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 9.5469 - val_loss: 25.1581\n",
      "Epoch 16394/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 9.5376 - val_loss: 25.1510\n",
      "Epoch 16395/100000\n",
      "11/11 [==============================] - 0s 564us/step - loss: 9.5284 - val_loss: 25.1434\n",
      "Epoch 16396/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 9.5191 - val_loss: 25.1362\n",
      "Epoch 16397/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 9.5098 - val_loss: 25.1289\n",
      "Epoch 16398/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 774us/step - loss: 9.5006 - val_loss: 25.1216\n",
      "Epoch 16399/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 9.4913 - val_loss: 25.1143\n",
      "Epoch 16400/100000\n",
      "11/11 [==============================] - 0s 623us/step - loss: 9.4821 - val_loss: 25.1070\n",
      "Epoch 16401/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 9.4729 - val_loss: 25.0998\n",
      "Epoch 16402/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 9.4636 - val_loss: 25.0923\n",
      "Epoch 16403/100000\n",
      "11/11 [==============================] - 0s 515us/step - loss: 9.4544 - val_loss: 25.0853\n",
      "Epoch 16404/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 9.4452 - val_loss: 25.0778\n",
      "Epoch 16405/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 9.4359 - val_loss: 25.0706\n",
      "Epoch 16406/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 9.4267 - val_loss: 25.0633\n",
      "Epoch 16407/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 9.4175 - val_loss: 25.0560\n",
      "Epoch 16408/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 9.4083 - val_loss: 25.0488\n",
      "Epoch 16409/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 9.3991 - val_loss: 25.0414\n",
      "Epoch 16410/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 9.3899 - val_loss: 25.0343\n",
      "Epoch 16411/100000\n",
      "11/11 [==============================] - 0s 427us/step - loss: 9.3807 - val_loss: 25.0269\n",
      "Epoch 16412/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 9.3715 - val_loss: 25.0199\n",
      "Epoch 16413/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 9.3624 - val_loss: 25.0125\n",
      "Epoch 16414/100000\n",
      "11/11 [==============================] - 0s 198us/step - loss: 9.3532 - val_loss: 25.0054\n",
      "Epoch 16415/100000\n",
      "11/11 [==============================] - 0s 381us/step - loss: 9.3440 - val_loss: 24.9981\n",
      "Epoch 16416/100000\n",
      "11/11 [==============================] - 0s 483us/step - loss: 9.3348 - val_loss: 24.9909\n",
      "Epoch 16417/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 9.3257 - val_loss: 24.9837\n",
      "Epoch 16418/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 9.3165 - val_loss: 24.9764\n",
      "Epoch 16419/100000\n",
      "11/11 [==============================] - 0s 236us/step - loss: 9.3074 - val_loss: 24.9693\n",
      "Epoch 16420/100000\n",
      "11/11 [==============================] - 0s 560us/step - loss: 9.2982 - val_loss: 24.9620\n",
      "Epoch 16421/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 9.2891 - val_loss: 24.9549\n",
      "Epoch 16422/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 9.2800 - val_loss: 24.9476\n",
      "Epoch 16423/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 9.2708 - val_loss: 24.9405\n",
      "Epoch 16424/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 9.2617 - val_loss: 24.9332\n",
      "Epoch 16425/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 9.2526 - val_loss: 24.9262\n",
      "Epoch 16426/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 9.2435 - val_loss: 24.9188\n",
      "Epoch 16427/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 9.2344 - val_loss: 24.9120\n",
      "Epoch 16428/100000\n",
      "11/11 [==============================] - 0s 275us/step - loss: 9.2252 - val_loss: 24.9043\n",
      "Epoch 16429/100000\n",
      "11/11 [==============================] - 0s 594us/step - loss: 9.2161 - val_loss: 24.8979\n",
      "Epoch 16430/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 9.2071 - val_loss: 24.8899\n",
      "Epoch 16431/100000\n",
      "11/11 [==============================] - 0s 575us/step - loss: 9.1980 - val_loss: 24.8837\n",
      "Epoch 16432/100000\n",
      "11/11 [==============================] - 0s 576us/step - loss: 9.1889 - val_loss: 24.8755\n",
      "Epoch 16433/100000\n",
      "11/11 [==============================] - 0s 803us/step - loss: 9.1798 - val_loss: 24.8694\n",
      "Epoch 16434/100000\n",
      "11/11 [==============================] - 0s 687us/step - loss: 9.1707 - val_loss: 24.8613\n",
      "Epoch 16435/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.1616 - val_loss: 24.8552\n",
      "Epoch 16436/100000\n",
      "11/11 [==============================] - 0s 969us/step - loss: 9.1526 - val_loss: 24.8470\n",
      "Epoch 16437/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 9.1435 - val_loss: 24.8410\n",
      "Epoch 16438/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 9.1345 - val_loss: 24.8326\n",
      "Epoch 16439/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 9.1254 - val_loss: 24.8268\n",
      "Epoch 16440/100000\n",
      "11/11 [==============================] - 0s 523us/step - loss: 9.1164 - val_loss: 24.8184\n",
      "Epoch 16441/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.1073 - val_loss: 24.8128\n",
      "Epoch 16442/100000\n",
      "11/11 [==============================] - 0s 969us/step - loss: 9.0983 - val_loss: 24.8042\n",
      "Epoch 16443/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 9.0893 - val_loss: 24.7987\n",
      "Epoch 16444/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 9.0802 - val_loss: 24.7899\n",
      "Epoch 16445/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 9.0712 - val_loss: 24.7848\n",
      "Epoch 16446/100000\n",
      "11/11 [==============================] - 0s 661us/step - loss: 9.0622 - val_loss: 24.7753\n",
      "Epoch 16447/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 9.0532 - val_loss: 24.7711\n",
      "Epoch 16448/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 9.0442 - val_loss: 24.7607\n",
      "Epoch 16449/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 9.0352 - val_loss: 24.7576\n",
      "Epoch 16450/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 9.0262 - val_loss: 24.7458\n",
      "Epoch 16451/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 9.0172 - val_loss: 24.7443\n",
      "Epoch 16452/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 9.0082 - val_loss: 24.7307\n",
      "Epoch 16453/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 8.9992 - val_loss: 24.7317\n",
      "Epoch 16454/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 8.9902 - val_loss: 24.7149\n",
      "Epoch 16455/100000\n",
      "11/11 [==============================] - 0s 450us/step - loss: 8.9813 - val_loss: 24.7199\n",
      "Epoch 16456/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 8.9723 - val_loss: 24.6979\n",
      "Epoch 16457/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 8.9634 - val_loss: 24.7095\n",
      "Epoch 16458/100000\n",
      "11/11 [==============================] - 0s 635us/step - loss: 8.9544 - val_loss: 24.6794\n",
      "Epoch 16459/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 8.9455 - val_loss: 24.7013\n",
      "Epoch 16460/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 8.9365 - val_loss: 24.6583\n",
      "Epoch 16461/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 8.9277 - val_loss: 24.6962\n",
      "Epoch 16462/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 8.9188 - val_loss: 24.6338\n",
      "Epoch 16463/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 8.9100 - val_loss: 24.6949\n",
      "Epoch 16464/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 8.9012 - val_loss: 24.6066\n",
      "Epoch 16465/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 8.8925 - val_loss: 24.6940\n",
      "Epoch 16466/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 8.8837 - val_loss: 24.5838\n",
      "Epoch 16467/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 8.8749 - val_loss: 24.6813\n",
      "Epoch 16468/100000\n",
      "11/11 [==============================] - 0s 591us/step - loss: 8.8660 - val_loss: 24.5798\n",
      "Epoch 16469/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 8.8568 - val_loss: 24.6441\n",
      "Epoch 16470/100000\n",
      "11/11 [==============================] - 0s 387us/step - loss: 8.8476 - val_loss: 24.5984\n",
      "Epoch 16471/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 8.8385 - val_loss: 24.5937\n",
      "Epoch 16472/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 8.8296 - val_loss: 24.6183\n",
      "Epoch 16473/100000\n",
      "11/11 [==============================] - 0s 689us/step - loss: 8.8209 - val_loss: 24.5564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16474/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 8.8122 - val_loss: 24.6155\n",
      "Epoch 16475/100000\n",
      "11/11 [==============================] - 0s 565us/step - loss: 8.8034 - val_loss: 24.5468\n",
      "Epoch 16476/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 8.7944 - val_loss: 24.5838\n",
      "Epoch 16477/100000\n",
      "11/11 [==============================] - 0s 278us/step - loss: 8.7855 - val_loss: 24.5584\n",
      "Epoch 16478/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 8.7765 - val_loss: 24.5423\n",
      "Epoch 16479/100000\n",
      "11/11 [==============================] - 0s 203us/step - loss: 8.7677 - val_loss: 24.5672\n",
      "Epoch 16480/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 8.7590 - val_loss: 24.5155\n",
      "Epoch 16481/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 8.7502 - val_loss: 24.5545\n",
      "Epoch 16482/100000\n",
      "11/11 [==============================] - 0s 251us/step - loss: 8.7414 - val_loss: 24.5116\n",
      "Epoch 16483/100000\n",
      "11/11 [==============================] - 0s 401us/step - loss: 8.7325 - val_loss: 24.5229\n",
      "Epoch 16484/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 8.7236 - val_loss: 24.5181\n",
      "Epoch 16485/100000\n",
      "11/11 [==============================] - 0s 325us/step - loss: 8.7148 - val_loss: 24.4913\n",
      "Epoch 16486/100000\n",
      "11/11 [==============================] - 0s 618us/step - loss: 8.7061 - val_loss: 24.5157\n",
      "Epoch 16487/100000\n",
      "11/11 [==============================] - 0s 402us/step - loss: 8.6973 - val_loss: 24.4749\n",
      "Epoch 16488/100000\n",
      "11/11 [==============================] - 0s 207us/step - loss: 8.6885 - val_loss: 24.4958\n",
      "Epoch 16489/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 8.6797 - val_loss: 24.4732\n",
      "Epoch 16490/100000\n",
      "11/11 [==============================] - 0s 210us/step - loss: 8.6709 - val_loss: 24.4671\n",
      "Epoch 16491/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 8.6622 - val_loss: 24.4730\n",
      "Epoch 16492/100000\n",
      "11/11 [==============================] - 0s 333us/step - loss: 8.6534 - val_loss: 24.4442\n",
      "Epoch 16493/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 8.6447 - val_loss: 24.4622\n",
      "Epoch 16494/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 8.6359 - val_loss: 24.4338\n",
      "Epoch 16495/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 8.6272 - val_loss: 24.4404\n",
      "Epoch 16496/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 8.6184 - val_loss: 24.4306\n",
      "Epoch 16497/100000\n",
      "11/11 [==============================] - 0s 519us/step - loss: 8.6096 - val_loss: 24.4167\n",
      "Epoch 16498/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 8.6009 - val_loss: 24.4245\n",
      "Epoch 16499/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 8.5922 - val_loss: 24.3998\n",
      "Epoch 16500/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 8.5835 - val_loss: 24.4097\n",
      "Epoch 16501/100000\n",
      "11/11 [==============================] - 0s 246us/step - loss: 8.5748 - val_loss: 24.3911\n",
      "Epoch 16502/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 8.5661 - val_loss: 24.3890\n",
      "Epoch 16503/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 8.5574 - val_loss: 24.3850\n",
      "Epoch 16504/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 8.5487 - val_loss: 24.3694\n",
      "Epoch 16505/100000\n",
      "11/11 [==============================] - 0s 211us/step - loss: 8.5400 - val_loss: 24.3752\n",
      "Epoch 16506/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 8.5313 - val_loss: 24.3553\n",
      "Epoch 16507/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 8.5226 - val_loss: 24.3595\n",
      "Epoch 16508/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 8.5139 - val_loss: 24.3462\n",
      "Epoch 16509/100000\n",
      "11/11 [==============================] - 0s 411us/step - loss: 8.5053 - val_loss: 24.3408\n",
      "Epoch 16510/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 8.4966 - val_loss: 24.3378\n",
      "Epoch 16511/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 8.4879 - val_loss: 24.3236\n",
      "Epoch 16512/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 8.4793 - val_loss: 24.3263\n",
      "Epoch 16513/100000\n",
      "11/11 [==============================] - 0s 633us/step - loss: 8.4706 - val_loss: 24.3104\n",
      "Epoch 16514/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 8.4620 - val_loss: 24.3108\n",
      "Epoch 16515/100000\n",
      "11/11 [==============================] - 0s 737us/step - loss: 8.4533 - val_loss: 24.3003\n",
      "Epoch 16516/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 8.4447 - val_loss: 24.2939\n",
      "Epoch 16517/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 8.4361 - val_loss: 24.2902\n",
      "Epoch 16518/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 8.4275 - val_loss: 24.2781\n",
      "Epoch 16519/100000\n",
      "11/11 [==============================] - 0s 637us/step - loss: 8.4188 - val_loss: 24.2781\n",
      "Epoch 16520/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 8.4102 - val_loss: 24.2649\n",
      "Epoch 16521/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 8.4016 - val_loss: 24.2635\n",
      "Epoch 16522/100000\n",
      "11/11 [==============================] - 0s 611us/step - loss: 8.3930 - val_loss: 24.2537\n",
      "Epoch 16523/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 8.3844 - val_loss: 24.2477\n",
      "Epoch 16524/100000\n",
      "11/11 [==============================] - 0s 552us/step - loss: 8.3758 - val_loss: 24.2427\n",
      "Epoch 16525/100000\n",
      "11/11 [==============================] - 0s 630us/step - loss: 8.3672 - val_loss: 24.2325\n",
      "Epoch 16526/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 8.3586 - val_loss: 24.2306\n",
      "Epoch 16527/100000\n",
      "11/11 [==============================] - 0s 844us/step - loss: 8.3501 - val_loss: 24.2191\n",
      "Epoch 16528/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 8.3415 - val_loss: 24.2167\n",
      "Epoch 16529/100000\n",
      "11/11 [==============================] - 0s 601us/step - loss: 8.3329 - val_loss: 24.2071\n",
      "Epoch 16530/100000\n",
      "11/11 [==============================] - 0s 705us/step - loss: 8.3243 - val_loss: 24.2019\n",
      "Epoch 16531/100000\n",
      "11/11 [==============================] - 0s 410us/step - loss: 8.3158 - val_loss: 24.1957\n",
      "Epoch 16532/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 8.3073 - val_loss: 24.1872\n",
      "Epoch 16533/100000\n",
      "11/11 [==============================] - 0s 550us/step - loss: 8.2987 - val_loss: 24.1835\n",
      "Epoch 16534/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 8.2902 - val_loss: 24.1735\n",
      "Epoch 16535/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 8.2816 - val_loss: 24.1703\n",
      "Epoch 16536/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 8.2731 - val_loss: 24.1608\n",
      "Epoch 16537/100000\n",
      "11/11 [==============================] - 0s 664us/step - loss: 8.2646 - val_loss: 24.1564\n",
      "Epoch 16538/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 8.2561 - val_loss: 24.1488\n",
      "Epoch 16539/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 8.2476 - val_loss: 24.1421\n",
      "Epoch 16540/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 8.2390 - val_loss: 24.1366\n",
      "Epoch 16541/100000\n",
      "11/11 [==============================] - 0s 553us/step - loss: 8.2305 - val_loss: 24.1283\n",
      "Epoch 16542/100000\n",
      "11/11 [==============================] - 0s 339us/step - loss: 8.2221 - val_loss: 24.1241\n",
      "Epoch 16543/100000\n",
      "11/11 [==============================] - 0s 351us/step - loss: 8.2136 - val_loss: 24.1151\n",
      "Epoch 16544/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 8.2051 - val_loss: 24.1108\n",
      "Epoch 16545/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 8.1966 - val_loss: 24.1026\n",
      "Epoch 16546/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 8.1881 - val_loss: 24.0973\n",
      "Epoch 16547/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 8.1796 - val_loss: 24.0902\n",
      "Epoch 16548/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 8.1712 - val_loss: 24.0836\n",
      "Epoch 16549/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 318us/step - loss: 8.1627 - val_loss: 24.0779\n",
      "Epoch 16550/100000\n",
      "11/11 [==============================] - 0s 283us/step - loss: 8.1543 - val_loss: 24.0702\n",
      "Epoch 16551/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 8.1458 - val_loss: 24.0652\n",
      "Epoch 16552/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 8.1374 - val_loss: 24.0571\n",
      "Epoch 16553/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 8.1289 - val_loss: 24.0523\n",
      "Epoch 16554/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 8.1205 - val_loss: 24.0444\n",
      "Epoch 16555/100000\n",
      "11/11 [==============================] - 0s 614us/step - loss: 8.1121 - val_loss: 24.0391\n",
      "Epoch 16556/100000\n",
      "11/11 [==============================] - 0s 654us/step - loss: 8.1037 - val_loss: 24.0319\n",
      "Epoch 16557/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 8.0953 - val_loss: 24.0258\n",
      "Epoch 16558/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 8.0868 - val_loss: 24.0194\n",
      "Epoch 16559/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 8.0784 - val_loss: 24.0126\n",
      "Epoch 16560/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 8.0700 - val_loss: 24.0069\n",
      "Epoch 16561/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 8.0616 - val_loss: 23.9995\n",
      "Epoch 16562/100000\n",
      "11/11 [==============================] - 0s 435us/step - loss: 8.0533 - val_loss: 23.9943\n",
      "Epoch 16563/100000\n",
      "11/11 [==============================] - 0s 220us/step - loss: 8.0449 - val_loss: 23.9866\n",
      "Epoch 16564/100000\n",
      "11/11 [==============================] - 0s 678us/step - loss: 8.0365 - val_loss: 23.9816\n",
      "Epoch 16565/100000\n",
      "11/11 [==============================] - 0s 511us/step - loss: 8.0282 - val_loss: 23.9739\n",
      "Epoch 16566/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 8.0198 - val_loss: 23.9688\n",
      "Epoch 16567/100000\n",
      "11/11 [==============================] - 0s 209us/step - loss: 8.0114 - val_loss: 23.9613\n",
      "Epoch 16568/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 8.0031 - val_loss: 23.9558\n",
      "Epoch 16569/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 7.9947 - val_loss: 23.9488\n",
      "Epoch 16570/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 7.9864 - val_loss: 23.9429\n",
      "Epoch 16571/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 7.9780 - val_loss: 23.9363\n",
      "Epoch 16572/100000\n",
      "11/11 [==============================] - 0s 677us/step - loss: 7.9697 - val_loss: 23.9301\n",
      "Epoch 16573/100000\n",
      "11/11 [==============================] - 0s 219us/step - loss: 7.9614 - val_loss: 23.9238\n",
      "Epoch 16574/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 7.9531 - val_loss: 23.9175\n",
      "Epoch 16575/100000\n",
      "11/11 [==============================] - 0s 234us/step - loss: 7.9447 - val_loss: 23.9112\n",
      "Epoch 16576/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 7.9364 - val_loss: 23.9049\n",
      "Epoch 16577/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 7.9281 - val_loss: 23.8985\n",
      "Epoch 16578/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 7.9198 - val_loss: 23.8924\n",
      "Epoch 16579/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 7.9116 - val_loss: 23.8859\n",
      "Epoch 16580/100000\n",
      "11/11 [==============================] - 0s 609us/step - loss: 7.9033 - val_loss: 23.8800\n",
      "Epoch 16581/100000\n",
      "11/11 [==============================] - 0s 243us/step - loss: 7.8950 - val_loss: 23.8732\n",
      "Epoch 16582/100000\n",
      "11/11 [==============================] - 0s 595us/step - loss: 7.8867 - val_loss: 23.8676\n",
      "Epoch 16583/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 7.8784 - val_loss: 23.8605\n",
      "Epoch 16584/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 7.8702 - val_loss: 23.8553\n",
      "Epoch 16585/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 7.8619 - val_loss: 23.8480\n",
      "Epoch 16586/100000\n",
      "11/11 [==============================] - 0s 363us/step - loss: 7.8537 - val_loss: 23.8429\n",
      "Epoch 16587/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 7.8454 - val_loss: 23.8355\n",
      "Epoch 16588/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 7.8372 - val_loss: 23.8306\n",
      "Epoch 16589/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 7.8290 - val_loss: 23.8230\n",
      "Epoch 16590/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 7.8207 - val_loss: 23.8182\n",
      "Epoch 16591/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 7.8125 - val_loss: 23.8106\n",
      "Epoch 16592/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 7.8043 - val_loss: 23.8058\n",
      "Epoch 16593/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 7.7961 - val_loss: 23.7983\n",
      "Epoch 16594/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 7.7879 - val_loss: 23.7935\n",
      "Epoch 16595/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 7.7797 - val_loss: 23.7860\n",
      "Epoch 16596/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 7.7715 - val_loss: 23.7812\n",
      "Epoch 16597/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 7.7633 - val_loss: 23.7737\n",
      "Epoch 16598/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 7.7551 - val_loss: 23.7690\n",
      "Epoch 16599/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 7.7470 - val_loss: 23.7614\n",
      "Epoch 16600/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 7.7388 - val_loss: 23.7569\n",
      "Epoch 16601/100000\n",
      "11/11 [==============================] - 0s 569us/step - loss: 7.7306 - val_loss: 23.7489\n",
      "Epoch 16602/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 7.7225 - val_loss: 23.7449\n",
      "Epoch 16603/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 7.7143 - val_loss: 23.7366\n",
      "Epoch 16604/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 7.7062 - val_loss: 23.7329\n",
      "Epoch 16605/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 7.6980 - val_loss: 23.7241\n",
      "Epoch 16606/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 7.6899 - val_loss: 23.7211\n",
      "Epoch 16607/100000\n",
      "11/11 [==============================] - 0s 757us/step - loss: 7.6818 - val_loss: 23.7116\n",
      "Epoch 16608/100000\n",
      "11/11 [==============================] - 0s 414us/step - loss: 7.6737 - val_loss: 23.7094\n",
      "Epoch 16609/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 7.6655 - val_loss: 23.6990\n",
      "Epoch 16610/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.6574 - val_loss: 23.6981\n",
      "Epoch 16611/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 7.6493 - val_loss: 23.6860\n",
      "Epoch 16612/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 7.6412 - val_loss: 23.6871\n",
      "Epoch 16613/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 7.6331 - val_loss: 23.6726\n",
      "Epoch 16614/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 7.6251 - val_loss: 23.6768\n",
      "Epoch 16615/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 7.6170 - val_loss: 23.6585\n",
      "Epoch 16616/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 7.6089 - val_loss: 23.6674\n",
      "Epoch 16617/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 7.6009 - val_loss: 23.6434\n",
      "Epoch 16618/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 7.5928 - val_loss: 23.6593\n",
      "Epoch 16619/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 7.5848 - val_loss: 23.6269\n",
      "Epoch 16620/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 7.5767 - val_loss: 23.6531\n",
      "Epoch 16621/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 7.5687 - val_loss: 23.6081\n",
      "Epoch 16622/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 7.5608 - val_loss: 23.6495\n",
      "Epoch 16623/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 7.5528 - val_loss: 23.5870\n",
      "Epoch 16624/100000\n",
      "11/11 [==============================] - 0s 830us/step - loss: 7.5449 - val_loss: 23.6481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16625/100000\n",
      "11/11 [==============================] - 0s 493us/step - loss: 7.5370 - val_loss: 23.5649\n",
      "Epoch 16626/100000\n",
      "11/11 [==============================] - 0s 561us/step - loss: 7.5291 - val_loss: 23.6453\n",
      "Epoch 16627/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 7.5212 - val_loss: 23.5482\n",
      "Epoch 16628/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 7.5132 - val_loss: 23.6320\n",
      "Epoch 16629/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 7.5052 - val_loss: 23.5463\n",
      "Epoch 16630/100000\n",
      "11/11 [==============================] - 0s 197us/step - loss: 7.4970 - val_loss: 23.6013\n",
      "Epoch 16631/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 7.4888 - val_loss: 23.5598\n",
      "Epoch 16632/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 7.4807 - val_loss: 23.5614\n",
      "Epoch 16633/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 7.4727 - val_loss: 23.5750\n",
      "Epoch 16634/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 7.4648 - val_loss: 23.5292\n",
      "Epoch 16635/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 7.4570 - val_loss: 23.5762\n",
      "Epoch 16636/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 7.4491 - val_loss: 23.5148\n",
      "Epoch 16637/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 7.4412 - val_loss: 23.5573\n",
      "Epoch 16638/100000\n",
      "11/11 [==============================] - 0s 239us/step - loss: 7.4332 - val_loss: 23.5177\n",
      "Epoch 16639/100000\n",
      "11/11 [==============================] - 0s 487us/step - loss: 7.4251 - val_loss: 23.5256\n",
      "Epoch 16640/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 7.4172 - val_loss: 23.5262\n",
      "Epoch 16641/100000\n",
      "11/11 [==============================] - 0s 340us/step - loss: 7.4093 - val_loss: 23.4970\n",
      "Epoch 16642/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 7.4015 - val_loss: 23.5259\n",
      "Epoch 16643/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 7.3936 - val_loss: 23.4819\n",
      "Epoch 16644/100000\n",
      "11/11 [==============================] - 0s 471us/step - loss: 7.3857 - val_loss: 23.5103\n",
      "Epoch 16645/100000\n",
      "11/11 [==============================] - 0s 555us/step - loss: 7.3778 - val_loss: 23.4804\n",
      "Epoch 16646/100000\n",
      "11/11 [==============================] - 0s 472us/step - loss: 7.3699 - val_loss: 23.4850\n",
      "Epoch 16647/100000\n",
      "11/11 [==============================] - 0s 496us/step - loss: 7.3620 - val_loss: 23.4831\n",
      "Epoch 16648/100000\n",
      "11/11 [==============================] - 0s 312us/step - loss: 7.3542 - val_loss: 23.4612\n",
      "Epoch 16649/100000\n",
      "11/11 [==============================] - 0s 528us/step - loss: 7.3463 - val_loss: 23.4795\n",
      "Epoch 16650/100000\n",
      "11/11 [==============================] - 0s 465us/step - loss: 7.3385 - val_loss: 23.4470\n",
      "Epoch 16651/100000\n",
      "11/11 [==============================] - 0s 625us/step - loss: 7.3307 - val_loss: 23.4653\n",
      "Epoch 16652/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 7.3228 - val_loss: 23.4423\n",
      "Epoch 16653/100000\n",
      "11/11 [==============================] - 0s 802us/step - loss: 7.3150 - val_loss: 23.4445\n",
      "Epoch 16654/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.3071 - val_loss: 23.4410\n",
      "Epoch 16655/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.2993 - val_loss: 23.4246\n",
      "Epoch 16656/100000\n",
      "11/11 [==============================] - 0s 737us/step - loss: 7.2915 - val_loss: 23.4355\n",
      "Epoch 16657/100000\n",
      "11/11 [==============================] - 0s 479us/step - loss: 7.2838 - val_loss: 23.4110\n",
      "Epoch 16658/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 7.2760 - val_loss: 23.4229\n",
      "Epoch 16659/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 7.2682 - val_loss: 23.4039\n",
      "Epoch 16660/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 7.2604 - val_loss: 23.4054\n",
      "Epoch 16661/100000\n",
      "11/11 [==============================] - 0s 675us/step - loss: 7.2526 - val_loss: 23.3995\n",
      "Epoch 16662/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.2448 - val_loss: 23.3880\n",
      "Epoch 16663/100000\n",
      "11/11 [==============================] - 0s 990us/step - loss: 7.2371 - val_loss: 23.3929\n",
      "Epoch 16664/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 7.2293 - val_loss: 23.3745\n",
      "Epoch 16665/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 7.2216 - val_loss: 23.3817\n",
      "Epoch 16666/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.2138 - val_loss: 23.3656\n",
      "Epoch 16667/100000\n",
      "11/11 [==============================] - 0s 439us/step - loss: 7.2061 - val_loss: 23.3669\n",
      "Epoch 16668/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 7.1983 - val_loss: 23.3590\n",
      "Epoch 16669/100000\n",
      "11/11 [==============================] - 0s 756us/step - loss: 7.1906 - val_loss: 23.3515\n",
      "Epoch 16670/100000\n",
      "11/11 [==============================] - 0s 613us/step - loss: 7.1829 - val_loss: 23.3516\n",
      "Epoch 16671/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 7.1752 - val_loss: 23.3380\n",
      "Epoch 16672/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 7.1675 - val_loss: 23.3414\n",
      "Epoch 16673/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 7.1598 - val_loss: 23.3277\n",
      "Epoch 16674/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 7.1521 - val_loss: 23.3286\n",
      "Epoch 16675/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 7.1444 - val_loss: 23.3193\n",
      "Epoch 16676/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 7.1367 - val_loss: 23.3147\n",
      "Epoch 16677/100000\n",
      "11/11 [==============================] - 0s 391us/step - loss: 7.1291 - val_loss: 23.3112\n",
      "Epoch 16678/100000\n",
      "11/11 [==============================] - 0s 417us/step - loss: 7.1214 - val_loss: 23.3015\n",
      "Epoch 16679/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 7.1137 - val_loss: 23.3018\n",
      "Epoch 16680/100000\n",
      "11/11 [==============================] - 0s 562us/step - loss: 7.1061 - val_loss: 23.2901\n",
      "Epoch 16681/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 7.0984 - val_loss: 23.2904\n",
      "Epoch 16682/100000\n",
      "11/11 [==============================] - 0s 600us/step - loss: 7.0908 - val_loss: 23.2804\n",
      "Epoch 16683/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 7.0832 - val_loss: 23.2780\n",
      "Epoch 16684/100000\n",
      "11/11 [==============================] - 0s 443us/step - loss: 7.0755 - val_loss: 23.2715\n",
      "Epoch 16685/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 7.0679 - val_loss: 23.2653\n",
      "Epoch 16686/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 7.0603 - val_loss: 23.2622\n",
      "Epoch 16687/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 7.0527 - val_loss: 23.2534\n",
      "Epoch 16688/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 7.0451 - val_loss: 23.2520\n",
      "Epoch 16689/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 7.0375 - val_loss: 23.2427\n",
      "Epoch 16690/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 7.0299 - val_loss: 23.2408\n",
      "Epoch 16691/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 7.0224 - val_loss: 23.2329\n",
      "Epoch 16692/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 7.0148 - val_loss: 23.2290\n",
      "Epoch 16693/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 7.0072 - val_loss: 23.2232\n",
      "Epoch 16694/100000\n",
      "11/11 [==============================] - 0s 568us/step - loss: 6.9997 - val_loss: 23.2174\n",
      "Epoch 16695/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 6.9921 - val_loss: 23.2134\n",
      "Epoch 16696/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 6.9846 - val_loss: 23.2062\n",
      "Epoch 16697/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 6.9770 - val_loss: 23.2031\n",
      "Epoch 16698/100000\n",
      "11/11 [==============================] - 0s 477us/step - loss: 6.9695 - val_loss: 23.1957\n",
      "Epoch 16699/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 6.9620 - val_loss: 23.1923\n",
      "Epoch 16700/100000\n",
      "11/11 [==============================] - 0s 776us/step - loss: 6.9544 - val_loss: 23.1855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16701/100000\n",
      "11/11 [==============================] - 0s 369us/step - loss: 6.9469 - val_loss: 23.1813\n",
      "Epoch 16702/100000\n",
      "11/11 [==============================] - 0s 849us/step - loss: 6.9394 - val_loss: 23.1756\n",
      "Epoch 16703/100000\n",
      "11/11 [==============================] - 0s 926us/step - loss: 6.9319 - val_loss: 23.1702\n",
      "Epoch 16704/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.9244 - val_loss: 23.1656\n",
      "Epoch 16705/100000\n",
      "11/11 [==============================] - 0s 993us/step - loss: 6.9170 - val_loss: 23.1594\n",
      "Epoch 16706/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.9095 - val_loss: 23.1554\n",
      "Epoch 16707/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.9020 - val_loss: 23.1488\n",
      "Epoch 16708/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.8945 - val_loss: 23.1450\n",
      "Epoch 16709/100000\n",
      "11/11 [==============================] - 0s 774us/step - loss: 6.8871 - val_loss: 23.1386\n",
      "Epoch 16710/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.8796 - val_loss: 23.1345\n",
      "Epoch 16711/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.8722 - val_loss: 23.1285\n",
      "Epoch 16712/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.8647 - val_loss: 23.1239\n",
      "Epoch 16713/100000\n",
      "11/11 [==============================] - 0s 910us/step - loss: 6.8573 - val_loss: 23.1185\n",
      "Epoch 16714/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.8499 - val_loss: 23.1133\n",
      "Epoch 16715/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.8424 - val_loss: 23.1084\n",
      "Epoch 16716/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.8350 - val_loss: 23.1029\n",
      "Epoch 16717/100000\n",
      "11/11 [==============================] - 0s 770us/step - loss: 6.8276 - val_loss: 23.0982\n",
      "Epoch 16718/100000\n",
      "11/11 [==============================] - 0s 615us/step - loss: 6.8202 - val_loss: 23.0926\n",
      "Epoch 16719/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.8128 - val_loss: 23.0880\n",
      "Epoch 16720/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 6.8054 - val_loss: 23.0825\n",
      "Epoch 16721/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.7980 - val_loss: 23.0777\n",
      "Epoch 16722/100000\n",
      "11/11 [==============================] - 0s 961us/step - loss: 6.7907 - val_loss: 23.0725\n",
      "Epoch 16723/100000\n",
      "11/11 [==============================] - 0s 782us/step - loss: 6.7833 - val_loss: 23.0676\n",
      "Epoch 16724/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 6.7760 - val_loss: 23.0624\n",
      "Epoch 16725/100000\n",
      "11/11 [==============================] - 0s 603us/step - loss: 6.7686 - val_loss: 23.0575\n",
      "Epoch 16726/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 6.7613 - val_loss: 23.0523\n",
      "Epoch 16727/100000\n",
      "11/11 [==============================] - 0s 632us/step - loss: 6.7539 - val_loss: 23.0474\n",
      "Epoch 16728/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 6.7466 - val_loss: 23.0423\n",
      "Epoch 16729/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 6.7393 - val_loss: 23.0374\n",
      "Epoch 16730/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 6.7319 - val_loss: 23.0322\n",
      "Epoch 16731/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 6.7246 - val_loss: 23.0275\n",
      "Epoch 16732/100000\n",
      "11/11 [==============================] - 0s 922us/step - loss: 6.7173 - val_loss: 23.0220\n",
      "Epoch 16733/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 6.7100 - val_loss: 23.0178\n",
      "Epoch 16734/100000\n",
      "11/11 [==============================] - 0s 682us/step - loss: 6.7027 - val_loss: 23.0119\n",
      "Epoch 16735/100000\n",
      "11/11 [==============================] - 0s 368us/step - loss: 6.6954 - val_loss: 23.0080\n",
      "Epoch 16736/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 6.6882 - val_loss: 23.0019\n",
      "Epoch 16737/100000\n",
      "11/11 [==============================] - 0s 305us/step - loss: 6.6809 - val_loss: 22.9982\n",
      "Epoch 16738/100000\n",
      "11/11 [==============================] - 0s 779us/step - loss: 6.6736 - val_loss: 22.9920\n",
      "Epoch 16739/100000\n",
      "11/11 [==============================] - 0s 773us/step - loss: 6.6664 - val_loss: 22.9885\n",
      "Epoch 16740/100000\n",
      "11/11 [==============================] - 0s 250us/step - loss: 6.6591 - val_loss: 22.9820\n",
      "Epoch 16741/100000\n",
      "11/11 [==============================] - 0s 966us/step - loss: 6.6519 - val_loss: 22.9787\n",
      "Epoch 16742/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.6446 - val_loss: 22.9722\n",
      "Epoch 16743/100000\n",
      "11/11 [==============================] - 0s 912us/step - loss: 6.6374 - val_loss: 22.9690\n",
      "Epoch 16744/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.6302 - val_loss: 22.9624\n",
      "Epoch 16745/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.6229 - val_loss: 22.9592\n",
      "Epoch 16746/100000\n",
      "11/11 [==============================] - 0s 242us/step - loss: 6.6157 - val_loss: 22.9527\n",
      "Epoch 16747/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 6.6085 - val_loss: 22.9495\n",
      "Epoch 16748/100000\n",
      "11/11 [==============================] - 0s 614us/step - loss: 6.6013 - val_loss: 22.9429\n",
      "Epoch 16749/100000\n",
      "11/11 [==============================] - 0s 710us/step - loss: 6.5941 - val_loss: 22.9400\n",
      "Epoch 16750/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.5869 - val_loss: 22.9332\n",
      "Epoch 16751/100000\n",
      "11/11 [==============================] - 0s 986us/step - loss: 6.5798 - val_loss: 22.9304\n",
      "Epoch 16752/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.5726 - val_loss: 22.9234\n",
      "Epoch 16753/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.5654 - val_loss: 22.9209\n",
      "Epoch 16754/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 6.5583 - val_loss: 22.9137\n",
      "Epoch 16755/100000\n",
      "11/11 [==============================] - 0s 818us/step - loss: 6.5511 - val_loss: 22.9116\n",
      "Epoch 16756/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.5439 - val_loss: 22.9038\n",
      "Epoch 16757/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.5368 - val_loss: 22.9025\n",
      "Epoch 16758/100000\n",
      "11/11 [==============================] - 0s 627us/step - loss: 6.5297 - val_loss: 22.8938\n",
      "Epoch 16759/100000\n",
      "11/11 [==============================] - 0s 276us/step - loss: 6.5226 - val_loss: 22.8937\n",
      "Epoch 16760/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.5154 - val_loss: 22.8836\n",
      "Epoch 16761/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.5083 - val_loss: 22.8851\n",
      "Epoch 16762/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.5012 - val_loss: 22.8731\n",
      "Epoch 16763/100000\n",
      "11/11 [==============================] - 0s 814us/step - loss: 6.4941 - val_loss: 22.8769\n",
      "Epoch 16764/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 6.4870 - val_loss: 22.8621\n",
      "Epoch 16765/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.4800 - val_loss: 22.8693\n",
      "Epoch 16766/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.4729 - val_loss: 22.8506\n",
      "Epoch 16767/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 6.4658 - val_loss: 22.8625\n",
      "Epoch 16768/100000\n",
      "11/11 [==============================] - 0s 535us/step - loss: 6.4588 - val_loss: 22.8382\n",
      "Epoch 16769/100000\n",
      "11/11 [==============================] - 0s 669us/step - loss: 6.4517 - val_loss: 22.8569\n",
      "Epoch 16770/100000\n",
      "11/11 [==============================] - 0s 993us/step - loss: 6.4447 - val_loss: 22.8247\n",
      "Epoch 16771/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.4377 - val_loss: 22.8527\n",
      "Epoch 16772/100000\n",
      "11/11 [==============================] - 0s 822us/step - loss: 6.4306 - val_loss: 22.8094\n",
      "Epoch 16773/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.4237 - val_loss: 22.8505\n",
      "Epoch 16774/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.4167 - val_loss: 22.7925\n",
      "Epoch 16775/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.4097 - val_loss: 22.8495\n",
      "Epoch 16776/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.4028 - val_loss: 22.7754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16777/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.3959 - val_loss: 22.8469\n",
      "Epoch 16778/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.3890 - val_loss: 22.7628\n",
      "Epoch 16779/100000\n",
      "11/11 [==============================] - 0s 725us/step - loss: 6.3820 - val_loss: 22.8365\n",
      "Epoch 16780/100000\n",
      "11/11 [==============================] - 0s 357us/step - loss: 6.3750 - val_loss: 22.7606\n",
      "Epoch 16781/100000\n",
      "11/11 [==============================] - 0s 658us/step - loss: 6.3679 - val_loss: 22.8138\n",
      "Epoch 16782/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 6.3608 - val_loss: 22.7699\n",
      "Epoch 16783/100000\n",
      "11/11 [==============================] - 0s 470us/step - loss: 6.3537 - val_loss: 22.7832\n",
      "Epoch 16784/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 6.3467 - val_loss: 22.7827\n",
      "Epoch 16785/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 6.3397 - val_loss: 22.7554\n",
      "Epoch 16786/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 6.3329 - val_loss: 22.7880\n",
      "Epoch 16787/100000\n",
      "11/11 [==============================] - 0s 326us/step - loss: 6.3260 - val_loss: 22.7384\n",
      "Epoch 16788/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 6.3191 - val_loss: 22.7802\n",
      "Epoch 16789/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 6.3122 - val_loss: 22.7341\n",
      "Epoch 16790/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 6.3052 - val_loss: 22.7603\n",
      "Epoch 16791/100000\n",
      "11/11 [==============================] - 0s 497us/step - loss: 6.2983 - val_loss: 22.7390\n",
      "Epoch 16792/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 6.2913 - val_loss: 22.7362\n",
      "Epoch 16793/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 6.2844 - val_loss: 22.7439\n",
      "Epoch 16794/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 6.2776 - val_loss: 22.7168\n",
      "Epoch 16795/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 6.2707 - val_loss: 22.7415\n",
      "Epoch 16796/100000\n",
      "11/11 [==============================] - 0s 448us/step - loss: 6.2639 - val_loss: 22.7064\n",
      "Epoch 16797/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 6.2570 - val_loss: 22.7294\n",
      "Epoch 16798/100000\n",
      "11/11 [==============================] - 0s 574us/step - loss: 6.2502 - val_loss: 22.7043\n",
      "Epoch 16799/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 6.2433 - val_loss: 22.7111\n",
      "Epoch 16800/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 6.2364 - val_loss: 22.7052\n",
      "Epoch 16801/100000\n",
      "11/11 [==============================] - 0s 693us/step - loss: 6.2296 - val_loss: 22.6929\n",
      "Epoch 16802/100000\n",
      "11/11 [==============================] - 0s 616us/step - loss: 6.2227 - val_loss: 22.7036\n",
      "Epoch 16803/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 6.2160 - val_loss: 22.6797\n",
      "Epoch 16804/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 6.2092 - val_loss: 22.6960\n",
      "Epoch 16805/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 6.2023 - val_loss: 22.6729\n",
      "Epoch 16806/100000\n",
      "11/11 [==============================] - 0s 183us/step - loss: 6.1955 - val_loss: 22.6831\n",
      "Epoch 16807/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 6.1887 - val_loss: 22.6701\n",
      "Epoch 16808/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 6.1819 - val_loss: 22.6679\n",
      "Epoch 16809/100000\n",
      "11/11 [==============================] - 0s 462us/step - loss: 6.1751 - val_loss: 22.6675\n",
      "Epoch 16810/100000\n",
      "11/11 [==============================] - 0s 400us/step - loss: 6.1684 - val_loss: 22.6543\n",
      "Epoch 16811/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 6.1616 - val_loss: 22.6620\n",
      "Epoch 16812/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 6.1549 - val_loss: 22.6443\n",
      "Epoch 16813/100000\n",
      "11/11 [==============================] - 0s 349us/step - loss: 6.1481 - val_loss: 22.6528\n",
      "Epoch 16814/100000\n",
      "11/11 [==============================] - 0s 466us/step - loss: 6.1414 - val_loss: 22.6379\n",
      "Epoch 16815/100000\n",
      "11/11 [==============================] - 0s 254us/step - loss: 6.1346 - val_loss: 22.6410\n",
      "Epoch 16816/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 6.1279 - val_loss: 22.6333\n",
      "Epoch 16817/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 6.1212 - val_loss: 22.6287\n",
      "Epoch 16818/100000\n",
      "11/11 [==============================] - 0s 233us/step - loss: 6.1144 - val_loss: 22.6283\n",
      "Epoch 16819/100000\n",
      "11/11 [==============================] - 0s 444us/step - loss: 6.1077 - val_loss: 22.6176\n",
      "Epoch 16820/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 6.1010 - val_loss: 22.6214\n",
      "Epoch 16821/100000\n",
      "11/11 [==============================] - 0s 310us/step - loss: 6.0943 - val_loss: 22.6086\n",
      "Epoch 16822/100000\n",
      "11/11 [==============================] - 0s 302us/step - loss: 6.0876 - val_loss: 22.6125\n",
      "Epoch 16823/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 6.0809 - val_loss: 22.6014\n",
      "Epoch 16824/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 6.0742 - val_loss: 22.6021\n",
      "Epoch 16825/100000\n",
      "11/11 [==============================] - 0s 370us/step - loss: 6.0676 - val_loss: 22.5953\n",
      "Epoch 16826/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 6.0609 - val_loss: 22.5914\n",
      "Epoch 16827/100000\n",
      "11/11 [==============================] - 0s 636us/step - loss: 6.0542 - val_loss: 22.5892\n",
      "Epoch 16828/100000\n",
      "11/11 [==============================] - 0s 344us/step - loss: 6.0476 - val_loss: 22.5813\n",
      "Epoch 16829/100000\n",
      "11/11 [==============================] - 0s 350us/step - loss: 6.0409 - val_loss: 22.5821\n",
      "Epoch 16830/100000\n",
      "11/11 [==============================] - 0s 445us/step - loss: 6.0343 - val_loss: 22.5725\n",
      "Epoch 16831/100000\n",
      "11/11 [==============================] - 0s 206us/step - loss: 6.0277 - val_loss: 22.5736\n",
      "Epoch 16832/100000\n",
      "11/11 [==============================] - 0s 590us/step - loss: 6.0210 - val_loss: 22.5648\n",
      "Epoch 16833/100000\n",
      "11/11 [==============================] - 0s 383us/step - loss: 6.0144 - val_loss: 22.5643\n",
      "Epoch 16834/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 6.0078 - val_loss: 22.5578\n",
      "Epoch 16835/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 6.0012 - val_loss: 22.5546\n",
      "Epoch 16836/100000\n",
      "11/11 [==============================] - 0s 366us/step - loss: 5.9946 - val_loss: 22.5510\n",
      "Epoch 16837/100000\n",
      "11/11 [==============================] - 0s 453us/step - loss: 5.9880 - val_loss: 22.5452\n",
      "Epoch 16838/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 5.9814 - val_loss: 22.5438\n",
      "Epoch 16839/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 5.9748 - val_loss: 22.5364\n",
      "Epoch 16840/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 5.9683 - val_loss: 22.5360\n",
      "Epoch 16841/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.9617 - val_loss: 22.5282\n",
      "Epoch 16842/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 5.9551 - val_loss: 22.5275\n",
      "Epoch 16843/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 5.9486 - val_loss: 22.5205\n",
      "Epoch 16844/100000\n",
      "11/11 [==============================] - 0s 954us/step - loss: 5.9420 - val_loss: 22.5188\n",
      "Epoch 16845/100000\n",
      "11/11 [==============================] - 0s 931us/step - loss: 5.9355 - val_loss: 22.5132\n",
      "Epoch 16846/100000\n",
      "11/11 [==============================] - 0s 321us/step - loss: 5.9289 - val_loss: 22.5099\n",
      "Epoch 16847/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.9224 - val_loss: 22.5058\n",
      "Epoch 16848/100000\n",
      "11/11 [==============================] - 0s 476us/step - loss: 5.9159 - val_loss: 22.5012\n",
      "Epoch 16849/100000\n",
      "11/11 [==============================] - 0s 723us/step - loss: 5.9094 - val_loss: 22.4984\n",
      "Epoch 16850/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.9029 - val_loss: 22.4928\n",
      "Epoch 16851/100000\n",
      "11/11 [==============================] - 0s 488us/step - loss: 5.8964 - val_loss: 22.4907\n",
      "Epoch 16852/100000\n",
      "11/11 [==============================] - 0s 794us/step - loss: 5.8898 - val_loss: 22.4847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16853/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 5.8834 - val_loss: 22.4828\n",
      "Epoch 16854/100000\n",
      "11/11 [==============================] - 0s 824us/step - loss: 5.8769 - val_loss: 22.4768\n",
      "Epoch 16855/100000\n",
      "11/11 [==============================] - 0s 814us/step - loss: 5.8704 - val_loss: 22.4745\n",
      "Epoch 16856/100000\n",
      "11/11 [==============================] - 0s 753us/step - loss: 5.8639 - val_loss: 22.4692\n",
      "Epoch 16857/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 5.8575 - val_loss: 22.4663\n",
      "Epoch 16858/100000\n",
      "11/11 [==============================] - 0s 286us/step - loss: 5.8510 - val_loss: 22.4617\n",
      "Epoch 16859/100000\n",
      "11/11 [==============================] - 0s 416us/step - loss: 5.8446 - val_loss: 22.4581\n",
      "Epoch 16860/100000\n",
      "11/11 [==============================] - 0s 359us/step - loss: 5.8381 - val_loss: 22.4542\n",
      "Epoch 16861/100000\n",
      "11/11 [==============================] - 0s 501us/step - loss: 5.8317 - val_loss: 22.4499\n",
      "Epoch 16862/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 5.8252 - val_loss: 22.4467\n",
      "Epoch 16863/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 5.8188 - val_loss: 22.4419\n",
      "Epoch 16864/100000\n",
      "11/11 [==============================] - 0s 304us/step - loss: 5.8124 - val_loss: 22.4392\n",
      "Epoch 16865/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 5.8060 - val_loss: 22.4339\n",
      "Epoch 16866/100000\n",
      "11/11 [==============================] - 0s 291us/step - loss: 5.7996 - val_loss: 22.4314\n",
      "Epoch 16867/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 5.7932 - val_loss: 22.4261\n",
      "Epoch 16868/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 5.7868 - val_loss: 22.4237\n",
      "Epoch 16869/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 5.7804 - val_loss: 22.4184\n",
      "Epoch 16870/100000\n",
      "11/11 [==============================] - 0s 348us/step - loss: 5.7740 - val_loss: 22.4160\n",
      "Epoch 16871/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 5.7676 - val_loss: 22.4108\n",
      "Epoch 16872/100000\n",
      "11/11 [==============================] - 0s 237us/step - loss: 5.7612 - val_loss: 22.4083\n",
      "Epoch 16873/100000\n",
      "11/11 [==============================] - 0s 412us/step - loss: 5.7549 - val_loss: 22.4033\n",
      "Epoch 16874/100000\n",
      "11/11 [==============================] - 0s 298us/step - loss: 5.7485 - val_loss: 22.4005\n",
      "Epoch 16875/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 5.7422 - val_loss: 22.3957\n",
      "Epoch 16876/100000\n",
      "11/11 [==============================] - 0s 297us/step - loss: 5.7358 - val_loss: 22.3928\n",
      "Epoch 16877/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 5.7295 - val_loss: 22.3881\n",
      "Epoch 16878/100000\n",
      "11/11 [==============================] - 0s 398us/step - loss: 5.7232 - val_loss: 22.3852\n",
      "Epoch 16879/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 5.7169 - val_loss: 22.3806\n",
      "Epoch 16880/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 5.7105 - val_loss: 22.3777\n",
      "Epoch 16881/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 5.7042 - val_loss: 22.3730\n",
      "Epoch 16882/100000\n",
      "11/11 [==============================] - 0s 760us/step - loss: 5.6979 - val_loss: 22.3702\n",
      "Epoch 16883/100000\n",
      "11/11 [==============================] - 0s 421us/step - loss: 5.6916 - val_loss: 22.3656\n",
      "Epoch 16884/100000\n",
      "11/11 [==============================] - 0s 525us/step - loss: 5.6853 - val_loss: 22.3626\n",
      "Epoch 16885/100000\n",
      "11/11 [==============================] - 0s 598us/step - loss: 5.6791 - val_loss: 22.3582\n",
      "Epoch 16886/100000\n",
      "11/11 [==============================] - 0s 429us/step - loss: 5.6728 - val_loss: 22.3552\n",
      "Epoch 16887/100000\n",
      "11/11 [==============================] - 0s 656us/step - loss: 5.6665 - val_loss: 22.3507\n",
      "Epoch 16888/100000\n",
      "11/11 [==============================] - 0s 636us/step - loss: 5.6602 - val_loss: 22.3477\n",
      "Epoch 16889/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 5.6540 - val_loss: 22.3433\n",
      "Epoch 16890/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 5.6477 - val_loss: 22.3404\n",
      "Epoch 16891/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 5.6415 - val_loss: 22.3358\n",
      "Epoch 16892/100000\n",
      "11/11 [==============================] - 0s 634us/step - loss: 5.6352 - val_loss: 22.3331\n",
      "Epoch 16893/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 5.6290 - val_loss: 22.3283\n",
      "Epoch 16894/100000\n",
      "11/11 [==============================] - 0s 473us/step - loss: 5.6228 - val_loss: 22.3259\n",
      "Epoch 16895/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 5.6165 - val_loss: 22.3208\n",
      "Epoch 16896/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 5.6103 - val_loss: 22.3188\n",
      "Epoch 16897/100000\n",
      "11/11 [==============================] - 0s 965us/step - loss: 5.6041 - val_loss: 22.3133\n",
      "Epoch 16898/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.5979 - val_loss: 22.3118\n",
      "Epoch 16899/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.5917 - val_loss: 22.3058\n",
      "Epoch 16900/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.5855 - val_loss: 22.3049\n",
      "Epoch 16901/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 5.5793 - val_loss: 22.2981\n",
      "Epoch 16902/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 5.5732 - val_loss: 22.2984\n",
      "Epoch 16903/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 5.5670 - val_loss: 22.2900\n",
      "Epoch 16904/100000\n",
      "11/11 [==============================] - 0s 629us/step - loss: 5.5608 - val_loss: 22.2921\n",
      "Epoch 16905/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5.5547 - val_loss: 22.2817\n",
      "Epoch 16906/100000\n",
      "11/11 [==============================] - 0s 685us/step - loss: 5.5485 - val_loss: 22.2864\n",
      "Epoch 16907/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 5.5424 - val_loss: 22.2727\n",
      "Epoch 16908/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.5362 - val_loss: 22.2816\n",
      "Epoch 16909/100000\n",
      "11/11 [==============================] - 0s 920us/step - loss: 5.5301 - val_loss: 22.2627\n",
      "Epoch 16910/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 5.5240 - val_loss: 22.2782\n",
      "Epoch 16911/100000\n",
      "11/11 [==============================] - 0s 767us/step - loss: 5.5179 - val_loss: 22.2511\n",
      "Epoch 16912/100000\n",
      "11/11 [==============================] - 0s 766us/step - loss: 5.5118 - val_loss: 22.2767\n",
      "Epoch 16913/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.5057 - val_loss: 22.2373\n",
      "Epoch 16914/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.4996 - val_loss: 22.2780\n",
      "Epoch 16915/100000\n",
      "11/11 [==============================] - 0s 846us/step - loss: 5.4936 - val_loss: 22.2206\n",
      "Epoch 16916/100000\n",
      "11/11 [==============================] - 0s 632us/step - loss: 5.4876 - val_loss: 22.2820\n",
      "Epoch 16917/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.4816 - val_loss: 22.2021\n",
      "Epoch 16918/100000\n",
      "11/11 [==============================] - 0s 963us/step - loss: 5.4757 - val_loss: 22.2860\n",
      "Epoch 16919/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 5.4698 - val_loss: 22.1873\n",
      "Epoch 16920/100000\n",
      "11/11 [==============================] - 0s 681us/step - loss: 5.4638 - val_loss: 22.2805\n",
      "Epoch 16921/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.4577 - val_loss: 22.1874\n",
      "Epoch 16922/100000\n",
      "11/11 [==============================] - 0s 307us/step - loss: 5.4515 - val_loss: 22.2553\n",
      "Epoch 16923/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 5.4452 - val_loss: 22.2066\n",
      "Epoch 16924/100000\n",
      "11/11 [==============================] - 0s 843us/step - loss: 5.4389 - val_loss: 22.2174\n",
      "Epoch 16925/100000\n",
      "11/11 [==============================] - 0s 870us/step - loss: 5.4328 - val_loss: 22.2305\n",
      "Epoch 16926/100000\n",
      "11/11 [==============================] - 0s 940us/step - loss: 5.4269 - val_loss: 22.1865\n",
      "Epoch 16927/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 5.4210 - val_loss: 22.2391\n",
      "Epoch 16928/100000\n",
      "11/11 [==============================] - 0s 948us/step - loss: 5.4151 - val_loss: 22.1760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16929/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 5.4091 - val_loss: 22.2240\n",
      "Epoch 16930/100000\n",
      "11/11 [==============================] - 0s 625us/step - loss: 5.4030 - val_loss: 22.1857\n",
      "Epoch 16931/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 5.3969 - val_loss: 22.1941\n",
      "Epoch 16932/100000\n",
      "11/11 [==============================] - 0s 509us/step - loss: 5.3908 - val_loss: 22.2013\n",
      "Epoch 16933/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.3849 - val_loss: 22.1689\n",
      "Epoch 16934/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.3790 - val_loss: 22.2052\n",
      "Epoch 16935/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 5.3731 - val_loss: 22.1610\n",
      "Epoch 16936/100000\n",
      "11/11 [==============================] - 0s 418us/step - loss: 5.3671 - val_loss: 22.1911\n",
      "Epoch 16937/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 5.3611 - val_loss: 22.1681\n",
      "Epoch 16938/100000\n",
      "11/11 [==============================] - 0s 591us/step - loss: 5.3551 - val_loss: 22.1676\n",
      "Epoch 16939/100000\n",
      "11/11 [==============================] - 0s 362us/step - loss: 5.3492 - val_loss: 22.1770\n",
      "Epoch 16940/100000\n",
      "11/11 [==============================] - 0s 409us/step - loss: 5.3432 - val_loss: 22.1494\n",
      "Epoch 16941/100000\n",
      "11/11 [==============================] - 0s 419us/step - loss: 5.3374 - val_loss: 22.1752\n",
      "Epoch 16942/100000\n",
      "11/11 [==============================] - 0s 264us/step - loss: 5.3315 - val_loss: 22.1439\n",
      "Epoch 16943/100000\n",
      "11/11 [==============================] - 0s 610us/step - loss: 5.3255 - val_loss: 22.1610\n",
      "Epoch 16944/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 5.3196 - val_loss: 22.1480\n",
      "Epoch 16945/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 5.3136 - val_loss: 22.1425\n",
      "Epoch 16946/100000\n",
      "11/11 [==============================] - 0s 374us/step - loss: 5.3078 - val_loss: 22.1516\n",
      "Epoch 16947/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 5.3019 - val_loss: 22.1295\n",
      "Epoch 16948/100000\n",
      "11/11 [==============================] - 0s 423us/step - loss: 5.2960 - val_loss: 22.1471\n",
      "Epoch 16949/100000\n",
      "11/11 [==============================] - 0s 289us/step - loss: 5.2901 - val_loss: 22.1256\n",
      "Epoch 16950/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 5.2843 - val_loss: 22.1343\n",
      "Epoch 16951/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 5.2784 - val_loss: 22.1270\n",
      "Epoch 16952/100000\n",
      "11/11 [==============================] - 0s 284us/step - loss: 5.2725 - val_loss: 22.1196\n",
      "Epoch 16953/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 5.2667 - val_loss: 22.1269\n",
      "Epoch 16954/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 5.2608 - val_loss: 22.1093\n",
      "Epoch 16955/100000\n",
      "11/11 [==============================] - 0s 360us/step - loss: 5.2550 - val_loss: 22.1208\n",
      "Epoch 16956/100000\n",
      "11/11 [==============================] - 0s 785us/step - loss: 5.2492 - val_loss: 22.1053\n",
      "Epoch 16957/100000\n",
      "11/11 [==============================] - 0s 279us/step - loss: 5.2433 - val_loss: 22.1098\n",
      "Epoch 16958/100000\n",
      "11/11 [==============================] - 0s 794us/step - loss: 5.2375 - val_loss: 22.1047\n",
      "Epoch 16959/100000\n",
      "11/11 [==============================] - 0s 281us/step - loss: 5.2317 - val_loss: 22.0979\n",
      "Epoch 16960/100000\n",
      "11/11 [==============================] - 0s 541us/step - loss: 5.2259 - val_loss: 22.1026\n",
      "Epoch 16961/100000\n",
      "11/11 [==============================] - 0s 358us/step - loss: 5.2201 - val_loss: 22.0893\n",
      "Epoch 16962/100000\n",
      "11/11 [==============================] - 0s 905us/step - loss: 5.2143 - val_loss: 22.0964\n",
      "Epoch 16963/100000\n",
      "11/11 [==============================] - 0s 456us/step - loss: 5.2085 - val_loss: 22.0846\n",
      "Epoch 16964/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 5.2027 - val_loss: 22.0867\n",
      "Epoch 16965/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 5.1969 - val_loss: 22.0821\n",
      "Epoch 16966/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.1911 - val_loss: 22.0766\n",
      "Epoch 16967/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 5.1854 - val_loss: 22.0787\n",
      "Epoch 16968/100000\n",
      "11/11 [==============================] - 0s 245us/step - loss: 5.1796 - val_loss: 22.0687\n",
      "Epoch 16969/100000\n",
      "11/11 [==============================] - 0s 642us/step - loss: 5.1739 - val_loss: 22.0728\n",
      "Epoch 16970/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 5.1681 - val_loss: 22.0634\n",
      "Epoch 16971/100000\n",
      "11/11 [==============================] - 0s 713us/step - loss: 5.1624 - val_loss: 22.0646\n",
      "Epoch 16972/100000\n",
      "11/11 [==============================] - 0s 612us/step - loss: 5.1566 - val_loss: 22.0597\n",
      "Epoch 16973/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 5.1509 - val_loss: 22.0557\n",
      "Epoch 16974/100000\n",
      "11/11 [==============================] - 0s 558us/step - loss: 5.1452 - val_loss: 22.0557\n",
      "Epoch 16975/100000\n",
      "11/11 [==============================] - 0s 475us/step - loss: 5.1394 - val_loss: 22.0479\n",
      "Epoch 16976/100000\n",
      "11/11 [==============================] - 0s 651us/step - loss: 5.1337 - val_loss: 22.0501\n",
      "Epoch 16977/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 5.1280 - val_loss: 22.0420\n",
      "Epoch 16978/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 5.1223 - val_loss: 22.0427\n",
      "Epoch 16979/100000\n",
      "11/11 [==============================] - 0s 654us/step - loss: 5.1166 - val_loss: 22.0373\n",
      "Epoch 16980/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 5.1109 - val_loss: 22.0348\n",
      "Epoch 16981/100000\n",
      "11/11 [==============================] - 0s 617us/step - loss: 5.1053 - val_loss: 22.0329\n",
      "Epoch 16982/100000\n",
      "11/11 [==============================] - 0s 399us/step - loss: 5.0996 - val_loss: 22.0274\n",
      "Epoch 16983/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 5.0939 - val_loss: 22.0276\n",
      "Epoch 16984/100000\n",
      "11/11 [==============================] - 0s 389us/step - loss: 5.0882 - val_loss: 22.0211\n",
      "Epoch 16985/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 5.0826 - val_loss: 22.0211\n",
      "Epoch 16986/100000\n",
      "11/11 [==============================] - 0s 356us/step - loss: 5.0769 - val_loss: 22.0157\n",
      "Epoch 16987/100000\n",
      "11/11 [==============================] - 0s 259us/step - loss: 5.0713 - val_loss: 22.0140\n",
      "Epoch 16988/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 5.0656 - val_loss: 22.0107\n",
      "Epoch 16989/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 5.0600 - val_loss: 22.0069\n",
      "Epoch 16990/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 5.0544 - val_loss: 22.0055\n",
      "Epoch 16991/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 5.0487 - val_loss: 22.0004\n",
      "Epoch 16992/100000\n",
      "11/11 [==============================] - 0s 490us/step - loss: 5.0431 - val_loss: 21.9996\n",
      "Epoch 16993/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 5.0375 - val_loss: 21.9946\n",
      "Epoch 16994/100000\n",
      "11/11 [==============================] - 0s 260us/step - loss: 5.0319 - val_loss: 21.9931\n",
      "Epoch 16995/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 5.0263 - val_loss: 21.9893\n",
      "Epoch 16996/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 5.0207 - val_loss: 21.9864\n",
      "Epoch 16997/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 5.0151 - val_loss: 21.9841\n",
      "Epoch 16998/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 5.0095 - val_loss: 21.9799\n",
      "Epoch 16999/100000\n",
      "11/11 [==============================] - 0s 338us/step - loss: 5.0039 - val_loss: 21.9784\n",
      "Epoch 17000/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 4.9983 - val_loss: 21.9739\n",
      "Epoch 17001/100000\n",
      "11/11 [==============================] - 0s 394us/step - loss: 4.9928 - val_loss: 21.9725\n",
      "Epoch 17002/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 4.9872 - val_loss: 21.9682\n",
      "Epoch 17003/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 4.9817 - val_loss: 21.9662\n",
      "Epoch 17004/100000\n",
      "11/11 [==============================] - 0s 353us/step - loss: 4.9761 - val_loss: 21.9628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17005/100000\n",
      "11/11 [==============================] - 0s 270us/step - loss: 4.9706 - val_loss: 21.9600\n",
      "Epoch 17006/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 4.9650 - val_loss: 21.9573\n",
      "Epoch 17007/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 4.9595 - val_loss: 21.9539\n",
      "Epoch 17008/100000\n",
      "11/11 [==============================] - 0s 346us/step - loss: 4.9540 - val_loss: 21.9518\n",
      "Epoch 17009/100000\n",
      "11/11 [==============================] - 0s 267us/step - loss: 4.9484 - val_loss: 21.9480\n",
      "Epoch 17010/100000\n",
      "11/11 [==============================] - 0s 544us/step - loss: 4.9429 - val_loss: 21.9460\n",
      "Epoch 17011/100000\n",
      "11/11 [==============================] - 0s 510us/step - loss: 4.9374 - val_loss: 21.9424\n",
      "Epoch 17012/100000\n",
      "11/11 [==============================] - 0s 622us/step - loss: 4.9319 - val_loss: 21.9399\n",
      "Epoch 17013/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.9264 - val_loss: 21.9369\n",
      "Epoch 17014/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 4.9209 - val_loss: 21.9339\n",
      "Epoch 17015/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.9154 - val_loss: 21.9314\n",
      "Epoch 17016/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.9100 - val_loss: 21.9280\n",
      "Epoch 17017/100000\n",
      "11/11 [==============================] - 0s 821us/step - loss: 4.9045 - val_loss: 21.9259\n",
      "Epoch 17018/100000\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 4.8990 - val_loss: 21.9223\n",
      "Epoch 17019/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.8935 - val_loss: 21.9202\n",
      "Epoch 17020/100000\n",
      "11/11 [==============================] - 0s 530us/step - loss: 4.8881 - val_loss: 21.9167\n",
      "Epoch 17021/100000\n",
      "11/11 [==============================] - 0s 873us/step - loss: 4.8826 - val_loss: 21.9145\n",
      "Epoch 17022/100000\n",
      "11/11 [==============================] - 0s 577us/step - loss: 4.8772 - val_loss: 21.9111\n",
      "Epoch 17023/100000\n",
      "11/11 [==============================] - 0s 469us/step - loss: 4.8717 - val_loss: 21.9088\n",
      "Epoch 17024/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 4.8663 - val_loss: 21.9058\n",
      "Epoch 17025/100000\n",
      "11/11 [==============================] - 0s 571us/step - loss: 4.8609 - val_loss: 21.9029\n",
      "Epoch 17026/100000\n",
      "11/11 [==============================] - 0s 263us/step - loss: 4.8554 - val_loss: 21.9004\n",
      "Epoch 17027/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 4.8500 - val_loss: 21.8971\n",
      "Epoch 17028/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 4.8446 - val_loss: 21.8951\n",
      "Epoch 17029/100000\n",
      "11/11 [==============================] - 0s 190us/step - loss: 4.8392 - val_loss: 21.8914\n",
      "Epoch 17030/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 4.8338 - val_loss: 21.8896\n",
      "Epoch 17031/100000\n",
      "11/11 [==============================] - 0s 332us/step - loss: 4.8284 - val_loss: 21.8859\n",
      "Epoch 17032/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 4.8230 - val_loss: 21.8842\n",
      "Epoch 17033/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 4.8176 - val_loss: 21.8804\n",
      "Epoch 17034/100000\n",
      "11/11 [==============================] - 0s 247us/step - loss: 4.8123 - val_loss: 21.8786\n",
      "Epoch 17035/100000\n",
      "11/11 [==============================] - 0s 377us/step - loss: 4.8069 - val_loss: 21.8752\n",
      "Epoch 17036/100000\n",
      "11/11 [==============================] - 0s 282us/step - loss: 4.8015 - val_loss: 21.8729\n",
      "Epoch 17037/100000\n",
      "11/11 [==============================] - 0s 459us/step - loss: 4.7961 - val_loss: 21.8699\n",
      "Epoch 17038/100000\n",
      "11/11 [==============================] - 0s 327us/step - loss: 4.7908 - val_loss: 21.8672\n",
      "Epoch 17039/100000\n",
      "11/11 [==============================] - 0s 375us/step - loss: 4.7854 - val_loss: 21.8648\n",
      "Epoch 17040/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 4.7801 - val_loss: 21.8615\n",
      "Epoch 17041/100000\n",
      "11/11 [==============================] - 0s 240us/step - loss: 4.7748 - val_loss: 21.8596\n",
      "Epoch 17042/100000\n",
      "11/11 [==============================] - 0s 452us/step - loss: 4.7694 - val_loss: 21.8560\n",
      "Epoch 17043/100000\n",
      "11/11 [==============================] - 0s 352us/step - loss: 4.7641 - val_loss: 21.8543\n",
      "Epoch 17044/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 4.7587 - val_loss: 21.8507\n",
      "Epoch 17045/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 4.7534 - val_loss: 21.8490\n",
      "Epoch 17046/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 4.7481 - val_loss: 21.8453\n",
      "Epoch 17047/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 4.7428 - val_loss: 21.8438\n",
      "Epoch 17048/100000\n",
      "11/11 [==============================] - 0s 324us/step - loss: 4.7375 - val_loss: 21.8400\n",
      "Epoch 17049/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 4.7322 - val_loss: 21.8383\n",
      "Epoch 17050/100000\n",
      "11/11 [==============================] - 0s 504us/step - loss: 4.7269 - val_loss: 21.8348\n",
      "Epoch 17051/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 4.7216 - val_loss: 21.8329\n",
      "Epoch 17052/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 4.7164 - val_loss: 21.8297\n",
      "Epoch 17053/100000\n",
      "11/11 [==============================] - 0s 232us/step - loss: 4.7111 - val_loss: 21.8276\n",
      "Epoch 17054/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 4.7058 - val_loss: 21.8247\n",
      "Epoch 17055/100000\n",
      "11/11 [==============================] - 0s 403us/step - loss: 4.7006 - val_loss: 21.8222\n",
      "Epoch 17056/100000\n",
      "11/11 [==============================] - 0s 502us/step - loss: 4.6953 - val_loss: 21.8196\n",
      "Epoch 17057/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 4.6900 - val_loss: 21.8169\n",
      "Epoch 17058/100000\n",
      "11/11 [==============================] - 0s 716us/step - loss: 4.6848 - val_loss: 21.8146\n",
      "Epoch 17059/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 4.6796 - val_loss: 21.8116\n",
      "Epoch 17060/100000\n",
      "11/11 [==============================] - 0s 672us/step - loss: 4.6743 - val_loss: 21.8095\n",
      "Epoch 17061/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 4.6691 - val_loss: 21.8063\n",
      "Epoch 17062/100000\n",
      "11/11 [==============================] - 0s 696us/step - loss: 4.6639 - val_loss: 21.8045\n",
      "Epoch 17063/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 4.6587 - val_loss: 21.8011\n",
      "Epoch 17064/100000\n",
      "11/11 [==============================] - 0s 521us/step - loss: 4.6534 - val_loss: 21.7995\n",
      "Epoch 17065/100000\n",
      "11/11 [==============================] - 0s 329us/step - loss: 4.6482 - val_loss: 21.7960\n",
      "Epoch 17066/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 4.6430 - val_loss: 21.7945\n",
      "Epoch 17067/100000\n",
      "11/11 [==============================] - 0s 354us/step - loss: 4.6378 - val_loss: 21.7908\n",
      "Epoch 17068/100000\n",
      "11/11 [==============================] - 0s 274us/step - loss: 4.6326 - val_loss: 21.7896\n",
      "Epoch 17069/100000\n",
      "11/11 [==============================] - 0s 578us/step - loss: 4.6274 - val_loss: 21.7856\n",
      "Epoch 17070/100000\n",
      "11/11 [==============================] - 0s 319us/step - loss: 4.6223 - val_loss: 21.7847\n",
      "Epoch 17071/100000\n",
      "11/11 [==============================] - 0s 513us/step - loss: 4.6171 - val_loss: 21.7804\n",
      "Epoch 17072/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 4.6119 - val_loss: 21.7800\n",
      "Epoch 17073/100000\n",
      "11/11 [==============================] - 0s 428us/step - loss: 4.6068 - val_loss: 21.7750\n",
      "Epoch 17074/100000\n",
      "11/11 [==============================] - 0s 376us/step - loss: 4.6016 - val_loss: 21.7753\n",
      "Epoch 17075/100000\n",
      "11/11 [==============================] - 0s 266us/step - loss: 4.5964 - val_loss: 21.7696\n",
      "Epoch 17076/100000\n",
      "11/11 [==============================] - 0s 261us/step - loss: 4.5913 - val_loss: 21.7710\n",
      "Epoch 17077/100000\n",
      "11/11 [==============================] - 0s 397us/step - loss: 4.5862 - val_loss: 21.7639\n",
      "Epoch 17078/100000\n",
      "11/11 [==============================] - 0s 559us/step - loss: 4.5810 - val_loss: 21.7669\n",
      "Epoch 17079/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 4.5759 - val_loss: 21.7581\n",
      "Epoch 17080/100000\n",
      "11/11 [==============================] - 0s 545us/step - loss: 4.5708 - val_loss: 21.7631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17081/100000\n",
      "11/11 [==============================] - 0s 424us/step - loss: 4.5656 - val_loss: 21.7518\n",
      "Epoch 17082/100000\n",
      "11/11 [==============================] - 0s 303us/step - loss: 4.5605 - val_loss: 21.7600\n",
      "Epoch 17083/100000\n",
      "11/11 [==============================] - 0s 580us/step - loss: 4.5554 - val_loss: 21.7449\n",
      "Epoch 17084/100000\n",
      "11/11 [==============================] - 0s 384us/step - loss: 4.5503 - val_loss: 21.7574\n",
      "Epoch 17085/100000\n",
      "11/11 [==============================] - 0s 625us/step - loss: 4.5452 - val_loss: 21.7370\n",
      "Epoch 17086/100000\n",
      "11/11 [==============================] - 0s 382us/step - loss: 4.5401 - val_loss: 21.7562\n",
      "Epoch 17087/100000\n",
      "11/11 [==============================] - 0s 257us/step - loss: 4.5351 - val_loss: 21.7280\n",
      "Epoch 17088/100000\n",
      "11/11 [==============================] - 0s 280us/step - loss: 4.5300 - val_loss: 21.7564\n",
      "Epoch 17089/100000\n",
      "11/11 [==============================] - 0s 317us/step - loss: 4.5249 - val_loss: 21.7172\n",
      "Epoch 17090/100000\n",
      "11/11 [==============================] - 0s 313us/step - loss: 4.5199 - val_loss: 21.7588\n",
      "Epoch 17091/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 4.5149 - val_loss: 21.7043\n",
      "Epoch 17092/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 4.5099 - val_loss: 21.7630\n",
      "Epoch 17093/100000\n",
      "11/11 [==============================] - 0s 645us/step - loss: 4.5049 - val_loss: 21.6906\n",
      "Epoch 17094/100000\n",
      "11/11 [==============================] - 0s 320us/step - loss: 4.5000 - val_loss: 21.7663\n",
      "Epoch 17095/100000\n",
      "11/11 [==============================] - 0s 534us/step - loss: 4.4950 - val_loss: 21.6801\n",
      "Epoch 17096/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 4.4901 - val_loss: 21.7623\n",
      "Epoch 17097/100000\n",
      "11/11 [==============================] - 0s 554us/step - loss: 4.4850 - val_loss: 21.6807\n",
      "Epoch 17098/100000\n",
      "11/11 [==============================] - 0s 441us/step - loss: 4.4799 - val_loss: 21.7442\n",
      "Epoch 17099/100000\n",
      "11/11 [==============================] - 0s 255us/step - loss: 4.4747 - val_loss: 21.6952\n",
      "Epoch 17100/100000\n",
      "11/11 [==============================] - 0s 594us/step - loss: 4.4695 - val_loss: 21.7159\n",
      "Epoch 17101/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 4.4644 - val_loss: 21.7152\n",
      "Epoch 17102/100000\n",
      "11/11 [==============================] - 0s 629us/step - loss: 4.4594 - val_loss: 21.6899\n",
      "Epoch 17103/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 4.4545 - val_loss: 21.7274\n",
      "Epoch 17104/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 4.4495 - val_loss: 21.6762\n",
      "Epoch 17105/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 4.4446 - val_loss: 21.7236\n",
      "Epoch 17106/100000\n",
      "11/11 [==============================] - 0s 230us/step - loss: 4.4396 - val_loss: 21.6775\n",
      "Epoch 17107/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 4.4345 - val_loss: 21.7057\n",
      "Epoch 17108/100000\n",
      "11/11 [==============================] - 0s 533us/step - loss: 4.4295 - val_loss: 21.6888\n",
      "Epoch 17109/100000\n",
      "11/11 [==============================] - 0s 336us/step - loss: 4.4245 - val_loss: 21.6838\n",
      "Epoch 17110/100000\n",
      "11/11 [==============================] - 0s 532us/step - loss: 4.4196 - val_loss: 21.6993\n",
      "Epoch 17111/100000\n",
      "11/11 [==============================] - 0s 315us/step - loss: 4.4146 - val_loss: 21.6690\n",
      "Epoch 17112/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 4.4097 - val_loss: 21.7001\n",
      "Epoch 17113/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 4.4048 - val_loss: 21.6654\n",
      "Epoch 17114/100000\n",
      "11/11 [==============================] - 0s 431us/step - loss: 4.3998 - val_loss: 21.6894\n",
      "Epoch 17115/100000\n",
      "11/11 [==============================] - 0s 294us/step - loss: 4.3949 - val_loss: 21.6706\n",
      "Epoch 17116/100000\n",
      "11/11 [==============================] - 0s 434us/step - loss: 4.3899 - val_loss: 21.6729\n",
      "Epoch 17117/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 4.3850 - val_loss: 21.6772\n",
      "Epoch 17118/100000\n",
      "11/11 [==============================] - 0s 463us/step - loss: 4.3801 - val_loss: 21.6591\n",
      "Epoch 17119/100000\n",
      "11/11 [==============================] - 0s 371us/step - loss: 4.3752 - val_loss: 21.6782\n",
      "Epoch 17120/100000\n",
      "11/11 [==============================] - 0s 272us/step - loss: 4.3703 - val_loss: 21.6530\n",
      "Epoch 17121/100000\n",
      "11/11 [==============================] - 0s 301us/step - loss: 4.3654 - val_loss: 21.6715\n",
      "Epoch 17122/100000\n",
      "11/11 [==============================] - 0s 273us/step - loss: 4.3605 - val_loss: 21.6541\n",
      "Epoch 17123/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 4.3555 - val_loss: 21.6598\n",
      "Epoch 17124/100000\n",
      "11/11 [==============================] - 0s 334us/step - loss: 4.3507 - val_loss: 21.6576\n",
      "Epoch 17125/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 4.3458 - val_loss: 21.6483\n",
      "Epoch 17126/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 4.3409 - val_loss: 21.6585\n",
      "Epoch 17127/100000\n",
      "11/11 [==============================] - 0s 520us/step - loss: 4.3361 - val_loss: 21.6410\n",
      "Epoch 17128/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 4.3312 - val_loss: 21.6543\n",
      "Epoch 17129/100000\n",
      "11/11 [==============================] - 0s 295us/step - loss: 4.3263 - val_loss: 21.6387\n",
      "Epoch 17130/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 4.3215 - val_loss: 21.6458\n",
      "Epoch 17131/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 4.3166 - val_loss: 21.6394\n",
      "Epoch 17132/100000\n",
      "11/11 [==============================] - 0s 343us/step - loss: 4.3118 - val_loss: 21.6364\n",
      "Epoch 17133/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 4.3069 - val_loss: 21.6397\n",
      "Epoch 17134/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 4.3021 - val_loss: 21.6289\n",
      "Epoch 17135/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 4.2973 - val_loss: 21.6373\n",
      "Epoch 17136/100000\n",
      "11/11 [==============================] - 0s 567us/step - loss: 4.2924 - val_loss: 21.6246\n",
      "Epoch 17137/100000\n",
      "11/11 [==============================] - 0s 482us/step - loss: 4.2876 - val_loss: 21.6314\n",
      "Epoch 17138/100000\n",
      "11/11 [==============================] - 0s 536us/step - loss: 4.2828 - val_loss: 21.6229\n",
      "Epoch 17139/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 4.2780 - val_loss: 21.6239\n",
      "Epoch 17140/100000\n",
      "11/11 [==============================] - 0s 512us/step - loss: 4.2732 - val_loss: 21.6219\n",
      "Epoch 17141/100000\n",
      "11/11 [==============================] - 0s 413us/step - loss: 4.2684 - val_loss: 21.6167\n",
      "Epoch 17142/100000\n",
      "11/11 [==============================] - 0s 587us/step - loss: 4.2636 - val_loss: 21.6201\n",
      "Epoch 17143/100000\n",
      "11/11 [==============================] - 0s 393us/step - loss: 4.2588 - val_loss: 21.6111\n",
      "Epoch 17144/100000\n",
      "11/11 [==============================] - 0s 341us/step - loss: 4.2540 - val_loss: 21.6164\n",
      "Epoch 17145/100000\n",
      "11/11 [==============================] - 0s 670us/step - loss: 4.2492 - val_loss: 21.6075\n",
      "Epoch 17146/100000\n",
      "11/11 [==============================] - 0s 390us/step - loss: 4.2445 - val_loss: 21.6110\n",
      "Epoch 17147/100000\n",
      "11/11 [==============================] - 0s 656us/step - loss: 4.2397 - val_loss: 21.6052\n",
      "Epoch 17148/100000\n",
      "11/11 [==============================] - 0s 330us/step - loss: 4.2349 - val_loss: 21.6046\n",
      "Epoch 17149/100000\n",
      "11/11 [==============================] - 0s 702us/step - loss: 4.2302 - val_loss: 21.6031\n",
      "Epoch 17150/100000\n",
      "11/11 [==============================] - 0s 373us/step - loss: 4.2254 - val_loss: 21.5986\n",
      "Epoch 17151/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 4.2207 - val_loss: 21.6002\n",
      "Epoch 17152/100000\n",
      "11/11 [==============================] - 0s 367us/step - loss: 4.2159 - val_loss: 21.5938\n",
      "Epoch 17153/100000\n",
      "11/11 [==============================] - 0s 323us/step - loss: 4.2112 - val_loss: 21.5963\n",
      "Epoch 17154/100000\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 4.2065 - val_loss: 21.5901\n",
      "Epoch 17155/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 4.2017 - val_loss: 21.5914\n",
      "Epoch 17156/100000\n",
      "11/11 [==============================] - 0s 388us/step - loss: 4.1970 - val_loss: 21.5872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17157/100000\n",
      "11/11 [==============================] - 0s 583us/step - loss: 4.1923 - val_loss: 21.5862\n",
      "Epoch 17158/100000\n",
      "11/11 [==============================] - 0s 331us/step - loss: 4.1876 - val_loss: 21.5843\n",
      "Epoch 17159/100000\n",
      "11/11 [==============================] - 0s 296us/step - loss: 4.1829 - val_loss: 21.5811\n",
      "Epoch 17160/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 4.1782 - val_loss: 21.5811\n",
      "Epoch 17161/100000\n",
      "11/11 [==============================] - 0s 262us/step - loss: 4.1735 - val_loss: 21.5764\n",
      "Epoch 17162/100000\n",
      "11/11 [==============================] - 0s 494us/step - loss: 4.1688 - val_loss: 21.5774\n",
      "Epoch 17163/100000\n",
      "11/11 [==============================] - 0s 415us/step - loss: 4.1641 - val_loss: 21.5724\n",
      "Epoch 17164/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 4.1594 - val_loss: 21.5731\n",
      "Epoch 17165/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 4.1547 - val_loss: 21.5688\n",
      "Epoch 17166/100000\n",
      "11/11 [==============================] - 0s 269us/step - loss: 4.1501 - val_loss: 21.5686\n",
      "Epoch 17167/100000\n",
      "11/11 [==============================] - 0s 538us/step - loss: 4.1454 - val_loss: 21.5656\n",
      "Epoch 17168/100000\n",
      "11/11 [==============================] - 0s 385us/step - loss: 4.1407 - val_loss: 21.5640\n",
      "Epoch 17169/100000\n",
      "11/11 [==============================] - 0s 422us/step - loss: 4.1361 - val_loss: 21.5624\n",
      "Epoch 17170/100000\n",
      "11/11 [==============================] - 0s 404us/step - loss: 4.1314 - val_loss: 21.5595\n",
      "Epoch 17171/100000\n",
      "11/11 [==============================] - 0s 256us/step - loss: 4.1268 - val_loss: 21.5589\n",
      "Epoch 17172/100000\n",
      "11/11 [==============================] - 0s 514us/step - loss: 4.1221 - val_loss: 21.5552\n",
      "Epoch 17173/100000\n",
      "11/11 [==============================] - 0s 216us/step - loss: 4.1175 - val_loss: 21.5551\n",
      "Epoch 17174/100000\n",
      "11/11 [==============================] - 0s 531us/step - loss: 4.1128 - val_loss: 21.5514\n",
      "Epoch 17175/100000\n",
      "11/11 [==============================] - 0s 342us/step - loss: 4.1082 - val_loss: 21.5511\n",
      "Epoch 17176/100000\n",
      "11/11 [==============================] - 0s 557us/step - loss: 4.1036 - val_loss: 21.5478\n",
      "Epoch 17177/100000\n",
      "11/11 [==============================] - 0s 328us/step - loss: 4.0990 - val_loss: 21.5470\n",
      "Epoch 17178/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 4.0943 - val_loss: 21.5443\n",
      "Epoch 17179/100000\n",
      "11/11 [==============================] - 0s 386us/step - loss: 4.0897 - val_loss: 21.5429\n",
      "Epoch 17180/100000\n",
      "11/11 [==============================] - 0s 265us/step - loss: 4.0851 - val_loss: 21.5407\n",
      "Epoch 17181/100000\n",
      "11/11 [==============================] - 0s 337us/step - loss: 4.0805 - val_loss: 21.5389\n",
      "Epoch 17182/100000\n",
      "11/11 [==============================] - 0s 277us/step - loss: 4.0760 - val_loss: 21.5371\n",
      "Epoch 17183/100000\n",
      "11/11 [==============================] - 0s 436us/step - loss: 4.0713 - val_loss: 21.5349\n",
      "Epoch 17184/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 4.0668 - val_loss: 21.5334\n",
      "Epoch 17185/100000\n",
      "11/11 [==============================] - 0s 288us/step - loss: 4.0622 - val_loss: 21.5311\n",
      "Epoch 17186/100000\n",
      "11/11 [==============================] - 0s 300us/step - loss: 4.0576 - val_loss: 21.5298\n",
      "Epoch 17187/100000\n",
      "11/11 [==============================] - 0s 311us/step - loss: 4.0530 - val_loss: 21.5274\n",
      "Epoch 17188/100000\n",
      "11/11 [==============================] - 0s 271us/step - loss: 4.0485 - val_loss: 21.5260\n",
      "Epoch 17189/100000\n",
      "11/11 [==============================] - 0s 458us/step - loss: 4.0439 - val_loss: 21.5239\n",
      "Epoch 17190/100000\n",
      "11/11 [==============================] - 0s 426us/step - loss: 4.0394 - val_loss: 21.5222\n",
      "Epoch 17191/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 4.0348 - val_loss: 21.5202\n",
      "Epoch 17192/100000\n",
      "11/11 [==============================] - 0s 507us/step - loss: 4.0303 - val_loss: 21.5184\n",
      "Epoch 17193/100000\n",
      "11/11 [==============================] - 0s 543us/step - loss: 4.0257 - val_loss: 21.5167\n",
      "Epoch 17194/100000\n",
      "11/11 [==============================] - 0s 454us/step - loss: 4.0212 - val_loss: 21.5147\n",
      "Epoch 17195/100000\n",
      "11/11 [==============================] - 0s 491us/step - loss: 4.0167 - val_loss: 21.5131\n",
      "Epoch 17196/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 4.0121 - val_loss: 21.5110\n",
      "Epoch 17197/100000\n",
      "11/11 [==============================] - 0s 318us/step - loss: 4.0076 - val_loss: 21.5095\n",
      "Epoch 17198/100000\n",
      "11/11 [==============================] - 0s 314us/step - loss: 4.0031 - val_loss: 21.5073\n",
      "Epoch 17199/100000\n",
      "11/11 [==============================] - 0s 527us/step - loss: 3.9986 - val_loss: 21.5060\n",
      "Epoch 17200/100000\n",
      "11/11 [==============================] - 0s 430us/step - loss: 3.9941 - val_loss: 21.5038\n",
      "Epoch 17201/100000\n",
      "11/11 [==============================] - 0s 442us/step - loss: 3.9896 - val_loss: 21.5024\n",
      "Epoch 17202/100000\n",
      "11/11 [==============================] - 0s 432us/step - loss: 3.9851 - val_loss: 21.5001\n",
      "Epoch 17203/100000\n",
      "11/11 [==============================] - 0s 248us/step - loss: 3.9806 - val_loss: 21.4990\n",
      "Epoch 17204/100000\n",
      "11/11 [==============================] - 0s 392us/step - loss: 3.9761 - val_loss: 21.4964\n",
      "Epoch 17205/100000\n",
      "11/11 [==============================] - 0s 372us/step - loss: 3.9716 - val_loss: 21.4955\n",
      "Epoch 17206/100000\n",
      "11/11 [==============================] - 0s 500us/step - loss: 3.9671 - val_loss: 21.4930\n",
      "Epoch 17207/100000\n",
      "11/11 [==============================] - 0s 347us/step - loss: 3.9626 - val_loss: 21.4919\n",
      "Epoch 17208/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 3.9582 - val_loss: 21.4895\n",
      "Epoch 17209/100000\n",
      "11/11 [==============================] - 0s 290us/step - loss: 3.9537 - val_loss: 21.4884\n",
      "Epoch 17210/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 3.9492 - val_loss: 21.4861\n",
      "Epoch 17211/100000\n",
      "11/11 [==============================] - 0s 395us/step - loss: 3.9448 - val_loss: 21.4849\n",
      "Epoch 17212/100000\n",
      "11/11 [==============================] - 0s 517us/step - loss: 3.9403 - val_loss: 21.4827\n",
      "Epoch 17213/100000\n",
      "11/11 [==============================] - 0s 440us/step - loss: 3.9359 - val_loss: 21.4814\n",
      "Epoch 17214/100000\n",
      "11/11 [==============================] - 0s 518us/step - loss: 3.9314 - val_loss: 21.4793\n",
      "Epoch 17215/100000\n",
      "11/11 [==============================] - 0s 460us/step - loss: 3.9270 - val_loss: 21.4779\n",
      "Epoch 17216/100000\n",
      "11/11 [==============================] - 0s 548us/step - loss: 3.9226 - val_loss: 21.4758\n",
      "Epoch 17217/100000\n",
      "11/11 [==============================] - 0s 309us/step - loss: 3.9182 - val_loss: 21.4746\n",
      "Epoch 17218/100000\n",
      "11/11 [==============================] - 0s 474us/step - loss: 3.9137 - val_loss: 21.4724\n",
      "Epoch 17219/100000\n",
      "11/11 [==============================] - 0s 379us/step - loss: 3.9093 - val_loss: 21.4713\n",
      "Epoch 17220/100000\n",
      "11/11 [==============================] - 0s 484us/step - loss: 3.9049 - val_loss: 21.4690\n",
      "Epoch 17221/100000\n",
      "11/11 [==============================] - 0s 580us/step - loss: 3.9005 - val_loss: 21.4679\n",
      "Epoch 17222/100000\n",
      "11/11 [==============================] - 0s 695us/step - loss: 3.8961 - val_loss: 21.4656\n",
      "Epoch 17223/100000\n",
      "11/11 [==============================] - 0s 408us/step - loss: 3.8917 - val_loss: 21.4646\n",
      "Epoch 17224/100000\n",
      "11/11 [==============================] - 0s 563us/step - loss: 3.8873 - val_loss: 21.4621\n",
      "Epoch 17225/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 3.8829 - val_loss: 21.4615\n",
      "Epoch 17226/100000\n",
      "11/11 [==============================] - 0s 468us/step - loss: 3.8785 - val_loss: 21.4587\n",
      "Epoch 17227/100000\n",
      "11/11 [==============================] - 0s 446us/step - loss: 3.8741 - val_loss: 21.4583\n",
      "Epoch 17228/100000\n",
      "11/11 [==============================] - 0s 478us/step - loss: 3.8698 - val_loss: 21.4552\n",
      "Epoch 17229/100000\n",
      "11/11 [==============================] - 0s 461us/step - loss: 3.8654 - val_loss: 21.4554\n",
      "Epoch 17230/100000\n",
      "11/11 [==============================] - 0s 299us/step - loss: 3.8610 - val_loss: 21.4516\n",
      "Epoch 17231/100000\n",
      "11/11 [==============================] - 0s 345us/step - loss: 3.8566 - val_loss: 21.4525\n",
      "Epoch 17232/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 364us/step - loss: 3.8523 - val_loss: 21.4479\n",
      "Epoch 17233/100000\n",
      "11/11 [==============================] - 0s 549us/step - loss: 3.8479 - val_loss: 21.4498\n",
      "Epoch 17234/100000\n",
      "11/11 [==============================] - 0s 361us/step - loss: 3.8436 - val_loss: 21.4440\n",
      "Epoch 17235/100000\n",
      "11/11 [==============================] - 0s 335us/step - loss: 3.8392 - val_loss: 21.4474\n",
      "Epoch 17236/100000\n",
      "11/11 [==============================] - 0s 208us/step - loss: 3.8349 - val_loss: 21.4399\n",
      "Epoch 17237/100000\n",
      "11/11 [==============================] - 0s 547us/step - loss: 3.8306 - val_loss: 21.4453\n",
      "Epoch 17238/100000\n",
      "11/11 [==============================] - 0s 365us/step - loss: 3.8262 - val_loss: 21.4354\n",
      "Epoch 17239/100000\n",
      "11/11 [==============================] - 0s 529us/step - loss: 3.8219 - val_loss: 21.4438\n",
      "Epoch 17240/100000\n",
      "11/11 [==============================] - 0s 449us/step - loss: 3.8176 - val_loss: 21.4303\n",
      "Epoch 17241/100000\n",
      "11/11 [==============================] - 0s 222us/step - loss: 3.8133 - val_loss: 21.4431\n",
      "Epoch 17242/100000\n",
      "11/11 [==============================] - 0s 516us/step - loss: 3.8090 - val_loss: 21.4242\n",
      "Epoch 17243/100000\n",
      "11/11 [==============================] - 0s 215us/step - loss: 3.8047 - val_loss: 21.4436\n",
      "Epoch 17244/100000\n",
      "11/11 [==============================] - 0s 522us/step - loss: 3.8004 - val_loss: 21.4165\n",
      "Epoch 17245/100000\n",
      "11/11 [==============================] - 0s 451us/step - loss: 3.7961 - val_loss: 21.4460\n",
      "Epoch 17246/100000\n",
      "11/11 [==============================] - 0s 241us/step - loss: 3.7918 - val_loss: 21.4068\n",
      "Epoch 17247/100000\n",
      "11/11 [==============================] - 0s 457us/step - loss: 3.7876 - val_loss: 21.4507\n",
      "Epoch 17248/100000\n",
      "11/11 [==============================] - 0s 322us/step - loss: 3.7834 - val_loss: 21.3949\n",
      "Epoch 17249/100000\n",
      "11/11 [==============================] - 0s 437us/step - loss: 3.7792 - val_loss: 21.4575\n",
      "Epoch 17250/100000\n",
      "11/11 [==============================] - 0s 480us/step - loss: 3.7750 - val_loss: 21.3820\n",
      "Epoch 17251/100000\n",
      "11/11 [==============================] - 0s 406us/step - loss: 3.7709 - val_loss: 21.4632\n",
      "Epoch 17252/100000\n",
      "11/11 [==============================] - 0s 438us/step - loss: 3.7667 - val_loss: 21.3731\n",
      "Epoch 17253/100000\n",
      "11/11 [==============================] - 0s 224us/step - loss: 3.7625 - val_loss: 21.4600\n",
      "Epoch 17254/100000\n",
      "11/11 [==============================] - 0s 823us/step - loss: 3.7582 - val_loss: 21.3769\n",
      "Epoch 17255/100000\n",
      "11/11 [==============================] - 0s 396us/step - loss: 3.7538 - val_loss: 21.4410\n",
      "Epoch 17256/100000\n",
      "11/11 [==============================] - 0s 425us/step - loss: 3.7493 - val_loss: 21.3961\n",
      "Epoch 17257/100000\n",
      "11/11 [==============================] - 0s 447us/step - loss: 3.7449 - val_loss: 21.4117\n",
      "Epoch 17258/100000\n",
      "11/11 [==============================] - 0s 285us/step - loss: 3.7406 - val_loss: 21.4196\n",
      "Epoch 17259/100000\n",
      "11/11 [==============================] - 0s 711us/step - loss: 3.7364 - val_loss: 21.3870\n",
      "Epoch 17260/100000\n",
      "11/11 [==============================] - 0s 506us/step - loss: 3.7323 - val_loss: 21.4324\n",
      "Epoch 17261/100000\n",
      "11/11 [==============================] - 0s 651us/step - loss: 3.7282 - val_loss: 21.3774\n",
      "Epoch 17262/100000\n",
      "11/11 [==============================] - 0s 481us/step - loss: 3.7240 - val_loss: 21.4264\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "callbacks = model.fit(x, y_smeared, validation_data=(x, y_smeared_val), epochs=100000, \n",
    "          callbacks=[EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(x)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x, y_pred)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x12bd76940>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b0ce7c126931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcallbacks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "callbacks[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
